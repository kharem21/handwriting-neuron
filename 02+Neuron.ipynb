{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNparams([0.196898, 0.375592, 0.0537909])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type NNparams\n",
    "    a::Array{Float64}\n",
    "end \n",
    "toyparams = NNparams([rand(),rand(),rand()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6224593312018546"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function σ(z::Float64)\n",
    "    return 1.0 / (1.0 + exp(-z))\n",
    "end\n",
    "σ(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: ∇ not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: ∇ not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "function updateNNparams(gradient::Array{Float64,1}, \n",
    "                        params::NNparams, learning_rate::Float64)\n",
    "   params.a = params.a - gradient*learning_rate\n",
    "    return params\n",
    "end\n",
    "#test\n",
    "toyparams = NNparams([rand(),rand(),rand()])\n",
    "grad = ∇(x,y,toyparams)\n",
    "updateNNparams(grad,toyparams,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printNNparam (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function printNNparam(param::NNparams)\n",
    "    @printf(\"PrintNN ==> %f %f %f\\n\", param.a[1], param.a[2], param.a[3])\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function output(params::NNparams, x::Array{Float64,1})\n",
    "    #nb_data = size(x[1,:])\n",
    "    #for i = 1:nb_data\n",
    "    #x = x[i, :]\n",
    "    return σ(dot(params.a,x))\n",
    "    #end\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(params::NNparams, yi::Array{Float64,1}, \n",
    "                x::Array{Float64,2})\n",
    "    nb_data = size(x)[1]\n",
    "     y_pred = zeros(length(yi))\n",
    "    @assert(size(x)[1]== length(yi))\n",
    "   for i = 1:nb_data\n",
    "        y_pred[i]= output(params,x[i,:])\n",
    "    end\n",
    "    return sum(yi.*log.(1e-7+y_pred) .+ (1-yi).*log.(1e-7+1-y_pred))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇ (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradient \n",
    "function ∇(x::Array{Float64,2},y::Array{Float64,1}, params::NNparams)\n",
    "    grad = [0.0 for i=1:size(x)[2]]\n",
    "    nb_data = size(x)[1]\n",
    "    for i = 1:nb_data\n",
    "        xi = x[i, :]\n",
    "        yi = y[i]\n",
    "        y_pred = output(params, xi)\n",
    "        grad = grad .+ xi.*(yi - y_pred)\n",
    "    end\n",
    "    grad = grad/ nb_data\n",
    "    return grad::Array{Float64,1}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convertdata_to_array (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function convertdata_to_array(dtf::DataFrame)\n",
    "    nb_data = size(dtf)[1]\n",
    "        x = zeros(Float64, nb_data, 3)\n",
    "        \n",
    "        x[:,1] = dtf[:x1]\n",
    "        x[:,2] = dtf[:x2]\n",
    "        x[:,3] = ones(Float64,size(x)[1])\n",
    "        \n",
    "        y = convert(Array, dtf[:y]) * 1.0\n",
    "        #x = convert(Array, df[:x1], df[:x2], ones(Float64, size(x)[1]))\n",
    "        return x,y\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.35569  \n",
       " 0.328564 \n",
       " 0.0562307\n",
       " 0.473233 "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_params(x::Array{Float64,2})\n",
    "    return [rand() for i = 1:size(x[1, :])[1]]\n",
    "    end \n",
    "test = init_params(rand(4,4))\n",
    "x= rand(5,5)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "select_trainingdata (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function select_trainingdata(x::Array{Float64,2}, y::Array{Float64,1}, batch_size::Int)\n",
    "    nb_data = length(y)\n",
    "    \n",
    "    ids = [i for i = 1:nb_data]\n",
    "    sampled_ids = sample(ids, batch_size)\n",
    "    \n",
    "    x_training = x[sampled_ids, :]\n",
    "    y_training = y[sampled_ids]\n",
    "    \n",
    "    return x_training, y_training\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: dtf not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: dtf not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "x,y = convertdata_to_array(dtf)\n",
    "testparams = init_params(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_learning_rate (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_learning_rate(init_learning_rate::Float64, nb_steps::Int)\n",
    "    return init_learning_rate* ((1.0)/ (1.0 + (.05*nb_steps)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 / 1000, loss = -1471.550288\n",
      "a_1 = 0.513667, a_2 = 0.160741, b = 0.081894\n",
      "\tgrad = 2.116161\n",
      "rate = 0.066667\n",
      "Step 2 / 1000, loss = -1850.575001\n",
      "a_1 = 0.640925, a_2 = 0.240230, b = 0.109283\n",
      "\tgrad = 2.396796\n",
      "rate = 0.063636\n",
      "Step 3 / 1000, loss = -2274.345499\n",
      "a_1 = 0.777038, a_2 = 0.327361, b = 0.138351\n",
      "\tgrad = 2.697660\n",
      "rate = 0.060870\n",
      "Step 4 / 1000, loss = -2692.776056\n",
      "a_1 = 0.905515, a_2 = 0.417119, b = 0.166482\n",
      "\tgrad = 2.729657\n",
      "rate = 0.058333\n",
      "Step 5 / 1000, loss = -3078.257618\n",
      "a_1 = 1.024091, a_2 = 0.497297, b = 0.193068\n",
      "\tgrad = 2.599766\n",
      "rate = 0.056000\n",
      "Step 6 / 1000, loss = -3447.754543\n",
      "a_1 = 1.135959, a_2 = 0.576671, b = 0.218486\n",
      "\tgrad = 2.590755\n",
      "rate = 0.053846\n",
      "Step 7 / 1000, loss = -3791.119279\n",
      "a_1 = 1.240077, a_2 = 0.652213, b = 0.242791\n",
      "\tgrad = 2.524723\n",
      "rate = 0.051852\n",
      "Step 8 / 1000, loss = -4140.178319\n",
      "a_1 = 1.347360, a_2 = 0.732731, b = 0.267514\n",
      "\tgrad = 2.727926\n",
      "rate = 0.050000\n",
      "Step 9 / 1000, loss = -4462.599519\n",
      "a_1 = 1.452677, a_2 = 0.807598, b = 0.291872\n",
      "\tgrad = 2.723763\n",
      "rate = 0.048276\n",
      "Step 10 / 1000, loss = -4751.972467\n",
      "a_1 = 1.555453, a_2 = 0.876095, b = 0.315275\n",
      "\tgrad = 2.693733\n",
      "rate = 0.046667\n",
      "Step 11 / 1000, loss = -5033.424872\n",
      "a_1 = 1.661638, a_2 = 0.951337, b = 0.339839\n",
      "\tgrad = 2.932573\n",
      "rate = 0.045161\n",
      "Step 12 / 1000, loss = -5257.094875\n",
      "a_1 = 1.754307, a_2 = 1.016257, b = 0.361684\n",
      "\tgrad = 2.633962\n",
      "rate = 0.043750\n",
      "Step 13 / 1000, loss = -5469.385960\n",
      "a_1 = 1.852427, a_2 = 1.082485, b = 0.382953\n",
      "\tgrad = 2.835053\n",
      "rate = 0.042424\n",
      "Step 14 / 1000, loss = -5654.263951\n",
      "a_1 = 1.944225, a_2 = 1.148229, b = 0.404322\n",
      "\tgrad = 2.790834\n",
      "rate = 0.041176\n",
      "Step 15 / 1000, loss = -5826.419929\n",
      "a_1 = 2.038509, a_2 = 1.215483, b = 0.426054\n",
      "\tgrad = 2.945859\n",
      "rate = 0.040000\n",
      "Step 16 / 1000, loss = -5969.709353\n",
      "a_1 = 2.128253, a_2 = 1.273200, b = 0.445998\n",
      "\tgrad = 2.791265\n",
      "rate = 0.038889\n",
      "Step 17 / 1000, loss = -6096.677145\n",
      "a_1 = 2.209086, a_2 = 1.335151, b = 0.465188\n",
      "\tgrad = 2.738910\n",
      "rate = 0.037838\n",
      "Step 18 / 1000, loss = -6207.682477\n",
      "a_1 = 2.287244, a_2 = 1.392085, b = 0.483766\n",
      "\tgrad = 2.672622\n",
      "rate = 0.036842\n",
      "Step 19 / 1000, loss = -6306.301741\n",
      "a_1 = 2.361917, a_2 = 1.446700, b = 0.501229\n",
      "\tgrad = 2.622679\n",
      "rate = 0.035897\n",
      "Step 20 / 1000, loss = -6392.401644\n",
      "a_1 = 2.430795, a_2 = 1.498482, b = 0.517260\n",
      "\tgrad = 2.504285\n",
      "rate = 0.035000\n",
      "Step 21 / 1000, loss = -6475.774196\n",
      "a_1 = 2.503175, a_2 = 1.550280, b = 0.534430\n",
      "\tgrad = 2.654650\n",
      "rate = 0.034146\n",
      "Step 22 / 1000, loss = -6548.756377\n",
      "a_1 = 2.573722, a_2 = 1.595463, b = 0.550302\n",
      "\tgrad = 2.557964\n",
      "rate = 0.033333\n",
      "Step 23 / 1000, loss = -6620.806279\n",
      "a_1 = 2.645483, a_2 = 1.644883, b = 0.566343\n",
      "\tgrad = 2.721169\n",
      "rate = 0.032558\n",
      "Step 24 / 1000, loss = -6685.420603\n",
      "a_1 = 2.713452, a_2 = 1.691998, b = 0.581848\n",
      "\tgrad = 2.644499\n",
      "rate = 0.031818\n",
      "Step 25 / 1000, loss = -6746.276227\n",
      "a_1 = 2.780020, a_2 = 1.740159, b = 0.597046\n",
      "\tgrad = 2.685784\n",
      "rate = 0.031111\n",
      "Step 26 / 1000, loss = -6803.429353\n",
      "a_1 = 2.846580, a_2 = 1.787642, b = 0.612574\n",
      "\tgrad = 2.734436\n",
      "rate = 0.030435\n",
      "Step 27 / 1000, loss = -6854.375232\n",
      "a_1 = 2.909145, a_2 = 1.832658, b = 0.627209\n",
      "\tgrad = 2.633813\n",
      "rate = 0.029787\n",
      "Step 28 / 1000, loss = -6903.627790\n",
      "a_1 = 2.977394, a_2 = 1.875264, b = 0.642126\n",
      "\tgrad = 2.805493\n",
      "rate = 0.029167\n",
      "Step 29 / 1000, loss = -6950.605745\n",
      "a_1 = 3.044404, a_2 = 1.920093, b = 0.657167\n",
      "\tgrad = 2.870467\n",
      "rate = 0.028571\n",
      "Step 30 / 1000, loss = -6992.251795\n",
      "a_1 = 3.104426, a_2 = 1.964701, b = 0.670931\n",
      "\tgrad = 2.715712\n",
      "rate = 0.028000\n",
      "Step 31 / 1000, loss = -7028.880215\n",
      "a_1 = 3.163437, a_2 = 2.003316, b = 0.684121\n",
      "\tgrad = 2.613570\n",
      "rate = 0.027451\n",
      "Step 32 / 1000, loss = -7064.159390\n",
      "a_1 = 3.219190, a_2 = 2.045780, b = 0.697460\n",
      "\tgrad = 2.649811\n",
      "rate = 0.026923\n",
      "Step 33 / 1000, loss = -7098.451836\n",
      "a_1 = 3.279614, a_2 = 2.086812, b = 0.710939\n",
      "\tgrad = 2.811717\n",
      "rate = 0.026415\n",
      "Step 34 / 1000, loss = -7129.083540\n",
      "a_1 = 3.333551, a_2 = 2.127738, b = 0.723298\n",
      "\tgrad = 2.654688\n",
      "rate = 0.025926\n",
      "Step 35 / 1000, loss = -7156.134392\n",
      "a_1 = 3.386567, a_2 = 2.162912, b = 0.735527\n",
      "\tgrad = 2.545245\n",
      "rate = 0.025455\n",
      "Step 36 / 1000, loss = -7183.250990\n",
      "a_1 = 3.437967, a_2 = 2.203095, b = 0.748085\n",
      "\tgrad = 2.657583\n",
      "rate = 0.025000\n",
      "Step 37 / 1000, loss = -7208.882946\n",
      "a_1 = 3.491574, a_2 = 2.240727, b = 0.760592\n",
      "\tgrad = 2.714873\n",
      "rate = 0.024561\n",
      "Step 38 / 1000, loss = -7233.280786\n",
      "a_1 = 3.542772, a_2 = 2.279849, b = 0.772799\n",
      "\tgrad = 2.716896\n",
      "rate = 0.024138\n",
      "Step 39 / 1000, loss = -7256.301641\n",
      "a_1 = 3.595883, a_2 = 2.316604, b = 0.784467\n",
      "\tgrad = 2.766026\n",
      "rate = 0.023729\n",
      "Step 40 / 1000, loss = -7277.877142\n",
      "a_1 = 3.647410, a_2 = 2.352588, b = 0.796336\n",
      "\tgrad = 2.741080\n",
      "rate = 0.023333\n",
      "Step 41 / 1000, loss = -7296.455837\n",
      "a_1 = 3.691898, a_2 = 2.385884, b = 0.807184\n",
      "\tgrad = 2.466894\n",
      "rate = 0.022951\n",
      "Step 42 / 1000, loss = -7317.320746\n",
      "a_1 = 3.747212, a_2 = 2.422656, b = 0.819300\n",
      "\tgrad = 2.990072\n",
      "rate = 0.022581\n",
      "Step 43 / 1000, loss = -7334.880938\n",
      "a_1 = 3.794122, a_2 = 2.455908, b = 0.830053\n",
      "\tgrad = 2.632340\n",
      "rate = 0.022222\n",
      "Step 44 / 1000, loss = -7351.719168\n",
      "a_1 = 3.841727, a_2 = 2.488377, b = 0.840657\n",
      "\tgrad = 2.678448\n",
      "rate = 0.021875\n",
      "Step 45 / 1000, loss = -7368.835691\n",
      "a_1 = 3.892524, a_2 = 2.522286, b = 0.851809\n",
      "\tgrad = 2.882522\n",
      "rate = 0.021538\n",
      "Step 46 / 1000, loss = -7384.757603\n",
      "a_1 = 3.940008, a_2 = 2.556046, b = 0.862898\n",
      "\tgrad = 2.795955\n",
      "rate = 0.021212\n",
      "Step 47 / 1000, loss = -7399.733182\n",
      "a_1 = 3.987216, a_2 = 2.588506, b = 0.873422\n",
      "\tgrad = 2.787620\n",
      "rate = 0.020896\n",
      "Step 48 / 1000, loss = -7413.498632\n",
      "a_1 = 4.031328, a_2 = 2.619977, b = 0.883522\n",
      "\tgrad = 2.677292\n",
      "rate = 0.020588\n",
      "Step 49 / 1000, loss = -7426.706780\n",
      "a_1 = 4.075951, a_2 = 2.650380, b = 0.893944\n",
      "\tgrad = 2.710369\n",
      "rate = 0.020290\n",
      "Step 50 / 1000, loss = -7439.529542\n",
      "a_1 = 4.120100, a_2 = 2.681566, b = 0.904058\n",
      "\tgrad = 2.749534\n",
      "rate = 0.020000\n",
      "Step 51 / 1000, loss = -7451.101446\n",
      "a_1 = 4.160695, a_2 = 2.710903, b = 0.913716\n",
      "\tgrad = 2.586879\n",
      "rate = 0.019718\n",
      "Step 52 / 1000, loss = -7463.146107\n",
      "a_1 = 4.204202, a_2 = 2.742657, b = 0.923825\n",
      "\tgrad = 2.818424\n",
      "rate = 0.019444\n",
      "Step 53 / 1000, loss = -7473.967040\n",
      "a_1 = 4.246177, a_2 = 2.770870, b = 0.933160\n",
      "\tgrad = 2.681711\n",
      "rate = 0.019178\n",
      "Step 54 / 1000, loss = -7484.083013\n",
      "a_1 = 4.287299, a_2 = 2.797313, b = 0.942409\n",
      "\tgrad = 2.630023\n",
      "rate = 0.018919\n",
      "Step 55 / 1000, loss = -7494.042796\n",
      "a_1 = 4.326932, a_2 = 2.825639, b = 0.951752\n",
      "\tgrad = 2.657271\n",
      "rate = 0.018667\n",
      "Step 56 / 1000, loss = -7503.655167\n",
      "a_1 = 4.367016, a_2 = 2.853226, b = 0.960959\n",
      "\tgrad = 2.688393\n",
      "rate = 0.018421\n",
      "Step 57 / 1000, loss = -7512.575986\n",
      "a_1 = 4.405479, a_2 = 2.879586, b = 0.969331\n",
      "\tgrad = 2.605628\n",
      "rate = 0.018182\n",
      "Step 58 / 1000, loss = -7521.628888\n",
      "a_1 = 4.443842, a_2 = 2.908330, b = 0.978161\n",
      "\tgrad = 2.715658\n",
      "rate = 0.017949\n",
      "Step 59 / 1000, loss = -7530.061498\n",
      "a_1 = 4.481105, a_2 = 2.935077, b = 0.987089\n",
      "\tgrad = 2.636914\n",
      "rate = 0.017722\n",
      "Step 60 / 1000, loss = -7538.356170\n",
      "a_1 = 4.518753, a_2 = 2.962266, b = 0.995731\n",
      "\tgrad = 2.699218\n",
      "rate = 0.017500\n",
      "Step 61 / 1000, loss = -7546.706999\n",
      "a_1 = 4.557387, a_2 = 2.990628, b = 1.004560\n",
      "\tgrad = 2.819592\n",
      "rate = 0.017284\n",
      "Step 62 / 1000, loss = -7554.139708\n",
      "a_1 = 4.592909, a_2 = 3.016229, b = 1.012733\n",
      "\tgrad = 2.608910\n",
      "rate = 0.017073\n",
      "Step 63 / 1000, loss = -7561.128031\n",
      "a_1 = 4.627669, a_2 = 3.040368, b = 1.020658\n",
      "\tgrad = 2.552567\n",
      "rate = 0.016867\n",
      "Step 64 / 1000, loss = -7567.824349\n",
      "a_1 = 4.662084, a_2 = 3.063659, b = 1.028540\n",
      "\tgrad = 2.537766\n",
      "rate = 0.016667\n",
      "Step 65 / 1000, loss = -7574.665384\n",
      "a_1 = 4.696367, a_2 = 3.089355, b = 1.036707\n",
      "\tgrad = 2.648090\n",
      "rate = 0.016471\n",
      "Step 66 / 1000, loss = -7580.699968\n",
      "a_1 = 4.729056, a_2 = 3.111095, b = 1.044077\n",
      "\tgrad = 2.453663\n",
      "rate = 0.016279\n",
      "Step 67 / 1000, loss = -7586.958534\n",
      "a_1 = 4.763767, a_2 = 3.133965, b = 1.051993\n",
      "\tgrad = 2.629599\n",
      "rate = 0.016092\n",
      "Step 68 / 1000, loss = -7593.041995\n",
      "a_1 = 4.796463, a_2 = 3.158091, b = 1.059831\n",
      "\tgrad = 2.601172\n",
      "rate = 0.015909\n",
      "Step 69 / 1000, loss = -7598.904966\n",
      "a_1 = 4.830279, a_2 = 3.180626, b = 1.067395\n",
      "\tgrad = 2.627764\n",
      "rate = 0.015730\n",
      "Step 70 / 1000, loss = -7604.630271\n",
      "a_1 = 4.864330, a_2 = 3.202725, b = 1.075062\n",
      "\tgrad = 2.655697\n",
      "rate = 0.015556\n",
      "Step 71 / 1000, loss = -7610.180743\n",
      "a_1 = 4.896482, a_2 = 3.225840, b = 1.082597\n",
      "\tgrad = 2.620122\n",
      "rate = 0.015385\n",
      "Step 72 / 1000, loss = -7615.797644\n",
      "a_1 = 4.930672, a_2 = 3.249088, b = 1.090144\n",
      "\tgrad = 2.761836\n",
      "rate = 0.015217\n",
      "Step 73 / 1000, loss = -7620.897550\n",
      "a_1 = 4.960928, a_2 = 3.271553, b = 1.097398\n",
      "\tgrad = 2.549273\n",
      "rate = 0.015054\n",
      "Step 74 / 1000, loss = -7625.888648\n",
      "a_1 = 4.992052, a_2 = 3.293139, b = 1.104710\n",
      "\tgrad = 2.590098\n",
      "rate = 0.014894\n",
      "Step 75 / 1000, loss = -7630.844076\n",
      "a_1 = 5.024075, a_2 = 3.314576, b = 1.112062\n",
      "\tgrad = 2.662125\n",
      "rate = 0.014737\n",
      "Step 76 / 1000, loss = -7635.647308\n",
      "a_1 = 5.055239, a_2 = 3.336290, b = 1.119074\n",
      "\tgrad = 2.648540\n",
      "rate = 0.014583\n",
      "Step 77 / 1000, loss = -7640.737374\n",
      "a_1 = 5.089751, a_2 = 3.359136, b = 1.126550\n",
      "\tgrad = 2.914026\n",
      "rate = 0.014433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 78 / 1000, loss = -7645.317528\n",
      "a_1 = 5.121581, a_2 = 3.379740, b = 1.133678\n",
      "\tgrad = 2.700713\n",
      "rate = 0.014286\n",
      "Step 79 / 1000, loss = -7649.685966\n",
      "a_1 = 5.150460, a_2 = 3.401478, b = 1.140450\n",
      "\tgrad = 2.600462\n",
      "rate = 0.014141\n",
      "Step 80 / 1000, loss = -7653.827918\n",
      "a_1 = 5.179225, a_2 = 3.421605, b = 1.147124\n",
      "\tgrad = 2.552591\n",
      "rate = 0.014000\n",
      "Step 81 / 1000, loss = -7658.105892\n",
      "a_1 = 5.209465, a_2 = 3.442891, b = 1.153927\n",
      "\tgrad = 2.712654\n",
      "rate = 0.013861\n",
      "Step 82 / 1000, loss = -7662.085396\n",
      "a_1 = 5.238274, a_2 = 3.462821, b = 1.160433\n",
      "\tgrad = 2.595855\n",
      "rate = 0.013725\n",
      "Step 83 / 1000, loss = -7666.292725\n",
      "a_1 = 5.268417, a_2 = 3.485041, b = 1.167282\n",
      "\tgrad = 2.800783\n",
      "rate = 0.013592\n",
      "Step 84 / 1000, loss = -7670.110844\n",
      "a_1 = 5.297208, a_2 = 3.504680, b = 1.173714\n",
      "\tgrad = 2.632703\n",
      "rate = 0.013462\n",
      "Step 85 / 1000, loss = -7674.077044\n",
      "a_1 = 5.328017, a_2 = 3.525061, b = 1.180553\n",
      "\tgrad = 2.817606\n",
      "rate = 0.013333\n",
      "Step 86 / 1000, loss = -7677.885349\n",
      "a_1 = 5.357330, a_2 = 3.545670, b = 1.187117\n",
      "\tgrad = 2.758168\n",
      "rate = 0.013208\n",
      "Step 87 / 1000, loss = -7681.552635\n",
      "a_1 = 5.386152, a_2 = 3.565583, b = 1.193737\n",
      "\tgrad = 2.724821\n",
      "rate = 0.013084\n",
      "Step 88 / 1000, loss = -7685.196865\n",
      "a_1 = 5.415267, a_2 = 3.585710, b = 1.200387\n",
      "\tgrad = 2.778207\n",
      "rate = 0.012963\n",
      "Step 89 / 1000, loss = -7688.814603\n",
      "a_1 = 5.444601, a_2 = 3.606142, b = 1.206975\n",
      "\tgrad = 2.830153\n",
      "rate = 0.012844\n",
      "Step 90 / 1000, loss = -7692.061112\n",
      "a_1 = 5.471820, a_2 = 3.624325, b = 1.213032\n",
      "\tgrad = 2.615554\n",
      "rate = 0.012727\n",
      "Step 91 / 1000, loss = -7695.313493\n",
      "a_1 = 5.499355, a_2 = 3.642926, b = 1.219185\n",
      "\tgrad = 2.679405\n",
      "rate = 0.012613\n",
      "Step 92 / 1000, loss = -7698.333743\n",
      "a_1 = 5.524833, a_2 = 3.660795, b = 1.225022\n",
      "\tgrad = 2.532961\n",
      "rate = 0.012500\n",
      "Step 93 / 1000, loss = -7701.413584\n",
      "a_1 = 5.551120, a_2 = 3.679300, b = 1.231091\n",
      "\tgrad = 2.640643\n",
      "rate = 0.012389\n",
      "Step 94 / 1000, loss = -7704.492645\n",
      "a_1 = 5.578226, a_2 = 3.697806, b = 1.237120\n",
      "\tgrad = 2.717232\n",
      "rate = 0.012281\n",
      "Step 95 / 1000, loss = -7707.656217\n",
      "a_1 = 5.606900, a_2 = 3.716717, b = 1.243463\n",
      "\tgrad = 2.869194\n",
      "rate = 0.012174\n",
      "Step 96 / 1000, loss = -7710.792996\n",
      "a_1 = 5.635376, a_2 = 3.736166, b = 1.249725\n",
      "\tgrad = 2.903995\n",
      "rate = 0.012069\n",
      "Step 97 / 1000, loss = -7713.726954\n",
      "a_1 = 5.661927, a_2 = 3.754979, b = 1.255718\n",
      "\tgrad = 2.765184\n",
      "rate = 0.011966\n",
      "Step 98 / 1000, loss = -7716.510719\n",
      "a_1 = 5.686683, a_2 = 3.773577, b = 1.261673\n",
      "\tgrad = 2.657600\n",
      "rate = 0.011864\n",
      "Step 99 / 1000, loss = -7719.223014\n",
      "a_1 = 5.710528, a_2 = 3.792496, b = 1.267496\n",
      "\tgrad = 2.634181\n",
      "rate = 0.011765\n",
      "Step 100 / 1000, loss = -7721.872743\n",
      "a_1 = 5.735911, a_2 = 3.809743, b = 1.273270\n",
      "\tgrad = 2.676609\n",
      "rate = 0.011667\n",
      "Step 101 / 1000, loss = -7724.402818\n",
      "a_1 = 5.760791, a_2 = 3.826257, b = 1.278731\n",
      "\tgrad = 2.623711\n",
      "rate = 0.011570\n",
      "Step 102 / 1000, loss = -7726.974611\n",
      "a_1 = 5.785324, a_2 = 3.844006, b = 1.284547\n",
      "\tgrad = 2.686912\n",
      "rate = 0.011475\n",
      "Step 103 / 1000, loss = -7729.460319\n",
      "a_1 = 5.809968, a_2 = 3.860874, b = 1.290227\n",
      "\tgrad = 2.670840\n",
      "rate = 0.011382\n",
      "Step 104 / 1000, loss = -7731.822077\n",
      "a_1 = 5.834062, a_2 = 3.876925, b = 1.295521\n",
      "\tgrad = 2.606719\n",
      "rate = 0.011290\n",
      "Step 105 / 1000, loss = -7734.327196\n",
      "a_1 = 5.859671, a_2 = 3.894358, b = 1.301255\n",
      "\tgrad = 2.813046\n",
      "rate = 0.011200\n",
      "Step 106 / 1000, loss = -7736.811171\n",
      "a_1 = 5.884786, a_2 = 3.912466, b = 1.306932\n",
      "\tgrad = 2.832993\n",
      "rate = 0.011111\n",
      "Step 107 / 1000, loss = -7739.312737\n",
      "a_1 = 5.911454, a_2 = 3.930011, b = 1.312796\n",
      "\tgrad = 2.944206\n",
      "rate = 0.011024\n",
      "Step 108 / 1000, loss = -7741.635477\n",
      "a_1 = 5.935382, a_2 = 3.947416, b = 1.318406\n",
      "\tgrad = 2.753485\n",
      "rate = 0.010938\n",
      "Step 109 / 1000, loss = -7743.837365\n",
      "a_1 = 5.958636, a_2 = 3.963910, b = 1.323755\n",
      "\tgrad = 2.672802\n",
      "rate = 0.010853\n",
      "Step 110 / 1000, loss = -7745.948701\n",
      "a_1 = 5.981790, a_2 = 3.979417, b = 1.328944\n",
      "\tgrad = 2.632140\n",
      "rate = 0.010769\n",
      "Step 111 / 1000, loss = -7747.965549\n",
      "a_1 = 6.003336, a_2 = 3.995000, b = 1.334084\n",
      "\tgrad = 2.534217\n",
      "rate = 0.010687\n",
      "Step 112 / 1000, loss = -7750.153282\n",
      "a_1 = 6.027090, a_2 = 4.012166, b = 1.339567\n",
      "\tgrad = 2.811146\n",
      "rate = 0.010606\n",
      "Step 113 / 1000, loss = -7752.293435\n",
      "a_1 = 6.050646, a_2 = 4.029196, b = 1.344945\n",
      "\tgrad = 2.808238\n",
      "rate = 0.010526\n",
      "Step 114 / 1000, loss = -7754.199544\n",
      "a_1 = 6.071972, a_2 = 4.044386, b = 1.349876\n",
      "\tgrad = 2.550154\n",
      "rate = 0.010448\n",
      "Step 115 / 1000, loss = -7756.255078\n",
      "a_1 = 6.095336, a_2 = 4.061029, b = 1.355092\n",
      "\tgrad = 2.811505\n",
      "rate = 0.010370\n",
      "Step 116 / 1000, loss = -7758.163148\n",
      "a_1 = 6.116923, a_2 = 4.076866, b = 1.360115\n",
      "\tgrad = 2.646192\n",
      "rate = 0.010294\n",
      "Step 117 / 1000, loss = -7759.985781\n",
      "a_1 = 6.138335, a_2 = 4.091617, b = 1.365040\n",
      "\tgrad = 2.589667\n",
      "rate = 0.010219\n",
      "Step 118 / 1000, loss = -7761.945254\n",
      "a_1 = 6.161318, a_2 = 4.107941, b = 1.370385\n",
      "\tgrad = 2.828186\n",
      "rate = 0.010145\n",
      "Step 119 / 1000, loss = -7763.811725\n",
      "a_1 = 6.183673, a_2 = 4.123648, b = 1.375380\n",
      "\tgrad = 2.757628\n",
      "rate = 0.010072\n",
      "Step 120 / 1000, loss = -7765.564130\n",
      "a_1 = 6.204742, a_2 = 4.138582, b = 1.380259\n",
      "\tgrad = 2.628206\n",
      "rate = 0.010000\n",
      "Step 121 / 1000, loss = -7767.213683\n",
      "a_1 = 6.225553, a_2 = 4.152026, b = 1.385005\n",
      "\tgrad = 2.540660\n",
      "rate = 0.009929\n",
      "Step 122 / 1000, loss = -7768.973636\n",
      "a_1 = 6.247078, a_2 = 4.167574, b = 1.389885\n",
      "\tgrad = 2.738246\n",
      "rate = 0.009859\n",
      "Step 123 / 1000, loss = -7770.543674\n",
      "a_1 = 6.266059, a_2 = 4.181745, b = 1.394535\n",
      "\tgrad = 2.465738\n",
      "rate = 0.009790\n",
      "Step 124 / 1000, loss = -7772.211411\n",
      "a_1 = 6.287309, a_2 = 4.196224, b = 1.399492\n",
      "\tgrad = 2.693546\n",
      "rate = 0.009722\n",
      "Step 125 / 1000, loss = -7773.902488\n",
      "a_1 = 6.308852, a_2 = 4.211337, b = 1.404531\n",
      "\tgrad = 2.775112\n",
      "rate = 0.009655\n",
      "Step 126 / 1000, loss = -7775.509189\n",
      "a_1 = 6.329861, a_2 = 4.225657, b = 1.409297\n",
      "\tgrad = 2.697619\n",
      "rate = 0.009589\n",
      "Step 127 / 1000, loss = -7777.129173\n",
      "a_1 = 6.351673, a_2 = 4.239963, b = 1.414096\n",
      "\tgrad = 2.784896\n",
      "rate = 0.009524\n",
      "Step 128 / 1000, loss = -7778.682942\n",
      "a_1 = 6.372571, a_2 = 4.254087, b = 1.418730\n",
      "\tgrad = 2.711071\n",
      "rate = 0.009459\n",
      "Step 129 / 1000, loss = -7780.129724\n",
      "a_1 = 6.392045, a_2 = 4.267426, b = 1.423221\n",
      "\tgrad = 2.557224\n",
      "rate = 0.009396\n",
      "Step 130 / 1000, loss = -7781.684096\n",
      "a_1 = 6.413357, a_2 = 4.281907, b = 1.427952\n",
      "\tgrad = 2.806837\n",
      "rate = 0.009333\n",
      "Step 131 / 1000, loss = -7783.233980\n",
      "a_1 = 6.434132, a_2 = 4.297093, b = 1.432791\n",
      "\tgrad = 2.824224\n",
      "rate = 0.009272\n",
      "Step 132 / 1000, loss = -7784.756490\n",
      "a_1 = 6.455144, a_2 = 4.311919, b = 1.437525\n",
      "\tgrad = 2.838902\n",
      "rate = 0.009211\n",
      "Step 133 / 1000, loss = -7786.161488\n",
      "a_1 = 6.475064, a_2 = 4.325321, b = 1.442081\n",
      "\tgrad = 2.670630\n",
      "rate = 0.009150\n",
      "Step 134 / 1000, loss = -7787.507131\n",
      "a_1 = 6.494532, a_2 = 4.338115, b = 1.446490\n",
      "\tgrad = 2.608035\n",
      "rate = 0.009091\n",
      "Step 135 / 1000, loss = -7788.854728\n",
      "a_1 = 6.514453, a_2 = 4.350834, b = 1.450969\n",
      "\tgrad = 2.663309\n",
      "rate = 0.009032\n",
      "Step 136 / 1000, loss = -7790.280439\n",
      "a_1 = 6.535309, a_2 = 4.365075, b = 1.455528\n",
      "\tgrad = 2.859541\n",
      "rate = 0.008974\n",
      "Step 137 / 1000, loss = -7791.628860\n",
      "a_1 = 6.554842, a_2 = 4.378936, b = 1.460013\n",
      "\tgrad = 2.732663\n",
      "rate = 0.008917\n",
      "Step 138 / 1000, loss = -7793.002142\n",
      "a_1 = 6.574906, a_2 = 4.393310, b = 1.464566\n",
      "\tgrad = 2.832478\n",
      "rate = 0.008861\n",
      "Step 139 / 1000, loss = -7794.311813\n",
      "a_1 = 6.594326, a_2 = 4.406989, b = 1.469056\n",
      "\tgrad = 2.745519\n",
      "rate = 0.008805\n",
      "Step 140 / 1000, loss = -7795.536950\n",
      "a_1 = 6.612327, a_2 = 4.420179, b = 1.473360\n",
      "\tgrad = 2.597382\n",
      "rate = 0.008750\n",
      "Step 141 / 1000, loss = -7796.744385\n",
      "a_1 = 6.630983, a_2 = 4.432652, b = 1.477612\n",
      "\tgrad = 2.626811\n",
      "rate = 0.008696\n",
      "Step 142 / 1000, loss = -7797.963654\n",
      "a_1 = 6.649843, a_2 = 4.445554, b = 1.481924\n",
      "\tgrad = 2.690778\n",
      "rate = 0.008642\n",
      "Step 143 / 1000, loss = -7799.207555\n",
      "a_1 = 6.668921, a_2 = 4.459335, b = 1.486227\n",
      "\tgrad = 2.785508\n",
      "rate = 0.008589\n",
      "Step 144 / 1000, loss = -7800.398070\n",
      "a_1 = 6.688063, a_2 = 4.471832, b = 1.490554\n",
      "\tgrad = 2.725438\n",
      "rate = 0.008537\n",
      "Step 145 / 1000, loss = -7801.408779\n",
      "a_1 = 6.703708, a_2 = 4.483193, b = 1.494312\n",
      "\tgrad = 2.321466\n",
      "rate = 0.008485\n",
      "Step 146 / 1000, loss = -7802.548039\n",
      "a_1 = 6.721746, a_2 = 4.496133, b = 1.498360\n",
      "\tgrad = 2.675588\n",
      "rate = 0.008434\n",
      "Step 147 / 1000, loss = -7803.651898\n",
      "a_1 = 6.739277, a_2 = 4.508768, b = 1.502442\n",
      "\tgrad = 2.623394\n",
      "rate = 0.008383\n",
      "Step 148 / 1000, loss = -7804.799465\n",
      "a_1 = 6.757704, a_2 = 4.522103, b = 1.506642\n",
      "\tgrad = 2.775558\n",
      "rate = 0.008333\n",
      "Step 149 / 1000, loss = -7805.899816\n",
      "a_1 = 6.775905, a_2 = 4.534621, b = 1.510759\n",
      "\tgrad = 2.712558\n",
      "rate = 0.008284\n",
      "Step 150 / 1000, loss = -7806.997631\n",
      "a_1 = 6.794531, a_2 = 4.547077, b = 1.514794\n",
      "\tgrad = 2.764564\n",
      "rate = 0.008235\n",
      "Step 151 / 1000, loss = -7808.068423\n",
      "a_1 = 6.812857, a_2 = 4.559164, b = 1.518944\n",
      "\tgrad = 2.728922\n",
      "rate = 0.008187\n",
      "Step 152 / 1000, loss = -7809.110903\n",
      "a_1 = 6.830638, a_2 = 4.571303, b = 1.522981\n",
      "\tgrad = 2.691179\n",
      "rate = 0.008140\n",
      "Step 153 / 1000, loss = -7810.150886\n",
      "a_1 = 6.848621, a_2 = 4.583419, b = 1.527076\n",
      "\tgrad = 2.726831\n",
      "rate = 0.008092\n",
      "Step 154 / 1000, loss = -7811.125534\n",
      "a_1 = 6.865548, a_2 = 4.595016, b = 1.530889\n",
      "\tgrad = 2.593879\n",
      "rate = 0.008046\n",
      "Step 155 / 1000, loss = -7812.073658\n",
      "a_1 = 6.882203, a_2 = 4.606396, b = 1.534593\n",
      "\tgrad = 2.563617\n",
      "rate = 0.008000\n",
      "Step 156 / 1000, loss = -7813.009507\n",
      "a_1 = 6.897952, a_2 = 4.618392, b = 1.538395\n",
      "\tgrad = 2.534299\n",
      "rate = 0.007955\n",
      "Step 157 / 1000, loss = -7813.929061\n",
      "a_1 = 6.914231, a_2 = 4.629572, b = 1.542223\n",
      "\tgrad = 2.543215\n",
      "rate = 0.007910\n",
      "Step 158 / 1000, loss = -7814.872672\n",
      "a_1 = 6.931692, a_2 = 4.640697, b = 1.546061\n",
      "\tgrad = 2.677179\n",
      "rate = 0.007865\n",
      "Step 159 / 1000, loss = -7815.825947\n",
      "a_1 = 6.948737, a_2 = 4.652761, b = 1.549964\n",
      "\tgrad = 2.716234\n",
      "rate = 0.007821\n",
      "Step 160 / 1000, loss = -7816.727295\n",
      "a_1 = 6.964586, a_2 = 4.664638, b = 1.553704\n",
      "\tgrad = 2.591367\n",
      "rate = 0.007778\n",
      "Step 161 / 1000, loss = -7817.642041\n",
      "a_1 = 6.981900, a_2 = 4.675793, b = 1.557494\n",
      "\tgrad = 2.707500\n",
      "rate = 0.007735\n",
      "Step 162 / 1000, loss = -7818.570499\n",
      "a_1 = 6.999325, a_2 = 4.687577, b = 1.561309\n",
      "\tgrad = 2.779253\n",
      "rate = 0.007692\n",
      "Step 163 / 1000, loss = -7819.509188\n",
      "a_1 = 7.017073, a_2 = 4.699507, b = 1.565302\n",
      "\tgrad = 2.843656\n",
      "rate = 0.007650\n",
      "Step 164 / 1000, loss = -7820.372511\n",
      "a_1 = 7.032741, a_2 = 4.711312, b = 1.569030\n",
      "\tgrad = 2.624375\n",
      "rate = 0.007609\n",
      "Step 165 / 1000, loss = -7821.226129\n",
      "a_1 = 7.048778, a_2 = 4.722708, b = 1.572722\n",
      "\tgrad = 2.645132\n",
      "rate = 0.007568\n",
      "Step 166 / 1000, loss = -7822.101719\n",
      "a_1 = 7.066032, a_2 = 4.733884, b = 1.576516\n",
      "\tgrad = 2.777335\n",
      "rate = 0.007527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 167 / 1000, loss = -7822.934340\n",
      "a_1 = 7.081387, a_2 = 4.745795, b = 1.580109\n",
      "\tgrad = 2.639737\n",
      "rate = 0.007487\n",
      "Step 168 / 1000, loss = -7823.781780\n",
      "a_1 = 7.097301, a_2 = 4.757776, b = 1.583877\n",
      "\tgrad = 2.722319\n",
      "rate = 0.007447\n",
      "Step 169 / 1000, loss = -7824.596661\n",
      "a_1 = 7.113453, a_2 = 4.768694, b = 1.587529\n",
      "\tgrad = 2.677760\n",
      "rate = 0.007407\n",
      "Step 170 / 1000, loss = -7825.443348\n",
      "a_1 = 7.130021, a_2 = 4.780491, b = 1.591338\n",
      "\tgrad = 2.808258\n",
      "rate = 0.007368\n",
      "Step 171 / 1000, loss = -7826.210430\n",
      "a_1 = 7.145160, a_2 = 4.791083, b = 1.594966\n",
      "\tgrad = 2.568807\n",
      "rate = 0.007330\n",
      "Step 172 / 1000, loss = -7826.997343\n",
      "a_1 = 7.160669, a_2 = 4.802429, b = 1.598494\n",
      "\tgrad = 2.679455\n",
      "rate = 0.007292\n",
      "Step 173 / 1000, loss = -7827.769213\n",
      "a_1 = 7.176309, a_2 = 4.813162, b = 1.602142\n",
      "\tgrad = 2.662824\n",
      "rate = 0.007254\n",
      "Step 174 / 1000, loss = -7828.553794\n",
      "a_1 = 7.192431, a_2 = 4.824024, b = 1.605909\n",
      "\tgrad = 2.744036\n",
      "rate = 0.007216\n",
      "Step 175 / 1000, loss = -7829.245465\n",
      "a_1 = 7.206444, a_2 = 4.833944, b = 1.609276\n",
      "\tgrad = 2.436822\n",
      "rate = 0.007179\n",
      "Step 176 / 1000, loss = -7829.991140\n",
      "a_1 = 7.221535, a_2 = 4.845023, b = 1.612776\n",
      "\tgrad = 2.666391\n",
      "rate = 0.007143\n",
      "Step 177 / 1000, loss = -7830.707866\n",
      "a_1 = 7.236799, a_2 = 4.855073, b = 1.616208\n",
      "\tgrad = 2.616606\n",
      "rate = 0.007107\n",
      "Step 178 / 1000, loss = -7831.406947\n",
      "a_1 = 7.251413, a_2 = 4.865401, b = 1.619509\n",
      "\tgrad = 2.573541\n",
      "rate = 0.007071\n",
      "Step 179 / 1000, loss = -7832.112305\n",
      "a_1 = 7.266300, a_2 = 4.875746, b = 1.622963\n",
      "\tgrad = 2.623222\n",
      "rate = 0.007035\n",
      "Step 180 / 1000, loss = -7832.806594\n",
      "a_1 = 7.280934, a_2 = 4.886160, b = 1.626358\n",
      "\tgrad = 2.611329\n",
      "rate = 0.007000\n",
      "Step 181 / 1000, loss = -7833.473144\n",
      "a_1 = 7.295327, a_2 = 4.896080, b = 1.629569\n",
      "\tgrad = 2.551571\n",
      "rate = 0.006965\n",
      "Step 182 / 1000, loss = -7834.175022\n",
      "a_1 = 7.310917, a_2 = 4.906297, b = 1.632965\n",
      "\tgrad = 2.733749\n",
      "rate = 0.006931\n",
      "Step 183 / 1000, loss = -7834.876758\n",
      "a_1 = 7.325978, a_2 = 4.917115, b = 1.636461\n",
      "\tgrad = 2.736258\n",
      "rate = 0.006897\n",
      "Step 184 / 1000, loss = -7835.574237\n",
      "a_1 = 7.340680, a_2 = 4.928363, b = 1.639920\n",
      "\tgrad = 2.744054\n",
      "rate = 0.006863\n",
      "Step 185 / 1000, loss = -7836.273922\n",
      "a_1 = 7.355839, a_2 = 4.939382, b = 1.643464\n",
      "\tgrad = 2.792759\n",
      "rate = 0.006829\n",
      "Step 186 / 1000, loss = -7836.953476\n",
      "a_1 = 7.370931, a_2 = 4.949913, b = 1.646930\n",
      "\tgrad = 2.755444\n",
      "rate = 0.006796\n",
      "Step 187 / 1000, loss = -7837.601503\n",
      "a_1 = 7.384735, a_2 = 4.960760, b = 1.650203\n",
      "\tgrad = 2.640446\n",
      "rate = 0.006763\n",
      "Step 188 / 1000, loss = -7838.264510\n",
      "a_1 = 7.399304, a_2 = 4.971660, b = 1.653528\n",
      "\tgrad = 2.748060\n",
      "rate = 0.006731\n",
      "Step 189 / 1000, loss = -7838.902520\n",
      "a_1 = 7.413694, a_2 = 4.981789, b = 1.656890\n",
      "\tgrad = 2.674655\n",
      "rate = 0.006699\n",
      "Step 190 / 1000, loss = -7839.527131\n",
      "a_1 = 7.427284, a_2 = 4.992324, b = 1.660224\n",
      "\tgrad = 2.627183\n",
      "rate = 0.006667\n",
      "Step 191 / 1000, loss = -7840.133601\n",
      "a_1 = 7.441021, a_2 = 5.002201, b = 1.663468\n",
      "\tgrad = 2.596430\n",
      "rate = 0.006635\n",
      "Step 192 / 1000, loss = -7840.774846\n",
      "a_1 = 7.456206, a_2 = 5.012280, b = 1.666836\n",
      "\tgrad = 2.806738\n",
      "rate = 0.006604\n",
      "Step 193 / 1000, loss = -7841.356794\n",
      "a_1 = 7.469630, a_2 = 5.021754, b = 1.670050\n",
      "\tgrad = 2.547097\n",
      "rate = 0.006573\n",
      "Step 194 / 1000, loss = -7841.979280\n",
      "a_1 = 7.484313, a_2 = 5.031783, b = 1.673471\n",
      "\tgrad = 2.767869\n",
      "rate = 0.006542\n",
      "Step 195 / 1000, loss = -7842.601265\n",
      "a_1 = 7.498995, a_2 = 5.042095, b = 1.676804\n",
      "\tgrad = 2.802377\n",
      "rate = 0.006512\n",
      "Step 196 / 1000, loss = -7843.193169\n",
      "a_1 = 7.512762, a_2 = 5.052203, b = 1.680045\n",
      "\tgrad = 2.682116\n",
      "rate = 0.006481\n",
      "Step 197 / 1000, loss = -7843.738838\n",
      "a_1 = 7.525991, a_2 = 5.061046, b = 1.683129\n",
      "\tgrad = 2.512377\n",
      "rate = 0.006452\n",
      "Step 198 / 1000, loss = -7844.324524\n",
      "a_1 = 7.539753, a_2 = 5.071189, b = 1.686391\n",
      "\tgrad = 2.710098\n",
      "rate = 0.006422\n",
      "Step 199 / 1000, loss = -7844.885442\n",
      "a_1 = 7.553790, a_2 = 5.080393, b = 1.689402\n",
      "\tgrad = 2.667620\n",
      "rate = 0.006393\n",
      "Step 200 / 1000, loss = -7845.476566\n",
      "a_1 = 7.568356, a_2 = 5.090401, b = 1.692648\n",
      "\tgrad = 2.823664\n",
      "rate = 0.006364\n",
      "Step 201 / 1000, loss = -7846.071821\n",
      "a_1 = 7.583222, a_2 = 5.100504, b = 1.695897\n",
      "\tgrad = 2.883286\n",
      "rate = 0.006335\n",
      "Step 202 / 1000, loss = -7846.619918\n",
      "a_1 = 7.596826, a_2 = 5.109943, b = 1.698981\n",
      "\tgrad = 2.670734\n",
      "rate = 0.006306\n",
      "Step 203 / 1000, loss = -7847.161245\n",
      "a_1 = 7.609927, a_2 = 5.119787, b = 1.701994\n",
      "\tgrad = 2.654036\n",
      "rate = 0.006278\n",
      "Step 204 / 1000, loss = -7847.700419\n",
      "a_1 = 7.622983, a_2 = 5.129615, b = 1.705100\n",
      "\tgrad = 2.661376\n",
      "rate = 0.006250\n",
      "Step 205 / 1000, loss = -7848.259112\n",
      "a_1 = 7.637321, a_2 = 5.139254, b = 1.708273\n",
      "\tgrad = 2.823198\n",
      "rate = 0.006222\n",
      "Step 206 / 1000, loss = -7848.807597\n",
      "a_1 = 7.651211, a_2 = 5.148996, b = 1.711445\n",
      "\tgrad = 2.786179\n",
      "rate = 0.006195\n",
      "Step 207 / 1000, loss = -7849.372935\n",
      "a_1 = 7.665774, a_2 = 5.159006, b = 1.714695\n",
      "\tgrad = 2.913427\n",
      "rate = 0.006167\n",
      "Step 208 / 1000, loss = -7849.927756\n",
      "a_1 = 7.679517, a_2 = 5.169472, b = 1.717931\n",
      "\tgrad = 2.862199\n",
      "rate = 0.006140\n",
      "Step 209 / 1000, loss = -7850.443451\n",
      "a_1 = 7.692508, a_2 = 5.179224, b = 1.720883\n",
      "\tgrad = 2.700510\n",
      "rate = 0.006114\n",
      "Step 210 / 1000, loss = -7850.963306\n",
      "a_1 = 7.705892, a_2 = 5.188784, b = 1.723982\n",
      "\tgrad = 2.749580\n",
      "rate = 0.006087\n",
      "Step 211 / 1000, loss = -7851.452917\n",
      "a_1 = 7.718947, a_2 = 5.197426, b = 1.726963\n",
      "\tgrad = 2.629771\n",
      "rate = 0.006061\n",
      "Step 212 / 1000, loss = -7851.948200\n",
      "a_1 = 7.731823, a_2 = 5.206802, b = 1.729842\n",
      "\tgrad = 2.682265\n",
      "rate = 0.006034\n",
      "Step 213 / 1000, loss = -7852.415700\n",
      "a_1 = 7.744240, a_2 = 5.215456, b = 1.732623\n",
      "\tgrad = 2.561127\n",
      "rate = 0.006009\n",
      "Step 214 / 1000, loss = -7852.882313\n",
      "a_1 = 7.756370, a_2 = 5.224368, b = 1.735483\n",
      "\tgrad = 2.560849\n",
      "rate = 0.005983\n",
      "Step 215 / 1000, loss = -7853.369615\n",
      "a_1 = 7.769354, a_2 = 5.233529, b = 1.738462\n",
      "\tgrad = 2.713720\n",
      "rate = 0.005957\n",
      "Step 216 / 1000, loss = -7853.829137\n",
      "a_1 = 7.781301, a_2 = 5.242394, b = 1.741416\n",
      "\tgrad = 2.556748\n",
      "rate = 0.005932\n",
      "Step 217 / 1000, loss = -7854.312244\n",
      "a_1 = 7.794835, a_2 = 5.251111, b = 1.744387\n",
      "\tgrad = 2.771210\n",
      "rate = 0.005907\n",
      "Step 218 / 1000, loss = -7854.786943\n",
      "a_1 = 7.808023, a_2 = 5.259887, b = 1.747334\n",
      "\tgrad = 2.739300\n",
      "rate = 0.005882\n",
      "Step 219 / 1000, loss = -7855.249615\n",
      "a_1 = 7.820653, a_2 = 5.268776, b = 1.750216\n",
      "\tgrad = 2.682098\n",
      "rate = 0.005858\n",
      "Step 220 / 1000, loss = -7855.688609\n",
      "a_1 = 7.832648, a_2 = 5.277263, b = 1.752998\n",
      "\tgrad = 2.563736\n",
      "rate = 0.005833\n",
      "Step 221 / 1000, loss = -7856.137342\n",
      "a_1 = 7.845162, a_2 = 5.285871, b = 1.755809\n",
      "\tgrad = 2.659019\n",
      "rate = 0.005809\n",
      "Step 222 / 1000, loss = -7856.595150\n",
      "a_1 = 7.858342, a_2 = 5.294378, b = 1.758696\n",
      "\tgrad = 2.757026\n",
      "rate = 0.005785\n",
      "Step 223 / 1000, loss = -7857.039991\n",
      "a_1 = 7.870634, a_2 = 5.303141, b = 1.761588\n",
      "\tgrad = 2.667939\n",
      "rate = 0.005761\n",
      "Step 224 / 1000, loss = -7857.450711\n",
      "a_1 = 7.882636, a_2 = 5.310703, b = 1.764285\n",
      "\tgrad = 2.516669\n",
      "rate = 0.005738\n",
      "Step 225 / 1000, loss = -7857.897972\n",
      "a_1 = 7.895491, a_2 = 5.319361, b = 1.767148\n",
      "\tgrad = 2.758175\n",
      "rate = 0.005714\n",
      "Step 226 / 1000, loss = -7858.345688\n",
      "a_1 = 7.907860, a_2 = 5.328615, b = 1.770021\n",
      "\tgrad = 2.760910\n",
      "rate = 0.005691\n",
      "Step 227 / 1000, loss = -7858.761664\n",
      "a_1 = 7.919305, a_2 = 5.337333, b = 1.772725\n",
      "\tgrad = 2.582629\n",
      "rate = 0.005668\n",
      "Step 228 / 1000, loss = -7859.203021\n",
      "a_1 = 7.931746, a_2 = 5.346403, b = 1.775615\n",
      "\tgrad = 2.774953\n",
      "rate = 0.005645\n",
      "Step 229 / 1000, loss = -7859.621123\n",
      "a_1 = 7.943622, a_2 = 5.354979, b = 1.778393\n",
      "\tgrad = 2.651966\n",
      "rate = 0.005622\n",
      "Step 230 / 1000, loss = -7860.049108\n",
      "a_1 = 7.956103, a_2 = 5.363565, b = 1.781248\n",
      "\tgrad = 2.752755\n",
      "rate = 0.005600\n",
      "Step 231 / 1000, loss = -7860.464514\n",
      "a_1 = 7.968200, a_2 = 5.372004, b = 1.784043\n",
      "\tgrad = 2.691461\n",
      "rate = 0.005578\n",
      "Step 232 / 1000, loss = -7860.871142\n",
      "a_1 = 7.979922, a_2 = 5.380587, b = 1.786704\n",
      "\tgrad = 2.658638\n",
      "rate = 0.005556\n",
      "Step 233 / 1000, loss = -7861.260384\n",
      "a_1 = 7.991715, a_2 = 5.388253, b = 1.789349\n",
      "\tgrad = 2.586423\n",
      "rate = 0.005534\n",
      "Step 234 / 1000, loss = -7861.671219\n",
      "a_1 = 8.003898, a_2 = 5.396707, b = 1.792138\n",
      "\tgrad = 2.737536\n",
      "rate = 0.005512\n",
      "Step 235 / 1000, loss = -7862.063356\n",
      "a_1 = 8.015147, a_2 = 5.405149, b = 1.794866\n",
      "\tgrad = 2.609364\n",
      "rate = 0.005490\n",
      "Step 236 / 1000, loss = -7862.463352\n",
      "a_1 = 8.026763, a_2 = 5.413738, b = 1.797649\n",
      "\tgrad = 2.690357\n",
      "rate = 0.005469\n",
      "Step 237 / 1000, loss = -7862.831978\n",
      "a_1 = 8.037126, a_2 = 5.422024, b = 1.800248\n",
      "\tgrad = 2.481982\n",
      "rate = 0.005447\n",
      "Step 238 / 1000, loss = -7863.214190\n",
      "a_1 = 8.048458, a_2 = 5.430209, b = 1.802917\n",
      "\tgrad = 2.622664\n",
      "rate = 0.005426\n",
      "Step 239 / 1000, loss = -7863.610172\n",
      "a_1 = 8.060687, a_2 = 5.438520, b = 1.805555\n",
      "\tgrad = 2.778468\n",
      "rate = 0.005405\n",
      "Step 240 / 1000, loss = -7864.002031\n",
      "a_1 = 8.072711, a_2 = 5.446781, b = 1.808274\n",
      "\tgrad = 2.756078\n",
      "rate = 0.005385\n",
      "Step 241 / 1000, loss = -7864.377377\n",
      "a_1 = 8.084215, a_2 = 5.454788, b = 1.810897\n",
      "\tgrad = 2.658231\n",
      "rate = 0.005364\n",
      "Step 242 / 1000, loss = -7864.761029\n",
      "a_1 = 8.096271, a_2 = 5.462753, b = 1.813617\n",
      "\tgrad = 2.751605\n",
      "rate = 0.005344\n",
      "Step 243 / 1000, loss = -7865.107525\n",
      "a_1 = 8.107123, a_2 = 5.470054, b = 1.816087\n",
      "\tgrad = 2.500558\n",
      "rate = 0.005323\n",
      "Step 244 / 1000, loss = -7865.487935\n",
      "a_1 = 8.118831, a_2 = 5.478383, b = 1.818781\n",
      "\tgrad = 2.756689\n",
      "rate = 0.005303\n",
      "Step 245 / 1000, loss = -7865.873492\n",
      "a_1 = 8.131133, a_2 = 5.486507, b = 1.821533\n",
      "\tgrad = 2.838769\n",
      "rate = 0.005283\n",
      "Step 246 / 1000, loss = -7866.245158\n",
      "a_1 = 8.143462, a_2 = 5.493967, b = 1.824222\n",
      "\tgrad = 2.785080\n",
      "rate = 0.005263\n",
      "Step 247 / 1000, loss = -7866.598324\n",
      "a_1 = 8.154195, a_2 = 5.502019, b = 1.826797\n",
      "\tgrad = 2.605616\n",
      "rate = 0.005243\n",
      "Step 248 / 1000, loss = -7866.966823\n",
      "a_1 = 8.165786, a_2 = 5.510234, b = 1.829429\n",
      "\tgrad = 2.765987\n",
      "rate = 0.005224\n",
      "Step 249 / 1000, loss = -7867.332050\n",
      "a_1 = 8.177366, a_2 = 5.518347, b = 1.832073\n",
      "\tgrad = 2.763800\n",
      "rate = 0.005204\n",
      "Step 250 / 1000, loss = -7867.691877\n",
      "a_1 = 8.188493, a_2 = 5.526612, b = 1.834738\n",
      "\tgrad = 2.722181\n",
      "rate = 0.005185\n",
      "Step 251 / 1000, loss = -7868.027442\n",
      "a_1 = 8.199146, a_2 = 5.534179, b = 1.837207\n",
      "\tgrad = 2.574143\n",
      "rate = 0.005166\n",
      "Step 252 / 1000, loss = -7868.389489\n",
      "a_1 = 8.210907, a_2 = 5.542249, b = 1.839832\n",
      "\tgrad = 2.817730\n",
      "rate = 0.005147\n",
      "Step 253 / 1000, loss = -7868.721656\n",
      "a_1 = 8.221708, a_2 = 5.549592, b = 1.842345\n",
      "\tgrad = 2.593480\n",
      "rate = 0.005128\n",
      "Step 254 / 1000, loss = -7869.073584\n",
      "a_1 = 8.232725, a_2 = 5.557910, b = 1.844961\n",
      "\tgrad = 2.749815\n",
      "rate = 0.005109\n",
      "Step 255 / 1000, loss = -7869.412779\n",
      "a_1 = 8.243559, a_2 = 5.565817, b = 1.847486\n",
      "\tgrad = 2.680903\n",
      "rate = 0.005091\n",
      "Step 256 / 1000, loss = -7869.740016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 8.254324, a_2 = 5.573241, b = 1.849926\n",
      "\tgrad = 2.622499\n",
      "rate = 0.005072\n",
      "Step 257 / 1000, loss = -7870.043652\n",
      "a_1 = 8.264459, a_2 = 5.579963, b = 1.852270\n",
      "\tgrad = 2.450503\n",
      "rate = 0.005054\n",
      "Step 258 / 1000, loss = -7870.364619\n",
      "a_1 = 8.274916, a_2 = 5.587562, b = 1.854612\n",
      "\tgrad = 2.608601\n",
      "rate = 0.005036\n",
      "Step 259 / 1000, loss = -7870.691653\n",
      "a_1 = 8.286332, a_2 = 5.594611, b = 1.857066\n",
      "\tgrad = 2.718118\n",
      "rate = 0.005018\n",
      "Step 260 / 1000, loss = -7871.006738\n",
      "a_1 = 8.296401, a_2 = 5.602255, b = 1.859476\n",
      "\tgrad = 2.573939\n",
      "rate = 0.005000\n",
      "Step 261 / 1000, loss = -7871.333477\n",
      "a_1 = 8.307428, a_2 = 5.609776, b = 1.861947\n",
      "\tgrad = 2.724538\n",
      "rate = 0.004982\n",
      "Step 262 / 1000, loss = -7871.640714\n",
      "a_1 = 8.317391, a_2 = 5.617167, b = 1.864360\n",
      "\tgrad = 2.545696\n",
      "rate = 0.004965\n",
      "Step 263 / 1000, loss = -7871.953638\n",
      "a_1 = 8.328246, a_2 = 5.624217, b = 1.866759\n",
      "\tgrad = 2.660876\n",
      "rate = 0.004947\n",
      "Step 264 / 1000, loss = -7872.273476\n",
      "a_1 = 8.338943, a_2 = 5.631828, b = 1.869233\n",
      "\tgrad = 2.710089\n",
      "rate = 0.004930\n",
      "Step 265 / 1000, loss = -7872.586298\n",
      "a_1 = 8.349184, a_2 = 5.639553, b = 1.871650\n",
      "\tgrad = 2.657306\n",
      "rate = 0.004912\n",
      "Step 266 / 1000, loss = -7872.897308\n",
      "a_1 = 8.359535, a_2 = 5.647204, b = 1.874019\n",
      "\tgrad = 2.673751\n",
      "rate = 0.004895\n",
      "Step 267 / 1000, loss = -7873.211965\n",
      "a_1 = 8.370408, a_2 = 5.654622, b = 1.876449\n",
      "\tgrad = 2.743790\n",
      "rate = 0.004878\n",
      "Step 268 / 1000, loss = -7873.522791\n",
      "a_1 = 8.380909, a_2 = 5.662079, b = 1.878967\n",
      "\tgrad = 2.699740\n",
      "rate = 0.004861\n",
      "Step 269 / 1000, loss = -7873.825462\n",
      "a_1 = 8.391265, a_2 = 5.669313, b = 1.881408\n",
      "\tgrad = 2.655949\n",
      "rate = 0.004844\n",
      "Step 270 / 1000, loss = -7874.103568\n",
      "a_1 = 8.400932, a_2 = 5.675921, b = 1.883629\n",
      "\tgrad = 2.468765\n",
      "rate = 0.004828\n",
      "Step 271 / 1000, loss = -7874.410494\n",
      "a_1 = 8.411685, a_2 = 5.683332, b = 1.885991\n",
      "\tgrad = 2.758558\n",
      "rate = 0.004811\n",
      "Step 272 / 1000, loss = -7874.721419\n",
      "a_1 = 8.422656, a_2 = 5.690750, b = 1.888455\n",
      "\tgrad = 2.809643\n",
      "rate = 0.004795\n",
      "Step 273 / 1000, loss = -7875.013324\n",
      "a_1 = 8.432778, a_2 = 5.697927, b = 1.890782\n",
      "\tgrad = 2.642058\n",
      "rate = 0.004778\n",
      "Step 274 / 1000, loss = -7875.299045\n",
      "a_1 = 8.443000, a_2 = 5.704669, b = 1.893111\n",
      "\tgrad = 2.617549\n",
      "rate = 0.004762\n",
      "Step 275 / 1000, loss = -7875.586368\n",
      "a_1 = 8.453275, a_2 = 5.711574, b = 1.895412\n",
      "\tgrad = 2.653395\n",
      "rate = 0.004746\n",
      "Step 276 / 1000, loss = -7875.863363\n",
      "a_1 = 8.463144, a_2 = 5.718304, b = 1.897649\n",
      "\tgrad = 2.569409\n",
      "rate = 0.004730\n",
      "Step 277 / 1000, loss = -7876.154828\n",
      "a_1 = 8.473104, a_2 = 5.725916, b = 1.899940\n",
      "\tgrad = 2.703472\n",
      "rate = 0.004714\n",
      "Step 278 / 1000, loss = -7876.447464\n",
      "a_1 = 8.483496, a_2 = 5.733112, b = 1.902364\n",
      "\tgrad = 2.739411\n",
      "rate = 0.004698\n",
      "Step 279 / 1000, loss = -7876.724017\n",
      "a_1 = 8.492821, a_2 = 5.740442, b = 1.904635\n",
      "\tgrad = 2.579400\n",
      "rate = 0.004682\n",
      "Step 280 / 1000, loss = -7876.999407\n",
      "a_1 = 8.502653, a_2 = 5.747299, b = 1.906912\n",
      "\tgrad = 2.614523\n",
      "rate = 0.004667\n",
      "Step 281 / 1000, loss = -7877.295694\n",
      "a_1 = 8.513522, a_2 = 5.754533, b = 1.909331\n",
      "\tgrad = 2.854766\n",
      "rate = 0.004651\n",
      "Step 282 / 1000, loss = -7877.595795\n",
      "a_1 = 8.524397, a_2 = 5.762062, b = 1.911774\n",
      "\tgrad = 2.901495\n",
      "rate = 0.004636\n",
      "Step 283 / 1000, loss = -7877.880587\n",
      "a_1 = 8.534827, a_2 = 5.769133, b = 1.914126\n",
      "\tgrad = 2.774350\n",
      "rate = 0.004620\n",
      "Step 284 / 1000, loss = -7878.156510\n",
      "a_1 = 8.544983, a_2 = 5.776016, b = 1.916396\n",
      "\tgrad = 2.709246\n",
      "rate = 0.004605\n",
      "Step 285 / 1000, loss = -7878.450625\n",
      "a_1 = 8.555827, a_2 = 5.783427, b = 1.918801\n",
      "\tgrad = 2.908982\n",
      "rate = 0.004590\n",
      "Step 286 / 1000, loss = -7878.727595\n",
      "a_1 = 8.565863, a_2 = 5.790559, b = 1.921116\n",
      "\tgrad = 2.738205\n",
      "rate = 0.004575\n",
      "Step 287 / 1000, loss = -7878.984097\n",
      "a_1 = 8.575072, a_2 = 5.797234, b = 1.923305\n",
      "\tgrad = 2.539972\n",
      "rate = 0.004560\n",
      "Step 288 / 1000, loss = -7879.231228\n",
      "a_1 = 8.584594, a_2 = 5.803259, b = 1.925332\n",
      "\tgrad = 2.518725\n",
      "rate = 0.004545\n",
      "Step 289 / 1000, loss = -7879.512549\n",
      "a_1 = 8.595343, a_2 = 5.810218, b = 1.927670\n",
      "\tgrad = 2.873006\n",
      "rate = 0.004531\n",
      "Step 290 / 1000, loss = -7879.782550\n",
      "a_1 = 8.605302, a_2 = 5.817194, b = 1.929973\n",
      "\tgrad = 2.740160\n",
      "rate = 0.004516\n",
      "Step 291 / 1000, loss = -7880.041980\n",
      "a_1 = 8.614874, a_2 = 5.824025, b = 1.932134\n",
      "\tgrad = 2.656063\n",
      "rate = 0.004502\n",
      "Step 292 / 1000, loss = -7880.302874\n",
      "a_1 = 8.624593, a_2 = 5.830823, b = 1.934341\n",
      "\tgrad = 2.688579\n",
      "rate = 0.004487\n",
      "Step 293 / 1000, loss = -7880.582922\n",
      "a_1 = 8.635298, a_2 = 5.838018, b = 1.936658\n",
      "\tgrad = 2.929959\n",
      "rate = 0.004473\n",
      "Step 294 / 1000, loss = -7880.844954\n",
      "a_1 = 8.645177, a_2 = 5.844904, b = 1.938847\n",
      "\tgrad = 2.744997\n",
      "rate = 0.004459\n",
      "Step 295 / 1000, loss = -7881.095419\n",
      "a_1 = 8.654296, a_2 = 5.851713, b = 1.941020\n",
      "\tgrad = 2.606936\n",
      "rate = 0.004444\n",
      "Step 296 / 1000, loss = -7881.353339\n",
      "a_1 = 8.663964, a_2 = 5.858513, b = 1.943275\n",
      "\tgrad = 2.716035\n",
      "rate = 0.004430\n",
      "Step 297 / 1000, loss = -7881.619818\n",
      "a_1 = 8.673767, a_2 = 5.865902, b = 1.945506\n",
      "\tgrad = 2.825193\n",
      "rate = 0.004416\n",
      "Step 298 / 1000, loss = -7881.873233\n",
      "a_1 = 8.683498, a_2 = 5.872527, b = 1.947698\n",
      "\tgrad = 2.719934\n",
      "rate = 0.004403\n",
      "Step 299 / 1000, loss = -7882.127240\n",
      "a_1 = 8.693085, a_2 = 5.879326, b = 1.949927\n",
      "\tgrad = 2.725747\n",
      "rate = 0.004389\n",
      "Step 300 / 1000, loss = -7882.368928\n",
      "a_1 = 8.702257, a_2 = 5.885809, b = 1.952045\n",
      "\tgrad = 2.612490\n",
      "rate = 0.004375\n",
      "Step 301 / 1000, loss = -7882.608293\n",
      "a_1 = 8.711592, a_2 = 5.892095, b = 1.954117\n",
      "\tgrad = 2.623834\n",
      "rate = 0.004361\n",
      "Step 302 / 1000, loss = -7882.844547\n",
      "a_1 = 8.720751, a_2 = 5.898430, b = 1.956138\n",
      "\tgrad = 2.603207\n",
      "rate = 0.004348\n",
      "Step 303 / 1000, loss = -7883.095107\n",
      "a_1 = 8.730537, a_2 = 5.905113, b = 1.958301\n",
      "\tgrad = 2.779156\n",
      "rate = 0.004334\n",
      "Step 304 / 1000, loss = -7883.349295\n",
      "a_1 = 8.740354, a_2 = 5.911985, b = 1.960539\n",
      "\tgrad = 2.821110\n",
      "rate = 0.004321\n",
      "Step 305 / 1000, loss = -7883.587169\n",
      "a_1 = 8.749739, a_2 = 5.918349, b = 1.962594\n",
      "\tgrad = 2.675404\n",
      "rate = 0.004308\n",
      "Step 306 / 1000, loss = -7883.828679\n",
      "a_1 = 8.759077, a_2 = 5.924951, b = 1.964737\n",
      "\tgrad = 2.709179\n",
      "rate = 0.004294\n",
      "Step 307 / 1000, loss = -7884.080177\n",
      "a_1 = 8.768841, a_2 = 5.931853, b = 1.966963\n",
      "\tgrad = 2.840871\n",
      "rate = 0.004281\n",
      "Step 308 / 1000, loss = -7884.320229\n",
      "a_1 = 8.778197, a_2 = 5.938431, b = 1.969110\n",
      "\tgrad = 2.726364\n",
      "rate = 0.004268\n",
      "Step 309 / 1000, loss = -7884.557757\n",
      "a_1 = 8.787319, a_2 = 5.945142, b = 1.971212\n",
      "\tgrad = 2.706654\n",
      "rate = 0.004255\n",
      "Step 310 / 1000, loss = -7884.775331\n",
      "a_1 = 8.795700, a_2 = 5.951190, b = 1.973223\n",
      "\tgrad = 2.481918\n",
      "rate = 0.004242\n",
      "Step 311 / 1000, loss = -7884.997667\n",
      "a_1 = 8.804564, a_2 = 5.957199, b = 1.975245\n",
      "\tgrad = 2.576664\n",
      "rate = 0.004230\n",
      "Step 312 / 1000, loss = -7885.232475\n",
      "a_1 = 8.813807, a_2 = 5.963676, b = 1.977395\n",
      "\tgrad = 2.724674\n",
      "rate = 0.004217\n",
      "Step 313 / 1000, loss = -7885.477267\n",
      "a_1 = 8.823550, a_2 = 5.970480, b = 1.979573\n",
      "\tgrad = 2.873581\n",
      "rate = 0.004204\n",
      "Step 314 / 1000, loss = -7885.702446\n",
      "a_1 = 8.832717, a_2 = 5.976518, b = 1.981639\n",
      "\tgrad = 2.664747\n",
      "rate = 0.004192\n",
      "Step 315 / 1000, loss = -7885.926902\n",
      "a_1 = 8.841480, a_2 = 5.982922, b = 1.983691\n",
      "\tgrad = 2.643218\n",
      "rate = 0.004179\n",
      "Step 316 / 1000, loss = -7886.150614\n",
      "a_1 = 8.850042, a_2 = 5.989448, b = 1.985775\n",
      "\tgrad = 2.631587\n",
      "rate = 0.004167\n",
      "Step 317 / 1000, loss = -7886.386758\n",
      "a_1 = 8.859539, a_2 = 5.996105, b = 1.987889\n",
      "\tgrad = 2.837828\n",
      "rate = 0.004154\n",
      "Step 318 / 1000, loss = -7886.616233\n",
      "a_1 = 8.868774, a_2 = 6.002530, b = 1.990006\n",
      "\tgrad = 2.763735\n",
      "rate = 0.004142\n",
      "Step 319 / 1000, loss = -7886.837641\n",
      "a_1 = 8.878032, a_2 = 6.008539, b = 1.992000\n",
      "\tgrad = 2.715857\n",
      "rate = 0.004130\n",
      "Step 320 / 1000, loss = -7887.071517\n",
      "a_1 = 8.887692, a_2 = 6.015022, b = 1.994121\n",
      "\tgrad = 2.871882\n",
      "rate = 0.004118\n",
      "Step 321 / 1000, loss = -7887.289519\n",
      "a_1 = 8.896610, a_2 = 6.021154, b = 1.996120\n",
      "\tgrad = 2.680739\n",
      "rate = 0.004106\n",
      "Step 322 / 1000, loss = -7887.503106\n",
      "a_1 = 8.905100, a_2 = 6.027332, b = 1.998142\n",
      "\tgrad = 2.612004\n",
      "rate = 0.004094\n",
      "Step 323 / 1000, loss = -7887.724679\n",
      "a_1 = 8.914321, a_2 = 6.033482, b = 2.000200\n",
      "\tgrad = 2.761894\n",
      "rate = 0.004082\n",
      "Step 324 / 1000, loss = -7887.937145\n",
      "a_1 = 8.922660, a_2 = 6.039798, b = 2.002218\n",
      "\tgrad = 2.617842\n",
      "rate = 0.004070\n",
      "Step 325 / 1000, loss = -7888.142815\n",
      "a_1 = 8.931112, a_2 = 6.045628, b = 2.004166\n",
      "\tgrad = 2.575579\n",
      "rate = 0.004058\n",
      "Step 326 / 1000, loss = -7888.344857\n",
      "a_1 = 8.939283, a_2 = 6.051459, b = 2.006116\n",
      "\tgrad = 2.527122\n",
      "rate = 0.004046\n",
      "Step 327 / 1000, loss = -7888.549756\n",
      "a_1 = 8.947314, a_2 = 6.057701, b = 2.008048\n",
      "\tgrad = 2.566225\n",
      "rate = 0.004035\n",
      "Step 328 / 1000, loss = -7888.745261\n",
      "a_1 = 8.955509, a_2 = 6.063242, b = 2.009883\n",
      "\tgrad = 2.500900\n",
      "rate = 0.004023\n",
      "Step 329 / 1000, loss = -7888.967792\n",
      "a_1 = 8.964865, a_2 = 6.069526, b = 2.012001\n",
      "\tgrad = 2.858708\n",
      "rate = 0.004011\n",
      "Step 330 / 1000, loss = -7889.184960\n",
      "a_1 = 8.973755, a_2 = 6.075949, b = 2.014045\n",
      "\tgrad = 2.789158\n",
      "rate = 0.004000\n",
      "Step 331 / 1000, loss = -7889.387677\n",
      "a_1 = 8.982489, a_2 = 6.081532, b = 2.016003\n",
      "\tgrad = 2.644726\n",
      "rate = 0.003989\n",
      "Step 332 / 1000, loss = -7889.585015\n",
      "a_1 = 8.990738, a_2 = 6.087235, b = 2.017904\n",
      "\tgrad = 2.566346\n",
      "rate = 0.003977\n",
      "Step 333 / 1000, loss = -7889.792212\n",
      "a_1 = 8.999541, a_2 = 6.093170, b = 2.019879\n",
      "\tgrad = 2.722962\n",
      "rate = 0.003966\n",
      "Step 334 / 1000, loss = -7889.990541\n",
      "a_1 = 9.008074, a_2 = 6.098797, b = 2.021770\n",
      "\tgrad = 2.628456\n",
      "rate = 0.003955\n",
      "Step 335 / 1000, loss = -7890.196479\n",
      "a_1 = 9.016971, a_2 = 6.104654, b = 2.023730\n",
      "\tgrad = 2.746336\n",
      "rate = 0.003944\n",
      "Step 336 / 1000, loss = -7890.403802\n",
      "a_1 = 9.025602, a_2 = 6.110862, b = 2.025716\n",
      "\tgrad = 2.750014\n",
      "rate = 0.003933\n",
      "Step 337 / 1000, loss = -7890.603023\n",
      "a_1 = 9.034049, a_2 = 6.116695, b = 2.027649\n",
      "\tgrad = 2.663795\n",
      "rate = 0.003922\n",
      "Step 338 / 1000, loss = -7890.803267\n",
      "a_1 = 9.042424, a_2 = 6.122689, b = 2.029600\n",
      "\tgrad = 2.680414\n",
      "rate = 0.003911\n",
      "Step 339 / 1000, loss = -7890.993556\n",
      "a_1 = 9.050490, a_2 = 6.128308, b = 2.031468\n",
      "\tgrad = 2.565895\n",
      "rate = 0.003900\n",
      "Step 340 / 1000, loss = -7891.202348\n",
      "a_1 = 9.059068, a_2 = 6.134824, b = 2.033471\n",
      "\tgrad = 2.817363\n",
      "rate = 0.003889\n",
      "Step 341 / 1000, loss = -7891.395084\n",
      "a_1 = 9.067384, a_2 = 6.140492, b = 2.035344\n",
      "\tgrad = 2.639839\n",
      "rate = 0.003878\n",
      "Step 342 / 1000, loss = -7891.595755\n",
      "a_1 = 9.075951, a_2 = 6.146552, b = 2.037270\n",
      "\tgrad = 2.758492\n",
      "rate = 0.003867\n",
      "Step 343 / 1000, loss = -7891.787450\n",
      "a_1 = 9.084211, a_2 = 6.152250, b = 2.039152\n",
      "\tgrad = 2.647272\n",
      "rate = 0.003857\n",
      "Step 344 / 1000, loss = -7891.981945\n",
      "a_1 = 9.092747, a_2 = 6.157930, b = 2.041063\n",
      "\tgrad = 2.711847\n",
      "rate = 0.003846\n",
      "Step 345 / 1000, loss = -7892.187287\n",
      "a_1 = 9.101677, a_2 = 6.164061, b = 2.043069\n",
      "\tgrad = 2.871959\n",
      "rate = 0.003836\n",
      "Step 346 / 1000, loss = -7892.358977\n",
      "a_1 = 9.108959, a_2 = 6.169357, b = 2.044764\n",
      "\tgrad = 2.395335\n",
      "rate = 0.003825\n",
      "Step 347 / 1000, loss = -7892.558187\n",
      "a_1 = 9.117576, a_2 = 6.175402, b = 2.046724\n",
      "\tgrad = 2.806613\n",
      "rate = 0.003815\n",
      "Step 348 / 1000, loss = -7892.755462\n",
      "a_1 = 9.125825, a_2 = 6.181586, b = 2.048729\n",
      "\tgrad = 2.760790\n",
      "rate = 0.003804\n",
      "Step 349 / 1000, loss = -7892.939182\n",
      "a_1 = 9.134018, a_2 = 6.186978, b = 2.050566\n",
      "\tgrad = 2.630121\n",
      "rate = 0.003794\n",
      "Step 350 / 1000, loss = -7893.121966\n",
      "a_1 = 9.142019, a_2 = 6.192510, b = 2.052393\n",
      "\tgrad = 2.615683\n",
      "rate = 0.003784\n",
      "Step 351 / 1000, loss = -7893.306346\n",
      "a_1 = 9.149983, a_2 = 6.198168, b = 2.054272\n",
      "\tgrad = 2.636279\n",
      "rate = 0.003774\n",
      "Step 352 / 1000, loss = -7893.489427\n",
      "a_1 = 9.157921, a_2 = 6.203823, b = 2.056120\n",
      "\tgrad = 2.635780\n",
      "rate = 0.003763\n",
      "Step 353 / 1000, loss = -7893.673665\n",
      "a_1 = 9.166040, a_2 = 6.209391, b = 2.058008\n",
      "\tgrad = 2.671014\n",
      "rate = 0.003753\n",
      "Step 354 / 1000, loss = -7893.856083\n",
      "a_1 = 9.174098, a_2 = 6.214944, b = 2.059865\n",
      "\tgrad = 2.660813\n",
      "rate = 0.003743\n",
      "Step 355 / 1000, loss = -7894.034641\n",
      "a_1 = 9.182222, a_2 = 6.220265, b = 2.061642\n",
      "\tgrad = 2.644550\n",
      "rate = 0.003733\n",
      "Step 356 / 1000, loss = -7894.227131\n",
      "a_1 = 9.190990, a_2 = 6.226058, b = 2.063541\n",
      "\tgrad = 2.867878\n",
      "rate = 0.003723\n",
      "Step 357 / 1000, loss = -7894.406841\n",
      "a_1 = 9.198936, a_2 = 6.231716, b = 2.065312\n",
      "\tgrad = 2.669776\n",
      "rate = 0.003714\n",
      "Step 358 / 1000, loss = -7894.583479\n",
      "a_1 = 9.206934, a_2 = 6.236999, b = 2.067152\n",
      "\tgrad = 2.635204\n",
      "rate = 0.003704\n",
      "Step 359 / 1000, loss = -7894.764413\n",
      "a_1 = 9.214805, a_2 = 6.242731, b = 2.069036\n",
      "\tgrad = 2.684983\n",
      "rate = 0.003694\n",
      "Step 360 / 1000, loss = -7894.948371\n",
      "a_1 = 9.223011, a_2 = 6.248433, b = 2.070941\n",
      "\tgrad = 2.761215\n",
      "rate = 0.003684\n",
      "Step 361 / 1000, loss = -7895.128371\n",
      "a_1 = 9.230985, a_2 = 6.254210, b = 2.072731\n",
      "\tgrad = 2.723545\n",
      "rate = 0.003675\n",
      "Step 362 / 1000, loss = -7895.305037\n",
      "a_1 = 9.238973, a_2 = 6.259725, b = 2.074519\n",
      "\tgrad = 2.693104\n",
      "rate = 0.003665\n",
      "Step 363 / 1000, loss = -7895.480254\n",
      "a_1 = 9.247018, a_2 = 6.265002, b = 2.076372\n",
      "\tgrad = 2.680518\n",
      "rate = 0.003655\n",
      "Step 364 / 1000, loss = -7895.654022\n",
      "a_1 = 9.254699, a_2 = 6.270627, b = 2.078148\n",
      "\tgrad = 2.656275\n",
      "rate = 0.003646\n",
      "Step 365 / 1000, loss = -7895.832698\n",
      "a_1 = 9.262942, a_2 = 6.276125, b = 2.079984\n",
      "\tgrad = 2.771346\n",
      "rate = 0.003636\n",
      "Step 366 / 1000, loss = -7895.997274\n",
      "a_1 = 9.270179, a_2 = 6.281436, b = 2.081743\n",
      "\tgrad = 2.521946\n",
      "rate = 0.003627\n",
      "Step 367 / 1000, loss = -7896.163871\n",
      "a_1 = 9.278067, a_2 = 6.286413, b = 2.083479\n",
      "\tgrad = 2.622445\n",
      "rate = 0.003618\n",
      "Step 368 / 1000, loss = -7896.335638\n",
      "a_1 = 9.286009, a_2 = 6.291677, b = 2.085316\n",
      "\tgrad = 2.689271\n",
      "rate = 0.003608\n",
      "Step 369 / 1000, loss = -7896.512415\n",
      "a_1 = 9.294158, a_2 = 6.297218, b = 2.087162\n",
      "\tgrad = 2.785862\n",
      "rate = 0.003599\n",
      "Step 370 / 1000, loss = -7896.689463\n",
      "a_1 = 9.302289, a_2 = 6.302843, b = 2.089004\n",
      "\tgrad = 2.801668\n",
      "rate = 0.003590\n",
      "Step 371 / 1000, loss = -7896.861372\n",
      "a_1 = 9.310162, a_2 = 6.308298, b = 2.090833\n",
      "\tgrad = 2.723262\n",
      "rate = 0.003581\n",
      "Step 372 / 1000, loss = -7897.036060\n",
      "a_1 = 9.318196, a_2 = 6.313952, b = 2.092623\n",
      "\tgrad = 2.796093\n",
      "rate = 0.003571\n",
      "Step 373 / 1000, loss = -7897.203670\n",
      "a_1 = 9.325894, a_2 = 6.319356, b = 2.094382\n",
      "\tgrad = 2.686115\n",
      "rate = 0.003562\n",
      "Step 374 / 1000, loss = -7897.370915\n",
      "a_1 = 9.333458, a_2 = 6.324914, b = 2.096120\n",
      "\tgrad = 2.686511\n",
      "rate = 0.003553\n",
      "Step 375 / 1000, loss = -7897.528517\n",
      "a_1 = 9.340667, a_2 = 6.330117, b = 2.097754\n",
      "\tgrad = 2.550210\n",
      "rate = 0.003544\n",
      "Step 376 / 1000, loss = -7897.696728\n",
      "a_1 = 9.348724, a_2 = 6.335301, b = 2.099550\n",
      "\tgrad = 2.757340\n",
      "rate = 0.003535\n",
      "Step 377 / 1000, loss = -7897.854005\n",
      "a_1 = 9.355902, a_2 = 6.340486, b = 2.101235\n",
      "\tgrad = 2.556013\n",
      "rate = 0.003526\n",
      "Step 378 / 1000, loss = -7898.010714\n",
      "a_1 = 9.362910, a_2 = 6.345818, b = 2.102910\n",
      "\tgrad = 2.548294\n",
      "rate = 0.003518\n",
      "Step 379 / 1000, loss = -7898.182658\n",
      "a_1 = 9.370768, a_2 = 6.351525, b = 2.104766\n",
      "\tgrad = 2.817974\n",
      "rate = 0.003509\n",
      "Step 380 / 1000, loss = -7898.347797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 9.378397, a_2 = 6.356997, b = 2.106530\n",
      "\tgrad = 2.729291\n",
      "rate = 0.003500\n",
      "Step 381 / 1000, loss = -7898.497549\n",
      "a_1 = 9.385543, a_2 = 6.361734, b = 2.108164\n",
      "\tgrad = 2.499738\n",
      "rate = 0.003491\n",
      "Step 382 / 1000, loss = -7898.652231\n",
      "a_1 = 9.392670, a_2 = 6.366922, b = 2.109825\n",
      "\tgrad = 2.575898\n",
      "rate = 0.003483\n",
      "Step 383 / 1000, loss = -7898.812166\n",
      "a_1 = 9.399875, a_2 = 6.372430, b = 2.111565\n",
      "\tgrad = 2.658201\n",
      "rate = 0.003474\n",
      "Step 384 / 1000, loss = -7898.966261\n",
      "a_1 = 9.407352, a_2 = 6.377370, b = 2.113191\n",
      "\tgrad = 2.628299\n",
      "rate = 0.003465\n",
      "Step 385 / 1000, loss = -7899.112741\n",
      "a_1 = 9.414232, a_2 = 6.382222, b = 2.114784\n",
      "\tgrad = 2.478727\n",
      "rate = 0.003457\n",
      "Step 386 / 1000, loss = -7899.275809\n",
      "a_1 = 9.421982, a_2 = 6.387594, b = 2.116546\n",
      "\tgrad = 2.781926\n",
      "rate = 0.003448\n",
      "Step 387 / 1000, loss = -7899.442169\n",
      "a_1 = 9.429896, a_2 = 6.393164, b = 2.118304\n",
      "\tgrad = 2.859362\n",
      "rate = 0.003440\n",
      "Step 388 / 1000, loss = -7899.590177\n",
      "a_1 = 9.437023, a_2 = 6.398008, b = 2.119910\n",
      "\tgrad = 2.554666\n",
      "rate = 0.003431\n",
      "Step 389 / 1000, loss = -7899.758972\n",
      "a_1 = 9.445026, a_2 = 6.403712, b = 2.121720\n",
      "\tgrad = 2.919257\n",
      "rate = 0.003423\n",
      "Step 390 / 1000, loss = -7899.917322\n",
      "a_1 = 9.452585, a_2 = 6.408989, b = 2.123458\n",
      "\tgrad = 2.747556\n",
      "rate = 0.003415\n",
      "Step 391 / 1000, loss = -7900.070569\n",
      "a_1 = 9.460239, a_2 = 6.413899, b = 2.125093\n",
      "\tgrad = 2.712271\n",
      "rate = 0.003406\n",
      "Step 392 / 1000, loss = -7900.228077\n",
      "a_1 = 9.467707, a_2 = 6.419274, b = 2.126813\n",
      "\tgrad = 2.754669\n",
      "rate = 0.003398\n",
      "Step 393 / 1000, loss = -7900.378104\n",
      "a_1 = 9.474831, a_2 = 6.424363, b = 2.128484\n",
      "\tgrad = 2.629421\n",
      "rate = 0.003390\n",
      "Step 394 / 1000, loss = -7900.530060\n",
      "a_1 = 9.482130, a_2 = 6.429519, b = 2.130148\n",
      "\tgrad = 2.687976\n",
      "rate = 0.003382\n",
      "Step 395 / 1000, loss = -7900.665021\n",
      "a_1 = 9.488568, a_2 = 6.434071, b = 2.131686\n",
      "\tgrad = 2.381238\n",
      "rate = 0.003373\n",
      "Step 396 / 1000, loss = -7900.815164\n",
      "a_1 = 9.496039, a_2 = 6.438889, b = 2.133395\n",
      "\tgrad = 2.690152\n",
      "rate = 0.003365\n",
      "Step 397 / 1000, loss = -7900.960864\n",
      "a_1 = 9.503159, a_2 = 6.443728, b = 2.135044\n",
      "\tgrad = 2.610579\n",
      "rate = 0.003357\n",
      "Step 398 / 1000, loss = -7901.115631\n",
      "a_1 = 9.510863, a_2 = 6.448881, b = 2.136725\n",
      "\tgrad = 2.812400\n",
      "rate = 0.003349\n",
      "Step 399 / 1000, loss = -7901.266910\n",
      "a_1 = 9.518169, a_2 = 6.454123, b = 2.138386\n",
      "\tgrad = 2.736900\n",
      "rate = 0.003341\n",
      "Step 400 / 1000, loss = -7901.408847\n",
      "a_1 = 9.525026, a_2 = 6.459087, b = 2.139932\n",
      "\tgrad = 2.581578\n",
      "rate = 0.003333\n",
      "Step 401 / 1000, loss = -7901.556007\n",
      "a_1 = 9.532088, a_2 = 6.464157, b = 2.141632\n",
      "\tgrad = 2.663813\n",
      "rate = 0.003325\n",
      "Step 402 / 1000, loss = -7901.689595\n",
      "a_1 = 9.538901, a_2 = 6.468435, b = 2.143168\n",
      "\tgrad = 2.468755\n",
      "rate = 0.003318\n",
      "Step 403 / 1000, loss = -7901.835067\n",
      "a_1 = 9.545952, a_2 = 6.473476, b = 2.144826\n",
      "\tgrad = 2.666126\n",
      "rate = 0.003310\n",
      "Step 404 / 1000, loss = -7901.970223\n",
      "a_1 = 9.552298, a_2 = 6.478383, b = 2.146358\n",
      "\tgrad = 2.473362\n",
      "rate = 0.003302\n",
      "Step 405 / 1000, loss = -7902.102153\n",
      "a_1 = 9.559083, a_2 = 6.482672, b = 2.147850\n",
      "\tgrad = 2.478644\n",
      "rate = 0.003294\n",
      "Step 406 / 1000, loss = -7902.247030\n",
      "a_1 = 9.566145, a_2 = 6.487779, b = 2.149477\n",
      "\tgrad = 2.697696\n",
      "rate = 0.003286\n",
      "Step 407 / 1000, loss = -7902.385186\n",
      "a_1 = 9.572961, a_2 = 6.492539, b = 2.151070\n",
      "\tgrad = 2.581571\n",
      "rate = 0.003279\n",
      "Step 408 / 1000, loss = -7902.519811\n",
      "a_1 = 9.579745, a_2 = 6.497063, b = 2.152630\n",
      "\tgrad = 2.538129\n",
      "rate = 0.003271\n",
      "Step 409 / 1000, loss = -7902.660050\n",
      "a_1 = 9.586950, a_2 = 6.501726, b = 2.154226\n",
      "\tgrad = 2.674837\n",
      "rate = 0.003263\n",
      "Step 410 / 1000, loss = -7902.802807\n",
      "a_1 = 9.594027, a_2 = 6.506753, b = 2.155838\n",
      "\tgrad = 2.711886\n",
      "rate = 0.003256\n",
      "Step 411 / 1000, loss = -7902.938500\n",
      "a_1 = 9.601038, a_2 = 6.511297, b = 2.157374\n",
      "\tgrad = 2.615140\n",
      "rate = 0.003248\n",
      "Step 412 / 1000, loss = -7903.076785\n",
      "a_1 = 9.607965, a_2 = 6.516096, b = 2.158975\n",
      "\tgrad = 2.646910\n",
      "rate = 0.003241\n",
      "Step 413 / 1000, loss = -7903.211410\n",
      "a_1 = 9.614524, a_2 = 6.521003, b = 2.160507\n",
      "\tgrad = 2.577439\n",
      "rate = 0.003233\n",
      "Step 414 / 1000, loss = -7903.345647\n",
      "a_1 = 9.621144, a_2 = 6.525803, b = 2.162065\n",
      "\tgrad = 2.580647\n",
      "rate = 0.003226\n",
      "Step 415 / 1000, loss = -7903.485903\n",
      "a_1 = 9.628211, a_2 = 6.530772, b = 2.163655\n",
      "\tgrad = 2.729423\n",
      "rate = 0.003218\n",
      "Step 416 / 1000, loss = -7903.627558\n",
      "a_1 = 9.635399, a_2 = 6.535751, b = 2.165277\n",
      "\tgrad = 2.769426\n",
      "rate = 0.003211\n",
      "Step 417 / 1000, loss = -7903.758928\n",
      "a_1 = 9.641965, a_2 = 6.540422, b = 2.166821\n",
      "\tgrad = 2.561034\n",
      "rate = 0.003204\n",
      "Step 418 / 1000, loss = -7903.893198\n",
      "a_1 = 9.648602, a_2 = 6.545304, b = 2.168390\n",
      "\tgrad = 2.624001\n",
      "rate = 0.003196\n",
      "Step 419 / 1000, loss = -7904.027281\n",
      "a_1 = 9.655363, a_2 = 6.550068, b = 2.169969\n",
      "\tgrad = 2.640453\n",
      "rate = 0.003189\n",
      "Step 420 / 1000, loss = -7904.170253\n",
      "a_1 = 9.662487, a_2 = 6.555307, b = 2.171620\n",
      "\tgrad = 2.827112\n",
      "rate = 0.003182\n",
      "Step 421 / 1000, loss = -7904.314135\n",
      "a_1 = 9.670158, a_2 = 6.560135, b = 2.173296\n",
      "\tgrad = 2.903340\n",
      "rate = 0.003175\n",
      "Step 422 / 1000, loss = -7904.448943\n",
      "a_1 = 9.677008, a_2 = 6.564971, b = 2.174880\n",
      "\tgrad = 2.694124\n",
      "rate = 0.003167\n",
      "Step 423 / 1000, loss = -7904.589517\n",
      "a_1 = 9.683986, a_2 = 6.570191, b = 2.176533\n",
      "\tgrad = 2.806753\n",
      "rate = 0.003160\n",
      "Step 424 / 1000, loss = -7904.723771\n",
      "a_1 = 9.690721, a_2 = 6.575095, b = 2.178141\n",
      "\tgrad = 2.690883\n",
      "rate = 0.003153\n",
      "Step 425 / 1000, loss = -7904.853751\n",
      "a_1 = 9.697312, a_2 = 6.579815, b = 2.179692\n",
      "\tgrad = 2.623598\n",
      "rate = 0.003146\n",
      "Step 426 / 1000, loss = -7904.981309\n",
      "a_1 = 9.703929, a_2 = 6.584368, b = 2.181195\n",
      "\tgrad = 2.603288\n",
      "rate = 0.003139\n",
      "Step 427 / 1000, loss = -7905.106460\n",
      "a_1 = 9.710544, a_2 = 6.588739, b = 2.182677\n",
      "\tgrad = 2.575397\n",
      "rate = 0.003132\n",
      "Step 428 / 1000, loss = -7905.238869\n",
      "a_1 = 9.717386, a_2 = 6.593596, b = 2.184205\n",
      "\tgrad = 2.729040\n",
      "rate = 0.003125\n",
      "Step 429 / 1000, loss = -7905.371542\n",
      "a_1 = 9.724383, a_2 = 6.598328, b = 2.185758\n",
      "\tgrad = 2.754415\n",
      "rate = 0.003118\n",
      "Step 430 / 1000, loss = -7905.506203\n",
      "a_1 = 9.731378, a_2 = 6.603225, b = 2.187354\n",
      "\tgrad = 2.792197\n",
      "rate = 0.003111\n",
      "Step 431 / 1000, loss = -7905.637940\n",
      "a_1 = 9.737899, a_2 = 6.608263, b = 2.188962\n",
      "\tgrad = 2.704567\n",
      "rate = 0.003104\n",
      "Step 432 / 1000, loss = -7905.767340\n",
      "a_1 = 9.744647, a_2 = 6.612951, b = 2.190526\n",
      "\tgrad = 2.700651\n",
      "rate = 0.003097\n",
      "Step 433 / 1000, loss = -7905.891268\n",
      "a_1 = 9.751299, a_2 = 6.617324, b = 2.192006\n",
      "\tgrad = 2.619894\n",
      "rate = 0.003091\n",
      "Step 434 / 1000, loss = -7906.024008\n",
      "a_1 = 9.758334, a_2 = 6.622114, b = 2.193594\n",
      "\tgrad = 2.807527\n",
      "rate = 0.003084\n",
      "Step 435 / 1000, loss = -7906.150856\n",
      "a_1 = 9.764950, a_2 = 6.626822, b = 2.195108\n",
      "\tgrad = 2.684360\n",
      "rate = 0.003077\n",
      "Step 436 / 1000, loss = -7906.274394\n",
      "a_1 = 9.771411, a_2 = 6.631461, b = 2.196554\n",
      "\tgrad = 2.633351\n",
      "rate = 0.003070\n",
      "Step 437 / 1000, loss = -7906.400376\n",
      "a_1 = 9.778084, a_2 = 6.636100, b = 2.198055\n",
      "\tgrad = 2.697846\n",
      "rate = 0.003063\n",
      "Step 438 / 1000, loss = -7906.526309\n",
      "a_1 = 9.784861, a_2 = 6.640677, b = 2.199550\n",
      "\tgrad = 2.719412\n",
      "rate = 0.003057\n",
      "Step 439 / 1000, loss = -7906.641251\n",
      "a_1 = 9.790772, a_2 = 6.645060, b = 2.200956\n",
      "\tgrad = 2.456277\n",
      "rate = 0.003050\n",
      "Step 440 / 1000, loss = -7906.758753\n",
      "a_1 = 9.796904, a_2 = 6.649503, b = 2.202380\n",
      "\tgrad = 2.531932\n",
      "rate = 0.003043\n",
      "Step 441 / 1000, loss = -7906.882421\n",
      "a_1 = 9.803563, a_2 = 6.654027, b = 2.203874\n",
      "\tgrad = 2.695950\n",
      "rate = 0.003037\n",
      "Step 442 / 1000, loss = -7907.011844\n",
      "a_1 = 9.810724, a_2 = 6.658570, b = 2.205465\n",
      "\tgrad = 2.847361\n",
      "rate = 0.003030\n",
      "Step 443 / 1000, loss = -7907.135475\n",
      "a_1 = 9.817317, a_2 = 6.663111, b = 2.207016\n",
      "\tgrad = 2.696876\n",
      "rate = 0.003024\n",
      "Step 444 / 1000, loss = -7907.267607\n",
      "a_1 = 9.824355, a_2 = 6.668111, b = 2.208607\n",
      "\tgrad = 2.909458\n",
      "rate = 0.003017\n",
      "Step 445 / 1000, loss = -7907.390217\n",
      "a_1 = 9.830844, a_2 = 6.672797, b = 2.210094\n",
      "\tgrad = 2.704057\n",
      "rate = 0.003011\n",
      "Step 446 / 1000, loss = -7907.510088\n",
      "a_1 = 9.837142, a_2 = 6.677408, b = 2.211572\n",
      "\tgrad = 2.644145\n",
      "rate = 0.003004\n",
      "Step 447 / 1000, loss = -7907.636585\n",
      "a_1 = 9.843941, a_2 = 6.682186, b = 2.213116\n",
      "\tgrad = 2.819569\n",
      "rate = 0.002998\n",
      "Step 448 / 1000, loss = -7907.756758\n",
      "a_1 = 9.850424, a_2 = 6.686698, b = 2.214603\n",
      "\tgrad = 2.686674\n",
      "rate = 0.002991\n",
      "Step 449 / 1000, loss = -7907.873303\n",
      "a_1 = 9.856687, a_2 = 6.691130, b = 2.216038\n",
      "\tgrad = 2.614946\n",
      "rate = 0.002985\n",
      "Step 450 / 1000, loss = -7907.985643\n",
      "a_1 = 9.862950, a_2 = 6.695255, b = 2.217400\n",
      "\tgrad = 2.558925\n",
      "rate = 0.002979\n",
      "Step 451 / 1000, loss = -7908.110878\n",
      "a_1 = 9.869685, a_2 = 6.700095, b = 2.218924\n",
      "\tgrad = 2.836914\n",
      "rate = 0.002972\n",
      "Step 452 / 1000, loss = -7908.233289\n",
      "a_1 = 9.876477, a_2 = 6.704539, b = 2.220491\n",
      "\tgrad = 2.786946\n",
      "rate = 0.002966\n",
      "Step 453 / 1000, loss = -7908.355563\n",
      "a_1 = 9.883304, a_2 = 6.709089, b = 2.221979\n",
      "\tgrad = 2.817090\n",
      "rate = 0.002960\n",
      "Step 454 / 1000, loss = -7908.479160\n",
      "a_1 = 9.890113, a_2 = 6.713725, b = 2.223530\n",
      "\tgrad = 2.838010\n",
      "rate = 0.002954\n",
      "Step 455 / 1000, loss = -7908.597011\n",
      "a_1 = 9.896384, a_2 = 6.718340, b = 2.225030\n",
      "\tgrad = 2.690134\n",
      "rate = 0.002947\n",
      "Step 456 / 1000, loss = -7908.710945\n",
      "a_1 = 9.902456, a_2 = 6.722836, b = 2.226468\n",
      "\tgrad = 2.615030\n",
      "rate = 0.002941\n",
      "Step 457 / 1000, loss = -7908.827658\n",
      "a_1 = 9.908818, a_2 = 6.727322, b = 2.227950\n",
      "\tgrad = 2.700055\n",
      "rate = 0.002935\n",
      "Step 458 / 1000, loss = -7908.943679\n",
      "a_1 = 9.914981, a_2 = 6.732013, b = 2.229389\n",
      "\tgrad = 2.689520\n",
      "rate = 0.002929\n",
      "Step 459 / 1000, loss = -7909.055393\n",
      "a_1 = 9.921000, a_2 = 6.736398, b = 2.230821\n",
      "\tgrad = 2.594597\n",
      "rate = 0.002923\n",
      "Step 460 / 1000, loss = -7909.175503\n",
      "a_1 = 9.927799, a_2 = 6.740962, b = 2.232285\n",
      "\tgrad = 2.852025\n",
      "rate = 0.002917\n",
      "Step 461 / 1000, loss = -7909.285887\n",
      "a_1 = 9.934001, a_2 = 6.745099, b = 2.233705\n",
      "\tgrad = 2.607669\n",
      "rate = 0.002911\n",
      "Step 462 / 1000, loss = -7909.401487\n",
      "a_1 = 9.940597, a_2 = 6.749461, b = 2.235134\n",
      "\tgrad = 2.766538\n",
      "rate = 0.002905\n",
      "Step 463 / 1000, loss = -7909.511141\n",
      "a_1 = 9.946469, a_2 = 6.753902, b = 2.236534\n",
      "\tgrad = 2.585487\n",
      "rate = 0.002899\n",
      "Step 464 / 1000, loss = -7909.620655\n",
      "a_1 = 9.952235, a_2 = 6.758401, b = 2.237963\n",
      "\tgrad = 2.576096\n",
      "rate = 0.002893\n",
      "Step 465 / 1000, loss = -7909.731740\n",
      "a_1 = 9.958352, a_2 = 6.762826, b = 2.239360\n",
      "\tgrad = 2.660064\n",
      "rate = 0.002887\n",
      "Step 466 / 1000, loss = -7909.838395\n",
      "a_1 = 9.964553, a_2 = 6.766748, b = 2.240731\n",
      "\tgrad = 2.590959\n",
      "rate = 0.002881\n",
      "Step 467 / 1000, loss = -7909.951757\n",
      "a_1 = 9.971148, a_2 = 6.771001, b = 2.242149\n",
      "\tgrad = 2.774189\n",
      "rate = 0.002875\n",
      "Step 468 / 1000, loss = -7910.060783\n",
      "a_1 = 9.977216, a_2 = 6.775280, b = 2.243566\n",
      "\tgrad = 2.634705\n",
      "rate = 0.002869\n",
      "Step 469 / 1000, loss = -7910.163274\n",
      "a_1 = 9.982841, a_2 = 6.779402, b = 2.244894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad = 2.479672\n",
      "rate = 0.002863\n",
      "Step 470 / 1000, loss = -7910.279969\n",
      "a_1 = 9.989309, a_2 = 6.784121, b = 2.246371\n",
      "\tgrad = 2.849440\n",
      "rate = 0.002857\n",
      "Step 471 / 1000, loss = -7910.388295\n",
      "a_1 = 9.995089, a_2 = 6.788760, b = 2.247726\n",
      "\tgrad = 2.642274\n",
      "rate = 0.002851\n",
      "Step 472 / 1000, loss = -7910.497228\n",
      "a_1 = 10.001379, a_2 = 6.792930, b = 2.249134\n",
      "\tgrad = 2.698229\n",
      "rate = 0.002846\n",
      "Step 473 / 1000, loss = -7910.604998\n",
      "a_1 = 10.007609, a_2 = 6.797124, b = 2.250497\n",
      "\tgrad = 2.687703\n",
      "rate = 0.002840\n",
      "Step 474 / 1000, loss = -7910.709057\n",
      "a_1 = 10.013413, a_2 = 6.801355, b = 2.251835\n",
      "\tgrad = 2.577805\n",
      "rate = 0.002834\n",
      "Step 475 / 1000, loss = -7910.820542\n",
      "a_1 = 10.019719, a_2 = 6.805767, b = 2.253306\n",
      "\tgrad = 2.770617\n",
      "rate = 0.002828\n",
      "Step 476 / 1000, loss = -7910.929529\n",
      "a_1 = 10.026061, a_2 = 6.809995, b = 2.254711\n",
      "\tgrad = 2.745914\n",
      "rate = 0.002823\n",
      "Step 477 / 1000, loss = -7911.041983\n",
      "a_1 = 10.032377, a_2 = 6.814602, b = 2.256156\n",
      "\tgrad = 2.822111\n",
      "rate = 0.002817\n",
      "Step 478 / 1000, loss = -7911.141391\n",
      "a_1 = 10.038017, a_2 = 6.818575, b = 2.257475\n",
      "\tgrad = 2.498382\n",
      "rate = 0.002811\n",
      "Step 479 / 1000, loss = -7911.250344\n",
      "a_1 = 10.044066, a_2 = 6.823069, b = 2.258922\n",
      "\tgrad = 2.735364\n",
      "rate = 0.002806\n",
      "Step 480 / 1000, loss = -7911.356607\n",
      "a_1 = 10.050143, a_2 = 6.827315, b = 2.260334\n",
      "\tgrad = 2.694953\n",
      "rate = 0.002800\n",
      "Step 481 / 1000, loss = -7911.449940\n",
      "a_1 = 10.055287, a_2 = 6.831243, b = 2.261572\n",
      "\tgrad = 2.358372\n",
      "rate = 0.002794\n",
      "Step 482 / 1000, loss = -7911.560313\n",
      "a_1 = 10.061511, a_2 = 6.835802, b = 2.263025\n",
      "\tgrad = 2.814714\n",
      "rate = 0.002789\n",
      "Step 483 / 1000, loss = -7911.670056\n",
      "a_1 = 10.067954, a_2 = 6.840174, b = 2.264438\n",
      "\tgrad = 2.843386\n",
      "rate = 0.002783\n",
      "Step 484 / 1000, loss = -7911.777428\n",
      "a_1 = 10.074103, a_2 = 6.844517, b = 2.265883\n",
      "\tgrad = 2.759712\n",
      "rate = 0.002778\n",
      "Step 485 / 1000, loss = -7911.877567\n",
      "a_1 = 10.079654, a_2 = 6.848741, b = 2.267241\n",
      "\tgrad = 2.563276\n",
      "rate = 0.002772\n",
      "Step 486 / 1000, loss = -7911.979711\n",
      "a_1 = 10.085551, a_2 = 6.852890, b = 2.268605\n",
      "\tgrad = 2.652230\n",
      "rate = 0.002767\n",
      "Step 487 / 1000, loss = -7912.085721\n",
      "a_1 = 10.091906, a_2 = 6.856977, b = 2.270036\n",
      "\tgrad = 2.784692\n",
      "rate = 0.002761\n",
      "Step 488 / 1000, loss = -7912.192201\n",
      "a_1 = 10.098039, a_2 = 6.861384, b = 2.271444\n",
      "\tgrad = 2.787844\n",
      "rate = 0.002756\n",
      "Step 489 / 1000, loss = -7912.295718\n",
      "a_1 = 10.104023, a_2 = 6.865625, b = 2.272841\n",
      "\tgrad = 2.714560\n",
      "rate = 0.002750\n",
      "Step 490 / 1000, loss = -7912.401237\n",
      "a_1 = 10.110306, a_2 = 6.869838, b = 2.274244\n",
      "\tgrad = 2.802543\n",
      "rate = 0.002745\n",
      "Step 491 / 1000, loss = -7912.505381\n",
      "a_1 = 10.116287, a_2 = 6.874285, b = 2.275592\n",
      "\tgrad = 2.764376\n",
      "rate = 0.002740\n",
      "Step 492 / 1000, loss = -7912.604272\n",
      "a_1 = 10.121939, a_2 = 6.878540, b = 2.276880\n",
      "\tgrad = 2.630046\n",
      "rate = 0.002734\n",
      "Step 493 / 1000, loss = -7912.697921\n",
      "a_1 = 10.127539, a_2 = 6.882374, b = 2.278091\n",
      "\tgrad = 2.526016\n",
      "rate = 0.002729\n",
      "Step 494 / 1000, loss = -7912.797230\n",
      "a_1 = 10.133409, a_2 = 6.886453, b = 2.279418\n",
      "\tgrad = 2.669207\n",
      "rate = 0.002724\n",
      "Step 495 / 1000, loss = -7912.899037\n",
      "a_1 = 10.139448, a_2 = 6.890629, b = 2.280782\n",
      "\tgrad = 2.747189\n",
      "rate = 0.002718\n",
      "Step 496 / 1000, loss = -7912.994353\n",
      "a_1 = 10.145161, a_2 = 6.894509, b = 2.282058\n",
      "\tgrad = 2.588305\n",
      "rate = 0.002713\n",
      "Step 497 / 1000, loss = -7913.094904\n",
      "a_1 = 10.151109, a_2 = 6.898717, b = 2.283390\n",
      "\tgrad = 2.735535\n",
      "rate = 0.002708\n",
      "Step 498 / 1000, loss = -7913.197132\n",
      "a_1 = 10.157180, a_2 = 6.902926, b = 2.284787\n",
      "\tgrad = 2.781434\n",
      "rate = 0.002703\n",
      "Step 499 / 1000, loss = -7913.303921\n",
      "a_1 = 10.163496, a_2 = 6.907411, b = 2.286222\n",
      "\tgrad = 2.920699\n",
      "rate = 0.002697\n",
      "Step 500 / 1000, loss = -7913.402078\n",
      "a_1 = 10.169221, a_2 = 6.911580, b = 2.287571\n",
      "\tgrad = 2.677883\n",
      "rate = 0.002692\n",
      "Step 501 / 1000, loss = -7913.498638\n",
      "a_1 = 10.175136, a_2 = 6.915484, b = 2.288872\n",
      "\tgrad = 2.681488\n",
      "rate = 0.002687\n",
      "Step 502 / 1000, loss = -7913.599104\n",
      "a_1 = 10.180975, a_2 = 6.919809, b = 2.290255\n",
      "\tgrad = 2.757943\n",
      "rate = 0.002682\n",
      "Step 503 / 1000, loss = -7913.698795\n",
      "a_1 = 10.187029, a_2 = 6.923922, b = 2.291604\n",
      "\tgrad = 2.780104\n",
      "rate = 0.002677\n",
      "Step 504 / 1000, loss = -7913.789614\n",
      "a_1 = 10.192445, a_2 = 6.927730, b = 2.292863\n",
      "\tgrad = 2.522541\n",
      "rate = 0.002672\n",
      "Step 505 / 1000, loss = -7913.889435\n",
      "a_1 = 10.198531, a_2 = 6.931893, b = 2.294199\n",
      "\tgrad = 2.810221\n",
      "rate = 0.002667\n",
      "Step 506 / 1000, loss = -7913.983397\n",
      "a_1 = 10.204214, a_2 = 6.935765, b = 2.295522\n",
      "\tgrad = 2.630913\n",
      "rate = 0.002662\n",
      "Step 507 / 1000, loss = -7914.078667\n",
      "a_1 = 10.209836, a_2 = 6.939926, b = 2.296813\n",
      "\tgrad = 2.677393\n",
      "rate = 0.002657\n",
      "Step 508 / 1000, loss = -7914.180993\n",
      "a_1 = 10.215846, a_2 = 6.944472, b = 2.298184\n",
      "\tgrad = 2.888705\n",
      "rate = 0.002652\n",
      "Step 509 / 1000, loss = -7914.271450\n",
      "a_1 = 10.221339, a_2 = 6.948270, b = 2.299438\n",
      "\tgrad = 2.567589\n",
      "rate = 0.002647\n",
      "Step 510 / 1000, loss = -7914.368982\n",
      "a_1 = 10.227300, a_2 = 6.952397, b = 2.300764\n",
      "\tgrad = 2.789898\n",
      "rate = 0.002642\n",
      "Step 511 / 1000, loss = -7914.464157\n",
      "a_1 = 10.233093, a_2 = 6.956473, b = 2.302053\n",
      "\tgrad = 2.731134\n",
      "rate = 0.002637\n",
      "Step 512 / 1000, loss = -7914.556304\n",
      "a_1 = 10.238733, a_2 = 6.960328, b = 2.303351\n",
      "\tgrad = 2.642271\n",
      "rate = 0.002632\n",
      "Step 513 / 1000, loss = -7914.649210\n",
      "a_1 = 10.244346, a_2 = 6.964366, b = 2.304622\n",
      "\tgrad = 2.676505\n",
      "rate = 0.002627\n",
      "Step 514 / 1000, loss = -7914.740278\n",
      "a_1 = 10.249804, a_2 = 6.968318, b = 2.305907\n",
      "\tgrad = 2.616498\n",
      "rate = 0.002622\n",
      "Step 515 / 1000, loss = -7914.830570\n",
      "a_1 = 10.255421, a_2 = 6.972072, b = 2.307176\n",
      "\tgrad = 2.626837\n",
      "rate = 0.002617\n",
      "Step 516 / 1000, loss = -7914.922713\n",
      "a_1 = 10.261069, a_2 = 6.976013, b = 2.308463\n",
      "\tgrad = 2.682580\n",
      "rate = 0.002612\n",
      "Step 517 / 1000, loss = -7915.015190\n",
      "a_1 = 10.266690, a_2 = 6.980071, b = 2.309733\n",
      "\tgrad = 2.703619\n",
      "rate = 0.002607\n",
      "Step 518 / 1000, loss = -7915.112013\n",
      "a_1 = 10.272540, a_2 = 6.984362, b = 2.311071\n",
      "\tgrad = 2.834647\n",
      "rate = 0.002602\n",
      "Step 519 / 1000, loss = -7915.206733\n",
      "a_1 = 10.278549, a_2 = 6.988262, b = 2.312408\n",
      "\tgrad = 2.805992\n",
      "rate = 0.002597\n",
      "Step 520 / 1000, loss = -7915.296862\n",
      "a_1 = 10.283917, a_2 = 6.992343, b = 2.313668\n",
      "\tgrad = 2.645663\n",
      "rate = 0.002593\n",
      "Step 521 / 1000, loss = -7915.386927\n",
      "a_1 = 10.289320, a_2 = 6.996419, b = 2.314918\n",
      "\tgrad = 2.659597\n",
      "rate = 0.002588\n",
      "Step 522 / 1000, loss = -7915.477483\n",
      "a_1 = 10.294912, a_2 = 7.000367, b = 2.316186\n",
      "\tgrad = 2.695414\n",
      "rate = 0.002583\n",
      "Step 523 / 1000, loss = -7915.569648\n",
      "a_1 = 10.300609, a_2 = 7.004351, b = 2.317506\n",
      "\tgrad = 2.744316\n",
      "rate = 0.002578\n",
      "Step 524 / 1000, loss = -7915.660549\n",
      "a_1 = 10.306225, a_2 = 7.008315, b = 2.318801\n",
      "\tgrad = 2.718087\n",
      "rate = 0.002574\n",
      "Step 525 / 1000, loss = -7915.754922\n",
      "a_1 = 10.312197, a_2 = 7.012351, b = 2.320126\n",
      "\tgrad = 2.853028\n",
      "rate = 0.002569\n",
      "Step 526 / 1000, loss = -7915.841529\n",
      "a_1 = 10.317640, a_2 = 7.016084, b = 2.321357\n",
      "\tgrad = 2.618507\n",
      "rate = 0.002564\n",
      "Step 527 / 1000, loss = -7915.931107\n",
      "a_1 = 10.323306, a_2 = 7.019954, b = 2.322616\n",
      "\tgrad = 2.725676\n",
      "rate = 0.002559\n",
      "Step 528 / 1000, loss = -7916.018934\n",
      "a_1 = 10.328824, a_2 = 7.023861, b = 2.323817\n",
      "\tgrad = 2.687825\n",
      "rate = 0.002555\n",
      "Step 529 / 1000, loss = -7916.108181\n",
      "a_1 = 10.334342, a_2 = 7.027839, b = 2.325092\n",
      "\tgrad = 2.713945\n",
      "rate = 0.002550\n",
      "Step 530 / 1000, loss = -7916.192984\n",
      "a_1 = 10.339683, a_2 = 7.031501, b = 2.326329\n",
      "\tgrad = 2.590031\n",
      "rate = 0.002545\n",
      "Step 531 / 1000, loss = -7916.278763\n",
      "a_1 = 10.345078, a_2 = 7.035250, b = 2.327569\n",
      "\tgrad = 2.631200\n",
      "rate = 0.002541\n",
      "Step 532 / 1000, loss = -7916.371906\n",
      "a_1 = 10.350932, a_2 = 7.039410, b = 2.328878\n",
      "\tgrad = 2.878220\n",
      "rate = 0.002536\n",
      "Step 533 / 1000, loss = -7916.456818\n",
      "a_1 = 10.356144, a_2 = 7.043308, b = 2.330088\n",
      "\tgrad = 2.614964\n",
      "rate = 0.002532\n",
      "Step 534 / 1000, loss = -7916.544740\n",
      "a_1 = 10.361713, a_2 = 7.047223, b = 2.331329\n",
      "\tgrad = 2.738104\n",
      "rate = 0.002527\n",
      "Step 535 / 1000, loss = -7916.626834\n",
      "a_1 = 10.367023, a_2 = 7.050724, b = 2.332527\n",
      "\tgrad = 2.565725\n",
      "rate = 0.002523\n",
      "Step 536 / 1000, loss = -7916.714918\n",
      "a_1 = 10.372540, a_2 = 7.054639, b = 2.333829\n",
      "\tgrad = 2.736112\n",
      "rate = 0.002518\n",
      "Step 537 / 1000, loss = -7916.801569\n",
      "a_1 = 10.377984, a_2 = 7.058536, b = 2.335085\n",
      "\tgrad = 2.710077\n",
      "rate = 0.002513\n",
      "Step 538 / 1000, loss = -7916.891272\n",
      "a_1 = 10.383922, a_2 = 7.062330, b = 2.336373\n",
      "\tgrad = 2.855147\n",
      "rate = 0.002509\n",
      "Step 539 / 1000, loss = -7916.972950\n",
      "a_1 = 10.389006, a_2 = 7.066048, b = 2.337577\n",
      "\tgrad = 2.560492\n",
      "rate = 0.002504\n",
      "Step 540 / 1000, loss = -7917.061909\n",
      "a_1 = 10.394526, a_2 = 7.070202, b = 2.338850\n",
      "\tgrad = 2.809717\n",
      "rate = 0.002500\n",
      "Step 541 / 1000, loss = -7917.148546\n",
      "a_1 = 10.399995, a_2 = 7.074138, b = 2.340112\n",
      "\tgrad = 2.747097\n",
      "rate = 0.002496\n",
      "Step 542 / 1000, loss = -7917.231997\n",
      "a_1 = 10.405259, a_2 = 7.077913, b = 2.341350\n",
      "\tgrad = 2.647424\n",
      "rate = 0.002491\n",
      "Step 543 / 1000, loss = -7917.319057\n",
      "a_1 = 10.410759, a_2 = 7.081968, b = 2.342581\n",
      "\tgrad = 2.792178\n",
      "rate = 0.002487\n",
      "Step 544 / 1000, loss = -7917.402077\n",
      "a_1 = 10.416248, a_2 = 7.085558, b = 2.343793\n",
      "\tgrad = 2.686987\n",
      "rate = 0.002482\n",
      "Step 545 / 1000, loss = -7917.481293\n",
      "a_1 = 10.421259, a_2 = 7.089154, b = 2.344982\n",
      "\tgrad = 2.534948\n",
      "rate = 0.002478\n",
      "Step 546 / 1000, loss = -7917.567044\n",
      "a_1 = 10.426838, a_2 = 7.092995, b = 2.346226\n",
      "\tgrad = 2.784231\n",
      "rate = 0.002473\n",
      "Step 547 / 1000, loss = -7917.650602\n",
      "a_1 = 10.432148, a_2 = 7.096845, b = 2.347456\n",
      "\tgrad = 2.702380\n",
      "rate = 0.002469\n",
      "Step 548 / 1000, loss = -7917.737898\n",
      "a_1 = 10.437874, a_2 = 7.100718, b = 2.348740\n",
      "\tgrad = 2.852826\n",
      "rate = 0.002465\n",
      "Step 549 / 1000, loss = -7917.821522\n",
      "a_1 = 10.443350, a_2 = 7.104443, b = 2.349977\n",
      "\tgrad = 2.738287\n",
      "rate = 0.002460\n",
      "Step 550 / 1000, loss = -7917.899852\n",
      "a_1 = 10.448326, a_2 = 7.108093, b = 2.351137\n",
      "\tgrad = 2.556302\n",
      "rate = 0.002456\n",
      "Step 551 / 1000, loss = -7917.981132\n",
      "a_1 = 10.453562, a_2 = 7.111826, b = 2.352341\n",
      "\tgrad = 2.668412\n",
      "rate = 0.002452\n",
      "Step 552 / 1000, loss = -7918.065770\n",
      "a_1 = 10.458878, a_2 = 7.115870, b = 2.353589\n",
      "\tgrad = 2.776140\n",
      "rate = 0.002448\n",
      "Step 553 / 1000, loss = -7918.144949\n",
      "a_1 = 10.464054, a_2 = 7.119462, b = 2.354766\n",
      "\tgrad = 2.623135\n",
      "rate = 0.002443\n",
      "Step 554 / 1000, loss = -7918.226270\n",
      "a_1 = 10.469210, a_2 = 7.123339, b = 2.355964\n",
      "\tgrad = 2.690139\n",
      "rate = 0.002439\n",
      "Step 555 / 1000, loss = -7918.305126\n",
      "a_1 = 10.474182, a_2 = 7.127067, b = 2.357167\n",
      "\tgrad = 2.600030\n",
      "rate = 0.002435\n",
      "Step 556 / 1000, loss = -7918.390849\n",
      "a_1 = 10.479781, a_2 = 7.131043, b = 2.358426\n",
      "\tgrad = 2.872151\n",
      "rate = 0.002431\n",
      "Step 557 / 1000, loss = -7918.471640\n",
      "a_1 = 10.485085, a_2 = 7.134704, b = 2.359656\n",
      "\tgrad = 2.704430\n",
      "rate = 0.002426\n",
      "Step 558 / 1000, loss = -7918.547152\n",
      "a_1 = 10.489933, a_2 = 7.138292, b = 2.360780\n",
      "\tgrad = 2.532548\n",
      "rate = 0.002422\n",
      "Step 559 / 1000, loss = -7918.626401\n",
      "a_1 = 10.494945, a_2 = 7.142082, b = 2.361994\n",
      "\tgrad = 2.647073\n",
      "rate = 0.002418\n",
      "Step 560 / 1000, loss = -7918.708860\n",
      "a_1 = 10.500286, a_2 = 7.145957, b = 2.363239\n",
      "\tgrad = 2.781985\n",
      "rate = 0.002414\n",
      "Step 561 / 1000, loss = -7918.780390\n",
      "a_1 = 10.505024, a_2 = 7.149206, b = 2.364336\n",
      "\tgrad = 2.427090\n",
      "rate = 0.002410\n",
      "Step 562 / 1000, loss = -7918.861474\n",
      "a_1 = 10.510311, a_2 = 7.153081, b = 2.365524\n",
      "\tgrad = 2.769217\n",
      "rate = 0.002405\n",
      "Step 563 / 1000, loss = -7918.942351\n",
      "a_1 = 10.515634, a_2 = 7.156803, b = 2.366773\n",
      "\tgrad = 2.754679\n",
      "rate = 0.002401\n",
      "Step 564 / 1000, loss = -7919.022117\n",
      "a_1 = 10.520951, a_2 = 7.160437, b = 2.368000\n",
      "\tgrad = 2.734665\n",
      "rate = 0.002397\n",
      "Step 565 / 1000, loss = -7919.100090\n",
      "a_1 = 10.526340, a_2 = 7.163911, b = 2.369151\n",
      "\tgrad = 2.722003\n",
      "rate = 0.002393\n",
      "Step 566 / 1000, loss = -7919.181077\n",
      "a_1 = 10.531764, a_2 = 7.167646, b = 2.370377\n",
      "\tgrad = 2.804040\n",
      "rate = 0.002389\n",
      "Step 567 / 1000, loss = -7919.258164\n",
      "a_1 = 10.536800, a_2 = 7.171329, b = 2.371548\n",
      "\tgrad = 2.661657\n",
      "rate = 0.002385\n",
      "Step 568 / 1000, loss = -7919.335771\n",
      "a_1 = 10.541949, a_2 = 7.174993, b = 2.372719\n",
      "\tgrad = 2.699196\n",
      "rate = 0.002381\n",
      "Step 569 / 1000, loss = -7919.413734\n",
      "a_1 = 10.547104, a_2 = 7.178631, b = 2.373938\n",
      "\tgrad = 2.703476\n",
      "rate = 0.002377\n",
      "Step 570 / 1000, loss = -7919.492411\n",
      "a_1 = 10.552315, a_2 = 7.182371, b = 2.375134\n",
      "\tgrad = 2.749897\n",
      "rate = 0.002373\n",
      "Step 571 / 1000, loss = -7919.566688\n",
      "a_1 = 10.557217, a_2 = 7.185907, b = 2.376278\n",
      "\tgrad = 2.596977\n",
      "rate = 0.002369\n",
      "Step 572 / 1000, loss = -7919.646980\n",
      "a_1 = 10.562487, a_2 = 7.189757, b = 2.377525\n",
      "\tgrad = 2.809632\n",
      "rate = 0.002365\n",
      "Step 573 / 1000, loss = -7919.724153\n",
      "a_1 = 10.567601, a_2 = 7.193413, b = 2.378731\n",
      "\tgrad = 2.711362\n",
      "rate = 0.002361\n",
      "Step 574 / 1000, loss = -7919.805571\n",
      "a_1 = 10.573162, a_2 = 7.197149, b = 2.379994\n",
      "\tgrad = 2.892371\n",
      "rate = 0.002357\n",
      "Step 575 / 1000, loss = -7919.881473\n",
      "a_1 = 10.578335, a_2 = 7.200623, b = 2.381192\n",
      "\tgrad = 2.696644\n",
      "rate = 0.002353\n",
      "Step 576 / 1000, loss = -7919.956923\n",
      "a_1 = 10.583399, a_2 = 7.204210, b = 2.382357\n",
      "\tgrad = 2.688173\n",
      "rate = 0.002349\n",
      "Step 577 / 1000, loss = -7920.035482\n",
      "a_1 = 10.588661, a_2 = 7.208011, b = 2.383548\n",
      "\tgrad = 2.814208\n",
      "rate = 0.002345\n",
      "Step 578 / 1000, loss = -7920.109253\n",
      "a_1 = 10.593652, a_2 = 7.211468, b = 2.384712\n",
      "\tgrad = 2.640717\n",
      "rate = 0.002341\n",
      "Step 579 / 1000, loss = -7920.182724\n",
      "a_1 = 10.598778, a_2 = 7.214805, b = 2.385857\n",
      "\tgrad = 2.662277\n",
      "rate = 0.002337\n",
      "Step 580 / 1000, loss = -7920.254830\n",
      "a_1 = 10.603759, a_2 = 7.218106, b = 2.387000\n",
      "\tgrad = 2.607555\n",
      "rate = 0.002333\n",
      "Step 581 / 1000, loss = -7920.328116\n",
      "a_1 = 10.608678, a_2 = 7.221602, b = 2.388168\n",
      "\tgrad = 2.638583\n",
      "rate = 0.002329\n",
      "Step 582 / 1000, loss = -7920.401470\n",
      "a_1 = 10.613705, a_2 = 7.225029, b = 2.389330\n",
      "\tgrad = 2.663303\n",
      "rate = 0.002326\n",
      "Step 583 / 1000, loss = -7920.473700\n",
      "a_1 = 10.618603, a_2 = 7.228508, b = 2.390452\n",
      "\tgrad = 2.632446\n",
      "rate = 0.002322\n",
      "Step 584 / 1000, loss = -7920.548404\n",
      "a_1 = 10.623688, a_2 = 7.232076, b = 2.391627\n",
      "\tgrad = 2.727728\n",
      "rate = 0.002318\n",
      "Step 585 / 1000, loss = -7920.618849\n",
      "a_1 = 10.628576, a_2 = 7.235372, b = 2.392733\n",
      "\tgrad = 2.591803\n",
      "rate = 0.002314\n",
      "Step 586 / 1000, loss = -7920.693604\n",
      "a_1 = 10.633727, a_2 = 7.238909, b = 2.393911\n",
      "\tgrad = 2.752626\n",
      "rate = 0.002310\n",
      "Step 587 / 1000, loss = -7920.765707\n",
      "a_1 = 10.638408, a_2 = 7.242610, b = 2.395046\n",
      "\tgrad = 2.633685\n",
      "rate = 0.002306\n",
      "Step 588 / 1000, loss = -7920.843235\n",
      "a_1 = 10.643814, a_2 = 7.246341, b = 2.396218\n",
      "\tgrad = 2.897450\n",
      "rate = 0.002303\n",
      "Step 589 / 1000, loss = -7920.917341\n",
      "a_1 = 10.648922, a_2 = 7.249906, b = 2.397379\n",
      "\tgrad = 2.756296\n",
      "rate = 0.002299\n",
      "Step 590 / 1000, loss = -7920.994933\n",
      "a_1 = 10.654283, a_2 = 7.253682, b = 2.398572\n",
      "\tgrad = 2.904304\n",
      "rate = 0.002295\n",
      "Step 591 / 1000, loss = -7921.068085\n",
      "a_1 = 10.659523, a_2 = 7.257079, b = 2.399700\n",
      "\tgrad = 2.769478\n",
      "rate = 0.002291\n",
      "Step 592 / 1000, loss = -7921.136755\n",
      "a_1 = 10.664365, a_2 = 7.260292, b = 2.400793\n",
      "\tgrad = 2.584548\n",
      "rate = 0.002288\n",
      "Step 593 / 1000, loss = -7921.206746\n",
      "a_1 = 10.669109, a_2 = 7.263735, b = 2.401921\n",
      "\tgrad = 2.613769\n",
      "rate = 0.002284\n",
      "Step 594 / 1000, loss = -7921.280389\n",
      "a_1 = 10.674209, a_2 = 7.267339, b = 2.403070\n",
      "\tgrad = 2.784685\n",
      "rate = 0.002280\n",
      "Step 595 / 1000, loss = -7921.349979\n",
      "a_1 = 10.679077, a_2 = 7.270658, b = 2.404186\n",
      "\tgrad = 2.634558\n",
      "rate = 0.002276\n",
      "Step 596 / 1000, loss = -7921.420334\n",
      "a_1 = 10.684124, a_2 = 7.273896, b = 2.405322\n",
      "\tgrad = 2.685056\n",
      "rate = 0.002273\n",
      "Step 597 / 1000, loss = -7921.486933\n",
      "a_1 = 10.688651, a_2 = 7.277205, b = 2.406400\n",
      "\tgrad = 2.516704\n",
      "rate = 0.002269\n",
      "Step 598 / 1000, loss = -7921.559076\n",
      "a_1 = 10.693742, a_2 = 7.280667, b = 2.407546\n",
      "\tgrad = 2.764116\n",
      "rate = 0.002265\n",
      "Step 599 / 1000, loss = -7921.632792\n",
      "a_1 = 10.699042, a_2 = 7.284105, b = 2.408729\n",
      "\tgrad = 2.841840\n",
      "rate = 0.002262\n",
      "Step 600 / 1000, loss = -7921.705135\n",
      "a_1 = 10.703928, a_2 = 7.287801, b = 2.409885\n",
      "\tgrad = 2.760930\n",
      "rate = 0.002258\n",
      "Step 601 / 1000, loss = -7921.778034\n",
      "a_1 = 10.708926, a_2 = 7.291501, b = 2.411033\n",
      "\tgrad = 2.805078\n",
      "rate = 0.002254\n",
      "Step 602 / 1000, loss = -7921.849036\n",
      "a_1 = 10.713888, a_2 = 7.295030, b = 2.412151\n",
      "\tgrad = 2.750336\n",
      "rate = 0.002251\n",
      "Step 603 / 1000, loss = -7921.920285\n",
      "a_1 = 10.718923, a_2 = 7.298571, b = 2.413253\n",
      "\tgrad = 2.782816\n",
      "rate = 0.002247\n",
      "Step 604 / 1000, loss = -7921.991026\n",
      "a_1 = 10.723936, a_2 = 7.302057, b = 2.414363\n",
      "\tgrad = 2.766185\n",
      "rate = 0.002244\n",
      "Step 605 / 1000, loss = -7922.060408\n",
      "a_1 = 10.728799, a_2 = 7.305489, b = 2.415481\n",
      "\tgrad = 2.703808\n",
      "rate = 0.002240\n",
      "Step 606 / 1000, loss = -7922.132594\n",
      "a_1 = 10.733986, a_2 = 7.308976, b = 2.416633\n",
      "\tgrad = 2.841392\n",
      "rate = 0.002236\n",
      "Step 607 / 1000, loss = -7922.196914\n",
      "a_1 = 10.738396, a_2 = 7.312265, b = 2.417675\n",
      "\tgrad = 2.507647\n",
      "rate = 0.002233\n",
      "Step 608 / 1000, loss = -7922.265742\n",
      "a_1 = 10.743341, a_2 = 7.315594, b = 2.418785\n",
      "\tgrad = 2.720106\n",
      "rate = 0.002229\n",
      "Step 609 / 1000, loss = -7922.337111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 10.748292, a_2 = 7.319236, b = 2.419932\n",
      "\tgrad = 2.809213\n",
      "rate = 0.002226\n",
      "Step 610 / 1000, loss = -7922.404211\n",
      "a_1 = 10.752960, a_2 = 7.322626, b = 2.421029\n",
      "\tgrad = 2.642476\n",
      "rate = 0.002222\n",
      "Step 611 / 1000, loss = -7922.473045\n",
      "a_1 = 10.757814, a_2 = 7.326073, b = 2.422145\n",
      "\tgrad = 2.730183\n",
      "rate = 0.002219\n",
      "Step 612 / 1000, loss = -7922.543583\n",
      "a_1 = 10.762728, a_2 = 7.329698, b = 2.423277\n",
      "\tgrad = 2.803547\n",
      "rate = 0.002215\n",
      "Step 613 / 1000, loss = -7922.609808\n",
      "a_1 = 10.767578, a_2 = 7.332817, b = 2.424381\n",
      "\tgrad = 2.654453\n",
      "rate = 0.002212\n",
      "Step 614 / 1000, loss = -7922.678948\n",
      "a_1 = 10.772376, a_2 = 7.336337, b = 2.425534\n",
      "\tgrad = 2.744853\n",
      "rate = 0.002208\n",
      "Step 615 / 1000, loss = -7922.749240\n",
      "a_1 = 10.777394, a_2 = 7.339863, b = 2.426669\n",
      "\tgrad = 2.829271\n",
      "rate = 0.002205\n",
      "Step 616 / 1000, loss = -7922.817817\n",
      "a_1 = 10.782275, a_2 = 7.343329, b = 2.427779\n",
      "\tgrad = 2.765637\n",
      "rate = 0.002201\n",
      "Step 617 / 1000, loss = -7922.889267\n",
      "a_1 = 10.787598, a_2 = 7.346762, b = 2.428917\n",
      "\tgrad = 2.928242\n",
      "rate = 0.002198\n",
      "Step 618 / 1000, loss = -7922.956701\n",
      "a_1 = 10.792349, a_2 = 7.350219, b = 2.430021\n",
      "\tgrad = 2.724717\n",
      "rate = 0.002194\n",
      "Step 619 / 1000, loss = -7923.024835\n",
      "a_1 = 10.797346, a_2 = 7.353518, b = 2.431149\n",
      "\tgrad = 2.780747\n",
      "rate = 0.002191\n",
      "Step 620 / 1000, loss = -7923.091476\n",
      "a_1 = 10.802022, a_2 = 7.356958, b = 2.432252\n",
      "\tgrad = 2.701373\n",
      "rate = 0.002188\n",
      "Step 621 / 1000, loss = -7923.157202\n",
      "a_1 = 10.806837, a_2 = 7.360192, b = 2.433328\n",
      "\tgrad = 2.700990\n",
      "rate = 0.002184\n",
      "Step 622 / 1000, loss = -7923.217829\n",
      "a_1 = 10.811124, a_2 = 7.363286, b = 2.434347\n",
      "\tgrad = 2.469031\n",
      "rate = 0.002181\n",
      "Step 623 / 1000, loss = -7923.281097\n",
      "a_1 = 10.815617, a_2 = 7.366549, b = 2.435387\n",
      "\tgrad = 2.594582\n",
      "rate = 0.002177\n",
      "Step 624 / 1000, loss = -7923.343431\n",
      "a_1 = 10.820060, a_2 = 7.369726, b = 2.436431\n",
      "\tgrad = 2.558120\n",
      "rate = 0.002174\n",
      "Step 625 / 1000, loss = -7923.406362\n",
      "a_1 = 10.824524, a_2 = 7.372948, b = 2.437494\n",
      "\tgrad = 2.583157\n",
      "rate = 0.002171\n",
      "Step 626 / 1000, loss = -7923.472437\n",
      "a_1 = 10.829237, a_2 = 7.376344, b = 2.438598\n",
      "\tgrad = 2.728251\n",
      "rate = 0.002167\n",
      "Step 627 / 1000, loss = -7923.536133\n",
      "a_1 = 10.833813, a_2 = 7.379588, b = 2.439666\n",
      "\tgrad = 2.639024\n",
      "rate = 0.002164\n",
      "Step 628 / 1000, loss = -7923.601395\n",
      "a_1 = 10.838576, a_2 = 7.382862, b = 2.440757\n",
      "\tgrad = 2.722471\n",
      "rate = 0.002160\n",
      "Step 629 / 1000, loss = -7923.666342\n",
      "a_1 = 10.843241, a_2 = 7.386209, b = 2.441840\n",
      "\tgrad = 2.708591\n",
      "rate = 0.002157\n",
      "Step 630 / 1000, loss = -7923.731837\n",
      "a_1 = 10.848050, a_2 = 7.389467, b = 2.442950\n",
      "\tgrad = 2.745575\n",
      "rate = 0.002154\n",
      "Step 631 / 1000, loss = -7923.796139\n",
      "a_1 = 10.852819, a_2 = 7.392631, b = 2.444040\n",
      "\tgrad = 2.709097\n",
      "rate = 0.002151\n",
      "Step 632 / 1000, loss = -7923.858222\n",
      "a_1 = 10.857442, a_2 = 7.395688, b = 2.445088\n",
      "\tgrad = 2.627041\n",
      "rate = 0.002147\n",
      "Step 633 / 1000, loss = -7923.923147\n",
      "a_1 = 10.862139, a_2 = 7.398997, b = 2.446200\n",
      "\tgrad = 2.729584\n",
      "rate = 0.002144\n",
      "Step 634 / 1000, loss = -7923.986809\n",
      "a_1 = 10.866832, a_2 = 7.402158, b = 2.447299\n",
      "\tgrad = 2.692673\n",
      "rate = 0.002141\n",
      "Step 635 / 1000, loss = -7924.050764\n",
      "a_1 = 10.871434, a_2 = 7.405552, b = 2.448348\n",
      "\tgrad = 2.719665\n",
      "rate = 0.002137\n",
      "Step 636 / 1000, loss = -7924.116278\n",
      "a_1 = 10.876307, a_2 = 7.408874, b = 2.449432\n",
      "\tgrad = 2.809849\n",
      "rate = 0.002134\n",
      "Step 637 / 1000, loss = -7924.181605\n",
      "a_1 = 10.881237, a_2 = 7.412145, b = 2.450506\n",
      "\tgrad = 2.821948\n",
      "rate = 0.002131\n",
      "Step 638 / 1000, loss = -7924.243888\n",
      "a_1 = 10.885736, a_2 = 7.415397, b = 2.451568\n",
      "\tgrad = 2.656306\n",
      "rate = 0.002128\n",
      "Step 639 / 1000, loss = -7924.311590\n",
      "a_1 = 10.890799, a_2 = 7.418845, b = 2.452687\n",
      "\tgrad = 2.931358\n",
      "rate = 0.002124\n",
      "Step 640 / 1000, loss = -7924.371317\n",
      "a_1 = 10.895269, a_2 = 7.421860, b = 2.453695\n",
      "\tgrad = 2.585616\n",
      "rate = 0.002121\n",
      "Step 641 / 1000, loss = -7924.433256\n",
      "a_1 = 10.899760, a_2 = 7.425119, b = 2.454748\n",
      "\tgrad = 2.666672\n",
      "rate = 0.002118\n",
      "Step 642 / 1000, loss = -7924.494014\n",
      "a_1 = 10.904176, a_2 = 7.428307, b = 2.455786\n",
      "\tgrad = 2.621787\n",
      "rate = 0.002115\n",
      "Step 643 / 1000, loss = -7924.552976\n",
      "a_1 = 10.908594, a_2 = 7.431303, b = 2.456785\n",
      "\tgrad = 2.571659\n",
      "rate = 0.002112\n",
      "Step 644 / 1000, loss = -7924.616309\n",
      "a_1 = 10.913080, a_2 = 7.434808, b = 2.457841\n",
      "\tgrad = 2.746169\n",
      "rate = 0.002108\n",
      "Step 645 / 1000, loss = -7924.678398\n",
      "a_1 = 10.917695, a_2 = 7.437985, b = 2.458913\n",
      "\tgrad = 2.709471\n",
      "rate = 0.002105\n",
      "Step 646 / 1000, loss = -7924.736377\n",
      "a_1 = 10.921965, a_2 = 7.441022, b = 2.459901\n",
      "\tgrad = 2.536846\n",
      "rate = 0.002102\n",
      "Step 647 / 1000, loss = -7924.797636\n",
      "a_1 = 10.926537, a_2 = 7.444245, b = 2.460912\n",
      "\tgrad = 2.708365\n",
      "rate = 0.002099\n",
      "Step 648 / 1000, loss = -7924.857351\n",
      "a_1 = 10.931008, a_2 = 7.447329, b = 2.461929\n",
      "\tgrad = 2.636350\n",
      "rate = 0.002096\n",
      "Step 649 / 1000, loss = -7924.916696\n",
      "a_1 = 10.935391, a_2 = 7.450487, b = 2.462925\n",
      "\tgrad = 2.625168\n",
      "rate = 0.002093\n",
      "Step 650 / 1000, loss = -7924.979551\n",
      "a_1 = 10.939957, a_2 = 7.453885, b = 2.463997\n",
      "\tgrad = 2.771542\n",
      "rate = 0.002090\n",
      "Step 651 / 1000, loss = -7925.045772\n",
      "a_1 = 10.944924, a_2 = 7.457380, b = 2.465098\n",
      "\tgrad = 2.958797\n",
      "rate = 0.002086\n",
      "Step 652 / 1000, loss = -7925.107434\n",
      "a_1 = 10.949533, a_2 = 7.460611, b = 2.466153\n",
      "\tgrad = 2.748466\n",
      "rate = 0.002083\n",
      "Step 653 / 1000, loss = -7925.165310\n",
      "a_1 = 10.953846, a_2 = 7.463684, b = 2.467132\n",
      "\tgrad = 2.588954\n",
      "rate = 0.002080\n",
      "Step 654 / 1000, loss = -7925.227453\n",
      "a_1 = 10.958573, a_2 = 7.466898, b = 2.468187\n",
      "\tgrad = 2.798541\n",
      "rate = 0.002077\n",
      "Step 655 / 1000, loss = -7925.285617\n",
      "a_1 = 10.962953, a_2 = 7.469964, b = 2.469173\n",
      "\tgrad = 2.621037\n",
      "rate = 0.002074\n",
      "Step 656 / 1000, loss = -7925.345970\n",
      "a_1 = 10.967366, a_2 = 7.473217, b = 2.470229\n",
      "\tgrad = 2.696123\n",
      "rate = 0.002071\n",
      "Step 657 / 1000, loss = -7925.410566\n",
      "a_1 = 10.972273, a_2 = 7.476531, b = 2.471364\n",
      "\tgrad = 2.915071\n",
      "rate = 0.002068\n",
      "Step 658 / 1000, loss = -7925.468948\n",
      "a_1 = 10.976582, a_2 = 7.479646, b = 2.472395\n",
      "\tgrad = 2.623121\n",
      "rate = 0.002065\n",
      "Step 659 / 1000, loss = -7925.523375\n",
      "a_1 = 10.980655, a_2 = 7.482534, b = 2.473341\n",
      "\tgrad = 2.464690\n",
      "rate = 0.002062\n",
      "Step 660 / 1000, loss = -7925.583896\n",
      "a_1 = 10.985178, a_2 = 7.485744, b = 2.474403\n",
      "\tgrad = 2.742720\n",
      "rate = 0.002059\n",
      "Step 661 / 1000, loss = -7925.642397\n",
      "a_1 = 10.989788, a_2 = 7.488699, b = 2.475394\n",
      "\tgrad = 2.706830\n",
      "rate = 0.002056\n",
      "Step 662 / 1000, loss = -7925.700652\n",
      "a_1 = 10.993993, a_2 = 7.491996, b = 2.476392\n",
      "\tgrad = 2.647985\n",
      "rate = 0.002053\n",
      "Step 663 / 1000, loss = -7925.763430\n",
      "a_1 = 10.998712, a_2 = 7.495362, b = 2.477478\n",
      "\tgrad = 2.877445\n",
      "rate = 0.002050\n",
      "Step 664 / 1000, loss = -7925.825345\n",
      "a_1 = 11.003314, a_2 = 7.498758, b = 2.478542\n",
      "\tgrad = 2.841975\n",
      "rate = 0.002047\n",
      "Step 665 / 1000, loss = -7925.885106\n",
      "a_1 = 11.007943, a_2 = 7.501811, b = 2.479601\n",
      "\tgrad = 2.762281\n",
      "rate = 0.002044\n",
      "Step 666 / 1000, loss = -7925.940772\n",
      "a_1 = 11.012080, a_2 = 7.504808, b = 2.480599\n",
      "\tgrad = 2.550507\n",
      "rate = 0.002041\n",
      "Step 667 / 1000, loss = -7925.995687\n",
      "a_1 = 11.016264, a_2 = 7.507678, b = 2.481583\n",
      "\tgrad = 2.536137\n",
      "rate = 0.002038\n",
      "Step 668 / 1000, loss = -7926.054625\n",
      "a_1 = 11.020755, a_2 = 7.510856, b = 2.482593\n",
      "\tgrad = 2.748596\n",
      "rate = 0.002035\n",
      "Step 669 / 1000, loss = -7926.117444\n",
      "a_1 = 11.025431, a_2 = 7.514341, b = 2.483678\n",
      "\tgrad = 2.919719\n",
      "rate = 0.002032\n",
      "Step 670 / 1000, loss = -7926.175444\n",
      "a_1 = 11.029819, a_2 = 7.517451, b = 2.484708\n",
      "\tgrad = 2.698615\n",
      "rate = 0.002029\n",
      "Step 671 / 1000, loss = -7926.229052\n",
      "a_1 = 11.033870, a_2 = 7.520350, b = 2.485655\n",
      "\tgrad = 2.502917\n",
      "rate = 0.002026\n",
      "Step 672 / 1000, loss = -7926.287290\n",
      "a_1 = 11.038369, a_2 = 7.523444, b = 2.486668\n",
      "\tgrad = 2.745087\n",
      "rate = 0.002023\n",
      "Step 673 / 1000, loss = -7926.345009\n",
      "a_1 = 11.042716, a_2 = 7.526594, b = 2.487690\n",
      "\tgrad = 2.705066\n",
      "rate = 0.002020\n",
      "Step 674 / 1000, loss = -7926.398244\n",
      "a_1 = 11.046756, a_2 = 7.529473, b = 2.488637\n",
      "\tgrad = 2.503561\n",
      "rate = 0.002017\n",
      "Step 675 / 1000, loss = -7926.456120\n",
      "a_1 = 11.051200, a_2 = 7.532617, b = 2.489638\n",
      "\tgrad = 2.747334\n",
      "rate = 0.002014\n",
      "Step 676 / 1000, loss = -7926.515419\n",
      "a_1 = 11.055753, a_2 = 7.535878, b = 2.490647\n",
      "\tgrad = 2.829203\n",
      "rate = 0.002011\n",
      "Step 677 / 1000, loss = -7926.575081\n",
      "a_1 = 11.060325, a_2 = 7.539073, b = 2.491720\n",
      "\tgrad = 2.827847\n",
      "rate = 0.002009\n",
      "Step 678 / 1000, loss = -7926.632817\n",
      "a_1 = 11.064709, a_2 = 7.542253, b = 2.492737\n",
      "\tgrad = 2.747421\n",
      "rate = 0.002006\n",
      "Step 679 / 1000, loss = -7926.688957\n",
      "a_1 = 11.068959, a_2 = 7.545343, b = 2.493738\n",
      "\tgrad = 2.670955\n",
      "rate = 0.002003\n",
      "Step 680 / 1000, loss = -7926.748025\n",
      "a_1 = 11.073344, a_2 = 7.548702, b = 2.494784\n",
      "\tgrad = 2.810915\n",
      "rate = 0.002000\n",
      "Step 681 / 1000, loss = -7926.802464\n",
      "a_1 = 11.077516, a_2 = 7.551721, b = 2.495729\n",
      "\tgrad = 2.621397\n",
      "rate = 0.001997\n",
      "Step 682 / 1000, loss = -7926.860390\n",
      "a_1 = 11.081920, a_2 = 7.554950, b = 2.496748\n",
      "\tgrad = 2.785690\n",
      "rate = 0.001994\n",
      "Step 683 / 1000, loss = -7926.919228\n",
      "a_1 = 11.086606, a_2 = 7.558085, b = 2.497760\n",
      "\tgrad = 2.876132\n",
      "rate = 0.001991\n",
      "Step 684 / 1000, loss = -7926.975917\n",
      "a_1 = 11.091184, a_2 = 7.560978, b = 2.498776\n",
      "\tgrad = 2.770771\n",
      "rate = 0.001989\n",
      "Step 685 / 1000, loss = -7927.033270\n",
      "a_1 = 11.095675, a_2 = 7.564066, b = 2.499795\n",
      "\tgrad = 2.791950\n",
      "rate = 0.001986\n",
      "Step 686 / 1000, loss = -7927.087044\n",
      "a_1 = 11.099793, a_2 = 7.567030, b = 2.500764\n",
      "\tgrad = 2.605220\n",
      "rate = 0.001983\n",
      "Step 687 / 1000, loss = -7927.141573\n",
      "a_1 = 11.103959, a_2 = 7.570058, b = 2.501746\n",
      "\tgrad = 2.647476\n",
      "rate = 0.001980\n",
      "Step 688 / 1000, loss = -7927.196387\n",
      "a_1 = 11.108198, a_2 = 7.573093, b = 2.502717\n",
      "\tgrad = 2.681842\n",
      "rate = 0.001977\n",
      "Step 689 / 1000, loss = -7927.251935\n",
      "a_1 = 11.112518, a_2 = 7.576134, b = 2.503712\n",
      "\tgrad = 2.722744\n",
      "rate = 0.001975\n",
      "Step 690 / 1000, loss = -7927.308679\n",
      "a_1 = 11.116858, a_2 = 7.579341, b = 2.504718\n",
      "\tgrad = 2.783739\n",
      "rate = 0.001972\n",
      "Step 691 / 1000, loss = -7927.366138\n",
      "a_1 = 11.121487, a_2 = 7.582374, b = 2.505738\n",
      "\tgrad = 2.858027\n",
      "rate = 0.001969\n",
      "Step 692 / 1000, loss = -7927.422609\n",
      "a_1 = 11.125883, a_2 = 7.585525, b = 2.506733\n",
      "\tgrad = 2.796610\n",
      "rate = 0.001966\n",
      "Step 693 / 1000, loss = -7927.477128\n",
      "a_1 = 11.130226, a_2 = 7.588476, b = 2.507697\n",
      "\tgrad = 2.718923\n",
      "rate = 0.001964\n",
      "Step 694 / 1000, loss = -7927.529872\n",
      "a_1 = 11.134429, a_2 = 7.591349, b = 2.508625\n",
      "\tgrad = 2.639192\n",
      "rate = 0.001961\n",
      "Step 695 / 1000, loss = -7927.587367\n",
      "a_1 = 11.138937, a_2 = 7.594540, b = 2.509647\n",
      "\tgrad = 2.868398\n",
      "rate = 0.001958\n",
      "Step 696 / 1000, loss = -7927.641258\n",
      "a_1 = 11.143260, a_2 = 7.597414, b = 2.510622\n",
      "\tgrad = 2.701727\n",
      "rate = 0.001955\n",
      "Step 697 / 1000, loss = -7927.693239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 11.147288, a_2 = 7.600341, b = 2.511558\n",
      "\tgrad = 2.594484\n",
      "rate = 0.001953\n",
      "Step 698 / 1000, loss = -7927.744396\n",
      "a_1 = 11.151335, a_2 = 7.603126, b = 2.512492\n",
      "\tgrad = 2.564672\n",
      "rate = 0.001950\n",
      "Step 699 / 1000, loss = -7927.797360\n",
      "a_1 = 11.155526, a_2 = 7.606027, b = 2.513453\n",
      "\tgrad = 2.663799\n",
      "rate = 0.001947\n",
      "Step 700 / 1000, loss = -7927.849831\n",
      "a_1 = 11.159657, a_2 = 7.608922, b = 2.514410\n",
      "\tgrad = 2.640741\n",
      "rate = 0.001944\n",
      "Step 701 / 1000, loss = -7927.905894\n",
      "a_1 = 11.164221, a_2 = 7.611941, b = 2.515402\n",
      "\tgrad = 2.863898\n",
      "rate = 0.001942\n",
      "Step 702 / 1000, loss = -7927.960243\n",
      "a_1 = 11.168458, a_2 = 7.615007, b = 2.516389\n",
      "\tgrad = 2.744613\n",
      "rate = 0.001939\n",
      "Step 703 / 1000, loss = -7928.012187\n",
      "a_1 = 11.172503, a_2 = 7.617990, b = 2.517311\n",
      "\tgrad = 2.639115\n",
      "rate = 0.001936\n",
      "Step 704 / 1000, loss = -7928.066040\n",
      "a_1 = 11.176724, a_2 = 7.621031, b = 2.518286\n",
      "\tgrad = 2.737151\n",
      "rate = 0.001934\n",
      "Step 705 / 1000, loss = -7928.120729\n",
      "a_1 = 11.181020, a_2 = 7.624107, b = 2.519282\n",
      "\tgrad = 2.784491\n",
      "rate = 0.001931\n",
      "Step 706 / 1000, loss = -7928.175519\n",
      "a_1 = 11.185283, a_2 = 7.627280, b = 2.520258\n",
      "\tgrad = 2.801838\n",
      "rate = 0.001928\n",
      "Step 707 / 1000, loss = -7928.229500\n",
      "a_1 = 11.189591, a_2 = 7.630282, b = 2.521236\n",
      "\tgrad = 2.773499\n",
      "rate = 0.001926\n",
      "Step 708 / 1000, loss = -7928.281311\n",
      "a_1 = 11.193772, a_2 = 7.633158, b = 2.522159\n",
      "\tgrad = 2.682259\n",
      "rate = 0.001923\n",
      "Step 709 / 1000, loss = -7928.333967\n",
      "a_1 = 11.197912, a_2 = 7.636126, b = 2.523133\n",
      "\tgrad = 2.700602\n",
      "rate = 0.001920\n",
      "Step 710 / 1000, loss = -7928.386501\n",
      "a_1 = 11.202177, a_2 = 7.638990, b = 2.524094\n",
      "\tgrad = 2.725045\n",
      "rate = 0.001918\n",
      "Step 711 / 1000, loss = -7928.442347\n",
      "a_1 = 11.206679, a_2 = 7.642147, b = 2.525076\n",
      "\tgrad = 2.916700\n",
      "rate = 0.001915\n",
      "Step 712 / 1000, loss = -7928.492235\n",
      "a_1 = 11.210724, a_2 = 7.644882, b = 2.525992\n",
      "\tgrad = 2.597340\n",
      "rate = 0.001913\n",
      "Step 713 / 1000, loss = -7928.542201\n",
      "a_1 = 11.214791, a_2 = 7.647655, b = 2.526888\n",
      "\tgrad = 2.619835\n",
      "rate = 0.001910\n",
      "Step 714 / 1000, loss = -7928.591586\n",
      "a_1 = 11.218691, a_2 = 7.650439, b = 2.527815\n",
      "\tgrad = 2.558658\n",
      "rate = 0.001907\n",
      "Step 715 / 1000, loss = -7928.645369\n",
      "a_1 = 11.222979, a_2 = 7.653499, b = 2.528794\n",
      "\tgrad = 2.812813\n",
      "rate = 0.001905\n",
      "Step 716 / 1000, loss = -7928.695800\n",
      "a_1 = 11.227081, a_2 = 7.656280, b = 2.529722\n",
      "\tgrad = 2.650926\n",
      "rate = 0.001902\n",
      "Step 717 / 1000, loss = -7928.748308\n",
      "a_1 = 11.231405, a_2 = 7.659153, b = 2.530680\n",
      "\tgrad = 2.778714\n",
      "rate = 0.001900\n",
      "Step 718 / 1000, loss = -7928.797351\n",
      "a_1 = 11.235157, a_2 = 7.662076, b = 2.531594\n",
      "\tgrad = 2.553087\n",
      "rate = 0.001897\n",
      "Step 719 / 1000, loss = -7928.849490\n",
      "a_1 = 11.239440, a_2 = 7.664958, b = 2.532543\n",
      "\tgrad = 2.770871\n",
      "rate = 0.001894\n",
      "Step 720 / 1000, loss = -7928.903757\n",
      "a_1 = 11.243862, a_2 = 7.668027, b = 2.533517\n",
      "\tgrad = 2.891444\n",
      "rate = 0.001892\n",
      "Step 721 / 1000, loss = -7928.950917\n",
      "a_1 = 11.247579, a_2 = 7.670725, b = 2.534415\n",
      "\tgrad = 2.476670\n",
      "rate = 0.001889\n",
      "Step 722 / 1000, loss = -7929.000691\n",
      "a_1 = 11.251729, a_2 = 7.673459, b = 2.535313\n",
      "\tgrad = 2.676721\n",
      "rate = 0.001887\n",
      "Step 723 / 1000, loss = -7929.049696\n",
      "a_1 = 11.255791, a_2 = 7.676122, b = 2.536229\n",
      "\tgrad = 2.622994\n",
      "rate = 0.001884\n",
      "Step 724 / 1000, loss = -7929.101829\n",
      "a_1 = 11.259906, a_2 = 7.679189, b = 2.537186\n",
      "\tgrad = 2.774428\n",
      "rate = 0.001882\n",
      "Step 725 / 1000, loss = -7929.154105\n",
      "a_1 = 11.264259, a_2 = 7.682070, b = 2.538141\n",
      "\tgrad = 2.824162\n",
      "rate = 0.001879\n",
      "Step 726 / 1000, loss = -7929.202570\n",
      "a_1 = 11.268142, a_2 = 7.684864, b = 2.539042\n",
      "\tgrad = 2.593626\n",
      "rate = 0.001877\n",
      "Step 727 / 1000, loss = -7929.253823\n",
      "a_1 = 11.272356, a_2 = 7.687698, b = 2.540009\n",
      "\tgrad = 2.758287\n",
      "rate = 0.001874\n",
      "Step 728 / 1000, loss = -7929.305603\n",
      "a_1 = 11.276505, a_2 = 7.690710, b = 2.540965\n",
      "\tgrad = 2.786979\n",
      "rate = 0.001872\n",
      "Step 729 / 1000, loss = -7929.355963\n",
      "a_1 = 11.280653, a_2 = 7.693496, b = 2.541920\n",
      "\tgrad = 2.721401\n",
      "rate = 0.001869\n",
      "Step 730 / 1000, loss = -7929.409856\n",
      "a_1 = 11.285025, a_2 = 7.696590, b = 2.542921\n",
      "\tgrad = 2.919005\n",
      "rate = 0.001867\n",
      "Step 731 / 1000, loss = -7929.458924\n",
      "a_1 = 11.289021, a_2 = 7.699368, b = 2.543849\n",
      "\tgrad = 2.657816\n",
      "rate = 0.001864\n",
      "Step 732 / 1000, loss = -7929.509281\n",
      "a_1 = 11.293115, a_2 = 7.702229, b = 2.544804\n",
      "\tgrad = 2.731523\n",
      "rate = 0.001862\n",
      "Step 733 / 1000, loss = -7929.559848\n",
      "a_1 = 11.297296, a_2 = 7.705113, b = 2.545728\n",
      "\tgrad = 2.776260\n",
      "rate = 0.001859\n",
      "Step 734 / 1000, loss = -7929.610465\n",
      "a_1 = 11.301509, a_2 = 7.707973, b = 2.546657\n",
      "\tgrad = 2.788151\n",
      "rate = 0.001857\n",
      "Step 735 / 1000, loss = -7929.658331\n",
      "a_1 = 11.305384, a_2 = 7.710745, b = 2.547558\n",
      "\tgrad = 2.614911\n",
      "rate = 0.001854\n",
      "Step 736 / 1000, loss = -7929.704151\n",
      "a_1 = 11.309090, a_2 = 7.713416, b = 2.548417\n",
      "\tgrad = 2.509817\n",
      "rate = 0.001852\n",
      "Step 737 / 1000, loss = -7929.752541\n",
      "a_1 = 11.313102, a_2 = 7.716136, b = 2.549333\n",
      "\tgrad = 2.667226\n",
      "rate = 0.001849\n",
      "Step 738 / 1000, loss = -7929.803241\n",
      "a_1 = 11.317313, a_2 = 7.719013, b = 2.550278\n",
      "\tgrad = 2.808437\n",
      "rate = 0.001847\n",
      "Step 739 / 1000, loss = -7929.852694\n",
      "a_1 = 11.321479, a_2 = 7.721791, b = 2.551191\n",
      "\tgrad = 2.759177\n",
      "rate = 0.001845\n",
      "Step 740 / 1000, loss = -7929.901581\n",
      "a_1 = 11.325496, a_2 = 7.724601, b = 2.552114\n",
      "\tgrad = 2.708178\n",
      "rate = 0.001842\n",
      "Step 741 / 1000, loss = -7929.949183\n",
      "a_1 = 11.329396, a_2 = 7.727343, b = 2.553019\n",
      "\tgrad = 2.637869\n",
      "rate = 0.001840\n",
      "Step 742 / 1000, loss = -7929.998115\n",
      "a_1 = 11.333317, a_2 = 7.730244, b = 2.553954\n",
      "\tgrad = 2.703049\n",
      "rate = 0.001837\n",
      "Step 743 / 1000, loss = -7930.044099\n",
      "a_1 = 11.337243, a_2 = 7.732774, b = 2.554821\n",
      "\tgrad = 2.589053\n",
      "rate = 0.001835\n",
      "Step 744 / 1000, loss = -7930.090427\n",
      "a_1 = 11.340984, a_2 = 7.735505, b = 2.555707\n",
      "\tgrad = 2.573516\n",
      "rate = 0.001832\n",
      "Step 745 / 1000, loss = -7930.138699\n",
      "a_1 = 11.344865, a_2 = 7.738381, b = 2.556628\n",
      "\tgrad = 2.687035\n",
      "rate = 0.001830\n",
      "Step 746 / 1000, loss = -7930.182594\n",
      "a_1 = 11.348403, a_2 = 7.741003, b = 2.557461\n",
      "\tgrad = 2.451680\n",
      "rate = 0.001828\n",
      "Step 747 / 1000, loss = -7930.229802\n",
      "a_1 = 11.352289, a_2 = 7.743728, b = 2.558370\n",
      "\tgrad = 2.647673\n",
      "rate = 0.001825\n",
      "Step 748 / 1000, loss = -7930.280252\n",
      "a_1 = 11.356588, a_2 = 7.746567, b = 2.559313\n",
      "\tgrad = 2.873002\n",
      "rate = 0.001823\n",
      "Step 749 / 1000, loss = -7930.328781\n",
      "a_1 = 11.360599, a_2 = 7.749388, b = 2.560238\n",
      "\tgrad = 2.741010\n",
      "rate = 0.001821\n",
      "Step 750 / 1000, loss = -7930.378608\n",
      "a_1 = 11.364788, a_2 = 7.752289, b = 2.561154\n",
      "\tgrad = 2.847604\n",
      "rate = 0.001818\n",
      "Step 751 / 1000, loss = -7930.425862\n",
      "a_1 = 11.368843, a_2 = 7.754907, b = 2.562056\n",
      "\tgrad = 2.704337\n",
      "rate = 0.001816\n",
      "Step 752 / 1000, loss = -7930.471616\n",
      "a_1 = 11.372583, a_2 = 7.757620, b = 2.562932\n",
      "\tgrad = 2.593311\n",
      "rate = 0.001813\n",
      "Step 753 / 1000, loss = -7930.518701\n",
      "a_1 = 11.376416, a_2 = 7.760441, b = 2.563831\n",
      "\tgrad = 2.673872\n",
      "rate = 0.001811\n",
      "Step 754 / 1000, loss = -7930.564148\n",
      "a_1 = 11.380190, a_2 = 7.763088, b = 2.564704\n",
      "\tgrad = 2.593884\n",
      "rate = 0.001809\n",
      "Step 755 / 1000, loss = -7930.609685\n",
      "a_1 = 11.383912, a_2 = 7.765823, b = 2.565570\n",
      "\tgrad = 2.601166\n",
      "rate = 0.001806\n",
      "Step 756 / 1000, loss = -7930.657506\n",
      "a_1 = 11.388108, a_2 = 7.768451, b = 2.566468\n",
      "\tgrad = 2.789441\n",
      "rate = 0.001804\n",
      "Step 757 / 1000, loss = -7930.702514\n",
      "a_1 = 11.391905, a_2 = 7.771043, b = 2.567331\n",
      "\tgrad = 2.595691\n",
      "rate = 0.001802\n",
      "Step 758 / 1000, loss = -7930.749289\n",
      "a_1 = 11.395804, a_2 = 7.773830, b = 2.568206\n",
      "\tgrad = 2.707317\n",
      "rate = 0.001799\n",
      "Step 759 / 1000, loss = -7930.799101\n",
      "a_1 = 11.399948, a_2 = 7.776804, b = 2.569142\n",
      "\tgrad = 2.885750\n",
      "rate = 0.001797\n",
      "Step 760 / 1000, loss = -7930.843414\n",
      "a_1 = 11.403782, a_2 = 7.779264, b = 2.570003\n",
      "\tgrad = 2.582864\n",
      "rate = 0.001795\n",
      "Step 761 / 1000, loss = -7930.889717\n",
      "a_1 = 11.407589, a_2 = 7.782056, b = 2.570889\n",
      "\tgrad = 2.679830\n",
      "rate = 0.001793\n",
      "Step 762 / 1000, loss = -7930.934072\n",
      "a_1 = 11.411297, a_2 = 7.784669, b = 2.571743\n",
      "\tgrad = 2.578568\n",
      "rate = 0.001790\n",
      "Step 763 / 1000, loss = -7930.979960\n",
      "a_1 = 11.415173, a_2 = 7.787354, b = 2.572621\n",
      "\tgrad = 2.682161\n",
      "rate = 0.001788\n",
      "Step 764 / 1000, loss = -7931.027668\n",
      "a_1 = 11.419298, a_2 = 7.790084, b = 2.573523\n",
      "\tgrad = 2.815833\n",
      "rate = 0.001786\n",
      "Step 765 / 1000, loss = -7931.071665\n",
      "a_1 = 11.423068, a_2 = 7.792614, b = 2.574368\n",
      "\tgrad = 2.589659\n",
      "rate = 0.001783\n",
      "Step 766 / 1000, loss = -7931.119653\n",
      "a_1 = 11.426980, a_2 = 7.795561, b = 2.575294\n",
      "\tgrad = 2.798469\n",
      "rate = 0.001781\n",
      "Step 767 / 1000, loss = -7931.165178\n",
      "a_1 = 11.430853, a_2 = 7.798250, b = 2.576153\n",
      "\tgrad = 2.694024\n",
      "rate = 0.001779\n",
      "Step 768 / 1000, loss = -7931.210079\n",
      "a_1 = 11.434567, a_2 = 7.800920, b = 2.577047\n",
      "\tgrad = 2.623037\n",
      "rate = 0.001777\n",
      "Step 769 / 1000, loss = -7931.256373\n",
      "a_1 = 11.438531, a_2 = 7.803605, b = 2.577941\n",
      "\tgrad = 2.744914\n",
      "rate = 0.001774\n",
      "Step 770 / 1000, loss = -7931.302232\n",
      "a_1 = 11.442380, a_2 = 7.806351, b = 2.578824\n",
      "\tgrad = 2.714180\n",
      "rate = 0.001772\n",
      "Step 771 / 1000, loss = -7931.349580\n",
      "a_1 = 11.446516, a_2 = 7.809015, b = 2.579749\n",
      "\tgrad = 2.828274\n",
      "rate = 0.001770\n",
      "Step 772 / 1000, loss = -7931.396633\n",
      "a_1 = 11.450420, a_2 = 7.811925, b = 2.580637\n",
      "\tgrad = 2.800157\n",
      "rate = 0.001768\n",
      "Step 773 / 1000, loss = -7931.439304\n",
      "a_1 = 11.454016, a_2 = 7.814463, b = 2.581470\n",
      "\tgrad = 2.537715\n",
      "rate = 0.001765\n",
      "Step 774 / 1000, loss = -7931.481494\n",
      "a_1 = 11.457706, a_2 = 7.816832, b = 2.582306\n",
      "\tgrad = 2.531073\n",
      "rate = 0.001763\n",
      "Step 775 / 1000, loss = -7931.527252\n",
      "a_1 = 11.461574, a_2 = 7.819528, b = 2.583215\n",
      "\tgrad = 2.726680\n",
      "rate = 0.001761\n",
      "Step 776 / 1000, loss = -7931.571607\n",
      "a_1 = 11.465307, a_2 = 7.822172, b = 2.584090\n",
      "\tgrad = 2.648677\n",
      "rate = 0.001759\n",
      "Step 777 / 1000, loss = -7931.614264\n",
      "a_1 = 11.468843, a_2 = 7.824806, b = 2.584916\n",
      "\tgrad = 2.553428\n",
      "rate = 0.001757\n",
      "Step 778 / 1000, loss = -7931.658430\n",
      "a_1 = 11.472516, a_2 = 7.827536, b = 2.585767\n",
      "\tgrad = 2.653066\n",
      "rate = 0.001754\n",
      "Step 779 / 1000, loss = -7931.705268\n",
      "a_1 = 11.476536, a_2 = 7.830320, b = 2.586669\n",
      "\tgrad = 2.838222\n",
      "rate = 0.001752\n",
      "Step 780 / 1000, loss = -7931.750776\n",
      "a_1 = 11.480303, a_2 = 7.833173, b = 2.587541\n",
      "\tgrad = 2.745952\n",
      "rate = 0.001750\n",
      "Step 781 / 1000, loss = -7931.795280\n",
      "a_1 = 11.483967, a_2 = 7.835942, b = 2.588418\n",
      "\tgrad = 2.674588\n",
      "rate = 0.001748\n",
      "Step 782 / 1000, loss = -7931.841093\n",
      "a_1 = 11.487972, a_2 = 7.838608, b = 2.589307\n",
      "\tgrad = 2.802747\n",
      "rate = 0.001746\n",
      "Step 783 / 1000, loss = -7931.885714\n",
      "a_1 = 11.491952, a_2 = 7.841128, b = 2.590177\n",
      "\tgrad = 2.747871\n",
      "rate = 0.001743\n",
      "Step 784 / 1000, loss = -7931.929574\n",
      "a_1 = 11.495625, a_2 = 7.843816, b = 2.591042\n",
      "\tgrad = 2.660981\n",
      "rate = 0.001741\n",
      "Step 785 / 1000, loss = -7931.971539\n",
      "a_1 = 11.499350, a_2 = 7.846185, b = 2.591877\n",
      "\tgrad = 2.583170\n",
      "rate = 0.001739\n",
      "Step 786 / 1000, loss = -7932.015122\n",
      "a_1 = 11.503067, a_2 = 7.848807, b = 2.592737\n",
      "\tgrad = 2.665121\n",
      "rate = 0.001737\n",
      "Step 787 / 1000, loss = -7932.058670\n",
      "a_1 = 11.506762, a_2 = 7.851438, b = 2.593602\n",
      "\tgrad = 2.662112\n",
      "rate = 0.001735\n",
      "Step 788 / 1000, loss = -7932.101322\n",
      "a_1 = 11.510431, a_2 = 7.853934, b = 2.594472\n",
      "\tgrad = 2.609304\n",
      "rate = 0.001733\n",
      "Step 789 / 1000, loss = -7932.144190\n",
      "a_1 = 11.514096, a_2 = 7.856536, b = 2.595311\n",
      "\tgrad = 2.642279\n",
      "rate = 0.001731\n",
      "Step 790 / 1000, loss = -7932.186953\n",
      "a_1 = 11.517757, a_2 = 7.859098, b = 2.596167\n",
      "\tgrad = 2.632453\n",
      "rate = 0.001728\n",
      "Step 791 / 1000, loss = -7932.228834\n",
      "a_1 = 11.521295, a_2 = 7.861703, b = 2.596982\n",
      "\tgrad = 2.588377\n",
      "rate = 0.001726\n",
      "Step 792 / 1000, loss = -7932.273897\n",
      "a_1 = 11.525196, a_2 = 7.864416, b = 2.597863\n",
      "\tgrad = 2.802971\n",
      "rate = 0.001724\n",
      "Step 793 / 1000, loss = -7932.316872\n",
      "a_1 = 11.528828, a_2 = 7.867073, b = 2.598713\n",
      "\tgrad = 2.659292\n",
      "rate = 0.001722\n",
      "Step 794 / 1000, loss = -7932.360583\n",
      "a_1 = 11.532669, a_2 = 7.869650, b = 2.599575\n",
      "\tgrad = 2.735958\n",
      "rate = 0.001720\n",
      "Step 795 / 1000, loss = -7932.401759\n",
      "a_1 = 11.536082, a_2 = 7.872199, b = 2.600427\n",
      "\tgrad = 2.528819\n",
      "rate = 0.001718\n",
      "Step 796 / 1000, loss = -7932.443752\n",
      "a_1 = 11.539505, a_2 = 7.874919, b = 2.601264\n",
      "\tgrad = 2.594799\n",
      "rate = 0.001716\n",
      "Step 797 / 1000, loss = -7932.482531\n",
      "a_1 = 11.542679, a_2 = 7.877403, b = 2.602049\n",
      "\tgrad = 2.395936\n",
      "rate = 0.001714\n",
      "Step 798 / 1000, loss = -7932.525372\n",
      "a_1 = 11.546229, a_2 = 7.880149, b = 2.602896\n",
      "\tgrad = 2.668997\n",
      "rate = 0.001711\n",
      "Step 799 / 1000, loss = -7932.572520\n",
      "a_1 = 11.550279, a_2 = 7.883084, b = 2.603809\n",
      "\tgrad = 2.974190\n",
      "rate = 0.001709\n",
      "Step 800 / 1000, loss = -7932.615348\n",
      "a_1 = 11.553980, a_2 = 7.885672, b = 2.604671\n",
      "\tgrad = 2.693005\n",
      "rate = 0.001707\n",
      "Step 801 / 1000, loss = -7932.660784\n",
      "a_1 = 11.557864, a_2 = 7.888545, b = 2.605544\n",
      "\tgrad = 2.878943\n",
      "rate = 0.001705\n",
      "Step 802 / 1000, loss = -7932.703967\n",
      "a_1 = 11.561603, a_2 = 7.891189, b = 2.606399\n",
      "\tgrad = 2.735235\n",
      "rate = 0.001703\n",
      "Step 803 / 1000, loss = -7932.745473\n",
      "a_1 = 11.565287, a_2 = 7.893649, b = 2.607223\n",
      "\tgrad = 2.648688\n",
      "rate = 0.001701\n",
      "Step 804 / 1000, loss = -7932.787422\n",
      "a_1 = 11.568803, a_2 = 7.896279, b = 2.608084\n",
      "\tgrad = 2.633464\n",
      "rate = 0.001699\n",
      "Step 805 / 1000, loss = -7932.830916\n",
      "a_1 = 11.572540, a_2 = 7.899003, b = 2.608938\n",
      "\tgrad = 2.771295\n",
      "rate = 0.001697\n",
      "Step 806 / 1000, loss = -7932.874904\n",
      "a_1 = 11.576467, a_2 = 7.901615, b = 2.609807\n",
      "\tgrad = 2.829497\n",
      "rate = 0.001695\n",
      "Step 807 / 1000, loss = -7932.916948\n",
      "a_1 = 11.580183, a_2 = 7.904108, b = 2.610662\n",
      "\tgrad = 2.690672\n",
      "rate = 0.001693\n",
      "Step 808 / 1000, loss = -7932.957322\n",
      "a_1 = 11.583737, a_2 = 7.906534, b = 2.611475\n",
      "\tgrad = 2.590477\n",
      "rate = 0.001691\n",
      "Step 809 / 1000, loss = -7933.000694\n",
      "a_1 = 11.587520, a_2 = 7.909205, b = 2.612337\n",
      "\tgrad = 2.788960\n",
      "rate = 0.001689\n",
      "Step 810 / 1000, loss = -7933.042684\n",
      "a_1 = 11.591146, a_2 = 7.911809, b = 2.613182\n",
      "\tgrad = 2.693629\n",
      "rate = 0.001687\n",
      "Step 811 / 1000, loss = -7933.082460\n",
      "a_1 = 11.594697, a_2 = 7.914187, b = 2.613975\n",
      "\tgrad = 2.579999\n",
      "rate = 0.001685\n",
      "Step 812 / 1000, loss = -7933.123725\n",
      "a_1 = 11.598184, a_2 = 7.916822, b = 2.614810\n",
      "\tgrad = 2.644131\n",
      "rate = 0.001683\n",
      "Step 813 / 1000, loss = -7933.164647\n",
      "a_1 = 11.601691, a_2 = 7.919408, b = 2.615630\n",
      "\tgrad = 2.638642\n",
      "rate = 0.001681\n",
      "Step 814 / 1000, loss = -7933.205311\n",
      "a_1 = 11.605214, a_2 = 7.921948, b = 2.616446\n",
      "\tgrad = 2.632386\n",
      "rate = 0.001679\n",
      "Step 815 / 1000, loss = -7933.247064\n",
      "a_1 = 11.608871, a_2 = 7.924563, b = 2.617264\n",
      "\tgrad = 2.725393\n",
      "rate = 0.001677\n",
      "Step 816 / 1000, loss = -7933.289026\n",
      "a_1 = 11.612541, a_2 = 7.927173, b = 2.618101\n",
      "\tgrad = 2.735196\n",
      "rate = 0.001675\n",
      "Step 817 / 1000, loss = -7933.329654\n",
      "a_1 = 11.616064, a_2 = 7.929720, b = 2.618919\n",
      "\tgrad = 2.644850\n",
      "rate = 0.001673\n",
      "Step 818 / 1000, loss = -7933.371749\n",
      "a_1 = 11.619729, a_2 = 7.932336, b = 2.619775\n",
      "\tgrad = 2.743521\n",
      "rate = 0.001671\n",
      "Step 819 / 1000, loss = -7933.413629\n",
      "a_1 = 11.623386, a_2 = 7.934962, b = 2.620612\n",
      "\tgrad = 2.744065\n",
      "rate = 0.001669\n",
      "Step 820 / 1000, loss = -7933.455985\n",
      "a_1 = 11.627161, a_2 = 7.937536, b = 2.621467\n",
      "\tgrad = 2.789386\n",
      "rate = 0.001667\n",
      "Step 821 / 1000, loss = -7933.498229\n",
      "a_1 = 11.630861, a_2 = 7.940153, b = 2.622330\n",
      "\tgrad = 2.771047\n",
      "rate = 0.001665\n",
      "Step 822 / 1000, loss = -7933.537335\n",
      "a_1 = 11.634263, a_2 = 7.942632, b = 2.623113\n",
      "\tgrad = 2.575156\n",
      "rate = 0.001663\n",
      "Step 823 / 1000, loss = -7933.577416\n",
      "a_1 = 11.637702, a_2 = 7.945182, b = 2.623936\n",
      "\tgrad = 2.625290\n",
      "rate = 0.001661\n",
      "Step 824 / 1000, loss = -7933.618555\n",
      "a_1 = 11.641374, a_2 = 7.947707, b = 2.624764\n",
      "\tgrad = 2.732622\n",
      "rate = 0.001659\n",
      "Step 825 / 1000, loss = -7933.658901\n",
      "a_1 = 11.644956, a_2 = 7.950201, b = 2.625579\n",
      "\tgrad = 2.679903\n",
      "rate = 0.001657\n",
      "Step 826 / 1000, loss = -7933.697468\n",
      "a_1 = 11.648417, a_2 = 7.952546, b = 2.626364\n",
      "\tgrad = 2.570390\n",
      "rate = 0.001655\n",
      "Step 827 / 1000, loss = -7933.738186\n",
      "a_1 = 11.652028, a_2 = 7.955087, b = 2.627182\n",
      "\tgrad = 2.716939\n",
      "rate = 0.001653\n",
      "Step 828 / 1000, loss = -7933.777207\n",
      "a_1 = 11.655378, a_2 = 7.957606, b = 2.627979\n",
      "\tgrad = 2.583889\n",
      "rate = 0.001651\n",
      "Step 829 / 1000, loss = -7933.817107\n",
      "a_1 = 11.658849, a_2 = 7.960158, b = 2.628787\n",
      "\tgrad = 2.658283\n",
      "rate = 0.001649\n",
      "Step 830 / 1000, loss = -7933.856345\n",
      "a_1 = 11.662296, a_2 = 7.962614, b = 2.629596\n",
      "\tgrad = 2.616487\n",
      "rate = 0.001647\n",
      "Step 831 / 1000, loss = -7933.898575\n",
      "a_1 = 11.665951, a_2 = 7.965361, b = 2.630443\n",
      "\tgrad = 2.826360\n",
      "rate = 0.001645\n",
      "Step 832 / 1000, loss = -7933.937501\n",
      "a_1 = 11.669363, a_2 = 7.967866, b = 2.631220\n",
      "\tgrad = 2.618825\n",
      "rate = 0.001643\n",
      "Step 833 / 1000, loss = -7933.977279\n",
      "a_1 = 11.672777, a_2 = 7.970444, b = 2.632043\n",
      "\tgrad = 2.654498\n",
      "rate = 0.001641\n",
      "Step 834 / 1000, loss = -7934.016457\n",
      "a_1 = 11.676207, a_2 = 7.972961, b = 2.632835\n",
      "\tgrad = 2.639829\n",
      "rate = 0.001639\n",
      "Step 835 / 1000, loss = -7934.057357\n",
      "a_1 = 11.679859, a_2 = 7.975506, b = 2.633673\n",
      "\tgrad = 2.766174\n",
      "rate = 0.001637\n",
      "Step 836 / 1000, loss = -7934.096435\n",
      "a_1 = 11.683365, a_2 = 7.977942, b = 2.634466\n",
      "\tgrad = 2.655232\n",
      "rate = 0.001636\n",
      "Step 837 / 1000, loss = -7934.136554\n",
      "a_1 = 11.686953, a_2 = 7.980459, b = 2.635281\n",
      "\tgrad = 2.728720\n",
      "rate = 0.001634\n",
      "Step 838 / 1000, loss = -7934.175057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 11.690452, a_2 = 7.982798, b = 2.636079\n",
      "\tgrad = 2.625057\n",
      "rate = 0.001632\n",
      "Step 839 / 1000, loss = -7934.216797\n",
      "a_1 = 11.694180, a_2 = 7.985412, b = 2.636938\n",
      "\tgrad = 2.843015\n",
      "rate = 0.001630\n",
      "Step 840 / 1000, loss = -7934.257579\n",
      "a_1 = 11.697779, a_2 = 7.988023, b = 2.637772\n",
      "\tgrad = 2.779094\n",
      "rate = 0.001628\n",
      "Step 841 / 1000, loss = -7934.296034\n",
      "a_1 = 11.701291, a_2 = 7.990415, b = 2.638541\n",
      "\tgrad = 2.655310\n",
      "rate = 0.001626\n",
      "Step 842 / 1000, loss = -7934.334151\n",
      "a_1 = 11.704748, a_2 = 7.992765, b = 2.639327\n",
      "\tgrad = 2.619500\n",
      "rate = 0.001624\n",
      "Step 843 / 1000, loss = -7934.375172\n",
      "a_1 = 11.708527, a_2 = 7.995284, b = 2.640154\n",
      "\tgrad = 2.845335\n",
      "rate = 0.001622\n",
      "Step 844 / 1000, loss = -7934.414782\n",
      "a_1 = 11.712023, a_2 = 7.997852, b = 2.640959\n",
      "\tgrad = 2.722558\n",
      "rate = 0.001620\n",
      "Step 845 / 1000, loss = -7934.454568\n",
      "a_1 = 11.715765, a_2 = 8.000202, b = 2.641778\n",
      "\tgrad = 2.776917\n",
      "rate = 0.001618\n",
      "Step 846 / 1000, loss = -7934.493799\n",
      "a_1 = 11.719329, a_2 = 8.002638, b = 2.642588\n",
      "\tgrad = 2.717035\n",
      "rate = 0.001617\n",
      "Step 847 / 1000, loss = -7934.532340\n",
      "a_1 = 11.722889, a_2 = 8.004963, b = 2.643394\n",
      "\tgrad = 2.679722\n",
      "rate = 0.001615\n",
      "Step 848 / 1000, loss = -7934.572419\n",
      "a_1 = 11.726480, a_2 = 8.007510, b = 2.644221\n",
      "\tgrad = 2.777308\n",
      "rate = 0.001613\n",
      "Step 849 / 1000, loss = -7934.611578\n",
      "a_1 = 11.730019, a_2 = 8.010019, b = 2.645008\n",
      "\tgrad = 2.736861\n",
      "rate = 0.001611\n",
      "Step 850 / 1000, loss = -7934.647316\n",
      "a_1 = 11.733175, a_2 = 8.012313, b = 2.645761\n",
      "\tgrad = 2.469290\n",
      "rate = 0.001609\n",
      "Step 851 / 1000, loss = -7934.682686\n",
      "a_1 = 11.736284, a_2 = 8.014604, b = 2.646505\n",
      "\tgrad = 2.446921\n",
      "rate = 0.001607\n",
      "Step 852 / 1000, loss = -7934.721840\n",
      "a_1 = 11.739893, a_2 = 8.017025, b = 2.647311\n",
      "\tgrad = 2.752795\n",
      "rate = 0.001606\n",
      "Step 853 / 1000, loss = -7934.760657\n",
      "a_1 = 11.743488, a_2 = 8.019405, b = 2.648114\n",
      "\tgrad = 2.735302\n",
      "rate = 0.001604\n",
      "Step 854 / 1000, loss = -7934.801464\n",
      "a_1 = 11.747153, a_2 = 8.022000, b = 2.648970\n",
      "\tgrad = 2.853669\n",
      "rate = 0.001602\n",
      "Step 855 / 1000, loss = -7934.839326\n",
      "a_1 = 11.750628, a_2 = 8.024381, b = 2.649744\n",
      "\tgrad = 2.676880\n",
      "rate = 0.001600\n",
      "Step 856 / 1000, loss = -7934.877056\n",
      "a_1 = 11.753971, a_2 = 8.026868, b = 2.650518\n",
      "\tgrad = 2.651238\n",
      "rate = 0.001598\n",
      "Step 857 / 1000, loss = -7934.914111\n",
      "a_1 = 11.757286, a_2 = 8.029271, b = 2.651284\n",
      "\tgrad = 2.609944\n",
      "rate = 0.001596\n",
      "Step 858 / 1000, loss = -7934.951344\n",
      "a_1 = 11.760631, a_2 = 8.031676, b = 2.652056\n",
      "\tgrad = 2.628387\n",
      "rate = 0.001595\n",
      "Step 859 / 1000, loss = -7934.988830\n",
      "a_1 = 11.764046, a_2 = 8.034042, b = 2.652841\n",
      "\tgrad = 2.654581\n",
      "rate = 0.001593\n",
      "Step 860 / 1000, loss = -7935.025832\n",
      "a_1 = 11.767486, a_2 = 8.036325, b = 2.653612\n",
      "\tgrad = 2.640273\n",
      "rate = 0.001591\n",
      "Step 861 / 1000, loss = -7935.065554\n",
      "a_1 = 11.771241, a_2 = 8.038744, b = 2.654431\n",
      "\tgrad = 2.857575\n",
      "rate = 0.001589\n",
      "Step 862 / 1000, loss = -7935.104515\n",
      "a_1 = 11.774861, a_2 = 8.041149, b = 2.655250\n",
      "\tgrad = 2.785976\n",
      "rate = 0.001587\n",
      "Step 863 / 1000, loss = -7935.144222\n",
      "a_1 = 11.778375, a_2 = 8.043819, b = 2.656058\n",
      "\tgrad = 2.830172\n",
      "rate = 0.001586\n",
      "Step 864 / 1000, loss = -7935.180975\n",
      "a_1 = 11.781768, a_2 = 8.046131, b = 2.656825\n",
      "\tgrad = 2.637070\n",
      "rate = 0.001584\n",
      "Step 865 / 1000, loss = -7935.219148\n",
      "a_1 = 11.785272, a_2 = 8.048563, b = 2.657617\n",
      "\tgrad = 2.742300\n",
      "rate = 0.001582\n",
      "Step 866 / 1000, loss = -7935.256291\n",
      "a_1 = 11.788593, a_2 = 8.051007, b = 2.658393\n",
      "\tgrad = 2.655422\n",
      "rate = 0.001580\n",
      "Step 867 / 1000, loss = -7935.293585\n",
      "a_1 = 11.792029, a_2 = 8.053362, b = 2.659178\n",
      "\tgrad = 2.685616\n",
      "rate = 0.001578\n",
      "Step 868 / 1000, loss = -7935.332002\n",
      "a_1 = 11.795464, a_2 = 8.055876, b = 2.659993\n",
      "\tgrad = 2.749002\n",
      "rate = 0.001577\n",
      "Step 869 / 1000, loss = -7935.370232\n",
      "a_1 = 11.798852, a_2 = 8.058455, b = 2.660782\n",
      "\tgrad = 2.749918\n",
      "rate = 0.001575\n",
      "Step 870 / 1000, loss = -7935.408974\n",
      "a_1 = 11.802403, a_2 = 8.060973, b = 2.661578\n",
      "\tgrad = 2.812902\n",
      "rate = 0.001573\n",
      "Step 871 / 1000, loss = -7935.448936\n",
      "a_1 = 11.805987, a_2 = 8.063634, b = 2.662406\n",
      "\tgrad = 2.889717\n",
      "rate = 0.001571\n",
      "Step 872 / 1000, loss = -7935.486241\n",
      "a_1 = 11.809362, a_2 = 8.066081, b = 2.663187\n",
      "\tgrad = 2.702112\n",
      "rate = 0.001570\n",
      "Step 873 / 1000, loss = -7935.523296\n",
      "a_1 = 11.812709, a_2 = 8.068551, b = 2.663948\n",
      "\tgrad = 2.697897\n",
      "rate = 0.001568\n",
      "Step 874 / 1000, loss = -7935.560793\n",
      "a_1 = 11.816223, a_2 = 8.070914, b = 2.664731\n",
      "\tgrad = 2.749469\n",
      "rate = 0.001566\n",
      "Step 875 / 1000, loss = -7935.598528\n",
      "a_1 = 11.819653, a_2 = 8.073443, b = 2.665494\n",
      "\tgrad = 2.767832\n",
      "rate = 0.001564\n",
      "Step 876 / 1000, loss = -7935.635371\n",
      "a_1 = 11.823170, a_2 = 8.075701, b = 2.666271\n",
      "\tgrad = 2.720353\n",
      "rate = 0.001562\n",
      "Step 877 / 1000, loss = -7935.670788\n",
      "a_1 = 11.826544, a_2 = 8.077880, b = 2.667018\n",
      "\tgrad = 2.617861\n",
      "rate = 0.001561\n",
      "Step 878 / 1000, loss = -7935.707779\n",
      "a_1 = 11.829934, a_2 = 8.080282, b = 2.667801\n",
      "\tgrad = 2.711785\n",
      "rate = 0.001559\n",
      "Step 879 / 1000, loss = -7935.746291\n",
      "a_1 = 11.833555, a_2 = 8.082719, b = 2.668608\n",
      "\tgrad = 2.850332\n",
      "rate = 0.001557\n",
      "Step 880 / 1000, loss = -7935.781294\n",
      "a_1 = 11.836814, a_2 = 8.084973, b = 2.669339\n",
      "\tgrad = 2.590283\n",
      "rate = 0.001556\n",
      "Step 881 / 1000, loss = -7935.817950\n",
      "a_1 = 11.840227, a_2 = 8.087332, b = 2.670108\n",
      "\tgrad = 2.715440\n",
      "rate = 0.001554\n",
      "Step 882 / 1000, loss = -7935.855238\n",
      "a_1 = 11.843739, a_2 = 8.089712, b = 2.670884\n",
      "\tgrad = 2.778764\n",
      "rate = 0.001552\n",
      "Step 883 / 1000, loss = -7935.893316\n",
      "a_1 = 11.847279, a_2 = 8.092188, b = 2.671678\n",
      "\tgrad = 2.833116\n",
      "rate = 0.001550\n",
      "Step 884 / 1000, loss = -7935.931663\n",
      "a_1 = 11.850746, a_2 = 8.094782, b = 2.672475\n",
      "\tgrad = 2.842889\n",
      "rate = 0.001549\n",
      "Step 885 / 1000, loss = -7935.966360\n",
      "a_1 = 11.854018, a_2 = 8.096950, b = 2.673227\n",
      "\tgrad = 2.583147\n",
      "rate = 0.001547\n",
      "Step 886 / 1000, loss = -7936.003158\n",
      "a_1 = 11.857476, a_2 = 8.099313, b = 2.674000\n",
      "\tgrad = 2.756377\n",
      "rate = 0.001545\n",
      "Step 887 / 1000, loss = -7936.040419\n",
      "a_1 = 11.860932, a_2 = 8.101723, b = 2.674798\n",
      "\tgrad = 2.778346\n",
      "rate = 0.001544\n",
      "Step 888 / 1000, loss = -7936.073933\n",
      "a_1 = 11.863985, a_2 = 8.103914, b = 2.675532\n",
      "\tgrad = 2.483546\n",
      "rate = 0.001542\n",
      "Step 889 / 1000, loss = -7936.108469\n",
      "a_1 = 11.867155, a_2 = 8.106177, b = 2.676277\n",
      "\tgrad = 2.574554\n",
      "rate = 0.001540\n",
      "Step 890 / 1000, loss = -7936.143114\n",
      "a_1 = 11.870425, a_2 = 8.108360, b = 2.677029\n",
      "\tgrad = 2.601640\n",
      "rate = 0.001538\n",
      "Step 891 / 1000, loss = -7936.178743\n",
      "a_1 = 11.873693, a_2 = 8.110722, b = 2.677790\n",
      "\tgrad = 2.670278\n",
      "rate = 0.001537\n",
      "Step 892 / 1000, loss = -7936.214279\n",
      "a_1 = 11.876911, a_2 = 8.113134, b = 2.678542\n",
      "\tgrad = 2.665383\n",
      "rate = 0.001535\n",
      "Step 893 / 1000, loss = -7936.249696\n",
      "a_1 = 11.880160, a_2 = 8.115502, b = 2.679294\n",
      "\tgrad = 2.666846\n",
      "rate = 0.001533\n",
      "Step 894 / 1000, loss = -7936.285224\n",
      "a_1 = 11.883504, a_2 = 8.117790, b = 2.680053\n",
      "\tgrad = 2.691844\n",
      "rate = 0.001532\n",
      "Step 895 / 1000, loss = -7936.317229\n",
      "a_1 = 11.886537, a_2 = 8.119826, b = 2.680743\n",
      "\tgrad = 2.429865\n",
      "rate = 0.001530\n",
      "Step 896 / 1000, loss = -7936.351028\n",
      "a_1 = 11.889650, a_2 = 8.122094, b = 2.681457\n",
      "\tgrad = 2.562690\n",
      "rate = 0.001528\n",
      "Step 897 / 1000, loss = -7936.385732\n",
      "a_1 = 11.892826, a_2 = 8.124443, b = 2.682191\n",
      "\tgrad = 2.631680\n",
      "rate = 0.001527\n",
      "Step 898 / 1000, loss = -7936.420139\n",
      "a_1 = 11.896104, a_2 = 8.126586, b = 2.682955\n",
      "\tgrad = 2.616329\n",
      "rate = 0.001525\n",
      "Step 899 / 1000, loss = -7936.456229\n",
      "a_1 = 11.899454, a_2 = 8.129007, b = 2.683713\n",
      "\tgrad = 2.758706\n",
      "rate = 0.001523\n",
      "Step 900 / 1000, loss = -7936.490512\n",
      "a_1 = 11.902559, a_2 = 8.131344, b = 2.684452\n",
      "\tgrad = 2.599463\n",
      "rate = 0.001522\n",
      "Step 901 / 1000, loss = -7936.526439\n",
      "a_1 = 11.905849, a_2 = 8.133806, b = 2.685206\n",
      "\tgrad = 2.748232\n",
      "rate = 0.001520\n",
      "Step 902 / 1000, loss = -7936.559921\n",
      "a_1 = 11.909040, a_2 = 8.135929, b = 2.685940\n",
      "\tgrad = 2.569853\n",
      "rate = 0.001518\n",
      "Step 903 / 1000, loss = -7936.593738\n",
      "a_1 = 11.912248, a_2 = 8.138084, b = 2.686684\n",
      "\tgrad = 2.594474\n",
      "rate = 0.001517\n",
      "Step 904 / 1000, loss = -7936.625728\n",
      "a_1 = 11.915238, a_2 = 8.140169, b = 2.687387\n",
      "\tgrad = 2.450791\n",
      "rate = 0.001515\n",
      "Step 905 / 1000, loss = -7936.660709\n",
      "a_1 = 11.918446, a_2 = 8.142533, b = 2.688146\n",
      "\tgrad = 2.679884\n",
      "rate = 0.001514\n",
      "Step 906 / 1000, loss = -7936.694994\n",
      "a_1 = 11.921658, a_2 = 8.144797, b = 2.688886\n",
      "\tgrad = 2.644892\n",
      "rate = 0.001512\n",
      "Step 907 / 1000, loss = -7936.728735\n",
      "a_1 = 11.924855, a_2 = 8.146968, b = 2.689629\n",
      "\tgrad = 2.605760\n",
      "rate = 0.001510\n",
      "Step 908 / 1000, loss = -7936.762285\n",
      "a_1 = 11.928029, a_2 = 8.149117, b = 2.690378\n",
      "\tgrad = 2.588850\n",
      "rate = 0.001509\n",
      "Step 909 / 1000, loss = -7936.796062\n",
      "a_1 = 11.931166, a_2 = 8.151384, b = 2.691109\n",
      "\tgrad = 2.613443\n",
      "rate = 0.001507\n",
      "Step 910 / 1000, loss = -7936.831740\n",
      "a_1 = 11.934629, a_2 = 8.153665, b = 2.691870\n",
      "\tgrad = 2.800875\n",
      "rate = 0.001505\n",
      "Step 911 / 1000, loss = -7936.868022\n",
      "a_1 = 11.937962, a_2 = 8.156141, b = 2.692657\n",
      "\tgrad = 2.810349\n",
      "rate = 0.001504\n",
      "Step 912 / 1000, loss = -7936.903225\n",
      "a_1 = 11.941380, a_2 = 8.158369, b = 2.693424\n",
      "\tgrad = 2.763991\n",
      "rate = 0.001502\n",
      "Step 913 / 1000, loss = -7936.936104\n",
      "a_1 = 11.944464, a_2 = 8.160564, b = 2.694137\n",
      "\tgrad = 2.566624\n",
      "rate = 0.001501\n",
      "Step 914 / 1000, loss = -7936.971284\n",
      "a_1 = 11.947847, a_2 = 8.162839, b = 2.694900\n",
      "\tgrad = 2.767172\n",
      "rate = 0.001499\n",
      "Step 915 / 1000, loss = -7937.003425\n",
      "a_1 = 11.950905, a_2 = 8.164919, b = 2.695614\n",
      "\tgrad = 2.515184\n",
      "rate = 0.001497\n",
      "Step 916 / 1000, loss = -7937.036934\n",
      "a_1 = 11.954138, a_2 = 8.167105, b = 2.696331\n",
      "\tgrad = 2.652962\n",
      "rate = 0.001496\n",
      "Step 917 / 1000, loss = -7937.072743\n",
      "a_1 = 11.957615, a_2 = 8.169374, b = 2.697123\n",
      "\tgrad = 2.829094\n",
      "rate = 0.001494\n",
      "Step 918 / 1000, loss = -7937.106303\n",
      "a_1 = 11.960826, a_2 = 8.171535, b = 2.697872\n",
      "\tgrad = 2.641549\n",
      "rate = 0.001493\n",
      "Step 919 / 1000, loss = -7937.139742\n",
      "a_1 = 11.963994, a_2 = 8.173757, b = 2.698601\n",
      "\tgrad = 2.640843\n",
      "rate = 0.001491\n",
      "Step 920 / 1000, loss = -7937.173844\n",
      "a_1 = 11.967172, a_2 = 8.176089, b = 2.699338\n",
      "\tgrad = 2.692160\n",
      "rate = 0.001489\n",
      "Step 921 / 1000, loss = -7937.209074\n",
      "a_1 = 11.970476, a_2 = 8.178512, b = 2.700085\n",
      "\tgrad = 2.799515\n",
      "rate = 0.001488\n",
      "Step 922 / 1000, loss = -7937.243454\n",
      "a_1 = 11.973644, a_2 = 8.180885, b = 2.700839\n",
      "\tgrad = 2.711091\n",
      "rate = 0.001486\n",
      "Step 923 / 1000, loss = -7937.275477\n",
      "a_1 = 11.976620, a_2 = 8.183082, b = 2.701538\n",
      "\tgrad = 2.535515\n",
      "rate = 0.001485\n",
      "Step 924 / 1000, loss = -7937.308877\n",
      "a_1 = 11.979785, a_2 = 8.185294, b = 2.702281\n",
      "\tgrad = 2.651429\n",
      "rate = 0.001483\n",
      "Step 925 / 1000, loss = -7937.342252\n",
      "a_1 = 11.982910, a_2 = 8.187558, b = 2.703016\n",
      "\tgrad = 2.651916\n",
      "rate = 0.001481\n",
      "Step 926 / 1000, loss = -7937.376159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 11.986126, a_2 = 8.189818, b = 2.703766\n",
      "\tgrad = 2.703825\n",
      "rate = 0.001480\n",
      "Step 927 / 1000, loss = -7937.407682\n",
      "a_1 = 11.989083, a_2 = 8.191930, b = 2.704476\n",
      "\tgrad = 2.504316\n",
      "rate = 0.001478\n",
      "Step 928 / 1000, loss = -7937.438790\n",
      "a_1 = 11.991990, a_2 = 8.194052, b = 2.705164\n",
      "\tgrad = 2.481251\n",
      "rate = 0.001477\n",
      "Step 929 / 1000, loss = -7937.472223\n",
      "a_1 = 11.995062, a_2 = 8.196380, b = 2.705906\n",
      "\tgrad = 2.660949\n",
      "rate = 0.001475\n",
      "Step 930 / 1000, loss = -7937.505355\n",
      "a_1 = 11.998075, a_2 = 8.198724, b = 2.706640\n",
      "\tgrad = 2.637531\n",
      "rate = 0.001474\n",
      "Step 931 / 1000, loss = -7937.538435\n",
      "a_1 = 12.001340, a_2 = 8.200897, b = 2.707339\n",
      "\tgrad = 2.706686\n",
      "rate = 0.001472\n",
      "Step 932 / 1000, loss = -7937.572770\n",
      "a_1 = 12.004631, a_2 = 8.203219, b = 2.708080\n",
      "\tgrad = 2.784460\n",
      "rate = 0.001471\n",
      "Step 933 / 1000, loss = -7937.607694\n",
      "a_1 = 12.007890, a_2 = 8.205699, b = 2.708818\n",
      "\tgrad = 2.832456\n",
      "rate = 0.001469\n",
      "Step 934 / 1000, loss = -7937.639840\n",
      "a_1 = 12.010933, a_2 = 8.207877, b = 2.709531\n",
      "\tgrad = 2.596430\n",
      "rate = 0.001468\n",
      "Step 935 / 1000, loss = -7937.674569\n",
      "a_1 = 12.014396, a_2 = 8.210120, b = 2.710278\n",
      "\tgrad = 2.860072\n",
      "rate = 0.001466\n",
      "Step 936 / 1000, loss = -7937.709202\n",
      "a_1 = 12.017777, a_2 = 8.212409, b = 2.711034\n",
      "\tgrad = 2.835128\n",
      "rate = 0.001464\n",
      "Step 937 / 1000, loss = -7937.742704\n",
      "a_1 = 12.021099, a_2 = 8.214592, b = 2.711758\n",
      "\tgrad = 2.762620\n",
      "rate = 0.001463\n",
      "Step 938 / 1000, loss = -7937.774337\n",
      "a_1 = 12.024183, a_2 = 8.216659, b = 2.712467\n",
      "\tgrad = 2.585792\n",
      "rate = 0.001461\n",
      "Step 939 / 1000, loss = -7937.806327\n",
      "a_1 = 12.027240, a_2 = 8.218820, b = 2.713178\n",
      "\tgrad = 2.610593\n",
      "rate = 0.001460\n",
      "Step 940 / 1000, loss = -7937.838180\n",
      "a_1 = 12.030248, a_2 = 8.221031, b = 2.713875\n",
      "\tgrad = 2.604123\n",
      "rate = 0.001458\n",
      "Step 941 / 1000, loss = -7937.869443\n",
      "a_1 = 12.033216, a_2 = 8.223161, b = 2.714574\n",
      "\tgrad = 2.553109\n",
      "rate = 0.001457\n",
      "Step 942 / 1000, loss = -7937.901952\n",
      "a_1 = 12.036431, a_2 = 8.225284, b = 2.715290\n",
      "\tgrad = 2.692500\n",
      "rate = 0.001455\n",
      "Step 943 / 1000, loss = -7937.935548\n",
      "a_1 = 12.039651, a_2 = 8.227579, b = 2.716029\n",
      "\tgrad = 2.767159\n",
      "rate = 0.001454\n",
      "Step 944 / 1000, loss = -7937.968654\n",
      "a_1 = 12.042832, a_2 = 8.229827, b = 2.716762\n",
      "\tgrad = 2.729198\n",
      "rate = 0.001452\n",
      "Step 945 / 1000, loss = -7938.000910\n",
      "a_1 = 12.045895, a_2 = 8.232033, b = 2.717488\n",
      "\tgrad = 2.649865\n",
      "rate = 0.001451\n",
      "Step 946 / 1000, loss = -7938.033946\n",
      "a_1 = 12.048993, a_2 = 8.234353, b = 2.718221\n",
      "\tgrad = 2.717796\n",
      "rate = 0.001449\n",
      "Step 947 / 1000, loss = -7938.066894\n",
      "a_1 = 12.052314, a_2 = 8.236473, b = 2.718945\n",
      "\tgrad = 2.766940\n",
      "rate = 0.001448\n",
      "Step 948 / 1000, loss = -7938.098020\n",
      "a_1 = 12.055309, a_2 = 8.238593, b = 2.719638\n",
      "\tgrad = 2.582061\n",
      "rate = 0.001446\n",
      "Step 949 / 1000, loss = -7938.130255\n",
      "a_1 = 12.058391, a_2 = 8.240788, b = 2.720367\n",
      "\tgrad = 2.666703\n",
      "rate = 0.001445\n",
      "Step 950 / 1000, loss = -7938.160893\n",
      "a_1 = 12.061412, a_2 = 8.242825, b = 2.721044\n",
      "\tgrad = 2.568080\n",
      "rate = 0.001443\n",
      "Step 951 / 1000, loss = -7938.193778\n",
      "a_1 = 12.064436, a_2 = 8.245161, b = 2.721800\n",
      "\tgrad = 2.701244\n",
      "rate = 0.001442\n",
      "Step 952 / 1000, loss = -7938.226871\n",
      "a_1 = 12.067681, a_2 = 8.247403, b = 2.722523\n",
      "\tgrad = 2.784395\n",
      "rate = 0.001440\n",
      "Step 953 / 1000, loss = -7938.260064\n",
      "a_1 = 12.070796, a_2 = 8.249787, b = 2.723248\n",
      "\tgrad = 2.771874\n",
      "rate = 0.001439\n",
      "Step 954 / 1000, loss = -7938.292329\n",
      "a_1 = 12.073860, a_2 = 8.252044, b = 2.723968\n",
      "\tgrad = 2.694774\n",
      "rate = 0.001437\n",
      "Step 955 / 1000, loss = -7938.325259\n",
      "a_1 = 12.077105, a_2 = 8.254290, b = 2.724680\n",
      "\tgrad = 2.792412\n",
      "rate = 0.001436\n",
      "Step 956 / 1000, loss = -7938.356455\n",
      "a_1 = 12.080271, a_2 = 8.256289, b = 2.725379\n",
      "\tgrad = 2.655616\n",
      "rate = 0.001434\n",
      "Step 957 / 1000, loss = -7938.387387\n",
      "a_1 = 12.083252, a_2 = 8.258402, b = 2.726081\n",
      "\tgrad = 2.596727\n",
      "rate = 0.001433\n",
      "Step 958 / 1000, loss = -7938.420175\n",
      "a_1 = 12.086446, a_2 = 8.260652, b = 2.726807\n",
      "\tgrad = 2.775936\n",
      "rate = 0.001431\n",
      "Step 959 / 1000, loss = -7938.451744\n",
      "a_1 = 12.089542, a_2 = 8.262768, b = 2.727523\n",
      "\tgrad = 2.669888\n",
      "rate = 0.001430\n",
      "Step 960 / 1000, loss = -7938.481773\n",
      "a_1 = 12.092465, a_2 = 8.264823, b = 2.728196\n",
      "\tgrad = 2.544869\n",
      "rate = 0.001429\n",
      "Step 961 / 1000, loss = -7938.513959\n",
      "a_1 = 12.095594, a_2 = 8.267081, b = 2.728892\n",
      "\tgrad = 2.748051\n",
      "rate = 0.001427\n",
      "Step 962 / 1000, loss = -7938.544124\n",
      "a_1 = 12.098542, a_2 = 8.269141, b = 2.729569\n",
      "\tgrad = 2.566169\n",
      "rate = 0.001426\n",
      "Step 963 / 1000, loss = -7938.575498\n",
      "a_1 = 12.101724, a_2 = 8.271189, b = 2.730269\n",
      "\tgrad = 2.702245\n",
      "rate = 0.001424\n",
      "Step 964 / 1000, loss = -7938.604608\n",
      "a_1 = 12.104508, a_2 = 8.273218, b = 2.730933\n",
      "\tgrad = 2.465554\n",
      "rate = 0.001423\n",
      "Step 965 / 1000, loss = -7938.636942\n",
      "a_1 = 12.107727, a_2 = 8.275344, b = 2.731678\n",
      "\tgrad = 2.764950\n",
      "rate = 0.001421\n",
      "Step 966 / 1000, loss = -7938.669218\n",
      "a_1 = 12.110949, a_2 = 8.277523, b = 2.732392\n",
      "\tgrad = 2.784837\n",
      "rate = 0.001420\n",
      "Step 967 / 1000, loss = -7938.702735\n",
      "a_1 = 12.114328, a_2 = 8.279751, b = 2.733138\n",
      "\tgrad = 2.901255\n",
      "rate = 0.001418\n",
      "Step 968 / 1000, loss = -7938.733755\n",
      "a_1 = 12.117269, a_2 = 8.281940, b = 2.733852\n",
      "\tgrad = 2.636258\n",
      "rate = 0.001417\n",
      "Step 969 / 1000, loss = -7938.764710\n",
      "a_1 = 12.120292, a_2 = 8.284072, b = 2.734553\n",
      "\tgrad = 2.659678\n",
      "rate = 0.001416\n",
      "Step 970 / 1000, loss = -7938.796426\n",
      "a_1 = 12.123460, a_2 = 8.286223, b = 2.735257\n",
      "\tgrad = 2.753324\n",
      "rate = 0.001414\n",
      "Step 971 / 1000, loss = -7938.827714\n",
      "a_1 = 12.126547, a_2 = 8.288375, b = 2.735957\n",
      "\tgrad = 2.709664\n",
      "rate = 0.001413\n",
      "Step 972 / 1000, loss = -7938.859501\n",
      "a_1 = 12.129567, a_2 = 8.290680, b = 2.736664\n",
      "\tgrad = 2.737849\n",
      "rate = 0.001411\n",
      "Step 973 / 1000, loss = -7938.890228\n",
      "a_1 = 12.132598, a_2 = 8.292829, b = 2.737338\n",
      "\tgrad = 2.678059\n",
      "rate = 0.001410\n",
      "Step 974 / 1000, loss = -7938.920508\n",
      "a_1 = 12.135583, a_2 = 8.294896, b = 2.738029\n",
      "\tgrad = 2.624836\n",
      "rate = 0.001408\n",
      "Step 975 / 1000, loss = -7938.951599\n",
      "a_1 = 12.138640, a_2 = 8.297033, b = 2.738738\n",
      "\tgrad = 2.698334\n",
      "rate = 0.001407\n",
      "Step 976 / 1000, loss = -7938.982707\n",
      "a_1 = 12.141634, a_2 = 8.299221, b = 2.739455\n",
      "\tgrad = 2.686427\n",
      "rate = 0.001406\n",
      "Step 977 / 1000, loss = -7939.011879\n",
      "a_1 = 12.144492, a_2 = 8.301248, b = 2.740118\n",
      "\tgrad = 2.539826\n",
      "rate = 0.001404\n",
      "Step 978 / 1000, loss = -7939.042218\n",
      "a_1 = 12.147452, a_2 = 8.303364, b = 2.740811\n",
      "\tgrad = 2.640586\n",
      "rate = 0.001403\n",
      "Step 979 / 1000, loss = -7939.073933\n",
      "a_1 = 12.150665, a_2 = 8.305486, b = 2.741528\n",
      "\tgrad = 2.794708\n",
      "rate = 0.001401\n",
      "Step 980 / 1000, loss = -7939.105197\n",
      "a_1 = 12.153747, a_2 = 8.307683, b = 2.742224\n",
      "\tgrad = 2.748747\n",
      "rate = 0.001400\n",
      "Step 981 / 1000, loss = -7939.134525\n",
      "a_1 = 12.156638, a_2 = 8.309697, b = 2.742903\n",
      "\tgrad = 2.565393\n",
      "rate = 0.001399\n",
      "Step 982 / 1000, loss = -7939.166296\n",
      "a_1 = 12.159792, a_2 = 8.311910, b = 2.743614\n",
      "\tgrad = 2.804066\n",
      "rate = 0.001397\n",
      "Step 983 / 1000, loss = -7939.199918\n",
      "a_1 = 12.163193, a_2 = 8.314193, b = 2.744369\n",
      "\tgrad = 2.984181\n",
      "rate = 0.001396\n",
      "Step 984 / 1000, loss = -7939.229077\n",
      "a_1 = 12.166113, a_2 = 8.316201, b = 2.745026\n",
      "\tgrad = 2.584575\n",
      "rate = 0.001394\n",
      "Step 985 / 1000, loss = -7939.260334\n",
      "a_1 = 12.169163, a_2 = 8.318418, b = 2.745736\n",
      "\tgrad = 2.754331\n",
      "rate = 0.001393\n",
      "Step 986 / 1000, loss = -7939.291988\n",
      "a_1 = 12.172205, a_2 = 8.320693, b = 2.746464\n",
      "\tgrad = 2.779463\n",
      "rate = 0.001392\n",
      "Step 987 / 1000, loss = -7939.322835\n",
      "a_1 = 12.175162, a_2 = 8.322952, b = 2.747158\n",
      "\tgrad = 2.723004\n",
      "rate = 0.001390\n",
      "Step 988 / 1000, loss = -7939.352018\n",
      "a_1 = 12.177964, a_2 = 8.325069, b = 2.747824\n",
      "\tgrad = 2.573565\n",
      "rate = 0.001389\n",
      "Step 989 / 1000, loss = -7939.382616\n",
      "a_1 = 12.180990, a_2 = 8.327195, b = 2.748532\n",
      "\tgrad = 2.713455\n",
      "rate = 0.001388\n",
      "Step 990 / 1000, loss = -7939.411312\n",
      "a_1 = 12.183800, a_2 = 8.329220, b = 2.749194\n",
      "\tgrad = 2.543896\n",
      "rate = 0.001386\n",
      "Step 991 / 1000, loss = -7939.441518\n",
      "a_1 = 12.186869, a_2 = 8.331283, b = 2.749877\n",
      "\tgrad = 2.715664\n",
      "rate = 0.001385\n",
      "Step 992 / 1000, loss = -7939.473151\n",
      "a_1 = 12.190032, a_2 = 8.333500, b = 2.750590\n",
      "\tgrad = 2.838971\n",
      "rate = 0.001383\n",
      "Step 993 / 1000, loss = -7939.502770\n",
      "a_1 = 12.192895, a_2 = 8.335658, b = 2.751263\n",
      "\tgrad = 2.639331\n",
      "rate = 0.001382\n",
      "Step 994 / 1000, loss = -7939.533042\n",
      "a_1 = 12.195955, a_2 = 8.337712, b = 2.751967\n",
      "\tgrad = 2.717863\n",
      "rate = 0.001381\n",
      "Step 995 / 1000, loss = -7939.563156\n",
      "a_1 = 12.198997, a_2 = 8.339813, b = 2.752641\n",
      "\tgrad = 2.724930\n",
      "rate = 0.001379\n",
      "Step 996 / 1000, loss = -7939.591811\n",
      "a_1 = 12.201890, a_2 = 8.341806, b = 2.753289\n",
      "\tgrad = 2.592592\n",
      "rate = 0.001378\n",
      "Step 997 / 1000, loss = -7939.621158\n",
      "a_1 = 12.204778, a_2 = 8.343898, b = 2.753963\n",
      "\tgrad = 2.636063\n",
      "rate = 0.001377\n",
      "Step 998 / 1000, loss = -7939.651844\n",
      "a_1 = 12.207823, a_2 = 8.346082, b = 2.754661\n",
      "\tgrad = 2.771490\n",
      "rate = 0.001375\n",
      "Step 999 / 1000, loss = -7939.681952\n",
      "a_1 = 12.210800, a_2 = 8.348197, b = 2.755366\n",
      "\tgrad = 2.707177\n",
      "rate = 0.001374\n",
      "Step 1000 / 1000, loss = -7939.710629\n",
      "a_1 = 12.213532, a_2 = 8.350324, b = 2.756030\n",
      "\tgrad = 2.568619\n",
      "rate = 0.001373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "print (generic function with 46 methods)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf = readtable(\"data.csv\")\n",
    "x,y = convertdata_to_array(dtf)\n",
    "nb_steps = 1000\n",
    "\n",
    "params = NNparams(init_params(x))\n",
    "param_history_a1 = Float64[]\n",
    "param_history_a2 = Float64[]\n",
    "param_history_a3 = Float64[]\n",
    "loss_history = Float64[]\n",
    "output_history = Float64[]\n",
    "grad_history = Float64[]\n",
    "learning_rate_history = Float64[]\n",
    "\n",
    "for s = 1:nb_steps  \n",
    "    x_training,y_training = select_trainingdata(x,y,1000)\n",
    "    grad = ∇(x_training, y_training, params)\n",
    "    learning_rate = update_learning_rate(.07,s)\n",
    "    params = updateNNparams(grad,params,learning_rate)\n",
    "    result = output(params, x_training[s,:])\n",
    "    loss_at_this_step = loss(params,y,x)\n",
    "    @printf(\"Step %d / %d, loss = %f\\n\", s, nb_steps, loss_at_this_step)\n",
    "    @printf(\"a_1 = %f, a_2 = %f, b = %f\\n\", params.a[1],params.a[2],\n",
    "        params.a[3])\n",
    "    @printf(\"\\tgrad = %f\\n\", norm(grad))\n",
    "    @printf(\"rate = %f\\n\",learning_rate)\n",
    "\n",
    "    #push!(param_history,params)\n",
    "    push!(param_history_a1, params.a[1])\n",
    "    push!(param_history_a2, params.a[2])\n",
    "    push!(param_history_a3, params.a[3])\n",
    "    \n",
    "    push!(loss_history, loss_at_this_step)\n",
    "    \n",
    "    #if s == 10\n",
    "        #for i = 1:s\n",
    "        #printNNparam(param_history[i])\n",
    "        #end\n",
    "    #end\n",
    "    #for i = 1:length(x_training[:,1])\n",
    "       push!(output_history,result)\n",
    "    #end\n",
    "end\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" />"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "x = [i for i= 1:nb_steps] ; y = loss_history\n",
    "plot(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" />"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "    #for s = 1:nb_steps\n",
    "        x = param_history_a1;\n",
    "        y = param_history_a2\n",
    "    #end\n",
    "plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAlgAAAGQCAYAAAByNR6YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XtclHXC//8XyEFBGQ6mWCiijqnJrnZvK2opHhC3QCWQULQQ0Cy7VUrykLitd5vVYnt3540ddrfwW3GoLbHM8kBWjrvp7upWu7WlIphF5GmGgweQ+f3h7tw/loOiw1xjvZ+PR49HM5/rM5/3xB+9H9f1ua7xsNvtdkRERETEaTyNDiAiIiLyfaOCJSIiIuJkLi1Ydrsdm82GrkqKiIjI95mXKxerrq7GZDJhtVoJCAhw5dJuz2q1YjKZjI4hl0B/q6uDh4eH0RFE5Cri4QF2O047CeTSgiWtO3/+vNER5BLpb3V1SU4NJqyPj9ExRMSNfVtZz8svHHfqZ6pgicj3WlgfHxUsEXE5bXIXERERcTKdwRIREREAzpxpxGY9zw/tXrQTxxsc//7555+3eIynpye9evWiW7dul/SZKlgiIiI/cI2Ndna8W80//u5JJ09v4Id1k8j5853o3r07ALNmzWrz2ISEBJYvX46nZ9sXAVWwREREfuB2vFtN2ZddWbxoPpFDB+Hl/cOqB/X1do4fu3AWa+jQoa0cU8++fft4+umnAXjooYfa/Mwf1n9BERERaeLM6Ub+8XdPFi+aT3JyvNFxDHHunJ1uXesBGDRoUKvHRUZGAvA///M/LFy4sM3LhdrkLiIi8gNms52nk6c3kUNbLxbyf4YPHw7AN9980+ZxKlgiIiI/YBc2tHv84C4LXi5vb28AGhsb2zxOBUtERESuChUVR0lIyMA8YDQTxicbHadNqqsiIiICwAP7Q/nc5uuStQYFnGXtsMp2zenWrSvLli3AZqvhsTXrOiiZc6hgiYiICACf23z580k/o2OQl5fPoYPl5K5dBYDVamNkVDyW3ZsYMeJGLJa9Bie8OF0iFBEREbeSmprAli2lWK02AAoLSoiNjSYoyGRwskvXrGC9/fbb3HjjjQwbNoyhQ4eSn58PQFVVFZMnT8ZsNjN06FA++OADx5y6ujpmzJjBgAEDGDhwIK+99prrvoGIiIh8r5hMAcTFx1BQsBG73U5+fjHpGSlGx2qXJpcI7XY7s2bNYufOnfzoRz/i8OHDDBo0iNtvv51ly5YRFRXFO++8w969e0lISKCsrAxvb29yc3Px9fXlwIEDlJWVMWLECMaNG0dISIhR30tERESuYpmZM7nrzoWYzf0ICQkmMnKw0ZHapdkeLA8PD06dOgWAzWYjJCQEX19fiouLOXDgAAA33XQT1157Le+//z4TJ06kqKiI3/72twBEREQQHR3NG2+8QWZmpgu/ioiIiFyJQQFn3WYtszmC8PAwspesJicny0WpnKdJwfLw8KCoqIjbb78df39/Tp48yeuvv051dTX19fWEhoY6ju3bty8VFRUAVFRUEB4e3uJYS2w2W5PXvr6++Pq65q4FERERaVl77+rraKmzElmxfA1x8RMBqKs7zehRUzh7rp5qWzXDh8WQlBTHQysXGZy0uSYFq6GhgUceeYTXX3+dMWPGsHfvXqZMmcL+/fudumjv3r2bvH7wwQdZunSpU9e42pw8edLoCHKJ9LcSEXENi2UPaXOSHQ/39PPrwr792zp0zYaGhouONzY2curUKU6cOOF4Pzg4uMlxTQrW/v37+frrrxkzZgxw4VJgWFgYH3/8MV5eXlRWVjrOYh0+fJg+ffoA0KdPH8rLy+nVq5djbNKkSa2GO3LkCAEBAY7XOoN1wb//ccR96W8lItJxKiurSEqcS2CgicKi9S5d28ur7SdYeXl54enpSWBgYJv/L2hyF2Hv3r355ptv+OyzzwA4cOAABw8e5Prrr2f69Ok888wzAOzdu5ejR48yduxYgCZjZWVl7Ny5k2nTprW6aEBAQJN/VK5ERETkX0JDe7DLUsJbmzfQtau/0XEuS5Oa1rNnT5577jmSk5Px9PSksbGRdevW0adPHx5//HFmz56N2WzGx8eHl156yXHKLjs7m/T0dPr370+nTp1Yt24d3bt3N+QLiYiIiBit2XmwGTNmMGPGjGYH9uzZk61bt7b4If7+/hQVFTk/nYiIiMhVSE9yFxEREXEyFSwRERERJ9OPPYuIiMhVYdeHH/HII09RW3caDw+YOHEMK1cuwtPT/c4XuV8iERERkRaYAgN49tkn+PDDN9i6tZA/7d1PcfGbRsdqkc5giYiICAANb78G37noae7XhOJ1a1KLQ3l5+Rw6WE7u2lUAWK02RkbFY9m9iaAgEwCdO/tyw9DrOXLka9fkbScVLBEREbngu0rsR1v/qTtn8mhjLDU1gVEjp5CzajEmUwCFBSXExkY7yhVAVdUx3npzO//vpac7Puxl0CVCERERcSsmUwBx8TEUFGzEbreTn19MekaKY7y6uobZsxey4L40hg27wcCkrdMZLBEREXE7mZkzuevOhZjN/QgJCSYycjAANTW1zEi5l8mx0cyff6fBKVunM1giIiLidszmCMLDw8hespr09Atnr2pr65iRci/jxo8i6/55Bidsm85giYiIyAXXhLa5N8rZa11M6qxEVixfQ1z8RACef+5l9u37lLq607y9uRSA+PgYFmfN7dCol0MFS0RERABavavPKBbLHtLmJDt++3hx1ly3LFMtUcESERERt1JZWUVS4lwCA00UFq03Os5lUcESERERtxIa2oNdlhKjY1wRbXIXERERcTIVLBEREREnU8ESERERcTIVLBEREREnU8ESERERcTLdRSgiIiJXhT/t/StLl/4SgPqGekb8dDiP/HIZvr4+BidrTgVLREREAHjm7xs5UlPlkrV6d+3B/CHT2jVnyA0Deefdl/H29qaxsZGM9Pt58YUi7p4/u4NSXj4VLBEREQHgSE0VX1qPGB2DvLx8Dh0sJ3ftKgCsVhsjo+Kx7N6En18XAM6dq+fMmbN4eLjsx33aRXuwRERExK2kpiawZUspVqsNgMKCEmJjowkKMlFRcZTx46YzZPBYunXrStqcOwxO2zIVLBEREXErJlMAcfExFBRsxG63k59fTHpGCgB9+lxH6Xuv8smnpZw7V8/bm7cbnLZlKlgiIiLidjIzZ7Ih/1VKSy2EhAQTGTm4ybi/vx/TpsXy+9+/bVDCtmkPloiIiAAXNp67y1pmcwTh4WFkL1lNTk4WAGVlFYSF9cLb2/vC2au3SxkyZKAr4rabCpaIiIgAtPuuvo6WOiuRFcvXEBc/EYBdH+7hN795hU6dOtFwvoFbbh5B1v3zDE7ZMhUsERERcUsWyx7S5iTj7e0NwOw7k5h9Z5LBqS6NCpaIiIi4lcrKKpIS5xIYaKKwaL3RcS6LCpaIiIi4ldDQHuyylBgd44roLkIRERERJ1PBEhEREXEyFSwRERERJ1PBEhEREXEyFSwRERERJ1PBEhERkauK3W4n8fZMBppvNjpKq/SYBhEREQHg2y1w7jvXrOVzDfT82eXNffbZ/0ffvr355JPPnRvKiVSwREREBLhQrs587eGi1eytjuTl5XPoYDm5a1cBYLXaGBkVj2X3Jr799jve2fIe//3Uat58c5uLsrafLhGKiIiIW0lNTWDLllKsVhsAhQUlxMZG07WrH0seWM0Tv8rB09O9K4x7pxMREZEfHJMpgLj4GAoKNmK328nPLyY9I4W1uc9y620TGDiwn9ERL0oFS0RERNxOZuZMNuS/SmmphZCQYCIjB/OHP/yJ3/62gJ/85GdMnZJGdXUNP/nJzzh27ITRcZvRHiwREREBLmw8b2tvlPPXap3ZHEF4eBjZS1aTk5MFQMmmFx3jFRVHmTjhDv70py0dmPLyqWCJiIgIcPl39XWU1FmJrFi+hrj4iUZHaTddIhQRERG3ZLHsIW1OMt7e3s3G+vS5ji++3GVAqkujM1giIiLiViorq0hKnEtgoInCovVGx7ksKlgiIiLiVkJDe7DLUmJ0jCuiS4QiIiIiTqaCJSIiIuJkKlgiIiIiTqaCJSIiIuJk2uQuIiIiVwWLZS+pMxfQv39fx3tvbd5Aly6djQvVChUsERERAeDLP/6aOmu5S9byM4Vjjspq97z+/fuyo7S4AxI5lwqWiIiIAFBnLaf62GdGxyAvL59DB8vJXbsKAKvVxsioeH6Vm2NwskunPVgiIiLiVlJTE9iypRSr1QZAYUEJsbHRBAaaKCurYML4ZGJjZ/LCC0UGJ22dzmCJiIiIWzGZAoiLj6GgYCN33z2b/Pxinn3uCfr27c3+v24jIKAbX3/9LakzFxAcHMjUqbFGR25GZ7BERETE7WRmzmRD/quUlloICQkmMnIw3bp1JSCgGwDXXtuThISf8dEf/2Jw0pbpDJaIiIgAFzaeu8taZnME4eFhZC9ZTU7Ohc3w3377HddcE4Knpyc1NbVs2/YBM2ZOc0XcdlPBEhEREYDLuquvI6XOSmTF8jXExU8E4K23tpOfX4xXJy8azjcQHz+JGTNUsEREREQumcWyh7Q5yXh7ewOQkTGDjIwZBqe6NCpYIiIi4lYqK6tISpxLYKCJwqL1Rse5LCpYIiIi4lZCQ3uwy1JidIwrorsIRURERJxMBUtERETEyVSwRERERJxMBUtERETEyVSwRERERJxMBUtERESuGp/9/UsSEjK45eZp3HLzNDZv3m50pBbpMQ0iIiICwAP/qOLz2nMuWWuQvw9rr+/Rrjl1dae5665FPL3uEUaMuJHz589z8qS1gxJeGRUsERERAeDz2nP8ufqs0THIy8vn0MFycteuAsBqtTEyKp57F6TxH//xI0aMuBGATp060b17sJFRW6VLhCIiIuJWUlMT2LKlFKvVBkBhQQmxsdF8V3UMH19vZqXex4Txydx330McO3bC4LQtU8ESERERt2IyBRAXH0NBwUbsdjv5+cWkZ6TQ0HCeDz/4iF/l5rB9RxG9QnuwdOkvjY7bIhUsERERcTuZmTPZkP8qpaUWQkKCiYwczHVhvRg1+iZ69eqJh4cHiUm38Zc/f2x01BZpD5aIiIgAFzaeu8taZnME4eFhZC9ZTU5OFgBTpkyi4JU3qK6uoVu3ruzYsYshN1zvirjtpoIlIiIiAO2+q6+jpc5KZMXyNcTFTwQgLKwXCxdlEHfbnXh6ehLaqwe5uasMTtkyFSwRERFxSxbLHtLmJOPt7e14b/r0eKZPjzcw1aVRwRIRERG3UllZRVLiXAIDTRQWrTc6zmVRwRIRERG3Ehrag12WEqNjXBHdRSgiIiLiZCpYIiIiIk6mgiUiIiLiZCpYIiIiIk6mTe4iIiJyVSgo2Mhvnn/F8fqbb74lKupGfvfCrw1M1bJmBevs2bM88MADvPvuu3Tu3Jkf//jHvPTSS1RVVXHnnXdy8OBBfH19ycvLY8yYMQDU1dWRkZHB3r178fT05NFHHyUpKcnlX0ZEREQuX6dXv4DKWtcsFurP+ekD2zVlxoxpzJgxzfF67JjbuT3xNmcnc4pmBWvZsmV4eHjwxRdf4OHhQWVlpeP9qKgo3nnnHfbu3UtCQgJlZWV4e3uTm5uLr68vBw4coKysjBEjRjBu3DhCQkJc/oVERETkMlXW4llR7ZKlGtsYy8vL59DBcnLXXnhKu9VqY2RUPJbdmwgKMgHwlz9/zLFjJ4iNHeuCtO3XZA9WbW0tv/3tb/nlL3+Jh4cHAKGhoQAUFxczf/58AG666SauvfZa3n//fQCKioocYxEREURHR/PGG2+47EuIiIjI90dqagJbtpRitdoAKCwoITY22lGuAF55ZSNJ0+OaPOXdnTQpWAcPHiQ4OJhHH32Un/zkJ9xyyy3s2LGD48ePU19f7yhbAH379qWiogKAiooKwsPDWxxric1ma/LP2bNnnf29RERE5CplMgUQFx9DQcFG7HY7+fnFpGekOMZra+vYuPEdZs5MMDBl25pcImxoaKC8vJwhQ4bw2GOPsW/fPmJiYvjb3/7m1EV79+7d5PWDDz7I0qVLnbrG1ebkyZNGR5BLpL+ViEjHy8ycyV13LsRs7kdISDCRkYMdY2++uY3rr+/P9df3d/q6DQ0NFx1vbGzk1KlTnDhxwvF+cHBwk+OaFKw+ffrg6elJamoqAMOHDyciIoJPPvkELy8vKisrHWexDh8+TJ8+fRzzysvL6dWrl2Ns0qRJrYY7cuQIAQEBjte+vr74+vpe9Et/3/37H0fcl/5WIvK9FOrf5t4oZ6/VFrM5gvDwMLKXrCYnJ6vJWMErb3TY2Ssvr7YfsODl5YWnpyeBgYFt/r+gyad0796dCRMm8O6773LrrbdSVlZGWVkZgwcPZvr06TzzzDM8/PDD7N27l6NHjzJ27IWNZf8ai4qKoqysjJ07d5KXl9fqogEBAU0KloiIiBivvXf1dbTUWYmsWL6GuPiJjvcOHDjMp5/+g5dfiTUw2cU1q2nPPPMMGRkZLF26FE9PT5599lmuu+46Hn/8cWbPno3ZbMbHx4eXXnrJsbEsOzub9PR0+vfvT6dOnVi3bh3du3d3+ZcRERGR7w+LZQ9pc5KbbGQfMKAvBw/9wcBUl6ZZwerXrx/vvfdeswN79uzJ1q1bW/wQf39/ioqKnJ9OREREfnAqK6tISpxLYKCJwqL1Rse5LHqSu4iIiLiV0NAe7LKUGB3jiui3CEVEREScTAVLRERExMlUsEREREScTAVLRERExMlUsEREREScTHcRioiIyFWhsbGRXzy8ltL3duPVqRNBQSbWPvlzIiL6GB2tGRUsERERAeC799dz7sQRl6zlE9yba8be0645776zkz179lNaWoy3tze/fvI5Hn30aZ5//lcdlPLyqWCJiIgIAOdOHOFs1RdGxyAvL59DB8vJXbsKAKvVxsioeH7+8AOcO1fP2bPn8PLyorqmlmt79TA4bctUsERERMStpKYmMGrkFHJWLcZkCqCwoITY2GimT4/j008+J3LoeLp29adXrx68sfF3RsdtkTa5i4iIiFsxmQKIi4+hoGAjdrud/Pxi0jNS2L//b3z++QH2/3Ubf/14OzffMoIHs//L6LgtUsESERERt5OZOZMN+a9SWmohJCSYyMjBvPrqm9x8808xmQLw9PQkOTkei2Wv0VFbpEuEIiIiAlzYeO4ua5nNEYSHh5G9ZDU5OVkAhIeHsWP7Lu659y58fLzZtu0DBg0a4Iq47aaCJSIiIgDtvquvo6XOSmTF8jXExU8EYM6cFL78oowJ46fj5eVFjx4hPPFEjsEpW6aCJSIiIm7JYtlD2pxkvL29AfD19WHtkz83ONWlUcESERERt1JZWUVS4lwCA00UFq03Os5lUcESERERtxIa2oNdlhKjY1wR3UUoIiIi4mQqWCIiIiJOpoIlIiIi4mQqWCIiIiJOpk3uIiIiclVobGxk9epf816phfPnz3PTTcN4/ImV+Ph4Gx2tGRUsERERAeCBf/ydz2trXbLWIH9/1l4/pF1zXnn5DT75+DO2bS/C29uLJQ+s5vnnX2bBgrSOCXkFVLBEREQEgM9ra/mzzWp0DPLy8jl0sJzctasAsFptjIyKJ37KJMaMiXKcsRo/YTS5v3rGLQuW9mCJiIiIW0lNTWDLllKsVhsAhQUlxMZGM2zYDbz77k6qq2uor69nU8lWjhz52uC0LVPBEhEREbdiMgUQFx9DQcFG7HY7+fnFpGekkJIylXHjR5MwLZ2EaRn06x+Ol1cno+O2SJcIRURExO1kZs7krjsXYjb3IyQkmMjIwQBkZ99DdvaFH6Xe+MYWrr++v5ExW6WCJSIiIsCFjefuspbZHEF4eBjZS1aTk5MFwJkzZzlz5iyBgQEcP36Sp59+gaVL73VF3HZTwRIRERGAdt/V19FSZyWyYvka4uInAlBtq+H22zPw8PTA3mgnc+5MJsVGGxuyFSpYIiIi4pYslj2kzUnG2/vCXYPX9Ajhw10bDU51aVSwRERExK1UVlaRlDiXwEAThUXrjY5zWVSwRERExK2EhvZgl6XE6BhXRI9pEBEREXEyFSwRERERJ1PBEhEREXEyFSwRERERJ1PBEhEREXEyFSwRERG5KlRUHCUhIQPzgNFMGJ/cbHzr1ve5efRURkbFkz4ni+rqGgNSXqDHNIiIiAgAH/3laU7Zyl2yVmBAOCNu/M92zenWrSvLli3AZqvhsTXrmozV1tZxf9bDvLHxd5jNESxf/ihPPvkcP//5/c6MfclUsERERASAU7Zyjp/4h9ExyMvL59DBcnLXrgLAarUxMioey+5NjBhxIxbL3mZzduzYRWTkIMzmCADS0u4g5Y75hhUsXSIUERERt5KamsCWLaVYrTYACgtKiI2NJijI1Oqco0e/ISysl+N1797X8u23x2hoaOjwvC1RwRIRERG3YjIFEBcfQ0HBRux2O/n5xaRnpBgdq11UsERERMTtZGbOZEP+q5SWWggJCSYycnCbx193XS+++uobx+sjR76mZ8/ueHkZsxtKe7BEREQEuLDx3F3WMpsjCA8PI3vJanJysi76eePHj2b5skf58ssyzOYIXnyxiKnTJjsrbrupYImIiAhAu+/q62ipsxJZsXwNcfETAairO83oUVM4e66eals1w4fFkJQUx0MrF9G1qz9PPvkwc9IW09BwnkGDBvA/T/+XYdlVsERERMQtWSx7SJuTjLe3NwB+fl3Yt39bq8fHTo4mdnK0i9K1TQVLRERE3EplZRVJiXMJDDRRWLTe6DiXRQVLRERE3EpoaA92WUqMjnFFdBehiIiIiJOpYImIiIg4mQqWiIiIiJOpYImIiIg4mQqWiIiIXBUqKo6SkJCBecBoJoxPbjJWW1tHyh3zGTJ4LAPNNxuU8P+oYImIiMhVoVu3rixbtoC89WuajXl5eXHffXMofvVZA5I1p8c0iIiICAAP/KOBz2tds9Ygf1h7fcs1JC8vn0MHy8lduwoAq9XGyKh4LLs3MWLEjVgse5vN8fX14eZbRlBRcbRDc18qFSwREREB4PNa+LPN7qLVPFodSU1NYNTIKeSsWozJFEBhQQmxsdEEBZlclO3K6RKhiIiIuBWTKYC4+BgKCjZit9vJzy8mPSPF6FjtojNYIiIi4nYyM2dy150LMZv7ERISTGTkYKMjtYvOYImIiIjbMZsjCA8PI3vJatLTr66zV6AzWCIiIvJPg/yhrb1Rzl+rbamzElmxfA1x8RMBqKs7zehRUzh7rp5qWzXDh8WQlBTHQysXATAuOonjx09SXV3D8GExjB59E+v+99GO/BqtUsESERERoPW7+oxisewhbU4y3t7eAPj5dWHf/m2tHv/eztdcFe2i3Ou/pIiIiPzgVVZWkZQ4l8BAE4VF642Oc1lUsERERMSthIb2YJelxOgYV0Sb3EVEREScTAVLRERExMlUsEREREScTAVLRERExMlUsEREREScTAVLRERErgoVFUdJSMjAPGA0E8YnNxn77O9fMm3qHG4ePZWxY25n8aJVnD59xqCkekyDiIiI/NNf3wug+oRrqkG34AZ+PM7WvjndurJs2QJsthoeW7OuyZhvZx8efXQ5Q24YyPnz57ln/jLWrXuB7Ox7nBn7kqlgiYiICADVJ7w4+a2P0THIy8vn0MFycteuAsBqtTEyKh7L7k2MGHEjFsveZnP69Qt3/HunTp0YNnwon39+wGWZ/50uEYqIiIhbSU1NYMuWUqzWC2e4CgtKiI2NJijIdEnza2vreOXl15k8OboDU7ZNBUtERETciskUQFx8DAUFG7Hb7eTnF5OekXJJc8+dq+fueQ8yduxIbr11QgcnbZ0uEYqIiIjbycycyV13LsRs7kdISDCRkYMvOqe+vp6752XTs+c1PPLLpS5I2ToVLBEREQEubDx3l7XM5gjCw8PIXrKanJysi35eQ0MD8+9eSmCgidy1q/Dw8HBW1MuigiUiIiIA7b6rr6OlzkpkxfI1xMVPBKCu7jSjR03h7Ll6qm3VDB8WQ1JSHA+tXETJxnfZvHkHQ4YMZOKEOwC46afDeOyxFYZkV8ESERERt2Sx7CFtTjLe3t4A+Pl1Yd/+bS0em5h0G4lJt7kyXptUsERERMStVFZWkZQ4l8BAE4VF642Oc1lUsERERMSthIb2YJelxOgYV0SPaRARERFxMhUsERERESdTwRIRERFxshYL1gsvvICHhwcbN24EoKqqismTJ2M2mxk6dCgffPCB49i6ujpmzJjBgAEDGDhwIK+99pprkouIiIi4qWab3A8fPszzzz9PVFSU471ly5YRFRXFO++8w969e0lISKCsrAxvb29yc3Px9fXlwIEDlJWVMWLECMaNG0dISIhLv4iIiIiIu2hyBquxsZHMzEyefvppfH19He8XFxczf/58AG666SauvfZa3n//fQCKioocYxEREURHR/PGG2+4Kr+IiIj8QFRUHCUhIQPzgNFMGJ/cZKy8/CsmxaQwYXwyY8fcTmbmEk6dMu7BqU3OYD355JOMHj2a//iP/3C8d/z4cerr6wkNDXW817dvXyoqKgCoqKggPDy8xbHW2GxNv7Cvr2+TQiciIiKu9/ofe1B5yscla4UGnuP2qKp2zenWrSvLli3AZqvhsTXrmn5eaA9KNr1Ily6dAVj50OPk/mq9Yb9J6ChYn376Kb///e+b7K/qKL17927y+sEHH2TpUmN/lNFoJ0+eNDqCXCL9rUTk+6rylA9HjnUxOgZ5efkcOlhO7tpVAFitNkZGxWPZvYkRI27EYtnbbI6v7/8Vw/Pnz1NXdxp/f792r93Q0PZvJDY0NNDY2MipU6c4ceKE4/3g4OAmxzkK1ocffsjhw4cxm80AVFZWMm/ePH7xi1/g5eVFZWWl4yzW4cOH6dOnDwB9+vShvLycXr16OcYmTZrUZrgjR44QEBDgeK0zWBf8+x9H3Jf+ViIiHSc1NYFRI6eQs2oxJlMAhQUlxMZGExRkanPeuXP1/GxyKl999TWDhwxkw4an2r22l1fbz2D38vLC09OTwMDANv9f4NiDdc899/DNN99w+PBhDh8+TFRUFM8gFw5CAAAgAElEQVQ99xz33HMP06dP55lnngFg7969HD16lLFjxwI0GSsrK2Pnzp1MmzatzXABAQFN/lG5EhERkX8xmQKIi4+hoGAjdrud/Pxi0jNSLjrPx8ebHaXFfPLpe5gH9GXDBuOebHBJz8F6/PHH2b17N2azmbS0NF566SXHDy9mZ2dz+vRp+vfvT2xsLOvWraN79+4dGlpERES+3zIzZ7Ih/1VKSy2EhAQTGTn4kuf6+HiTkjKN1159qwMTtq3V82A7d+50/HvPnj3ZunVri8f5+/tTVFTk9GAiIiLiWqGB59xmLbM5gvDwMLKXrCYnJ+uin3fkyNeEhATh59eFxsZGNr25lSFDBjorbrvpx55FREQEoN139XW01FmJrFi+hrj4iQDU1Z1m9KgpnD1XT7WtmuHDYkhKiuOhlYv47O9fsOafdxY2NjYS+aPBht1BCCpYIiIi4qYslj2kzUl2bEvy8+vCvv3bWjx2Umw0k2KjXZiubSpYIiIi4lYqK6tISpxLYKCJwqL1Rse5LCpYIiIi4lZCQ3uwy1JidIwrckl3EYqIiIjIpVPBEhEREXEyFSwRERERJ1PBEhEREXEyFSwRERG5KlRUHCUhIQPzgNFMGJ/c6nELF+YQ2vPHWK02F6ZrSncRioiICABer+3G89tTLlmrsWcgDUmj2jWnW7euLFu2AJuthsf++VDRf7d583a8L/KDza5gfAIRERFxC57fnsKz4pjRMcjLy+fQwXJy164CwGq1MTIqHsvuTYwYcSMWy94W531XdZynnvotr7/+G15++XVXRm5GlwhFRETEraSmJrBlS6njEl9hQQmxsdEEBZnanPfAA79gVc5iunb1d0XMNqlgiYiIiFsxmQKIi4+hoGAjdrud/Pxi0jNS2pzz8kuvc11YKDffMsJFKdumgiUiIiJuJzNzJhvyX6W01EJISDCRkYPbPN5i2cu77+zkJz/5GT/5yc8AGD9uOp988pkr4jajPVgiIiICXNh47i5rmc0RhIeHkb1kNTk5WRf9vLz1a5q8Du35Y0rfexWTKeCKcl4uFSwREREBaPddfR0tdVYiK5avIS5+IgB1dacZPWoKZ8/VU22rZviwGJKS4nho5SKDkzangiUiIiJuyWLZQ9qcZLy9vQHw8+vCvv3bLmlu5bd/7choF6WCJSIiIm6lsrKKpMS5BAaaKCxab3Scy6KCJSIiIm4lNLQHuywlRse4IrqLUERERMTJVLBEREREnEwFS0RERMTJVLBEREREnEwFS0RERMTJVLBERETkqlBRcZSEhAzMA0YzYXxys7Frew1nwvhkxz+HDx8xKKke0yAiIiL/dPaNkzRW1btkLc8e3vgmBLVrTrduXVm2bAE2Ww2PrVnXbLxrV392lBY7K+IVUcESERERABqr6mk84pqC1Za8vHwOHSwnd+0qAKxWGyOj4rHs3sSIETdisew1OOHF6RKhiIiIuJXU1AS2bCnFarUBUFhQQmxsNEFBpjbn1dWdZlJMCjET72Dt2mc4f/68K+K2SAVLRERE3IrJFEBcfAwFBRux2+3k5xeTnpHS5pyePa9h3/6tbN1WSPGrz/HRH/exfv0GFyVuTgVLRERE3E5m5kw25L9KaamFkJBgIiMHt3m8r68P11wTAkBQkIkZM6bx0R//4oqoLdIeLBEREQEubDx3l7XM5gjCw8PIXrKanJysi37ed98dJzAwAG9vb86ePcfmt3cwNHKQs+K2mwqWiIiIALT7rr6OljorkRXL1xAXPxG4sMdq9KgpnD1XT7WtmuHDYkhKiuOhlYvYs2cfTzyeR6dOnWg438DNo3/K4sVzDcuugiUiIiJuyWLZQ9qcZLy9L5zt8vPrwr7921o89rbbJnLbbRNdGa9NKlgiIiLiViorq0hKnEtgoInCovVGx7ksKlgiIiLiVkJDe7DLUmJ0jCuiuwhFREREnEwFS0RERMTJVLBEREREnEwFS0RERMTJVLBERETkqlBRcZSEhAzMA0YzYXxys/GvvvqG2bP+k9GjpnDLLQn85jevGJDyAt1FKCIiIgC89cmLfFd91CVrXdPtOuIi09o1p1u3rixbtgCbrYbH1qxrMma320mfk8V9/5nOlCmTAPiu6riz4rabCpaIiIgA8F31UY6eOmh0DPLy8jl0sJzctasAsFptjIyKx7J7EyNG3IjFsrfZnA8/+AgfHx9HuQK4pkeIyzL/O10iFBEREbeSmprAli2lWK02AAoLSoiNjSYoyNTqnC++OEhISBB3z3uQiROSmZO2mPLDX7kqcjMqWCIiIuJWTKYA4uJjKCjYiN1uJz+/mPSMlDbnNJw/z65de8i6fx7bdxQTPW4Uc+dluyhxcypYIiIi4nYyM2eyIf9VSksthIQEExk5uM3jr7uuF5GRgxg0aAAASUlxfPLxZ9TX17sibjPagyUiIiLAhY3n7rKW2RxBeHgY2UtWk5OTddHPGz9+NP+1+td888239OrVkx07dmEeGOH4oWhXU8ESERERgHbf1dfRUmclsmL5GuLiJwJQV3ea0aOmcPZcPdW2aoYPiyEpKY6HVi7C39+PJ361klmp/4ndbicgoCvPPvOEYdlVsERERMQtWSx7SJuT7DgL5efXhX37t7V6fHT0KKKjR7kqXptUsERERMStVFZWkZQ4l8BAE4VF642Oc1lUsERERMSthIb2YJelxOgYV0R3EYqIiIg4mQqWiIiIiJOpYImIiIg4mQqWiIiIiJOpYImIiIg4me4iFBERkatCRcVRFi1axaeffE6fPtexo7TYMfbeexYe+a+nHK+PHTtBjx4hbNteZERUFSwRERG5YMsf3ufYqRMuWat7YDA/Gzm2XXO6devKsmULsNlqeGzNuiZj48aNZty40Y7Xs1LvY/TNNzkl6+VQwRIREREAjp06wdfHqoyOQV5ePocOlpO7dhUAVquNkVHxWHZvYsSIG7FY9rY5v7Kyil279vDr//6FK+K2SHuwRERExK2kpiawZUspVqsNgMKCEmJjowkKMl3S/KLCTUyYcDPXXBPSkTHbpIIlIiIibsVkCiAuPoaCgo3Y7Xby84tJz0i5pLl2u52Cgo3MmJnQwSnbpkuEIiIi4nYyM2dy150LMZv7ERISTGTk4Euat3v3nzh79izjxhn7o88qWCIiIgJc2HjuLmuZzRGEh4eRvWQ1OTlZl/y5Ba+8wR13TKVTp05XGvGKqGCJiIgIQLvv6utoqbMSWbF8DXHxEwGoqzvN6FFTOHuunmpbNcOHxZCUFMdDKxcBYLNVs3nzDnbu/L2RsQEVLBEREXFTFsse0uYk4+3tDYCfXxf27d/W6vEBAd0oO/yRq+K1SQVLRERE3EplZRVJiXMJDDRRWLTe6DiXRQVLRERE3EpoaA92WUqMjnFF9JgGERERESdTwRIRERFxMhUsERERESdTwRIRERFxMhUsERERuSpUVBwlISED84DRTBif3Gz86ad/xy23JDBhfDK3/mwWf/nLJwakvEB3EYqIiAgAv9v3d76y1bhkrbCArqQPH9KuOd26dWXZsgXYbDU8tmZdk7FPP/2cF18s5oMPXsff34/XXnuLFcvX8M67rzgz9iVTwRIREREAvrLVcPCk1egY5OXlc+hgOblrVwFgtdoYGRWPZfcmRoy4EYtlb7M5Hh4eNNQ3UFd7Gn9/P6zWaq69tqerozuoYImIiIhbSU1NYNTIKeSsWozJFEBhQQmxsdEEBZlanXPDDdcz7+5Z/PSntxIYGICPjw8bS37nwtRNaQ+WiIiIuBWTKYC4+BgKCjZit9vJzy8mPSOlzTnl5V/x9uYd/OGPb7Jv/zbm3T2Lu+c96KLEzalgiYiIiNvJzJzJhvxXKS21EBISTGTk4DaP37x5B4MHmwkN7QFASspU9uzZz7lz9a6I24wuEYqIiAhwYeO5u6xlNkcQHh5G9pLV5ORkXfTzwsOvo7BwI7W1dfj7+7Ft2wf07x+Oj4+3syK3iwqWiIiIALT7rr6OljorkRXL1xAXPxGAurrTjB41hbPn6qm2VTN8WAxJSXE8tHIRt946gf37/kbspBn4+Pjg59eFvPWPGZZdBUtERETcksWyh7Q5yXh7XzgL5efXhX37t7V4rIeHBw+tXMRDKxe5MmKrVLBERETErVRWVpGUOJfAQBOFReuNjnNZVLBERETErYSG9mCXpcToGFekyV2EZ86cYdq0aQwcOJAf//jHxMTEcODAAQCqqqqYPHkyZrOZoUOH8sEHHzjm1dXVMWPGDAYMGMDAgQN57bXXXPstRERERNxIs8c0zJs3j3/84x/89a9/ZerUqWRmZgKwbNkyoqKi+PLLL3nhhReYOXMm9fUXbn3Mzc3F19eXAwcO8O6773Lvvfdy/Phx134TERERETfRpGB17tyZW2+9FQ8PDwCioqI4fPgwAMXFxcyfPx+Am266iWuvvZb3338fgKKiIsdYREQE0dHRvPHGG676DiIiIiJupc09WE899RRTp07l+PHj1NfXExoa6hjr27cvFRUVAFRUVBAeHt7iWEtsNluT176+vvj6+l7WFxARERFxN60WrEcffZQDBw6wY8cOTp8+7dRFe/fu3eT1gw8+yNKlS526xtXm5MmTRkeQS6S/lYjI91dDQ8NFxxsbGzl16hQnTpxwvB8cHNzkuBYLVm5uLq+//jrbt2/Hz88PPz8/vLy8qKysdJzFOnz4MH369AGgT58+lJeX06tXL8fYpEmTWg135MgRAgICHK91BuuCf//jiPvS30pExPUqKo6yaNEqPv3kc/r0uY4dpcVNxv/3f1+kuGgTjXY7A/qH899PrcZkCmjl01rm5dX2Axa8vLzw9PQkMDCwzf8XNPuUJ598koKCArZv305gYKDj/enTp/PMM8/w8MMPs3fvXo4ePcrYsWObjEVFRVFWVsbOnTvJy8trddGAgIAmBUtERESM9+hnf+dgTa1L1urf1Z8Vg9v35Phu3bqybNkCbLYaHluzrsnY++//gcLCErZseYmuXf359ZPPsWbNOh57bIUzY1+yJgXrq6++4oEHHqBfv36MGzcOuHB26aOPPuLxxx9n9uzZmM1mfHx8eOmllxxPVs3OziY9PZ3+/fvTqVMn1q1bR/fu3V3/bUREROSyHayp5VOb1egY5OXlc+hgOblrVwFgtdoYGRWPZfcmRoy4EYtlb7M5f/vbF4z46XC6dvUHYMLEW7g9IcM9ClZYWBh2u73FA3v27MnWrVtbHPP396eoqMj56UREROQHJzU1gVEjp5CzajEmUwCFBSXExkYTFGRqdc6PfjSYF18ooqrqGNdcE8Lvf7+ZmppaTp60tjmvozR7DpaIiIiIkUymAOLiYygo2Ijdbic/v5j0jJQ259x880+55967mDXrP7n1Z7PoHhIEgJdXJ1dEbkY/lSMiIiJuJzNzJnfduRCzuR8hIcFERg6+6Jw5c+5gzpw7APjznz7m2mt70q1b146O2iIVLBEREQEubDx3l7XM5gjCw8PIXrKanJysS/rMb7/9jp49r6Gu7jRPPPG/3LsgzQlJL48KloiIiAC0+66+jpY6K5EVy9cQFz8RgLq604weNYWz5+qptlUzfFgMSUlxPLRyEQB3JM+n0d5I/bkGkqbfRkbGDMOyq2CJiIiIW7JY9pA2J9nx1AI/vy7s27+t1eN3vv97V0W7KBUsERERcSuVlVUkJc4lMNBEYdF6o+NcFhUsERERcSuhoT3YZSkxOsYV0WMaRERERJxMBUtERETEyVSwRERERJxMBUtERETEyVSwRERE5Kqw68OPmBw7k1tuSWDMmARWr/41jY2NjvGtW9/n5tFTGRkVT/qcLKqrawzLetXdRejh4WF0BBERETGAKTCAZ599gvC+YZw5c5bk6fMoLn6TlJSp1NbWcX/Ww7yx8XeYzREsX/4oTz75HD//+f2GZL2qCpbKlYiISMc5uM2XuuOuubjlF9JI/5izLY7l5eVz6GA5uWtXAWC12hgZFY9l9yaCgkwAdO7syw1Dr+fIka8B2LFjF5GRgzCbIwBIS7uDlDvmq2C1R3JqMGF9fIyOISJu7LNPT7PlTavRMUSuKnXHPan5ppPRMUhNTWDUyCnkrFqMyRRAYUEJsbHRjnIFUFV1jLfe3M7/e+lpAI4e/YawsF6O8d69r+Xbb4/R0NCAl5fr685VWbDC+vioYIlIm76trDc6gohcJpMpgLj4GAoKNnL33bPJzy/m2eeecIxXV9cwe/ZCFtyXxrBhNxiYtHXa5C4iIiJuJzNzJhvyX6W01EJISDCRkYMBqKmpZUbKvUyOjWb+/Dsdx193XS+++uobx+sjR76mZ8/uhpy9AhUsERERcUNmcwTh4WFkL1lNenoKALW1dcxIuZdx40eRdf+8JsePHz+ajz/+jC+/LAPgxReLmDptsstz/8tVeYlQREREnM8vpPHiB7lwrdRZiaxYvoa4+IkAPP/cy+zb9yl1dad5e3MpAPHxMSzOmkvXrv48+eTDzElbTEPDeQYNGsD/PP1fHfod2qKCJSIiIgCt3tVnFItlD2lzkvH29gZgcdZcFmfNbfX42MnRxE6OdlG6tqlgiYiIiFuprKwiKXEugYEmCovWGx3nsqhgiYiIiFsJDe3BLkuJ0TGuiDa5i4iIiDiZCpaIiIiIk6lgiYiIiDiZCpaIiIiIk6lgiYiIiDiZ7iIUERGRq8KuDz/ikUeeorbuNB4eMHHiGFauXISnpye1tXVkpN/Pxx9/RkPDeb74cpehWVWwREREBADLHz/h5Klql6wVFNiN0VGR7ZpjCgzg2WefILxvGGfOnCV5+jyKi98kJWUqXl5e3HffHAKDTNyekNlBqS+dCpaIiIgAcPJUNd8dO2V0DPLy8jl0sJzctasAsFptjIyKx7J7E0FBJgA6d/blhqHXc+TI1wD4+vpw8y0jqKg4alju/z/twRIRERG3kpqawJYtpVitNgAKC0qIjY12lCuAqqpjvPXmdmJixhgVs00qWCIiIuJWTKYA4uJjKCjYiN1uJz+/mPSMFMd4dXUNs2cvZMF9aQwbdoOBSVunS4QiIiLidjIzZ3LXnQsxm/sREhJMZORgAGpqapmRci+TY6OZP/9Og1O2TgVLREREgAsbz91lLbM5gvDwMLKXrCYnJwuA2to6ZqTcy7jxo8i6f54rYl42FSwREREBaPddfR0tdVYiK5avIS5+IgDPP/cy+/Z9Sl3dad7eXApAfHwMi7PmAjAuOonjx09SXV3D8GExjB59E+v+91FDsqtgiYiIiFuyWPaQNicZb29vABZnzXWUqZa8t/M1V0W7KBUsERERcSuVlVUkJc4lMNBEYdF6o+NcFhUsERERcSuhoT3YZSkxOsYV0WMaRERERJxMBUtERETEyVSwRERERJxMBUtERETEyVSwRERERJxMdxGKiIjIVWHXhx/xyCNPUVt3Gg8PmDhxDCtXLsLT05PP/v4ly5c/yrFjJ+jUqRPDhw9lzWMr6NKlsyFZVbBEREQEgN99+h5fVR93yVph3UJIHzquXXNMgQE8++wThPcN48yZsyRPn0dx8ZukpEzFt7MPjz66nCE3DOT8+fPcM38Z69a9QHb2PR30DdqmgiUiIiIAfFV9nIPWb42OQV5ePocOlpO7dhUAVquNkVHxWHZvIijIBEDnzr7cMPR6jhz5GoB+/cId8zt16sSw4UP5/PMDrg//T9qDJSIiIm4lNTWBLVtKsVptABQWlBAbG+0oVwBVVcd4683txMSMaTa/traOV15+ncmTo10VuRkVLBEREXErJlMAcfExFBRsxG63k59fTHpGimO8urqG2bMXsuC+NIYNu6HJ3HPn6rl73oOMHTuSW2+d4OroDrpEKCIiIm4nM3Mmd925ELO5HyEhwURGDgagpqaWGSn3Mjk2mvnz72wyp76+nrvnZdOz5zU88sulRsR2UMESERER4MLGc3dZy2yOIDw8jOwlq8nJyQIuXPqbkXIv48aPIuv+eU2Ob2hoYP7dSwkMNJG7dhUeHh4dlv1SqGCJiIgIQLvv6utoqbMSWbF8DXHxEwF4/rmX2bfvU+rqTvP25lIA4uNjWJw1l5KN77J58w6GDBnIxAl3AHDTT4fx2GMrDMmugiUiIiJuyWLZQ9qcZLy9vQFYnDWXxVlzWzw2Mek2EpNuc2W8NqlgiYiIiFuprKwiKXEugYEmCovWGx3nsqhgiYiIiFsJDe3BLkuJ0TGuiB7TICIiIuJkKlgiIiIiTqaCJSIiIuJkKlgiIiIiTqZN7iIiInJV2PXhRzzyyFPU1p3GwwMmThzDypWL8PT0pLz8K+ZmLuH8+UYaGhowD+xHbu4qAgMDDMmqgiUiIiIAbPvgO46fOOeStUKCfYgZc0275pgCA3j22ScI7xvGmTNnSZ4+j+LiN0lJmUpoaA9KNr1Ily6dAVj50OPk/mq9YT+Zo4IlIiIiABw/cY5vqs4aHYO8vHwOHSwnd+0qAKxWGyOj4rHs3kRQkAmAzp19uWHo9Rw58jUAvr4+jvnnz5+nru40/v5+rg//T9qDJSIiIm4lNTWBLVtKsVptABQWlBAbG+0oVwBVVcd4683txMSMcbx37lw9E8YnM2TwWA6VVZD94D0uz/4vKlgiIiLiVkymAOLiYygo2Ijdbic/v5j0jBTHeHV1DbNnL2TBfWkMG3aD430fH292lBbzyafvYR7Qlw0bXjMiPqCCJSIiIm4oM3MmG/JfpbTUQkhIMJGRgwGoqallRsq9TI6NZv78O1uc6+PjTUrKNF579S1XRm5Ce7BEREQEuLDx3F3WMpsjCA8PI3vJanJysgCora1jRsq9jBs/iqz75zU5/siRrwkJCcLPrwuNjY1senMrQ4YM7LD8F6OCJSIiIgDtvquvo6XOSmTF8jXExU8E4PnnXmbfvk+pqzvN25tLAYiPj2Fx1lw++/sXrFmzDoDGxkYifzTYsDsIQQVLRERE3JTFsoe0Ocl4e3sDsDhrLouz5rZ47KTYaCbFRrswXdtUsERERMStVFZWkZQ4l8BAE4VF642Oc1lUsERERMSthIb2YJelxOgYV0R3EYqIiIg4mQqWiIiIiJOpYImIiIg4mQqWiIiIiJOpYImIiIg4mQqWiIiIXBV2ffgRk2NncsstCYwZk8Dq1b+msbGx2XELF+YQ2vPHjh+LNoIe0yAiIiIAHNr5CadPVrtkrS5B3egXHdmuOabAAJ599gnC+4Zx5sxZkqfPo7j4TVJSpjqO2bx5O95extcb4xOIiIiIWzh9spqab08ZHYO8vHwOHSwnd+0qAKxWGyOj4rHs3kRQkAmAzp19uWHo9Rw58rVj3ndVx3nqqd/y+uu/4eWXXzck+7/oEqGIiIi4ldTUBLZsKXVc4issKCE2NtpRrgCqqo7x1pvbiYkZ43jvgQd+waqcxXTt6u/yzP9OBUtERETciskUQFx8DAUFG7Hb7eTnF5OekeIYr66uYfbshSy4L41hw24A4OWXXue6sFBuvmWEUbGbUMESERERt5OZOZMN/1979x7U9JXFAfybBAxSQEBAhBhKgPIqKoS2zi5bi6NdpDC0g7tjR2YbaZu2iFQstt1t2ZlS2zrVztjHFLo7baDqtDNCSx+7anGoM74qj4nAytudBCoiq7xfhiRn/2D7U1ZElDyoOZ8Z/oj3zs25uZgc7u/m/EoOorLyJBYv9kZMTCQAYHh4BE9uzELS7x/B88//Seh/8mQ1jhw+hvj49YiPXw8AWJP4BzQ0NNklfj6DxRhjjDEAkwfP58tzhYUFIyhIhh15BcjPzwUAjIyM4smNWUhc8xvkbldP6f9x4TtTHvsvWYHKHw9i0SIPywY+SxZLsNra2vDUU0/h8uXLWLRoEYqLixEdHW2p4RljjDFmZbf7rT5r25SRjr/8+R2kpK4FAPz9bweg1f4Lo6Nj+Oc/KgEAqanrsC33WXuGOS2LJVjPPfcc1Go1VCoVSktLoVKpUF1dbanhGWOMMeZgTp6sgmrzH+Hs7AwA2Jb77KyTqe5LddYM7ZYscgarp6cHNTU1yMjIAACkp6ejs7MT7e3tlhieMcYYYw6ku7sHCb9NQ0N9M9TqDHuHc0cssoPV2dmJpUuXwul/hb1EIhHkcjk6OjoQGhoq9CMiAMCFCxcwOHituqpUKoVUKp31813qnrBE2Iyxu1jvZSMAfr9g7FZ6rxhhMkkwMUEwGMje4QAAvL19UfljufDY2nFNGK+NbzKZZuxrMplgNpsxPDw8JZcBAHd3d4hEIgA2PuQ+NDRZHTYqKmpO4xzQXLFEOIwxB8DvF4zdmo+PD65cNsLdjf8g0Wq1M7brdDp0dnbigQceuKFtYGAAHh6Th+otkmAtW7YMFy9ehNFohJOTE4gIHR0dkMvlU/oFBATg/PnzcHZ2FjI84PZ3sBhjjDFmGa2trVCr1YiMjERERIS9w5n3Fi5ciGXLluHQoUO47777prS5u1/7ZqRFEiw/Pz/ExcVh//79UKlUKCsrg0wmm3J5EADEYjEUCoUlnpIxxhhjFuDm5gaxWAyJRAKJRGLvcOY9iUQCsVgMNzc3YbdqOha7RPjJJ59ApVLh7bffhoeHBzQajaWGZowxxhj7VbFYghUeHo7Tp09bajjGGGOMsSkqKyvx6quvYnh4GCKRCI899hh27doFsVgMnU6HkJAQxMRcq+VVVlaGkJAQu8TKldytaLbFV3fv3o2SkhKYzWaEh4dDo9HA09MTANDX14fs7GxUV1fD2dkZqamp2LVrl62nctezxFqVlJRgz549kEgkEIlEeOutt5CcnGzrqdz1cnJy8O2330Kv10Or1WLlypXT9vv++++Rl5cHk8mEmJgYFBcXC9v5Z86cgVqtxtjYGGQyGfbt24fAwEBbTsMhzHWturq6sHnzZuh0OkilUoSFhaGoqAi+vr42nsndr7e3Fy0tLfi4sRe9IheIJdNXcTIZjTAYDAqrMBsAAAa8SURBVCBMHvtxkUqB685UA4DBYMCEwYCFC11vOg4AhHrdg7/+Luy24vTy8sKXX34JhUKB8fFxrF27Fp9//jlUKhWAyTNQZ8+eva0xrYXvRWhFvxRfbW1txSuvvCL8AlyvoqICGo0Gp0+fRmNjI5RKJV577TWhPTMzE7GxsWhtbcW5c+ewbds2G87Accx1rXp7e7F161ZUVFTg7Nmz+PDDD6cdg83dhg0bcOLECQQFBd20z/DwMJ5++mmUl5ejra0NAQEBePPNNwEAZrMZmzZtwt69e9Ha2ork5GT+f2Ulc10riUSC/Px8tLS0oL6+HgqFAjt27LBV+A7F1dUVwcHB6LoKnLsygoaeoWl/GnvH0D5swvlhE9oGJ9Dwn+Eb+rT0X8W/R2nGcRp6htDeN3LTePbs2QO1+tqtcPr7++Hj44OgoCDhLLeLiwtWrlwJnU5n7ZfnjnCCZSWzLb5aV1eHhIQE4ZsHycnJ2LdvHwCgvb0dNTU12L59u9Df39/fRjNwHJZYK7PZDCISSpH09/dDJpPZcBaO4+GHH77la3vo0CHExsYK34jKysrCF198AQCora2Fk5MTEhMTAUwm19999x3Gx8etG7gDmutaLVmyBAkJCULfhx56aN5+mP7aubi4YMGCBfYOQ/DMM8+gvLwc/f39AACNRoO0tDR4e3sLfbq7u1FaWoqUlBTh30ZGRqBUKhEXF4eCgoJb1rSyJk6wrGSm4qvXUyqVOHr0KLq7u0FEOHDgAIaGhtDb24vGxkbIZDK88MILUCqVePTRR29Zn4PdPkuslY+PD4qKihAXF4egoCBkZmaiuLjYDrNhANDR0TFl1+Tee+8VSsn8f5u7u7twOYrZ3kxrdT2TyYSPPvoIaWlptg6R2YGnpyc2bNiAzz77DESEwsJCZGdnC+2Dg4NITU3Fyy+/jPj4eADA0qVLceHCBdTW1uLo0aM4fvw43nvvPXtNgRMse0tMTEReXh5SUlKwatUq4WyBk5MTjEYjqqqqsHHjRtTW1iI3NxcpKSmYmOBCcPYw01oNDAzg/fffR1VVFfR6PT799FM88cQTMBgMdo6asV8/IkJWVha8vLzw4osv2jscZiM5OTkoKirC4cOH4evri9jYWACTRcuTkpKQlpY25QqPVCqFn58fAMDb2xuZmZk4fvy4XWIH+JC71cy2+CowuSWelZUFAPjpp58gk8ng4eEBuVyOwMBA4VLG+vXrYTAYoNfrb6gxxu6cJdaqtLQUnp6eiIyMBACkpqYiMzMTer0eYWG3d4iTzZ1cLkdFRYXwWKfTCbuUcrkcer1eaBsaGsLAwAACAgLsEarDm2mtfpGTk4POzk6Ul5dDLOZ9AWuSuYrh4jL9IXej0QjjhBEuC10ATB6NGB8bh+s9rjBcNUzZdSQyQyQSQypdAInT9KlGqNc9M8YSEREBhUIBtVqNd999F8Dkmb2kpCQkJSXh9ddfn9K/p6cHXl5ecHZ2xtWrV/HVV18JSZldELOa1atXk0ajISKigwcPklKpnLZfV1cXERGNjIzQunXr6IMPPiAiIrPZTNHR0VRXV0dERGfOnKHFixfT+Pi49YN3MHNdq9raWvL19aWLFy8SEdGpU6fI09OTxsbGrB+8gwoKCiKtVjtt2+DgIPn6+lJTUxMREW3ZsoVeeuklIiIymUykUCiosrKSiIh2795N6enptgnaQd3pWhERbd26lZKSkvh9z4qamppIqVRSU1MT1dXV0cjIyLT9jEYjabVaGh0dJSIivV5PHR0d0/adaZzbUVpaSv7+/mQwGIiIaOfOneTk5EQrVqwQfnbu3ElERGVlZRQdHU3Lly+nqKgoys7OtsrvzfWv10w4wbKi5uZmWrVqFYWFhZFSqaT6+noiIsrPz6fCwkKh3/33309RUVEUGhpKb7zxBpnNZqGtpqaGHnzwQYqJiaH4+Hg6duyYzefhCCyxVnv37qXIyEhavnw5xcXF0Q8//GDzeTgCtVpNgYGBJJFIyM/Pj0JCQojoxrX65ptvKDw8nEJCQigtLY36+/uFtlOnTlFMTAyFhYXR6tWrb/ohweZmrmt14sQJAkARERHCh+njjz9ul7nczZqamig4OJi+/vprqq6uJq1WK7wH/vzzz3Tp0iWhb19fHzU0NFB9fT21tbXRxMTEtGNaKsHasmULFRQUzHkcS5ptgiUiovlx62zGGGOM2VxzczMyMjKwf//+eXMvwq6uLqxZswbe3t44cuTIlHv82dtsXy8+g8UYY4yxeSUgIADNzc32DmNO+LQgY4wxxpiFcYLFGGOMMWZh/wWl/XK4dO1hzwAAAABJRU5ErkJggg==\" />"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "histogram(1000,output_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Array{Float64,1}:\n",
       " 0.956709\n",
       " 0.990173\n",
       " 0.999646\n",
       " 0.997762\n",
       " 0.999972\n",
       " 0.979385\n",
       " 0.999996\n",
       " 0.999992\n",
       " 0.967924\n",
       " 0.999929\n",
       " 0.999999\n",
       " 1.0     \n",
       " 1.0     \n",
       " ⋮       \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(loss_history[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
