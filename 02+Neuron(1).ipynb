{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNparams([0.169884, 0.645101, 0.828618])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type NNparams\n",
    "    a::Array{Float64}\n",
    "end \n",
    "toyparams = NNparams([rand(),rand(),rand()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6224593312018546"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function σ(z::Float64)\n",
    "    return 1.0 / (1.0 + exp(-z))\n",
    "end\n",
    "σ(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: ∇ not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: ∇ not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "function updateNNparams(gradient::Array{Float64,1}, \n",
    "                        params::NNparams, learning_rate::Float64)\n",
    "   params.a = params.a - gradient*learning_rate\n",
    "    return params\n",
    "end\n",
    "#test\n",
    "toyparams = NNparams([rand(),rand(),rand()])\n",
    "grad = ∇(x,y,toyparams)\n",
    "updateNNparams(grad,toyparams,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printNNparam (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function printNNparam(param::NNparams)\n",
    "    @printf(\"PrintNN ==> %f %f %f\\n\", param.a[1], param.a[2], param.a[3])\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function output(params::NNparams, x::Array{Float64,1})\n",
    "    #nb_data = size(x[1,:])\n",
    "    #for i = 1:nb_data\n",
    "    #x = x[i, :]\n",
    "    return σ(dot(params.a,x))\n",
    "    #end\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(params::NNparams, yi::Array{Float64,1}, \n",
    "                x::Array{Float64,2})\n",
    "    nb_data = size(x)[1]\n",
    "     y_pred = zeros(length(yi))\n",
    "    @assert(size(x)[1]== length(yi))\n",
    "   for i = 1:nb_data\n",
    "        y_pred[i]= output(params,x[i,:])\n",
    "    end\n",
    "    return sum(yi.*log.(1e-7+y_pred) .+ (1-yi).*log.(1e-7+1-y_pred))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇ (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradient \n",
    "function ∇(x::Array{Float64,2},y::Array{Float64,1}, params::NNparams)\n",
    "    grad = [0.0 for i=1:size(x)[2]]\n",
    "    nb_data = size(x)[1]\n",
    "    for i = 1:nb_data\n",
    "        xi = x[i, :]\n",
    "        yi = y[i]\n",
    "        y_pred = output(params, xi)\n",
    "        grad = grad .+ xi.*(yi - y_pred)\n",
    "    end\n",
    "    grad = grad/ nb_data\n",
    "    return grad::Array{Float64,1}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convertdata_to_array (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function convertdata_to_array(dtf::DataFrame)\n",
    "    nb_data = size(dtf)[1]\n",
    "        x = zeros(Float64, nb_data, 3)\n",
    "        \n",
    "        x[:,1] = dtf[:x1]\n",
    "        x[:,2] = dtf[:x2]\n",
    "        x[:,3] = ones(Float64,size(x)[1])\n",
    "        \n",
    "        y = convert(Array, dtf[:y]) * 1.0\n",
    "        #x = convert(Array, df[:x1], df[:x2], ones(Float64, size(x)[1]))\n",
    "        return x,y\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.822537 \n",
       " 0.939647 \n",
       " 0.793042 \n",
       " 0.0891053"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_params(x::Array{Float64,2})\n",
    "    return [rand() for i = 1:size(x[1, :])[1]]\n",
    "    end \n",
    "test = init_params(rand(4,4))\n",
    "x= rand(5,5)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "select_trainingdata (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function select_trainingdata(x::Array{Float64,2}, y::Array{Float64,1}, batch_size::Int)\n",
    "    nb_data = length(y)\n",
    "    \n",
    "    ids = [i for i = 1:nb_data]\n",
    "    sampled_ids = sample(ids, batch_size)\n",
    "    \n",
    "    x_training = x[sampled_ids, :]\n",
    "    y_training = y[sampled_ids]\n",
    "    \n",
    "    return x_training, y_training\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: dtf not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: dtf not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "x,y = convertdata_to_array(dtf)\n",
    "testparams = init_params(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_learning_rate (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_learning_rate(init_learning_rate::Float64, nb_steps::Int)\n",
    "    return init_learning_rate* ((1.0)/ (1.0 + (.05*nb_steps)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 / 1000, loss = -1835.595863\n",
      "a_1 = 0.723218, a_2 = 0.098086, b = 0.117513\n",
      "\tgrad = 2.316462\n",
      "rate = 0.066667\n",
      "Step 2 / 1000, loss = -2211.614654\n",
      "a_1 = 0.846337, a_2 = 0.177824, b = 0.144447\n",
      "\tgrad = 2.343575\n",
      "rate = 0.063636\n",
      "Step 3 / 1000, loss = -2611.753696\n",
      "a_1 = 0.973069, a_2 = 0.261276, b = 0.172157\n",
      "\tgrad = 2.534117\n",
      "rate = 0.060870\n",
      "Step 4 / 1000, loss = -3035.246201\n",
      "a_1 = 1.105752, a_2 = 0.348155, b = 0.200022\n",
      "\tgrad = 2.760435\n",
      "rate = 0.058333\n",
      "Step 5 / 1000, loss = -3444.734395\n",
      "a_1 = 1.227595, a_2 = 0.440292, b = 0.228007\n",
      "\tgrad = 2.773205\n",
      "rate = 0.056000\n",
      "Step 6 / 1000, loss = -3833.163435\n",
      "a_1 = 1.345697, a_2 = 0.527118, b = 0.254824\n",
      "\tgrad = 2.767465\n",
      "rate = 0.053846\n",
      "Step 7 / 1000, loss = -4208.901303\n",
      "a_1 = 1.464497, a_2 = 0.613101, b = 0.282515\n",
      "\tgrad = 2.878242\n",
      "rate = 0.051852\n",
      "Step 8 / 1000, loss = -4523.239516\n",
      "a_1 = 1.571560, a_2 = 0.686870, b = 0.307089\n",
      "\tgrad = 2.646380\n",
      "rate = 0.050000\n",
      "Step 9 / 1000, loss = -4811.108151\n",
      "a_1 = 1.676868, a_2 = 0.760108, b = 0.331052\n",
      "\tgrad = 2.703010\n",
      "rate = 0.048276\n",
      "Step 10 / 1000, loss = -5074.966887\n",
      "a_1 = 1.780171, a_2 = 0.835640, b = 0.354642\n",
      "\tgrad = 2.788434\n",
      "rate = 0.046667\n",
      "Step 11 / 1000, loss = -5296.236305\n",
      "a_1 = 1.879587, a_2 = 0.899209, b = 0.376569\n",
      "\tgrad = 2.657647\n",
      "rate = 0.045161\n",
      "Step 12 / 1000, loss = -5491.462693\n",
      "a_1 = 1.973332, a_2 = 0.962833, b = 0.397710\n",
      "\tgrad = 2.634344\n",
      "rate = 0.043750\n",
      "Step 13 / 1000, loss = -5665.270135\n",
      "a_1 = 2.062750, a_2 = 1.026514, b = 0.418388\n",
      "\tgrad = 2.633077\n",
      "rate = 0.042424\n",
      "Step 14 / 1000, loss = -5815.399667\n",
      "a_1 = 2.147871, a_2 = 1.085613, b = 0.437591\n",
      "\tgrad = 2.559473\n",
      "rate = 0.041176\n",
      "Step 15 / 1000, loss = -5952.154138\n",
      "a_1 = 2.233556, a_2 = 1.142806, b = 0.456874\n",
      "\tgrad = 2.620219\n",
      "rate = 0.040000\n",
      "Step 16 / 1000, loss = -6075.120523\n",
      "a_1 = 2.314937, a_2 = 1.201014, b = 0.475510\n",
      "\tgrad = 2.617074\n",
      "rate = 0.038889\n",
      "Step 17 / 1000, loss = -6190.266719\n",
      "a_1 = 2.397990, a_2 = 1.259610, b = 0.494349\n",
      "\tgrad = 2.732043\n",
      "rate = 0.037838\n",
      "Step 18 / 1000, loss = -6292.958167\n",
      "a_1 = 2.476247, a_2 = 1.317213, b = 0.513218\n",
      "\tgrad = 2.686762\n",
      "rate = 0.036842\n",
      "Step 19 / 1000, loss = -6380.996654\n",
      "a_1 = 2.548885, a_2 = 1.369448, b = 0.529906\n",
      "\tgrad = 2.535355\n",
      "rate = 0.035897\n",
      "Step 20 / 1000, loss = -6462.362452\n",
      "a_1 = 2.621864, a_2 = 1.419129, b = 0.546861\n",
      "\tgrad = 2.568513\n",
      "rate = 0.035000\n",
      "Step 21 / 1000, loss = -6542.803552\n",
      "a_1 = 2.698549, a_2 = 1.471586, b = 0.563894\n",
      "\tgrad = 2.766297\n",
      "rate = 0.034146\n",
      "Step 22 / 1000, loss = -6618.914264\n",
      "a_1 = 2.775797, a_2 = 1.524291, b = 0.581167\n",
      "\tgrad = 2.852890\n",
      "rate = 0.033333\n",
      "Step 23 / 1000, loss = -6685.770857\n",
      "a_1 = 2.846434, a_2 = 1.574518, b = 0.597643\n",
      "\tgrad = 2.709813\n",
      "rate = 0.032558\n",
      "Step 24 / 1000, loss = -6747.447732\n",
      "a_1 = 2.916458, a_2 = 1.622834, b = 0.613877\n",
      "\tgrad = 2.722032\n",
      "rate = 0.031818\n",
      "Step 25 / 1000, loss = -6805.820974\n",
      "a_1 = 2.984792, a_2 = 1.673125, b = 0.629555\n",
      "\tgrad = 2.773343\n",
      "rate = 0.031111\n",
      "Step 26 / 1000, loss = -6856.614839\n",
      "a_1 = 3.048934, a_2 = 1.718353, b = 0.644515\n",
      "\tgrad = 2.625192\n",
      "rate = 0.030435\n",
      "Step 27 / 1000, loss = -6902.844085\n",
      "a_1 = 3.109890, a_2 = 1.762274, b = 0.659131\n",
      "\tgrad = 2.569526\n",
      "rate = 0.029787\n",
      "Step 28 / 1000, loss = -6948.184408\n",
      "a_1 = 3.170234, a_2 = 1.810069, b = 0.673810\n",
      "\tgrad = 2.686850\n",
      "rate = 0.029167\n",
      "Step 29 / 1000, loss = -6987.772415\n",
      "a_1 = 3.228971, a_2 = 1.851884, b = 0.687110\n",
      "\tgrad = 2.566117\n",
      "rate = 0.028571\n",
      "Step 30 / 1000, loss = -7025.036225\n",
      "a_1 = 3.286402, a_2 = 1.893861, b = 0.700509\n",
      "\tgrad = 2.585241\n",
      "rate = 0.028000\n",
      "Step 31 / 1000, loss = -7060.930854\n",
      "a_1 = 3.346048, a_2 = 1.935426, b = 0.714242\n",
      "\tgrad = 2.695190\n",
      "rate = 0.027451\n",
      "Step 32 / 1000, loss = -7094.684456\n",
      "a_1 = 3.405720, a_2 = 1.976245, b = 0.727730\n",
      "\tgrad = 2.731667\n",
      "rate = 0.026923\n",
      "Step 33 / 1000, loss = -7127.852175\n",
      "a_1 = 3.465646, a_2 = 2.019785, b = 0.741715\n",
      "\tgrad = 2.853748\n",
      "rate = 0.026415\n",
      "Step 34 / 1000, loss = -7156.064566\n",
      "a_1 = 3.518938, a_2 = 2.058755, b = 0.754406\n",
      "\tgrad = 2.593156\n",
      "rate = 0.025926\n",
      "Step 35 / 1000, loss = -7182.266514\n",
      "a_1 = 3.570819, a_2 = 2.096581, b = 0.766538\n",
      "\tgrad = 2.567016\n",
      "rate = 0.025455\n",
      "Step 36 / 1000, loss = -7207.578911\n",
      "a_1 = 3.626151, a_2 = 2.132766, b = 0.778554\n",
      "\tgrad = 2.687825\n",
      "rate = 0.025000\n",
      "Step 37 / 1000, loss = -7232.327921\n",
      "a_1 = 3.683005, a_2 = 2.169287, b = 0.791148\n",
      "\tgrad = 2.798592\n",
      "rate = 0.024561\n",
      "Step 38 / 1000, loss = -7255.300133\n",
      "a_1 = 3.734226, a_2 = 2.207261, b = 0.803202\n",
      "\tgrad = 2.688391\n",
      "rate = 0.024138\n",
      "Step 39 / 1000, loss = -7276.553533\n",
      "a_1 = 3.786602, a_2 = 2.241626, b = 0.815028\n",
      "\tgrad = 2.686594\n",
      "rate = 0.023729\n",
      "Step 40 / 1000, loss = -7297.156007\n",
      "a_1 = 3.835656, a_2 = 2.279077, b = 0.826248\n",
      "\tgrad = 2.688330\n",
      "rate = 0.023333\n",
      "Step 41 / 1000, loss = -7316.856235\n",
      "a_1 = 3.888669, a_2 = 2.313173, b = 0.837901\n",
      "\tgrad = 2.792883\n",
      "rate = 0.022951\n",
      "Step 42 / 1000, loss = -7335.535234\n",
      "a_1 = 3.940205, a_2 = 2.347291, b = 0.849188\n",
      "\tgrad = 2.782409\n",
      "rate = 0.022581\n",
      "Step 43 / 1000, loss = -7351.865181\n",
      "a_1 = 3.985659, a_2 = 2.378893, b = 0.859734\n",
      "\tgrad = 2.536003\n",
      "rate = 0.022222\n",
      "Step 44 / 1000, loss = -7367.721754\n",
      "a_1 = 4.031108, a_2 = 2.410862, b = 0.870203\n",
      "\tgrad = 2.584865\n",
      "rate = 0.021875\n",
      "Step 45 / 1000, loss = -7383.439555\n",
      "a_1 = 4.075536, a_2 = 2.445315, b = 0.880705\n",
      "\tgrad = 2.655442\n",
      "rate = 0.021538\n",
      "Step 46 / 1000, loss = -7397.638741\n",
      "a_1 = 4.119071, a_2 = 2.475931, b = 0.890988\n",
      "\tgrad = 2.555443\n",
      "rate = 0.021212\n",
      "Step 47 / 1000, loss = -7412.196151\n",
      "a_1 = 4.164934, a_2 = 2.508827, b = 0.901510\n",
      "\tgrad = 2.747646\n",
      "rate = 0.020896\n",
      "Step 48 / 1000, loss = -7426.026875\n",
      "a_1 = 4.209513, a_2 = 2.541648, b = 0.911712\n",
      "\tgrad = 2.734085\n",
      "rate = 0.020588\n",
      "Step 49 / 1000, loss = -7440.025739\n",
      "a_1 = 4.257624, a_2 = 2.574989, b = 0.922647\n",
      "\tgrad = 2.934841\n",
      "rate = 0.020290\n",
      "Step 50 / 1000, loss = -7451.992493\n",
      "a_1 = 4.300420, a_2 = 2.604237, b = 0.932423\n",
      "\tgrad = 2.637473\n",
      "rate = 0.020000\n",
      "Step 51 / 1000, loss = -7463.784849\n",
      "a_1 = 4.343654, a_2 = 2.634298, b = 0.942197\n",
      "\tgrad = 2.716097\n",
      "rate = 0.019718\n",
      "Step 52 / 1000, loss = -7475.455337\n",
      "a_1 = 4.387606, a_2 = 2.665214, b = 0.952149\n",
      "\tgrad = 2.810574\n",
      "rate = 0.019444\n",
      "Step 53 / 1000, loss = -7486.020294\n",
      "a_1 = 4.428235, a_2 = 2.694438, b = 0.961371\n",
      "\tgrad = 2.653523\n",
      "rate = 0.019178\n",
      "Step 54 / 1000, loss = -7495.723642\n",
      "a_1 = 4.466908, a_2 = 2.721696, b = 0.970430\n",
      "\tgrad = 2.546336\n",
      "rate = 0.018919\n",
      "Step 55 / 1000, loss = -7505.266597\n",
      "a_1 = 4.506156, a_2 = 2.749426, b = 0.979164\n",
      "\tgrad = 2.616602\n",
      "rate = 0.018667\n",
      "Step 56 / 1000, loss = -7514.837888\n",
      "a_1 = 4.546220, a_2 = 2.778172, b = 0.988502\n",
      "\tgrad = 2.724367\n",
      "rate = 0.018421\n",
      "Step 57 / 1000, loss = -7523.881512\n",
      "a_1 = 4.585683, a_2 = 2.805645, b = 0.997716\n",
      "\tgrad = 2.692753\n",
      "rate = 0.018182\n",
      "Step 58 / 1000, loss = -7532.651425\n",
      "a_1 = 4.625118, a_2 = 2.833047, b = 1.006740\n",
      "\tgrad = 2.722276\n",
      "rate = 0.017949\n",
      "Step 59 / 1000, loss = -7541.284275\n",
      "a_1 = 4.665459, a_2 = 2.860556, b = 1.015668\n",
      "\tgrad = 2.800980\n",
      "rate = 0.017722\n",
      "Step 60 / 1000, loss = -7549.308855\n",
      "a_1 = 4.701577, a_2 = 2.888446, b = 1.024399\n",
      "\tgrad = 2.654889\n",
      "rate = 0.017500\n",
      "Step 61 / 1000, loss = -7556.824402\n",
      "a_1 = 4.737686, a_2 = 2.914212, b = 1.032744\n",
      "\tgrad = 2.611488\n",
      "rate = 0.017284\n",
      "Step 62 / 1000, loss = -7564.059001\n",
      "a_1 = 4.772941, a_2 = 2.939865, b = 1.041006\n",
      "\tgrad = 2.599199\n",
      "rate = 0.017073\n",
      "Step 63 / 1000, loss = -7571.359461\n",
      "a_1 = 4.811421, a_2 = 2.964965, b = 1.049404\n",
      "\tgrad = 2.768888\n",
      "rate = 0.016867\n",
      "Step 64 / 1000, loss = -7578.164996\n",
      "a_1 = 4.847484, a_2 = 2.989376, b = 1.057500\n",
      "\tgrad = 2.657643\n",
      "rate = 0.016667\n",
      "Step 65 / 1000, loss = -7584.747732\n",
      "a_1 = 4.882292, a_2 = 3.014317, b = 1.065323\n",
      "\tgrad = 2.642871\n",
      "rate = 0.016471\n",
      "Step 66 / 1000, loss = -7590.907258\n",
      "a_1 = 4.917513, a_2 = 3.036543, b = 1.073103\n",
      "\tgrad = 2.602614\n",
      "rate = 0.016279\n",
      "Step 67 / 1000, loss = -7597.008076\n",
      "a_1 = 4.951640, a_2 = 3.060303, b = 1.080777\n",
      "\tgrad = 2.627752\n",
      "rate = 0.016092\n",
      "Step 68 / 1000, loss = -7603.301276\n",
      "a_1 = 4.988489, a_2 = 3.084751, b = 1.088811\n",
      "\tgrad = 2.825183\n",
      "rate = 0.015909\n",
      "Step 69 / 1000, loss = -7609.463222\n",
      "a_1 = 5.025434, a_2 = 3.109100, b = 1.097003\n",
      "\tgrad = 2.860621\n",
      "rate = 0.015730\n",
      "Step 70 / 1000, loss = -7615.227181\n",
      "a_1 = 5.057959, a_2 = 3.134343, b = 1.105042\n",
      "\tgrad = 2.696700\n",
      "rate = 0.015556\n",
      "Step 71 / 1000, loss = -7620.350465\n",
      "a_1 = 5.088925, a_2 = 3.156307, b = 1.112070\n",
      "\tgrad = 2.509648\n",
      "rate = 0.015385\n",
      "Step 72 / 1000, loss = -7625.699687\n",
      "a_1 = 5.121670, a_2 = 3.179824, b = 1.119614\n",
      "\tgrad = 2.695208\n",
      "rate = 0.015217\n",
      "Step 73 / 1000, loss = -7630.818690\n",
      "a_1 = 5.154790, a_2 = 3.201996, b = 1.126839\n",
      "\tgrad = 2.690820\n",
      "rate = 0.015054\n",
      "Step 74 / 1000, loss = -7635.771990\n",
      "a_1 = 5.185300, a_2 = 3.225372, b = 1.134164\n",
      "\tgrad = 2.627114\n",
      "rate = 0.014894\n",
      "Step 75 / 1000, loss = -7641.019479\n",
      "a_1 = 5.219247, a_2 = 3.250004, b = 1.141912\n",
      "\tgrad = 2.894200\n",
      "rate = 0.014737\n",
      "Step 76 / 1000, loss = -7645.800922\n",
      "a_1 = 5.251996, a_2 = 3.271923, b = 1.149188\n",
      "\tgrad = 2.747910\n",
      "rate = 0.014583\n",
      "Step 77 / 1000, loss = -7650.152806\n",
      "a_1 = 5.282013, a_2 = 3.292370, b = 1.156100\n",
      "\tgrad = 2.561567\n",
      "rate = 0.014433\n",
      "Step 78 / 1000, loss = -7654.864260\n",
      "a_1 = 5.315277, a_2 = 3.314928, b = 1.163511\n",
      "\tgrad = 2.860844\n",
      "rate = 0.014286\n",
      "Step 79 / 1000, loss = -7659.438056\n",
      "a_1 = 5.347754, a_2 = 3.337503, b = 1.170934\n",
      "\tgrad = 2.845712\n",
      "rate = 0.014141\n",
      "Step 80 / 1000, loss = -7663.674889\n",
      "a_1 = 5.377293, a_2 = 3.359655, b = 1.177903\n",
      "\tgrad = 2.683903\n",
      "rate = 0.014000\n",
      "Step 81 / 1000, loss = -7667.784669\n",
      "a_1 = 5.406739, a_2 = 3.381248, b = 1.184846\n",
      "\tgrad = 2.681467\n",
      "rate = 0.013861\n",
      "Step 82 / 1000, loss = -7671.524389\n",
      "a_1 = 5.433939, a_2 = 3.401161, b = 1.191392\n",
      "\tgrad = 2.501889\n",
      "rate = 0.013725\n",
      "Step 83 / 1000, loss = -7675.067394\n",
      "a_1 = 5.461344, a_2 = 3.419361, b = 1.197698\n",
      "\tgrad = 2.464430\n",
      "rate = 0.013592\n",
      "Step 84 / 1000, loss = -7678.785263\n",
      "a_1 = 5.489436, a_2 = 3.439640, b = 1.204386\n",
      "\tgrad = 2.621245\n",
      "rate = 0.013462\n",
      "Step 85 / 1000, loss = -7682.429092\n",
      "a_1 = 5.517852, a_2 = 3.459467, b = 1.211077\n",
      "\tgrad = 2.646727\n",
      "rate = 0.013333\n",
      "Step 86 / 1000, loss = -7686.137024\n",
      "a_1 = 5.547298, a_2 = 3.480029, b = 1.217850\n",
      "\tgrad = 2.767208\n",
      "rate = 0.013208\n",
      "Step 87 / 1000, loss = -7689.695043\n",
      "a_1 = 5.576335, a_2 = 3.499905, b = 1.224351\n",
      "\tgrad = 2.734879\n",
      "rate = 0.013084\n",
      "Step 88 / 1000, loss = -7693.104053\n",
      "a_1 = 5.604028, a_2 = 3.519685, b = 1.230674\n",
      "\tgrad = 2.670202\n",
      "rate = 0.012963\n",
      "Step 89 / 1000, loss = -7696.633069\n",
      "a_1 = 5.632825, a_2 = 3.540764, b = 1.237288\n",
      "\tgrad = 2.825802\n",
      "rate = 0.012844\n",
      "Step 90 / 1000, loss = -7699.830547\n",
      "a_1 = 5.659828, a_2 = 3.559713, b = 1.243434\n",
      "\tgrad = 2.636561\n",
      "rate = 0.012727\n",
      "Step 91 / 1000, loss = -7703.046713\n",
      "a_1 = 5.686852, a_2 = 3.579405, b = 1.249802\n",
      "\tgrad = 2.698753\n",
      "rate = 0.012613\n",
      "Step 92 / 1000, loss = -7706.141113\n",
      "a_1 = 5.713655, a_2 = 3.598317, b = 1.256001\n",
      "\tgrad = 2.670792\n",
      "rate = 0.012500\n",
      "Step 93 / 1000, loss = -7709.212314\n",
      "a_1 = 5.741768, a_2 = 3.616409, b = 1.262331\n",
      "\tgrad = 2.746293\n",
      "rate = 0.012389\n",
      "Step 94 / 1000, loss = -7712.303768\n",
      "a_1 = 5.769137, a_2 = 3.636114, b = 1.268581\n",
      "\tgrad = 2.792893\n",
      "rate = 0.012281\n",
      "Step 95 / 1000, loss = -7715.117093\n",
      "a_1 = 5.793719, a_2 = 3.654818, b = 1.274375\n",
      "\tgrad = 2.581578\n",
      "rate = 0.012174\n",
      "Step 96 / 1000, loss = -7717.842722\n",
      "a_1 = 5.818065, a_2 = 3.672988, b = 1.280107\n",
      "\tgrad = 2.561498\n",
      "rate = 0.012069\n",
      "Step 97 / 1000, loss = -7720.583999\n",
      "a_1 = 5.843269, a_2 = 3.691165, b = 1.285994\n",
      "\tgrad = 2.643142\n",
      "rate = 0.011966\n",
      "Step 98 / 1000, loss = -7723.245955\n",
      "a_1 = 5.867163, a_2 = 3.709771, b = 1.291796\n",
      "\tgrad = 2.598907\n",
      "rate = 0.011864\n",
      "Step 99 / 1000, loss = -7725.905827\n",
      "a_1 = 5.892534, a_2 = 3.727795, b = 1.297524\n",
      "\tgrad = 2.689845\n",
      "rate = 0.011765\n",
      "Step 100 / 1000, loss = -7728.343275\n",
      "a_1 = 5.916338, a_2 = 3.744352, b = 1.302808\n",
      "\tgrad = 2.526253\n",
      "rate = 0.011667\n",
      "Step 101 / 1000, loss = -7731.029364\n",
      "a_1 = 5.942250, a_2 = 3.763294, b = 1.308801\n",
      "\tgrad = 2.822038\n",
      "rate = 0.011570\n",
      "Step 102 / 1000, loss = -7733.431474\n",
      "a_1 = 5.966077, a_2 = 3.780123, b = 1.314297\n",
      "\tgrad = 2.586789\n",
      "rate = 0.011475\n",
      "Step 103 / 1000, loss = -7735.998672\n",
      "a_1 = 5.991974, a_2 = 3.798319, b = 1.320180\n",
      "\tgrad = 2.828365\n",
      "rate = 0.011382\n",
      "Step 104 / 1000, loss = -7738.226359\n",
      "a_1 = 6.014606, a_2 = 3.814280, b = 1.325508\n",
      "\tgrad = 2.497808\n",
      "rate = 0.011290\n",
      "Step 105 / 1000, loss = -7740.518679\n",
      "a_1 = 6.038813, a_2 = 3.830448, b = 1.330984\n",
      "\tgrad = 2.644728\n",
      "rate = 0.011200\n",
      "Step 106 / 1000, loss = -7742.926895\n",
      "a_1 = 6.063785, a_2 = 3.848424, b = 1.336650\n",
      "\tgrad = 2.815770\n",
      "rate = 0.011111\n",
      "Step 107 / 1000, loss = -7745.202681\n",
      "a_1 = 6.088160, a_2 = 3.865210, b = 1.342117\n",
      "\tgrad = 2.730204\n",
      "rate = 0.011024\n",
      "Step 108 / 1000, loss = -7747.358780\n",
      "a_1 = 6.111037, a_2 = 3.881650, b = 1.347443\n",
      "\tgrad = 2.621280\n",
      "rate = 0.010938\n",
      "Step 109 / 1000, loss = -7749.432080\n",
      "a_1 = 6.133920, a_2 = 3.897249, b = 1.352499\n",
      "\tgrad = 2.593968\n",
      "rate = 0.010853\n",
      "Step 110 / 1000, loss = -7751.624565\n",
      "a_1 = 6.159049, a_2 = 3.913316, b = 1.358034\n",
      "\tgrad = 2.816955\n",
      "rate = 0.010769\n",
      "Step 111 / 1000, loss = -7753.594878\n",
      "a_1 = 6.181230, a_2 = 3.928400, b = 1.363164\n",
      "\tgrad = 2.555365\n",
      "rate = 0.010687\n",
      "Step 112 / 1000, loss = -7755.631282\n",
      "a_1 = 6.204827, a_2 = 3.943921, b = 1.368434\n",
      "\tgrad = 2.709018\n",
      "rate = 0.010606\n",
      "Step 113 / 1000, loss = -7757.562636\n",
      "a_1 = 6.226428, a_2 = 3.959581, b = 1.373603\n",
      "\tgrad = 2.581661\n",
      "rate = 0.010526\n",
      "Step 114 / 1000, loss = -7759.411882\n",
      "a_1 = 6.248182, a_2 = 3.974035, b = 1.378628\n",
      "\tgrad = 2.545773\n",
      "rate = 0.010448\n",
      "Step 115 / 1000, loss = -7761.400048\n",
      "a_1 = 6.271632, a_2 = 3.990111, b = 1.383896\n",
      "\tgrad = 2.788272\n",
      "rate = 0.010370\n",
      "Step 116 / 1000, loss = -7763.336408\n",
      "a_1 = 6.295440, a_2 = 4.005323, b = 1.389156\n",
      "\tgrad = 2.791725\n",
      "rate = 0.010294\n",
      "Step 117 / 1000, loss = -7765.378030\n",
      "a_1 = 6.320641, a_2 = 4.021820, b = 1.394683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad = 2.996745\n",
      "rate = 0.010219\n",
      "Step 118 / 1000, loss = -7767.127557\n",
      "a_1 = 6.342336, a_2 = 4.036251, b = 1.399492\n",
      "\tgrad = 2.611733\n",
      "rate = 0.010145\n",
      "Step 119 / 1000, loss = -7768.914324\n",
      "a_1 = 6.364073, a_2 = 4.051698, b = 1.404487\n",
      "\tgrad = 2.693689\n",
      "rate = 0.010072\n",
      "Step 120 / 1000, loss = -7770.646016\n",
      "a_1 = 6.385708, a_2 = 4.066532, b = 1.409427\n",
      "\tgrad = 2.669323\n",
      "rate = 0.010000\n",
      "Step 121 / 1000, loss = -7772.272719\n",
      "a_1 = 6.405525, a_2 = 4.081102, b = 1.414272\n",
      "\tgrad = 2.524864\n",
      "rate = 0.009929\n",
      "Step 122 / 1000, loss = -7773.973538\n",
      "a_1 = 6.427076, a_2 = 4.096293, b = 1.419083\n",
      "\tgrad = 2.718523\n",
      "rate = 0.009859\n",
      "Step 123 / 1000, loss = -7775.513717\n",
      "a_1 = 6.447023, a_2 = 4.109921, b = 1.423597\n",
      "\tgrad = 2.510238\n",
      "rate = 0.009790\n",
      "Step 124 / 1000, loss = -7777.121034\n",
      "a_1 = 6.467654, a_2 = 4.124805, b = 1.428195\n",
      "\tgrad = 2.659017\n",
      "rate = 0.009722\n",
      "Step 125 / 1000, loss = -7778.799544\n",
      "a_1 = 6.489615, a_2 = 4.140244, b = 1.433205\n",
      "\tgrad = 2.828382\n",
      "rate = 0.009655\n",
      "Step 126 / 1000, loss = -7780.406895\n",
      "a_1 = 6.511823, a_2 = 4.154536, b = 1.437923\n",
      "\tgrad = 2.797727\n",
      "rate = 0.009589\n",
      "Step 127 / 1000, loss = -7782.007940\n",
      "a_1 = 6.532804, a_2 = 4.170030, b = 1.442788\n",
      "\tgrad = 2.785823\n",
      "rate = 0.009524\n",
      "Step 128 / 1000, loss = -7783.540618\n",
      "a_1 = 6.553816, a_2 = 4.184357, b = 1.447583\n",
      "\tgrad = 2.735790\n",
      "rate = 0.009459\n",
      "Step 129 / 1000, loss = -7785.026731\n",
      "a_1 = 6.574070, a_2 = 4.198790, b = 1.452196\n",
      "\tgrad = 2.692114\n",
      "rate = 0.009396\n",
      "Step 130 / 1000, loss = -7786.495785\n",
      "a_1 = 6.594701, a_2 = 4.212911, b = 1.456778\n",
      "\tgrad = 2.723306\n",
      "rate = 0.009333\n",
      "Step 131 / 1000, loss = -7787.838034\n",
      "a_1 = 6.613628, a_2 = 4.225885, b = 1.461191\n",
      "\tgrad = 2.520249\n",
      "rate = 0.009272\n",
      "Step 132 / 1000, loss = -7789.289806\n",
      "a_1 = 6.633642, a_2 = 4.240791, b = 1.465879\n",
      "\tgrad = 2.756858\n",
      "rate = 0.009211\n",
      "Step 133 / 1000, loss = -7790.639885\n",
      "a_1 = 6.652968, a_2 = 4.254243, b = 1.470408\n",
      "\tgrad = 2.620481\n",
      "rate = 0.009150\n",
      "Step 134 / 1000, loss = -7791.960990\n",
      "a_1 = 6.672405, a_2 = 4.267337, b = 1.474808\n",
      "\tgrad = 2.623068\n",
      "rate = 0.009091\n",
      "Step 135 / 1000, loss = -7793.247969\n",
      "a_1 = 6.691700, a_2 = 4.280187, b = 1.479035\n",
      "\tgrad = 2.608866\n",
      "rate = 0.009032\n",
      "Step 136 / 1000, loss = -7794.552504\n",
      "a_1 = 6.710299, a_2 = 4.294294, b = 1.483440\n",
      "\tgrad = 2.647086\n",
      "rate = 0.008974\n",
      "Step 137 / 1000, loss = -7795.899547\n",
      "a_1 = 6.730416, a_2 = 4.308346, b = 1.488094\n",
      "\tgrad = 2.800898\n",
      "rate = 0.008917\n",
      "Step 138 / 1000, loss = -7797.190533\n",
      "a_1 = 6.749520, a_2 = 4.322281, b = 1.492622\n",
      "\tgrad = 2.717175\n",
      "rate = 0.008861\n",
      "Step 139 / 1000, loss = -7798.401581\n",
      "a_1 = 6.767773, a_2 = 4.335359, b = 1.496919\n",
      "\tgrad = 2.596386\n",
      "rate = 0.008805\n",
      "Step 140 / 1000, loss = -7799.678855\n",
      "a_1 = 6.787776, a_2 = 4.349007, b = 1.501302\n",
      "\tgrad = 2.812532\n",
      "rate = 0.008750\n",
      "Step 141 / 1000, loss = -7800.896859\n",
      "a_1 = 6.806586, a_2 = 4.362532, b = 1.505571\n",
      "\tgrad = 2.709066\n",
      "rate = 0.008696\n",
      "Step 142 / 1000, loss = -7802.072758\n",
      "a_1 = 6.824667, a_2 = 4.375737, b = 1.509952\n",
      "\tgrad = 2.639986\n",
      "rate = 0.008642\n",
      "Step 143 / 1000, loss = -7803.318996\n",
      "a_1 = 6.843630, a_2 = 4.390384, b = 1.514504\n",
      "\tgrad = 2.839622\n",
      "rate = 0.008589\n",
      "Step 144 / 1000, loss = -7804.449572\n",
      "a_1 = 6.862191, a_2 = 4.402879, b = 1.518558\n",
      "\tgrad = 2.663708\n",
      "rate = 0.008537\n",
      "Step 145 / 1000, loss = -7805.581658\n",
      "a_1 = 6.881016, a_2 = 4.415444, b = 1.522681\n",
      "\tgrad = 2.711407\n",
      "rate = 0.008485\n",
      "Step 146 / 1000, loss = -7806.712058\n",
      "a_1 = 6.899418, a_2 = 4.428511, b = 1.526965\n",
      "\tgrad = 2.723781\n",
      "rate = 0.008434\n",
      "Step 147 / 1000, loss = -7807.764222\n",
      "a_1 = 6.916388, a_2 = 4.441149, b = 1.530930\n",
      "\tgrad = 2.568017\n",
      "rate = 0.008383\n",
      "Step 148 / 1000, loss = -7808.862411\n",
      "a_1 = 6.934856, a_2 = 4.454003, b = 1.535055\n",
      "\tgrad = 2.745044\n",
      "rate = 0.008333\n",
      "Step 149 / 1000, loss = -7809.907118\n",
      "a_1 = 6.953047, a_2 = 4.465823, b = 1.539131\n",
      "\tgrad = 2.664565\n",
      "rate = 0.008284\n",
      "Step 150 / 1000, loss = -7810.954383\n",
      "a_1 = 6.970555, a_2 = 4.478723, b = 1.543141\n",
      "\tgrad = 2.685272\n",
      "rate = 0.008235\n",
      "Step 151 / 1000, loss = -7812.036159\n",
      "a_1 = 6.989883, a_2 = 4.491208, b = 1.547332\n",
      "\tgrad = 2.856677\n",
      "rate = 0.008187\n",
      "Step 152 / 1000, loss = -7813.069445\n",
      "a_1 = 7.008141, a_2 = 4.503492, b = 1.551475\n",
      "\tgrad = 2.751078\n",
      "rate = 0.008140\n",
      "Step 153 / 1000, loss = -7814.079166\n",
      "a_1 = 7.026327, a_2 = 4.515716, b = 1.555319\n",
      "\tgrad = 2.749114\n",
      "rate = 0.008092\n",
      "Step 154 / 1000, loss = -7815.087758\n",
      "a_1 = 7.043955, a_2 = 4.528350, b = 1.559510\n",
      "\tgrad = 2.745324\n",
      "rate = 0.008046\n",
      "Step 155 / 1000, loss = -7815.972312\n",
      "a_1 = 7.059586, a_2 = 4.539603, b = 1.563126\n",
      "\tgrad = 2.449569\n",
      "rate = 0.008000\n",
      "Step 156 / 1000, loss = -7816.894028\n",
      "a_1 = 7.076049, a_2 = 4.551396, b = 1.566928\n",
      "\tgrad = 2.590421\n",
      "rate = 0.007955\n",
      "Step 157 / 1000, loss = -7817.785522\n",
      "a_1 = 7.091952, a_2 = 4.562946, b = 1.570732\n",
      "\tgrad = 2.531014\n",
      "rate = 0.007910\n",
      "Step 158 / 1000, loss = -7818.699642\n",
      "a_1 = 7.109057, a_2 = 4.574407, b = 1.574562\n",
      "\tgrad = 2.662753\n",
      "rate = 0.007865\n",
      "Step 159 / 1000, loss = -7819.558708\n",
      "a_1 = 7.124925, a_2 = 4.585555, b = 1.578222\n",
      "\tgrad = 2.523244\n",
      "rate = 0.007821\n",
      "Step 160 / 1000, loss = -7820.434355\n",
      "a_1 = 7.141488, a_2 = 4.596689, b = 1.582072\n",
      "\tgrad = 2.613214\n",
      "rate = 0.007778\n",
      "Step 161 / 1000, loss = -7821.351356\n",
      "a_1 = 7.159087, a_2 = 4.608554, b = 1.585962\n",
      "\tgrad = 2.789860\n",
      "rate = 0.007735\n",
      "Step 162 / 1000, loss = -7822.195959\n",
      "a_1 = 7.174923, a_2 = 4.620035, b = 1.589592\n",
      "\tgrad = 2.586175\n",
      "rate = 0.007692\n",
      "Step 163 / 1000, loss = -7823.043854\n",
      "a_1 = 7.191783, a_2 = 4.630822, b = 1.593333\n",
      "\tgrad = 2.661689\n",
      "rate = 0.007650\n",
      "Step 164 / 1000, loss = -7823.911254\n",
      "a_1 = 7.208345, a_2 = 4.642784, b = 1.597137\n",
      "\tgrad = 2.731229\n",
      "rate = 0.007609\n",
      "Step 165 / 1000, loss = -7824.770943\n",
      "a_1 = 7.225557, a_2 = 4.654137, b = 1.600943\n",
      "\tgrad = 2.770690\n",
      "rate = 0.007568\n",
      "Step 166 / 1000, loss = -7825.643511\n",
      "a_1 = 7.242718, a_2 = 4.666237, b = 1.604797\n",
      "\tgrad = 2.836336\n",
      "rate = 0.007527\n",
      "Step 167 / 1000, loss = -7826.383258\n",
      "a_1 = 7.256693, a_2 = 4.677043, b = 1.608248\n",
      "\tgrad = 2.404129\n",
      "rate = 0.007487\n",
      "Step 168 / 1000, loss = -7827.191681\n",
      "a_1 = 7.272486, a_2 = 4.688580, b = 1.612045\n",
      "\tgrad = 2.675501\n",
      "rate = 0.007447\n",
      "Step 169 / 1000, loss = -7827.998161\n",
      "a_1 = 7.289362, a_2 = 4.699353, b = 1.615794\n",
      "\tgrad = 2.749776\n",
      "rate = 0.007407\n",
      "Step 170 / 1000, loss = -7828.763530\n",
      "a_1 = 7.305204, a_2 = 4.709896, b = 1.619419\n",
      "\tgrad = 2.628983\n",
      "rate = 0.007368\n",
      "Step 171 / 1000, loss = -7829.529756\n",
      "a_1 = 7.321388, a_2 = 4.720325, b = 1.623098\n",
      "\tgrad = 2.674352\n",
      "rate = 0.007330\n",
      "Step 172 / 1000, loss = -7830.316017\n",
      "a_1 = 7.337479, a_2 = 4.731879, b = 1.626766\n",
      "\tgrad = 2.762771\n",
      "rate = 0.007292\n",
      "Step 173 / 1000, loss = -7831.105030\n",
      "a_1 = 7.353849, a_2 = 4.743474, b = 1.630487\n",
      "\tgrad = 2.812715\n",
      "rate = 0.007254\n",
      "Step 174 / 1000, loss = -7831.822217\n",
      "a_1 = 7.368612, a_2 = 4.754220, b = 1.633979\n",
      "\tgrad = 2.576151\n",
      "rate = 0.007216\n",
      "Step 175 / 1000, loss = -7832.554637\n",
      "a_1 = 7.384340, a_2 = 4.764846, b = 1.637518\n",
      "\tgrad = 2.689372\n",
      "rate = 0.007179\n",
      "Step 176 / 1000, loss = -7833.333969\n",
      "a_1 = 7.400883, a_2 = 4.776619, b = 1.641254\n",
      "\tgrad = 2.890341\n",
      "rate = 0.007143\n",
      "Step 177 / 1000, loss = -7834.063608\n",
      "a_1 = 7.416150, a_2 = 4.788187, b = 1.644665\n",
      "\tgrad = 2.737780\n",
      "rate = 0.007107\n",
      "Step 178 / 1000, loss = -7834.760065\n",
      "a_1 = 7.430923, a_2 = 4.799068, b = 1.648087\n",
      "\tgrad = 2.639569\n",
      "rate = 0.007071\n",
      "Step 179 / 1000, loss = -7835.437118\n",
      "a_1 = 7.445654, a_2 = 4.809434, b = 1.651478\n",
      "\tgrad = 2.605362\n",
      "rate = 0.007035\n",
      "Step 180 / 1000, loss = -7836.129014\n",
      "a_1 = 7.460936, a_2 = 4.820029, b = 1.654942\n",
      "\tgrad = 2.702247\n",
      "rate = 0.007000\n",
      "Step 181 / 1000, loss = -7836.772180\n",
      "a_1 = 7.475483, a_2 = 4.829679, b = 1.658229\n",
      "\tgrad = 2.550312\n",
      "rate = 0.006965\n",
      "Step 182 / 1000, loss = -7837.484550\n",
      "a_1 = 7.491759, a_2 = 4.840556, b = 1.661770\n",
      "\tgrad = 2.870365\n",
      "rate = 0.006931\n",
      "Step 183 / 1000, loss = -7838.177500\n",
      "a_1 = 7.507280, a_2 = 4.851510, b = 1.665336\n",
      "\tgrad = 2.802654\n",
      "rate = 0.006897\n",
      "Step 184 / 1000, loss = -7838.805519\n",
      "a_1 = 7.521670, a_2 = 4.861226, b = 1.668657\n",
      "\tgrad = 2.575884\n",
      "rate = 0.006863\n",
      "Step 185 / 1000, loss = -7839.451681\n",
      "a_1 = 7.536464, a_2 = 4.871532, b = 1.671989\n",
      "\tgrad = 2.684804\n",
      "rate = 0.006829\n",
      "Step 186 / 1000, loss = -7840.113684\n",
      "a_1 = 7.551968, a_2 = 4.881973, b = 1.675408\n",
      "\tgrad = 2.796040\n",
      "rate = 0.006796\n",
      "Step 187 / 1000, loss = -7840.706368\n",
      "a_1 = 7.566066, a_2 = 4.891184, b = 1.678566\n",
      "\tgrad = 2.533403\n",
      "rate = 0.006763\n",
      "Step 188 / 1000, loss = -7841.341984\n",
      "a_1 = 7.581238, a_2 = 4.901233, b = 1.681931\n",
      "\tgrad = 2.749578\n",
      "rate = 0.006731\n",
      "Step 189 / 1000, loss = -7841.947421\n",
      "a_1 = 7.595521, a_2 = 4.911009, b = 1.685253\n",
      "\tgrad = 2.630970\n",
      "rate = 0.006699\n",
      "Step 190 / 1000, loss = -7842.522657\n",
      "a_1 = 7.608792, a_2 = 4.920798, b = 1.688366\n",
      "\tgrad = 2.517321\n",
      "rate = 0.006667\n",
      "Step 191 / 1000, loss = -7843.137168\n",
      "a_1 = 7.623476, a_2 = 4.931016, b = 1.691657\n",
      "\tgrad = 2.741390\n",
      "rate = 0.006635\n",
      "Step 192 / 1000, loss = -7843.753057\n",
      "a_1 = 7.638582, a_2 = 4.940960, b = 1.695065\n",
      "\tgrad = 2.786749\n",
      "rate = 0.006604\n",
      "Step 193 / 1000, loss = -7844.318327\n",
      "a_1 = 7.651800, a_2 = 4.950881, b = 1.698173\n",
      "\tgrad = 2.558631\n",
      "rate = 0.006573\n",
      "Step 194 / 1000, loss = -7844.870909\n",
      "a_1 = 7.665042, a_2 = 4.960395, b = 1.701255\n",
      "\tgrad = 2.536442\n",
      "rate = 0.006542\n",
      "Step 195 / 1000, loss = -7845.465411\n",
      "a_1 = 7.679540, a_2 = 4.970556, b = 1.704588\n",
      "\tgrad = 2.766691\n",
      "rate = 0.006512\n",
      "Step 196 / 1000, loss = -7846.026048\n",
      "a_1 = 7.692813, a_2 = 4.980523, b = 1.707861\n",
      "\tgrad = 2.610205\n",
      "rate = 0.006481\n",
      "Step 197 / 1000, loss = -7846.584830\n",
      "a_1 = 7.706412, a_2 = 4.990290, b = 1.711119\n",
      "\tgrad = 2.643824\n",
      "rate = 0.006452\n",
      "Step 198 / 1000, loss = -7847.190423\n",
      "a_1 = 7.721480, a_2 = 5.000976, b = 1.714477\n",
      "\tgrad = 2.923576\n",
      "rate = 0.006422\n",
      "Step 199 / 1000, loss = -7847.756893\n",
      "a_1 = 7.735495, a_2 = 5.011106, b = 1.717718\n",
      "\tgrad = 2.752197\n",
      "rate = 0.006393\n",
      "Step 200 / 1000, loss = -7848.298444\n",
      "a_1 = 7.749226, a_2 = 5.020621, b = 1.720842\n",
      "\tgrad = 2.670608\n",
      "rate = 0.006364\n",
      "Step 201 / 1000, loss = -7848.785825\n",
      "a_1 = 7.761685, a_2 = 5.029167, b = 1.723706\n",
      "\tgrad = 2.427518\n",
      "rate = 0.006335\n",
      "Step 202 / 1000, loss = -7849.333259\n",
      "a_1 = 7.775711, a_2 = 5.038986, b = 1.726852\n",
      "\tgrad = 2.760396\n",
      "rate = 0.006306\n",
      "Step 203 / 1000, loss = -7849.886334\n",
      "a_1 = 7.790201, a_2 = 5.048751, b = 1.730060\n",
      "\tgrad = 2.829808\n",
      "rate = 0.006278\n",
      "Step 204 / 1000, loss = -7850.438586\n",
      "a_1 = 7.804300, a_2 = 5.059023, b = 1.733260\n",
      "\tgrad = 2.837633\n",
      "rate = 0.006250\n",
      "Step 205 / 1000, loss = -7850.949746\n",
      "a_1 = 7.817761, a_2 = 5.068166, b = 1.736340\n",
      "\tgrad = 2.661524\n",
      "rate = 0.006222\n",
      "Step 206 / 1000, loss = -7851.446595\n",
      "a_1 = 7.830472, a_2 = 5.077458, b = 1.739400\n",
      "\tgrad = 2.589443\n",
      "rate = 0.006195\n",
      "Step 207 / 1000, loss = -7851.985695\n",
      "a_1 = 7.844480, a_2 = 5.087745, b = 1.742533\n",
      "\tgrad = 2.863324\n",
      "rate = 0.006167\n",
      "Step 208 / 1000, loss = -7852.492496\n",
      "a_1 = 7.858274, a_2 = 5.096900, b = 1.745560\n",
      "\tgrad = 2.740781\n",
      "rate = 0.006140\n",
      "Step 209 / 1000, loss = -7852.972836\n",
      "a_1 = 7.870807, a_2 = 5.106124, b = 1.748500\n",
      "\tgrad = 2.590587\n",
      "rate = 0.006114\n",
      "Step 210 / 1000, loss = -7853.471533\n",
      "a_1 = 7.884609, a_2 = 5.115079, b = 1.751592\n",
      "\tgrad = 2.750160\n",
      "rate = 0.006087\n",
      "Step 211 / 1000, loss = -7853.958302\n",
      "a_1 = 7.897957, a_2 = 5.124034, b = 1.754647\n",
      "\tgrad = 2.699658\n",
      "rate = 0.006061\n",
      "Step 212 / 1000, loss = -7854.438560\n",
      "a_1 = 7.911071, a_2 = 5.133106, b = 1.757628\n",
      "\tgrad = 2.688233\n",
      "rate = 0.006034\n",
      "Step 213 / 1000, loss = -7854.937623\n",
      "a_1 = 7.924326, a_2 = 5.143053, b = 1.760704\n",
      "\tgrad = 2.805163\n",
      "rate = 0.006009\n",
      "Step 214 / 1000, loss = -7855.400544\n",
      "a_1 = 7.937358, a_2 = 5.151649, b = 1.763635\n",
      "\tgrad = 2.654953\n",
      "rate = 0.005983\n",
      "Step 215 / 1000, loss = -7855.890543\n",
      "a_1 = 7.951042, a_2 = 5.161071, b = 1.766679\n",
      "\tgrad = 2.835249\n",
      "rate = 0.005957\n",
      "Step 216 / 1000, loss = -7856.330300\n",
      "a_1 = 7.963231, a_2 = 5.169594, b = 1.769527\n",
      "\tgrad = 2.552806\n",
      "rate = 0.005932\n",
      "Step 217 / 1000, loss = -7856.820172\n",
      "a_1 = 7.976968, a_2 = 5.179174, b = 1.772634\n",
      "\tgrad = 2.883472\n",
      "rate = 0.005907\n",
      "Step 218 / 1000, loss = -7857.260258\n",
      "a_1 = 7.989819, a_2 = 5.187438, b = 1.775433\n",
      "\tgrad = 2.640676\n",
      "rate = 0.005882\n",
      "Step 219 / 1000, loss = -7857.705441\n",
      "a_1 = 8.002507, a_2 = 5.196050, b = 1.778391\n",
      "\tgrad = 2.666073\n",
      "rate = 0.005858\n",
      "Step 220 / 1000, loss = -7858.141304\n",
      "a_1 = 8.014703, a_2 = 5.204883, b = 1.781232\n",
      "\tgrad = 2.627033\n",
      "rate = 0.005833\n",
      "Step 221 / 1000, loss = -7858.584764\n",
      "a_1 = 8.027886, a_2 = 5.213369, b = 1.784067\n",
      "\tgrad = 2.742590\n",
      "rate = 0.005809\n",
      "Step 222 / 1000, loss = -7859.023340\n",
      "a_1 = 8.040757, a_2 = 5.221950, b = 1.786942\n",
      "\tgrad = 2.719748\n",
      "rate = 0.005785\n",
      "Step 223 / 1000, loss = -7859.435038\n",
      "a_1 = 8.053040, a_2 = 5.229944, b = 1.789638\n",
      "\tgrad = 2.586432\n",
      "rate = 0.005761\n",
      "Step 224 / 1000, loss = -7859.866454\n",
      "a_1 = 8.065349, a_2 = 5.238852, b = 1.792541\n",
      "\tgrad = 2.695942\n",
      "rate = 0.005738\n",
      "Step 225 / 1000, loss = -7860.288232\n",
      "a_1 = 8.077877, a_2 = 5.247307, b = 1.795324\n",
      "\tgrad = 2.689521\n",
      "rate = 0.005714\n",
      "Step 226 / 1000, loss = -7860.723734\n",
      "a_1 = 8.090277, a_2 = 5.256676, b = 1.798175\n",
      "\tgrad = 2.776461\n",
      "rate = 0.005691\n",
      "Step 227 / 1000, loss = -7861.138454\n",
      "a_1 = 8.102565, a_2 = 5.265206, b = 1.800952\n",
      "\tgrad = 2.684239\n",
      "rate = 0.005668\n",
      "Step 228 / 1000, loss = -7861.521136\n",
      "a_1 = 8.113897, a_2 = 5.273123, b = 1.803566\n",
      "\tgrad = 2.492112\n",
      "rate = 0.005645\n",
      "Step 229 / 1000, loss = -7861.910664\n",
      "a_1 = 8.125407, a_2 = 5.281345, b = 1.806197\n",
      "\tgrad = 2.558915\n",
      "rate = 0.005622\n",
      "Step 230 / 1000, loss = -7862.303685\n",
      "a_1 = 8.137292, a_2 = 5.289511, b = 1.808846\n",
      "\tgrad = 2.618090\n",
      "rate = 0.005600\n",
      "Step 231 / 1000, loss = -7862.721750\n",
      "a_1 = 8.149829, a_2 = 5.298354, b = 1.811707\n",
      "\tgrad = 2.798020\n",
      "rate = 0.005578\n",
      "Step 232 / 1000, loss = -7863.127761\n",
      "a_1 = 8.161931, a_2 = 5.307119, b = 1.814490\n",
      "\tgrad = 2.735955\n",
      "rate = 0.005556\n",
      "Step 233 / 1000, loss = -7863.538040\n",
      "a_1 = 8.174807, a_2 = 5.315503, b = 1.817312\n",
      "\tgrad = 2.823093\n",
      "rate = 0.005534\n",
      "Step 234 / 1000, loss = -7863.925747\n",
      "a_1 = 8.186554, a_2 = 5.323897, b = 1.819991\n",
      "\tgrad = 2.664069\n",
      "rate = 0.005512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 235 / 1000, loss = -7864.289375\n",
      "a_1 = 8.197994, a_2 = 5.331385, b = 1.822582\n",
      "\tgrad = 2.534811\n",
      "rate = 0.005490\n",
      "Step 236 / 1000, loss = -7864.673619\n",
      "a_1 = 8.210140, a_2 = 5.339426, b = 1.825261\n",
      "\tgrad = 2.708344\n",
      "rate = 0.005469\n",
      "Step 237 / 1000, loss = -7865.049100\n",
      "a_1 = 8.221718, a_2 = 5.347502, b = 1.827990\n",
      "\tgrad = 2.639304\n",
      "rate = 0.005447\n",
      "Step 238 / 1000, loss = -7865.436798\n",
      "a_1 = 8.233846, a_2 = 5.355909, b = 1.830720\n",
      "\tgrad = 2.765522\n",
      "rate = 0.005426\n",
      "Step 239 / 1000, loss = -7865.798119\n",
      "a_1 = 8.245291, a_2 = 5.363662, b = 1.833303\n",
      "\tgrad = 2.601721\n",
      "rate = 0.005405\n",
      "Step 240 / 1000, loss = -7866.172044\n",
      "a_1 = 8.256602, a_2 = 5.372208, b = 1.836017\n",
      "\tgrad = 2.680511\n",
      "rate = 0.005385\n",
      "Step 241 / 1000, loss = -7866.551187\n",
      "a_1 = 8.268691, a_2 = 5.380389, b = 1.838796\n",
      "\tgrad = 2.770302\n",
      "rate = 0.005364\n",
      "Step 242 / 1000, loss = -7866.945271\n",
      "a_1 = 8.281158, a_2 = 5.389153, b = 1.841638\n",
      "\tgrad = 2.900994\n",
      "rate = 0.005344\n",
      "Step 243 / 1000, loss = -7867.311406\n",
      "a_1 = 8.292746, a_2 = 5.397428, b = 1.844252\n",
      "\tgrad = 2.719681\n",
      "rate = 0.005323\n",
      "Step 244 / 1000, loss = -7867.665932\n",
      "a_1 = 8.303912, a_2 = 5.405523, b = 1.846829\n",
      "\tgrad = 2.645694\n",
      "rate = 0.005303\n",
      "Step 245 / 1000, loss = -7868.022805\n",
      "a_1 = 8.315282, a_2 = 5.413622, b = 1.849444\n",
      "\tgrad = 2.688323\n",
      "rate = 0.005283\n",
      "Step 246 / 1000, loss = -7868.388600\n",
      "a_1 = 8.326850, a_2 = 5.422149, b = 1.852086\n",
      "\tgrad = 2.776267\n",
      "rate = 0.005263\n",
      "Step 247 / 1000, loss = -7868.762281\n",
      "a_1 = 8.338956, a_2 = 5.430720, b = 1.854776\n",
      "\tgrad = 2.874991\n",
      "rate = 0.005243\n",
      "Step 248 / 1000, loss = -7869.078832\n",
      "a_1 = 8.349192, a_2 = 5.437949, b = 1.857153\n",
      "\tgrad = 2.441619\n",
      "rate = 0.005224\n",
      "Step 249 / 1000, loss = -7869.422253\n",
      "a_1 = 8.360675, a_2 = 5.445643, b = 1.859656\n",
      "\tgrad = 2.699113\n",
      "rate = 0.005204\n",
      "Step 250 / 1000, loss = -7869.739418\n",
      "a_1 = 8.371027, a_2 = 5.452947, b = 1.862046\n",
      "\tgrad = 2.486465\n",
      "rate = 0.005185\n",
      "Step 251 / 1000, loss = -7870.083641\n",
      "a_1 = 8.382529, a_2 = 5.460760, b = 1.864614\n",
      "\tgrad = 2.737145\n",
      "rate = 0.005166\n",
      "Step 252 / 1000, loss = -7870.439571\n",
      "a_1 = 8.394163, a_2 = 5.469162, b = 1.867269\n",
      "\tgrad = 2.835321\n",
      "rate = 0.005147\n",
      "Step 253 / 1000, loss = -7870.776619\n",
      "a_1 = 8.405554, a_2 = 5.476791, b = 1.869849\n",
      "\tgrad = 2.720324\n",
      "rate = 0.005128\n",
      "Step 254 / 1000, loss = -7871.126557\n",
      "a_1 = 8.417295, a_2 = 5.484955, b = 1.872470\n",
      "\tgrad = 2.845470\n",
      "rate = 0.005109\n",
      "Step 255 / 1000, loss = -7871.447193\n",
      "a_1 = 8.428317, a_2 = 5.492190, b = 1.874944\n",
      "\tgrad = 2.634872\n",
      "rate = 0.005091\n",
      "Step 256 / 1000, loss = -7871.784928\n",
      "a_1 = 8.439554, a_2 = 5.500363, b = 1.877444\n",
      "\tgrad = 2.783383\n",
      "rate = 0.005072\n",
      "Step 257 / 1000, loss = -7872.093995\n",
      "a_1 = 8.449518, a_2 = 5.508002, b = 1.879880\n",
      "\tgrad = 2.530414\n",
      "rate = 0.005054\n",
      "Step 258 / 1000, loss = -7872.409626\n",
      "a_1 = 8.460322, a_2 = 5.515280, b = 1.882403\n",
      "\tgrad = 2.634878\n",
      "rate = 0.005036\n",
      "Step 259 / 1000, loss = -7872.737348\n",
      "a_1 = 8.471231, a_2 = 5.523243, b = 1.884983\n",
      "\tgrad = 2.740303\n",
      "rate = 0.005018\n",
      "Step 260 / 1000, loss = -7873.065411\n",
      "a_1 = 8.482680, a_2 = 5.531047, b = 1.887408\n",
      "\tgrad = 2.813241\n",
      "rate = 0.005000\n",
      "Step 261 / 1000, loss = -7873.380474\n",
      "a_1 = 8.493390, a_2 = 5.538599, b = 1.889938\n",
      "\tgrad = 2.678834\n",
      "rate = 0.004982\n",
      "Step 262 / 1000, loss = -7873.701735\n",
      "a_1 = 8.504446, a_2 = 5.546412, b = 1.892406\n",
      "\tgrad = 2.772001\n",
      "rate = 0.004965\n",
      "Step 263 / 1000, loss = -7874.026561\n",
      "a_1 = 8.515593, a_2 = 5.554338, b = 1.894963\n",
      "\tgrad = 2.812738\n",
      "rate = 0.004947\n",
      "Step 264 / 1000, loss = -7874.334361\n",
      "a_1 = 8.526489, a_2 = 5.561586, b = 1.897423\n",
      "\tgrad = 2.701049\n",
      "rate = 0.004930\n",
      "Step 265 / 1000, loss = -7874.648031\n",
      "a_1 = 8.537433, a_2 = 5.569275, b = 1.899864\n",
      "\tgrad = 2.767885\n",
      "rate = 0.004912\n",
      "Step 266 / 1000, loss = -7874.936670\n",
      "a_1 = 8.547308, a_2 = 5.576471, b = 1.902199\n",
      "\tgrad = 2.541221\n",
      "rate = 0.004895\n",
      "Step 267 / 1000, loss = -7875.239175\n",
      "a_1 = 8.558072, a_2 = 5.583686, b = 1.904672\n",
      "\tgrad = 2.704470\n",
      "rate = 0.004878\n",
      "Step 268 / 1000, loss = -7875.533510\n",
      "a_1 = 8.568340, a_2 = 5.591048, b = 1.907010\n",
      "\tgrad = 2.643154\n",
      "rate = 0.004861\n",
      "Step 269 / 1000, loss = -7875.841290\n",
      "a_1 = 8.578973, a_2 = 5.598776, b = 1.909553\n",
      "\tgrad = 2.763779\n",
      "rate = 0.004844\n",
      "Step 270 / 1000, loss = -7876.138908\n",
      "a_1 = 8.589775, a_2 = 5.605976, b = 1.911933\n",
      "\tgrad = 2.733955\n",
      "rate = 0.004828\n",
      "Step 271 / 1000, loss = -7876.421500\n",
      "a_1 = 8.599664, a_2 = 5.613138, b = 1.914238\n",
      "\tgrad = 2.582603\n",
      "rate = 0.004811\n",
      "Step 272 / 1000, loss = -7876.716437\n",
      "a_1 = 8.610095, a_2 = 5.620667, b = 1.916582\n",
      "\tgrad = 2.727387\n",
      "rate = 0.004795\n",
      "Step 273 / 1000, loss = -7877.009262\n",
      "a_1 = 8.620356, a_2 = 5.628249, b = 1.918943\n",
      "\tgrad = 2.715543\n",
      "rate = 0.004778\n",
      "Step 274 / 1000, loss = -7877.299034\n",
      "a_1 = 8.630733, a_2 = 5.635605, b = 1.921295\n",
      "\tgrad = 2.716373\n",
      "rate = 0.004762\n",
      "Step 275 / 1000, loss = -7877.576921\n",
      "a_1 = 8.640461, a_2 = 5.642905, b = 1.923558\n",
      "\tgrad = 2.606851\n",
      "rate = 0.004746\n",
      "Step 276 / 1000, loss = -7877.859418\n",
      "a_1 = 8.650450, a_2 = 5.650309, b = 1.925857\n",
      "\tgrad = 2.673196\n",
      "rate = 0.004730\n",
      "Step 277 / 1000, loss = -7878.141558\n",
      "a_1 = 8.661425, a_2 = 5.656869, b = 1.928176\n",
      "\tgrad = 2.756845\n",
      "rate = 0.004714\n",
      "Step 278 / 1000, loss = -7878.412434\n",
      "a_1 = 8.671059, a_2 = 5.663907, b = 1.930478\n",
      "\tgrad = 2.586492\n",
      "rate = 0.004698\n",
      "Step 279 / 1000, loss = -7878.709985\n",
      "a_1 = 8.681931, a_2 = 5.671547, b = 1.932941\n",
      "\tgrad = 2.886313\n",
      "rate = 0.004682\n",
      "Step 280 / 1000, loss = -7878.999155\n",
      "a_1 = 8.692301, a_2 = 5.679165, b = 1.935368\n",
      "\tgrad = 2.805946\n",
      "rate = 0.004667\n",
      "Step 281 / 1000, loss = -7879.278631\n",
      "a_1 = 8.702916, a_2 = 5.686185, b = 1.937637\n",
      "\tgrad = 2.779222\n",
      "rate = 0.004651\n",
      "Step 282 / 1000, loss = -7879.559383\n",
      "a_1 = 8.713359, a_2 = 5.693459, b = 1.939941\n",
      "\tgrad = 2.789966\n",
      "rate = 0.004636\n",
      "Step 283 / 1000, loss = -7879.821156\n",
      "a_1 = 8.723134, a_2 = 5.700140, b = 1.942182\n",
      "\tgrad = 2.607987\n",
      "rate = 0.004620\n",
      "Step 284 / 1000, loss = -7880.067100\n",
      "a_1 = 8.732224, a_2 = 5.706564, b = 1.944277\n",
      "\tgrad = 2.459322\n",
      "rate = 0.004605\n",
      "Step 285 / 1000, loss = -7880.324306\n",
      "a_1 = 8.741692, a_2 = 5.713344, b = 1.946485\n",
      "\tgrad = 2.582376\n",
      "rate = 0.004590\n",
      "Step 286 / 1000, loss = -7880.588860\n",
      "a_1 = 8.751719, a_2 = 5.720117, b = 1.948763\n",
      "\tgrad = 2.691141\n",
      "rate = 0.004575\n",
      "Step 287 / 1000, loss = -7880.855270\n",
      "a_1 = 8.761722, a_2 = 5.727129, b = 1.951021\n",
      "\tgrad = 2.724058\n",
      "rate = 0.004560\n",
      "Step 288 / 1000, loss = -7881.101820\n",
      "a_1 = 8.771229, a_2 = 5.733352, b = 1.953184\n",
      "\tgrad = 2.544717\n",
      "rate = 0.004545\n",
      "Step 289 / 1000, loss = -7881.373797\n",
      "a_1 = 8.781439, a_2 = 5.740614, b = 1.955499\n",
      "\tgrad = 2.812295\n",
      "rate = 0.004531\n",
      "Step 290 / 1000, loss = -7881.629326\n",
      "a_1 = 8.791304, a_2 = 5.747213, b = 1.957708\n",
      "\tgrad = 2.673112\n",
      "rate = 0.004516\n",
      "Step 291 / 1000, loss = -7881.871934\n",
      "a_1 = 8.800700, a_2 = 5.753540, b = 1.959779\n",
      "\tgrad = 2.558017\n",
      "rate = 0.004502\n",
      "Step 292 / 1000, loss = -7882.136041\n",
      "a_1 = 8.810927, a_2 = 5.760500, b = 1.962022\n",
      "\tgrad = 2.801884\n",
      "rate = 0.004487\n",
      "Step 293 / 1000, loss = -7882.395419\n",
      "a_1 = 8.820391, a_2 = 5.767754, b = 1.964326\n",
      "\tgrad = 2.715166\n",
      "rate = 0.004473\n",
      "Step 294 / 1000, loss = -7882.665289\n",
      "a_1 = 8.830694, a_2 = 5.775096, b = 1.966631\n",
      "\tgrad = 2.884239\n",
      "rate = 0.004459\n",
      "Step 295 / 1000, loss = -7882.914216\n",
      "a_1 = 8.840449, a_2 = 5.781616, b = 1.968822\n",
      "\tgrad = 2.685606\n",
      "rate = 0.004444\n",
      "Step 296 / 1000, loss = -7883.172912\n",
      "a_1 = 8.850395, a_2 = 5.788681, b = 1.971050\n",
      "\tgrad = 2.799358\n",
      "rate = 0.004430\n",
      "Step 297 / 1000, loss = -7883.395374\n",
      "a_1 = 8.859347, a_2 = 5.794392, b = 1.973015\n",
      "\tgrad = 2.444966\n",
      "rate = 0.004416\n",
      "Step 298 / 1000, loss = -7883.643856\n",
      "a_1 = 8.868715, a_2 = 5.801367, b = 1.975208\n",
      "\tgrad = 2.699249\n",
      "rate = 0.004403\n",
      "Step 299 / 1000, loss = -7883.882303\n",
      "a_1 = 8.877838, a_2 = 5.807936, b = 1.977354\n",
      "\tgrad = 2.607871\n",
      "rate = 0.004389\n",
      "Step 300 / 1000, loss = -7884.136936\n",
      "a_1 = 8.887632, a_2 = 5.815021, b = 1.979602\n",
      "\tgrad = 2.810480\n",
      "rate = 0.004375\n",
      "Step 301 / 1000, loss = -7884.367927\n",
      "a_1 = 8.896469, a_2 = 5.821470, b = 1.981691\n",
      "\tgrad = 2.553589\n",
      "rate = 0.004361\n",
      "Step 302 / 1000, loss = -7884.609629\n",
      "a_1 = 8.905839, a_2 = 5.828245, b = 1.983817\n",
      "\tgrad = 2.704110\n",
      "rate = 0.004348\n",
      "Step 303 / 1000, loss = -7884.844681\n",
      "a_1 = 8.914886, a_2 = 5.834884, b = 1.985924\n",
      "\tgrad = 2.634164\n",
      "rate = 0.004334\n",
      "Step 304 / 1000, loss = -7885.081253\n",
      "a_1 = 8.924335, a_2 = 5.841239, b = 1.988102\n",
      "\tgrad = 2.682998\n",
      "rate = 0.004321\n",
      "Step 305 / 1000, loss = -7885.305326\n",
      "a_1 = 8.933064, a_2 = 5.847504, b = 1.990156\n",
      "\tgrad = 2.539494\n",
      "rate = 0.004308\n",
      "Step 306 / 1000, loss = -7885.530273\n",
      "a_1 = 8.941531, a_2 = 5.854094, b = 1.992217\n",
      "\tgrad = 2.544180\n",
      "rate = 0.004294\n",
      "Step 307 / 1000, loss = -7885.760929\n",
      "a_1 = 8.950758, a_2 = 5.860434, b = 1.994328\n",
      "\tgrad = 2.660874\n",
      "rate = 0.004281\n",
      "Step 308 / 1000, loss = -7885.982771\n",
      "a_1 = 8.959664, a_2 = 5.866565, b = 1.996347\n",
      "\tgrad = 2.576913\n",
      "rate = 0.004268\n",
      "Step 309 / 1000, loss = -7886.210756\n",
      "a_1 = 8.968799, a_2 = 5.872899, b = 1.998440\n",
      "\tgrad = 2.658347\n",
      "rate = 0.004255\n",
      "Step 310 / 1000, loss = -7886.442269\n",
      "a_1 = 8.978182, a_2 = 5.879331, b = 2.000536\n",
      "\tgrad = 2.726502\n",
      "rate = 0.004242\n",
      "Step 311 / 1000, loss = -7886.658426\n",
      "a_1 = 8.986783, a_2 = 5.885400, b = 2.002575\n",
      "\tgrad = 2.535118\n",
      "rate = 0.004230\n",
      "Step 312 / 1000, loss = -7886.881354\n",
      "a_1 = 8.995958, a_2 = 5.891464, b = 2.004662\n",
      "\tgrad = 2.654547\n",
      "rate = 0.004217\n",
      "Step 313 / 1000, loss = -7887.108925\n",
      "a_1 = 9.004964, a_2 = 5.898134, b = 2.006705\n",
      "\tgrad = 2.709581\n",
      "rate = 0.004204\n",
      "Step 314 / 1000, loss = -7887.333504\n",
      "a_1 = 9.014079, a_2 = 5.904448, b = 2.008805\n",
      "\tgrad = 2.692410\n",
      "rate = 0.004192\n",
      "Step 315 / 1000, loss = -7887.565415\n",
      "a_1 = 9.023081, a_2 = 5.911404, b = 2.010949\n",
      "\tgrad = 2.770184\n",
      "rate = 0.004179\n",
      "Step 316 / 1000, loss = -7887.794133\n",
      "a_1 = 9.032053, a_2 = 5.918200, b = 2.013087\n",
      "\tgrad = 2.749448\n",
      "rate = 0.004167\n",
      "Step 317 / 1000, loss = -7888.012285\n",
      "a_1 = 9.040747, a_2 = 5.924649, b = 2.015097\n",
      "\tgrad = 2.650234\n",
      "rate = 0.004154\n",
      "Step 318 / 1000, loss = -7888.222536\n",
      "a_1 = 9.048972, a_2 = 5.930854, b = 2.017164\n",
      "\tgrad = 2.537129\n",
      "rate = 0.004142\n",
      "Step 319 / 1000, loss = -7888.434337\n",
      "a_1 = 9.057669, a_2 = 5.936888, b = 2.019179\n",
      "\tgrad = 2.609172\n",
      "rate = 0.004130\n",
      "Step 320 / 1000, loss = -7888.665874\n",
      "a_1 = 9.067391, a_2 = 5.943466, b = 2.021300\n",
      "\tgrad = 2.896830\n",
      "rate = 0.004118\n",
      "Step 321 / 1000, loss = -7888.878547\n",
      "a_1 = 9.076062, a_2 = 5.949665, b = 2.023324\n",
      "\tgrad = 2.642703\n",
      "rate = 0.004106\n",
      "Step 322 / 1000, loss = -7889.092995\n",
      "a_1 = 9.085026, a_2 = 5.955785, b = 2.025354\n",
      "\tgrad = 2.697422\n",
      "rate = 0.004094\n",
      "Step 323 / 1000, loss = -7889.299274\n",
      "a_1 = 9.093612, a_2 = 5.961759, b = 2.027297\n",
      "\tgrad = 2.606417\n",
      "rate = 0.004082\n",
      "Step 324 / 1000, loss = -7889.512988\n",
      "a_1 = 9.102516, a_2 = 5.967922, b = 2.029352\n",
      "\tgrad = 2.708331\n",
      "rate = 0.004070\n",
      "Step 325 / 1000, loss = -7889.706338\n",
      "a_1 = 9.110440, a_2 = 5.973609, b = 2.031239\n",
      "\tgrad = 2.448169\n",
      "rate = 0.004058\n",
      "Step 326 / 1000, loss = -7889.902258\n",
      "a_1 = 9.118538, a_2 = 5.979393, b = 2.033121\n",
      "\tgrad = 2.502981\n",
      "rate = 0.004046\n",
      "Step 327 / 1000, loss = -7890.110467\n",
      "a_1 = 9.127382, a_2 = 5.985420, b = 2.035090\n",
      "\tgrad = 2.697041\n",
      "rate = 0.004035\n",
      "Step 328 / 1000, loss = -7890.304493\n",
      "a_1 = 9.135643, a_2 = 5.990952, b = 2.036996\n",
      "\tgrad = 2.516563\n",
      "rate = 0.004023\n",
      "Step 329 / 1000, loss = -7890.511111\n",
      "a_1 = 9.144343, a_2 = 5.997079, b = 2.038950\n",
      "\tgrad = 2.696834\n",
      "rate = 0.004011\n",
      "Step 330 / 1000, loss = -7890.729721\n",
      "a_1 = 9.153608, a_2 = 6.003535, b = 2.041030\n",
      "\tgrad = 2.870802\n",
      "rate = 0.004000\n",
      "Step 331 / 1000, loss = -7890.935192\n",
      "a_1 = 9.162428, a_2 = 6.009574, b = 2.042968\n",
      "\tgrad = 2.723676\n",
      "rate = 0.003989\n",
      "Step 332 / 1000, loss = -7891.142883\n",
      "a_1 = 9.171259, a_2 = 6.015688, b = 2.045001\n",
      "\tgrad = 2.748408\n",
      "rate = 0.003977\n",
      "Step 333 / 1000, loss = -7891.352583\n",
      "a_1 = 9.179843, a_2 = 6.022215, b = 2.047035\n",
      "\tgrad = 2.767039\n",
      "rate = 0.003966\n",
      "Step 334 / 1000, loss = -7891.563982\n",
      "a_1 = 9.188935, a_2 = 6.028575, b = 2.049009\n",
      "\tgrad = 2.849506\n",
      "rate = 0.003955\n",
      "Step 335 / 1000, loss = -7891.762310\n",
      "a_1 = 9.197230, a_2 = 6.034575, b = 2.051004\n",
      "\tgrad = 2.644818\n",
      "rate = 0.003944\n",
      "Step 336 / 1000, loss = -7891.977166\n",
      "a_1 = 9.206549, a_2 = 6.040940, b = 2.053092\n",
      "\tgrad = 2.918349\n",
      "rate = 0.003933\n",
      "Step 337 / 1000, loss = -7892.175493\n",
      "a_1 = 9.214833, a_2 = 6.047128, b = 2.055021\n",
      "\tgrad = 2.682179\n",
      "rate = 0.003922\n",
      "Step 338 / 1000, loss = -7892.366935\n",
      "a_1 = 9.223136, a_2 = 6.052824, b = 2.056918\n",
      "\tgrad = 2.620260\n",
      "rate = 0.003911\n",
      "Step 339 / 1000, loss = -7892.567242\n",
      "a_1 = 9.231720, a_2 = 6.058925, b = 2.058895\n",
      "\tgrad = 2.747541\n",
      "rate = 0.003900\n",
      "Step 340 / 1000, loss = -7892.775914\n",
      "a_1 = 9.240786, a_2 = 6.065244, b = 2.060937\n",
      "\tgrad = 2.889747\n",
      "rate = 0.003889\n",
      "Step 341 / 1000, loss = -7892.986811\n",
      "a_1 = 9.249861, a_2 = 6.071780, b = 2.062980\n",
      "\tgrad = 2.931499\n",
      "rate = 0.003878\n",
      "Step 342 / 1000, loss = -7893.179017\n",
      "a_1 = 9.258228, a_2 = 6.077640, b = 2.064879\n",
      "\tgrad = 2.686666\n",
      "rate = 0.003867\n",
      "Step 343 / 1000, loss = -7893.369628\n",
      "a_1 = 9.266399, a_2 = 6.083629, b = 2.066742\n",
      "\tgrad = 2.670840\n",
      "rate = 0.003857\n",
      "Step 344 / 1000, loss = -7893.560400\n",
      "a_1 = 9.274895, a_2 = 6.089346, b = 2.068634\n",
      "\tgrad = 2.707556\n",
      "rate = 0.003846\n",
      "Step 345 / 1000, loss = -7893.756621\n",
      "a_1 = 9.283381, a_2 = 6.095498, b = 2.070571\n",
      "\tgrad = 2.778880\n",
      "rate = 0.003836\n",
      "Step 346 / 1000, loss = -7893.940598\n",
      "a_1 = 9.291438, a_2 = 6.101136, b = 2.072442\n",
      "\tgrad = 2.616987\n",
      "rate = 0.003825\n",
      "Step 347 / 1000, loss = -7894.128149\n",
      "a_1 = 9.299778, a_2 = 6.106806, b = 2.074353\n",
      "\tgrad = 2.690625\n",
      "rate = 0.003815\n",
      "Step 348 / 1000, loss = -7894.312214\n",
      "a_1 = 9.307686, a_2 = 6.112651, b = 2.076224\n",
      "\tgrad = 2.631267\n",
      "rate = 0.003804\n",
      "Step 349 / 1000, loss = -7894.483278\n",
      "a_1 = 9.315186, a_2 = 6.117950, b = 2.077989\n",
      "\tgrad = 2.464620\n",
      "rate = 0.003794\n",
      "Step 350 / 1000, loss = -7894.666493\n",
      "a_1 = 9.323120, a_2 = 6.123719, b = 2.079896\n",
      "\tgrad = 2.641196\n",
      "rate = 0.003784\n",
      "Step 351 / 1000, loss = -7894.858142\n",
      "a_1 = 9.331758, a_2 = 6.129560, b = 2.081850\n",
      "\tgrad = 2.811294\n",
      "rate = 0.003774\n",
      "Step 352 / 1000, loss = -7895.049226\n",
      "a_1 = 9.340221, a_2 = 6.135612, b = 2.083758\n",
      "\tgrad = 2.810797\n",
      "rate = 0.003763\n",
      "Step 353 / 1000, loss = -7895.244895\n",
      "a_1 = 9.348909, a_2 = 6.141758, b = 2.085762\n",
      "\tgrad = 2.885134\n",
      "rate = 0.003753\n",
      "Step 354 / 1000, loss = -7895.438042\n",
      "a_1 = 9.357717, a_2 = 6.147652, b = 2.087750\n",
      "\tgrad = 2.880516\n",
      "rate = 0.003743\n",
      "Step 355 / 1000, loss = -7895.618960\n",
      "a_1 = 9.366000, a_2 = 6.153174, b = 2.089617\n",
      "\tgrad = 2.713088\n",
      "rate = 0.003733\n",
      "Step 356 / 1000, loss = -7895.796418\n",
      "a_1 = 9.373753, a_2 = 6.158957, b = 2.091441\n",
      "\tgrad = 2.643571\n",
      "rate = 0.003723\n",
      "Step 357 / 1000, loss = -7895.969281\n",
      "a_1 = 9.381463, a_2 = 6.164454, b = 2.093242\n",
      "\tgrad = 2.595399\n",
      "rate = 0.003714\n",
      "Step 358 / 1000, loss = -7896.149706\n",
      "a_1 = 9.389559, a_2 = 6.170231, b = 2.095090\n",
      "\tgrad = 2.731314\n",
      "rate = 0.003704\n",
      "Step 359 / 1000, loss = -7896.332492\n",
      "a_1 = 9.397637, a_2 = 6.176162, b = 2.097007\n",
      "\tgrad = 2.762195\n",
      "rate = 0.003694\n",
      "Step 360 / 1000, loss = -7896.516513\n",
      "a_1 = 9.405780, a_2 = 6.182173, b = 2.098931\n",
      "\tgrad = 2.796363\n",
      "rate = 0.003684\n",
      "Step 361 / 1000, loss = -7896.684918\n",
      "a_1 = 9.413352, a_2 = 6.187631, b = 2.100672\n",
      "\tgrad = 2.584103\n",
      "rate = 0.003675\n",
      "Step 362 / 1000, loss = -7896.864775\n",
      "a_1 = 9.421512, a_2 = 6.193453, b = 2.102519\n",
      "\tgrad = 2.781115\n",
      "rate = 0.003665\n",
      "Step 363 / 1000, loss = -7897.042076\n",
      "a_1 = 9.429618, a_2 = 6.199143, b = 2.104361\n",
      "\tgrad = 2.755877\n",
      "rate = 0.003655\n",
      "Step 364 / 1000, loss = -7897.223786\n",
      "a_1 = 9.438001, a_2 = 6.204995, b = 2.106217\n",
      "\tgrad = 2.850091\n",
      "rate = 0.003646\n",
      "Step 365 / 1000, loss = -7897.403098\n",
      "a_1 = 9.446321, a_2 = 6.210738, b = 2.108068\n",
      "\tgrad = 2.826303\n",
      "rate = 0.003636\n",
      "Step 366 / 1000, loss = -7897.577973\n",
      "a_1 = 9.454353, a_2 = 6.216402, b = 2.109903\n",
      "\tgrad = 2.756477\n",
      "rate = 0.003627\n",
      "Step 367 / 1000, loss = -7897.750178\n",
      "a_1 = 9.462191, a_2 = 6.222085, b = 2.111705\n",
      "\tgrad = 2.722162\n",
      "rate = 0.003618\n",
      "Step 368 / 1000, loss = -7897.923842\n",
      "a_1 = 9.470145, a_2 = 6.227747, b = 2.113563\n",
      "\tgrad = 2.754417\n",
      "rate = 0.003608\n",
      "Step 369 / 1000, loss = -7898.095018\n",
      "a_1 = 9.478075, a_2 = 6.233349, b = 2.115352\n",
      "\tgrad = 2.743249\n",
      "rate = 0.003599\n",
      "Step 370 / 1000, loss = -7898.262007\n",
      "a_1 = 9.486016, a_2 = 6.238622, b = 2.117129\n",
      "\tgrad = 2.701266\n",
      "rate = 0.003590\n",
      "Step 371 / 1000, loss = -7898.425529\n",
      "a_1 = 9.493973, a_2 = 6.243619, b = 2.118897\n",
      "\tgrad = 2.670052\n",
      "rate = 0.003581\n",
      "Step 372 / 1000, loss = -7898.596367\n",
      "a_1 = 9.502233, a_2 = 6.248964, b = 2.120715\n",
      "\tgrad = 2.801502\n",
      "rate = 0.003571\n",
      "Step 373 / 1000, loss = -7898.755308\n",
      "a_1 = 9.509777, a_2 = 6.254021, b = 2.122454\n",
      "\tgrad = 2.595841\n",
      "rate = 0.003562\n",
      "Step 374 / 1000, loss = -7898.913122\n",
      "a_1 = 9.516893, a_2 = 6.259420, b = 2.124166\n",
      "\tgrad = 2.559414\n",
      "rate = 0.003553\n",
      "Step 375 / 1000, loss = -7899.071695\n",
      "a_1 = 9.524066, a_2 = 6.264864, b = 2.125882\n",
      "\tgrad = 2.586376\n",
      "rate = 0.003544\n",
      "Step 376 / 1000, loss = -7899.235976\n",
      "a_1 = 9.531748, a_2 = 6.270423, b = 2.127589\n",
      "\tgrad = 2.725478\n",
      "rate = 0.003535\n",
      "Step 377 / 1000, loss = -7899.403810\n",
      "a_1 = 9.539486, a_2 = 6.276190, b = 2.129363\n",
      "\tgrad = 2.782479\n",
      "rate = 0.003526\n",
      "Step 378 / 1000, loss = -7899.562852\n",
      "a_1 = 9.546912, a_2 = 6.281494, b = 2.131118\n",
      "\tgrad = 2.641826\n",
      "rate = 0.003518\n",
      "Step 379 / 1000, loss = -7899.724343\n",
      "a_1 = 9.554459, a_2 = 6.286954, b = 2.132869\n",
      "\tgrad = 2.701396\n",
      "rate = 0.003509\n",
      "Step 380 / 1000, loss = -7899.879991\n",
      "a_1 = 9.561992, a_2 = 6.292051, b = 2.134539\n",
      "\tgrad = 2.641869\n",
      "rate = 0.003500\n",
      "Step 381 / 1000, loss = -7900.037478\n",
      "a_1 = 9.569440, a_2 = 6.297464, b = 2.136180\n",
      "\tgrad = 2.678760\n",
      "rate = 0.003491\n",
      "Step 382 / 1000, loss = -7900.205670\n",
      "a_1 = 9.577519, a_2 = 6.303056, b = 2.138008\n",
      "\tgrad = 2.869812\n",
      "rate = 0.003483\n",
      "Step 383 / 1000, loss = -7900.371199\n",
      "a_1 = 9.585580, a_2 = 6.308526, b = 2.139790\n",
      "\tgrad = 2.850826\n",
      "rate = 0.003474\n",
      "Step 384 / 1000, loss = -7900.523992\n",
      "a_1 = 9.592980, a_2 = 6.313531, b = 2.141509\n",
      "\tgrad = 2.625164\n",
      "rate = 0.003465\n",
      "Step 385 / 1000, loss = -7900.680893\n",
      "a_1 = 9.600477, a_2 = 6.318878, b = 2.143216\n",
      "\tgrad = 2.709403\n",
      "rate = 0.003457\n",
      "Step 386 / 1000, loss = -7900.839415\n",
      "a_1 = 9.608433, a_2 = 6.323977, b = 2.144944\n",
      "\tgrad = 2.785746\n",
      "rate = 0.003448\n",
      "Step 387 / 1000, loss = -7900.985427\n",
      "a_1 = 9.615563, a_2 = 6.328805, b = 2.146581\n",
      "\tgrad = 2.548344\n",
      "rate = 0.003440\n",
      "Step 388 / 1000, loss = -7901.133069\n",
      "a_1 = 9.622459, a_2 = 6.334016, b = 2.148221\n",
      "\tgrad = 2.563663\n",
      "rate = 0.003431\n",
      "Step 389 / 1000, loss = -7901.294560\n",
      "a_1 = 9.630249, a_2 = 6.339522, b = 2.150022\n",
      "\tgrad = 2.836085\n",
      "rate = 0.003423\n",
      "Step 390 / 1000, loss = -7901.447944\n",
      "a_1 = 9.637654, a_2 = 6.344778, b = 2.151733\n",
      "\tgrad = 2.706157\n",
      "rate = 0.003415\n",
      "Step 391 / 1000, loss = -7901.594975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 9.644808, a_2 = 6.349784, b = 2.153381\n",
      "\tgrad = 2.608781\n",
      "rate = 0.003406\n",
      "Step 392 / 1000, loss = -7901.735171\n",
      "a_1 = 9.651709, a_2 = 6.354467, b = 2.154985\n",
      "\tgrad = 2.499173\n",
      "rate = 0.003398\n",
      "Step 393 / 1000, loss = -7901.895623\n",
      "a_1 = 9.659456, a_2 = 6.360109, b = 2.156744\n",
      "\tgrad = 2.874477\n",
      "rate = 0.003390\n",
      "Step 394 / 1000, loss = -7902.041972\n",
      "a_1 = 9.666738, a_2 = 6.365016, b = 2.158401\n",
      "\tgrad = 2.642586\n",
      "rate = 0.003382\n",
      "Step 395 / 1000, loss = -7902.196716\n",
      "a_1 = 9.674120, a_2 = 6.370581, b = 2.160112\n",
      "\tgrad = 2.786768\n",
      "rate = 0.003373\n",
      "Step 396 / 1000, loss = -7902.343768\n",
      "a_1 = 9.681287, a_2 = 6.375658, b = 2.161808\n",
      "\tgrad = 2.658007\n",
      "rate = 0.003365\n",
      "Step 397 / 1000, loss = -7902.489783\n",
      "a_1 = 9.688822, a_2 = 6.380422, b = 2.163453\n",
      "\tgrad = 2.700102\n",
      "rate = 0.003357\n",
      "Step 398 / 1000, loss = -7902.638753\n",
      "a_1 = 9.696477, a_2 = 6.385394, b = 2.165097\n",
      "\tgrad = 2.769233\n",
      "rate = 0.003349\n",
      "Step 399 / 1000, loss = -7902.777865\n",
      "a_1 = 9.703373, a_2 = 6.390214, b = 2.166681\n",
      "\tgrad = 2.562158\n",
      "rate = 0.003341\n",
      "Step 400 / 1000, loss = -7902.917249\n",
      "a_1 = 9.710309, a_2 = 6.395088, b = 2.168241\n",
      "\tgrad = 2.586066\n",
      "rate = 0.003333\n",
      "Step 401 / 1000, loss = -7903.055750\n",
      "a_1 = 9.717129, a_2 = 6.399875, b = 2.169887\n",
      "\tgrad = 2.554013\n",
      "rate = 0.003325\n",
      "Step 402 / 1000, loss = -7903.199385\n",
      "a_1 = 9.724312, a_2 = 6.404990, b = 2.171453\n",
      "\tgrad = 2.699660\n",
      "rate = 0.003318\n",
      "Step 403 / 1000, loss = -7903.339303\n",
      "a_1 = 9.731499, a_2 = 6.409681, b = 2.173078\n",
      "\tgrad = 2.639039\n",
      "rate = 0.003310\n",
      "Step 404 / 1000, loss = -7903.474106\n",
      "a_1 = 9.738317, a_2 = 6.414316, b = 2.174646\n",
      "\tgrad = 2.541678\n",
      "rate = 0.003302\n",
      "Step 405 / 1000, loss = -7903.618787\n",
      "a_1 = 9.745614, a_2 = 6.419436, b = 2.176267\n",
      "\tgrad = 2.750350\n",
      "rate = 0.003294\n",
      "Step 406 / 1000, loss = -7903.759189\n",
      "a_1 = 9.752747, a_2 = 6.424299, b = 2.177897\n",
      "\tgrad = 2.673468\n",
      "rate = 0.003286\n",
      "Step 407 / 1000, loss = -7903.897543\n",
      "a_1 = 9.759790, a_2 = 6.429092, b = 2.179513\n",
      "\tgrad = 2.644766\n",
      "rate = 0.003279\n",
      "Step 408 / 1000, loss = -7904.047167\n",
      "a_1 = 9.767296, a_2 = 6.434495, b = 2.181204\n",
      "\tgrad = 2.874049\n",
      "rate = 0.003271\n",
      "Step 409 / 1000, loss = -7904.184667\n",
      "a_1 = 9.774087, a_2 = 6.439529, b = 2.182794\n",
      "\tgrad = 2.635697\n",
      "rate = 0.003263\n",
      "Step 410 / 1000, loss = -7904.321311\n",
      "a_1 = 9.780708, a_2 = 6.444596, b = 2.184421\n",
      "\tgrad = 2.609420\n",
      "rate = 0.003256\n",
      "Step 411 / 1000, loss = -7904.458007\n",
      "a_1 = 9.787626, a_2 = 6.449498, b = 2.186010\n",
      "\tgrad = 2.655451\n",
      "rate = 0.003248\n",
      "Step 412 / 1000, loss = -7904.597704\n",
      "a_1 = 9.794741, a_2 = 6.454527, b = 2.187614\n",
      "\tgrad = 2.733639\n",
      "rate = 0.003241\n",
      "Step 413 / 1000, loss = -7904.737842\n",
      "a_1 = 9.801859, a_2 = 6.459592, b = 2.189240\n",
      "\tgrad = 2.748445\n",
      "rate = 0.003233\n",
      "Step 414 / 1000, loss = -7904.870876\n",
      "a_1 = 9.808524, a_2 = 6.464482, b = 2.190802\n",
      "\tgrad = 2.608137\n",
      "rate = 0.003226\n",
      "Step 415 / 1000, loss = -7905.006634\n",
      "a_1 = 9.815552, a_2 = 6.469252, b = 2.192427\n",
      "\tgrad = 2.686889\n",
      "rate = 0.003218\n",
      "Step 416 / 1000, loss = -7905.141760\n",
      "a_1 = 9.822412, a_2 = 6.474151, b = 2.194042\n",
      "\tgrad = 2.673014\n",
      "rate = 0.003211\n",
      "Step 417 / 1000, loss = -7905.271933\n",
      "a_1 = 9.829080, a_2 = 6.478869, b = 2.195583\n",
      "\tgrad = 2.594670\n",
      "rate = 0.003204\n",
      "Step 418 / 1000, loss = -7905.407721\n",
      "a_1 = 9.836153, a_2 = 6.483734, b = 2.197178\n",
      "\tgrad = 2.731852\n",
      "rate = 0.003196\n",
      "Step 419 / 1000, loss = -7905.542818\n",
      "a_1 = 9.843181, a_2 = 6.488566, b = 2.198795\n",
      "\tgrad = 2.721779\n",
      "rate = 0.003189\n",
      "Step 420 / 1000, loss = -7905.674058\n",
      "a_1 = 9.849602, a_2 = 6.493595, b = 2.200398\n",
      "\tgrad = 2.612486\n",
      "rate = 0.003182\n",
      "Step 421 / 1000, loss = -7905.808161\n",
      "a_1 = 9.856928, a_2 = 6.498165, b = 2.201985\n",
      "\tgrad = 2.765439\n",
      "rate = 0.003175\n",
      "Step 422 / 1000, loss = -7905.940157\n",
      "a_1 = 9.863811, a_2 = 6.502969, b = 2.203556\n",
      "\tgrad = 2.696036\n",
      "rate = 0.003167\n",
      "Step 423 / 1000, loss = -7906.063490\n",
      "a_1 = 9.870232, a_2 = 6.507415, b = 2.205073\n",
      "\tgrad = 2.517495\n",
      "rate = 0.003160\n",
      "Step 424 / 1000, loss = -7906.196498\n",
      "a_1 = 9.877226, a_2 = 6.512330, b = 2.206612\n",
      "\tgrad = 2.754547\n",
      "rate = 0.003153\n",
      "Step 425 / 1000, loss = -7906.324001\n",
      "a_1 = 9.883501, a_2 = 6.517330, b = 2.208163\n",
      "\tgrad = 2.597545\n",
      "rate = 0.003146\n",
      "Step 426 / 1000, loss = -7906.453673\n",
      "a_1 = 9.890348, a_2 = 6.522072, b = 2.209714\n",
      "\tgrad = 2.698861\n",
      "rate = 0.003139\n",
      "Step 427 / 1000, loss = -7906.584922\n",
      "a_1 = 9.897409, a_2 = 6.526790, b = 2.211280\n",
      "\tgrad = 2.756996\n",
      "rate = 0.003132\n",
      "Step 428 / 1000, loss = -7906.711806\n",
      "a_1 = 9.904132, a_2 = 6.531373, b = 2.212855\n",
      "\tgrad = 2.651984\n",
      "rate = 0.003125\n",
      "Step 429 / 1000, loss = -7906.837201\n",
      "a_1 = 9.910728, a_2 = 6.535997, b = 2.214395\n",
      "\tgrad = 2.630261\n",
      "rate = 0.003118\n",
      "Step 430 / 1000, loss = -7906.972334\n",
      "a_1 = 9.917943, a_2 = 6.541010, b = 2.215994\n",
      "\tgrad = 2.870668\n",
      "rate = 0.003111\n",
      "Step 431 / 1000, loss = -7907.093134\n",
      "a_1 = 9.924418, a_2 = 6.545400, b = 2.217484\n",
      "\tgrad = 2.565439\n",
      "rate = 0.003104\n",
      "Step 432 / 1000, loss = -7907.216230\n",
      "a_1 = 9.930926, a_2 = 6.550045, b = 2.218962\n",
      "\tgrad = 2.625024\n",
      "rate = 0.003097\n",
      "Step 433 / 1000, loss = -7907.343046\n",
      "a_1 = 9.937476, a_2 = 6.554914, b = 2.220535\n",
      "\tgrad = 2.689341\n",
      "rate = 0.003091\n",
      "Step 434 / 1000, loss = -7907.467474\n",
      "a_1 = 9.944032, a_2 = 6.559630, b = 2.222061\n",
      "\tgrad = 2.665238\n",
      "rate = 0.003084\n",
      "Step 435 / 1000, loss = -7907.594264\n",
      "a_1 = 9.950786, a_2 = 6.564419, b = 2.223602\n",
      "\tgrad = 2.737235\n",
      "rate = 0.003077\n",
      "Step 436 / 1000, loss = -7907.716246\n",
      "a_1 = 9.957421, a_2 = 6.568931, b = 2.225085\n",
      "\tgrad = 2.657803\n",
      "rate = 0.003070\n",
      "Step 437 / 1000, loss = -7907.837849\n",
      "a_1 = 9.963859, a_2 = 6.573582, b = 2.226583\n",
      "\tgrad = 2.638097\n",
      "rate = 0.003063\n",
      "Step 438 / 1000, loss = -7907.967077\n",
      "a_1 = 9.970697, a_2 = 6.578594, b = 2.228151\n",
      "\tgrad = 2.820507\n",
      "rate = 0.003057\n",
      "Step 439 / 1000, loss = -7908.088289\n",
      "a_1 = 9.977296, a_2 = 6.583123, b = 2.229643\n",
      "\tgrad = 2.669343\n",
      "rate = 0.003050\n",
      "Step 440 / 1000, loss = -7908.199615\n",
      "a_1 = 9.983546, a_2 = 6.587157, b = 2.231000\n",
      "\tgrad = 2.484555\n",
      "rate = 0.003043\n",
      "Step 441 / 1000, loss = -7908.316041\n",
      "a_1 = 9.989780, a_2 = 6.591643, b = 2.232437\n",
      "\tgrad = 2.572759\n",
      "rate = 0.003037\n",
      "Step 442 / 1000, loss = -7908.432890\n",
      "a_1 = 9.995990, a_2 = 6.596195, b = 2.233888\n",
      "\tgrad = 2.585688\n",
      "rate = 0.003030\n",
      "Step 443 / 1000, loss = -7908.556161\n",
      "a_1 = 10.002730, a_2 = 6.600901, b = 2.235391\n",
      "\tgrad = 2.763651\n",
      "rate = 0.003024\n",
      "Step 444 / 1000, loss = -7908.681355\n",
      "a_1 = 10.009708, a_2 = 6.605599, b = 2.236912\n",
      "\tgrad = 2.833221\n",
      "rate = 0.003017\n",
      "Step 445 / 1000, loss = -7908.803492\n",
      "a_1 = 10.016383, a_2 = 6.610269, b = 2.238432\n",
      "\tgrad = 2.752486\n",
      "rate = 0.003011\n",
      "Step 446 / 1000, loss = -7908.921582\n",
      "a_1 = 10.022929, a_2 = 6.614691, b = 2.239925\n",
      "\tgrad = 2.675968\n",
      "rate = 0.003004\n",
      "Step 447 / 1000, loss = -7909.038464\n",
      "a_1 = 10.029376, a_2 = 6.619212, b = 2.241346\n",
      "\tgrad = 2.669238\n",
      "rate = 0.002998\n",
      "Step 448 / 1000, loss = -7909.155986\n",
      "a_1 = 10.036114, a_2 = 6.623486, b = 2.242818\n",
      "\tgrad = 2.712262\n",
      "rate = 0.002991\n",
      "Step 449 / 1000, loss = -7909.275261\n",
      "a_1 = 10.042536, a_2 = 6.628216, b = 2.244316\n",
      "\tgrad = 2.718460\n",
      "rate = 0.002985\n",
      "Step 450 / 1000, loss = -7909.394370\n",
      "a_1 = 10.049027, a_2 = 6.632868, b = 2.245830\n",
      "\tgrad = 2.728703\n",
      "rate = 0.002979\n",
      "Step 451 / 1000, loss = -7909.512287\n",
      "a_1 = 10.055785, a_2 = 6.637235, b = 2.247307\n",
      "\tgrad = 2.752421\n",
      "rate = 0.002972\n",
      "Step 452 / 1000, loss = -7909.628255\n",
      "a_1 = 10.062155, a_2 = 6.641789, b = 2.248769\n",
      "\tgrad = 2.685471\n",
      "rate = 0.002966\n",
      "Step 453 / 1000, loss = -7909.747356\n",
      "a_1 = 10.068509, a_2 = 6.646691, b = 2.250252\n",
      "\tgrad = 2.757357\n",
      "rate = 0.002960\n",
      "Step 454 / 1000, loss = -7909.860872\n",
      "a_1 = 10.074878, a_2 = 6.651101, b = 2.251670\n",
      "\tgrad = 2.666395\n",
      "rate = 0.002954\n",
      "Step 455 / 1000, loss = -7909.977045\n",
      "a_1 = 10.081238, a_2 = 6.655697, b = 2.253173\n",
      "\tgrad = 2.710674\n",
      "rate = 0.002947\n",
      "Step 456 / 1000, loss = -7910.094433\n",
      "a_1 = 10.087731, a_2 = 6.660353, b = 2.254664\n",
      "\tgrad = 2.763289\n",
      "rate = 0.002941\n",
      "Step 457 / 1000, loss = -7910.215882\n",
      "a_1 = 10.094733, a_2 = 6.664935, b = 2.256211\n",
      "\tgrad = 2.899582\n",
      "rate = 0.002935\n",
      "Step 458 / 1000, loss = -7910.327164\n",
      "a_1 = 10.100747, a_2 = 6.669576, b = 2.257593\n",
      "\tgrad = 2.636419\n",
      "rate = 0.002929\n",
      "Step 459 / 1000, loss = -7910.439735\n",
      "a_1 = 10.107110, a_2 = 6.673939, b = 2.259057\n",
      "\tgrad = 2.686501\n",
      "rate = 0.002923\n",
      "Step 460 / 1000, loss = -7910.553192\n",
      "a_1 = 10.113437, a_2 = 6.678461, b = 2.260519\n",
      "\tgrad = 2.713161\n",
      "rate = 0.002917\n",
      "Step 461 / 1000, loss = -7910.667090\n",
      "a_1 = 10.119813, a_2 = 6.682962, b = 2.262012\n",
      "\tgrad = 2.729930\n",
      "rate = 0.002911\n",
      "Step 462 / 1000, loss = -7910.779082\n",
      "a_1 = 10.126354, a_2 = 6.687208, b = 2.263455\n",
      "\tgrad = 2.730460\n",
      "rate = 0.002905\n",
      "Step 463 / 1000, loss = -7910.899005\n",
      "a_1 = 10.133137, a_2 = 6.691992, b = 2.264994\n",
      "\tgrad = 2.912464\n",
      "rate = 0.002899\n",
      "Step 464 / 1000, loss = -7911.006871\n",
      "a_1 = 10.139279, a_2 = 6.696219, b = 2.266417\n",
      "\tgrad = 2.624200\n",
      "rate = 0.002893\n",
      "Step 465 / 1000, loss = -7911.117392\n",
      "a_1 = 10.145605, a_2 = 6.700508, b = 2.267898\n",
      "\tgrad = 2.696913\n",
      "rate = 0.002887\n",
      "Step 466 / 1000, loss = -7911.229719\n",
      "a_1 = 10.152039, a_2 = 6.705040, b = 2.269310\n",
      "\tgrad = 2.775781\n",
      "rate = 0.002881\n",
      "Step 467 / 1000, loss = -7911.339912\n",
      "a_1 = 10.158249, a_2 = 6.709546, b = 2.270730\n",
      "\tgrad = 2.714105\n",
      "rate = 0.002875\n",
      "Step 468 / 1000, loss = -7911.447988\n",
      "a_1 = 10.164296, a_2 = 6.714030, b = 2.272121\n",
      "\tgrad = 2.668550\n",
      "rate = 0.002869\n",
      "Step 469 / 1000, loss = -7911.561360\n",
      "a_1 = 10.170938, a_2 = 6.718532, b = 2.273556\n",
      "\tgrad = 2.847057\n",
      "rate = 0.002863\n",
      "Step 470 / 1000, loss = -7911.671432\n",
      "a_1 = 10.177345, a_2 = 6.722868, b = 2.275007\n",
      "\tgrad = 2.755216\n",
      "rate = 0.002857\n",
      "Step 471 / 1000, loss = -7911.783674\n",
      "a_1 = 10.183688, a_2 = 6.727545, b = 2.276453\n",
      "\tgrad = 2.809872\n",
      "rate = 0.002851\n",
      "Step 472 / 1000, loss = -7911.893303\n",
      "a_1 = 10.189721, a_2 = 6.732285, b = 2.277864\n",
      "\tgrad = 2.741535\n",
      "rate = 0.002846\n",
      "Step 473 / 1000, loss = -7912.002553\n",
      "a_1 = 10.196041, a_2 = 6.736799, b = 2.279244\n",
      "\tgrad = 2.777832\n",
      "rate = 0.002840\n",
      "Step 474 / 1000, loss = -7912.109742\n",
      "a_1 = 10.202069, a_2 = 6.741324, b = 2.280650\n",
      "\tgrad = 2.705305\n",
      "rate = 0.002834\n",
      "Step 475 / 1000, loss = -7912.221106\n",
      "a_1 = 10.208670, a_2 = 6.745787, b = 2.282084\n",
      "\tgrad = 2.862882\n",
      "rate = 0.002828\n",
      "Step 476 / 1000, loss = -7912.329147\n",
      "a_1 = 10.215115, a_2 = 6.750036, b = 2.283517\n",
      "\tgrad = 2.781455\n",
      "rate = 0.002823\n",
      "Step 477 / 1000, loss = -7912.436016\n",
      "a_1 = 10.221434, a_2 = 6.754344, b = 2.284917\n",
      "\tgrad = 2.759908\n",
      "rate = 0.002817\n",
      "Step 478 / 1000, loss = -7912.545775\n",
      "a_1 = 10.227808, a_2 = 6.758918, b = 2.286343\n",
      "\tgrad = 2.836491\n",
      "rate = 0.002811\n",
      "Step 479 / 1000, loss = -7912.652732\n",
      "a_1 = 10.234085, a_2 = 6.763285, b = 2.287765\n",
      "\tgrad = 2.772343\n",
      "rate = 0.002806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 480 / 1000, loss = -7912.756639\n",
      "a_1 = 10.240242, a_2 = 6.767501, b = 2.289146\n",
      "\tgrad = 2.710062\n",
      "rate = 0.002800\n",
      "Step 481 / 1000, loss = -7912.859112\n",
      "a_1 = 10.246144, a_2 = 6.771783, b = 2.290537\n",
      "\tgrad = 2.656867\n",
      "rate = 0.002794\n",
      "Step 482 / 1000, loss = -7912.964803\n",
      "a_1 = 10.252416, a_2 = 6.776070, b = 2.291965\n",
      "\tgrad = 2.771688\n",
      "rate = 0.002789\n",
      "Step 483 / 1000, loss = -7913.065427\n",
      "a_1 = 10.258020, a_2 = 6.780466, b = 2.293348\n",
      "\tgrad = 2.606937\n",
      "rate = 0.002783\n",
      "Step 484 / 1000, loss = -7913.164264\n",
      "a_1 = 10.263765, a_2 = 6.784598, b = 2.294701\n",
      "\tgrad = 2.593676\n",
      "rate = 0.002778\n",
      "Step 485 / 1000, loss = -7913.263510\n",
      "a_1 = 10.269730, a_2 = 6.788651, b = 2.296023\n",
      "\tgrad = 2.644555\n",
      "rate = 0.002772\n",
      "Step 486 / 1000, loss = -7913.366342\n",
      "a_1 = 10.275572, a_2 = 6.793116, b = 2.297432\n",
      "\tgrad = 2.705833\n",
      "rate = 0.002767\n",
      "Step 487 / 1000, loss = -7913.469103\n",
      "a_1 = 10.281825, a_2 = 6.797250, b = 2.298823\n",
      "\tgrad = 2.761174\n",
      "rate = 0.002761\n",
      "Step 488 / 1000, loss = -7913.570420\n",
      "a_1 = 10.287720, a_2 = 6.801562, b = 2.300215\n",
      "\tgrad = 2.697700\n",
      "rate = 0.002756\n",
      "Step 489 / 1000, loss = -7913.663506\n",
      "a_1 = 10.293205, a_2 = 6.805453, b = 2.301511\n",
      "\tgrad = 2.489912\n",
      "rate = 0.002750\n",
      "Step 490 / 1000, loss = -7913.759331\n",
      "a_1 = 10.298864, a_2 = 6.809521, b = 2.302812\n",
      "\tgrad = 2.582686\n",
      "rate = 0.002745\n",
      "Step 491 / 1000, loss = -7913.857508\n",
      "a_1 = 10.304667, a_2 = 6.813721, b = 2.304135\n",
      "\tgrad = 2.659080\n",
      "rate = 0.002740\n",
      "Step 492 / 1000, loss = -7913.954743\n",
      "a_1 = 10.310325, a_2 = 6.817917, b = 2.305486\n",
      "\tgrad = 2.622966\n",
      "rate = 0.002734\n",
      "Step 493 / 1000, loss = -7914.050246\n",
      "a_1 = 10.316092, a_2 = 6.821873, b = 2.306809\n",
      "\tgrad = 2.608104\n",
      "rate = 0.002729\n",
      "Step 494 / 1000, loss = -7914.149121\n",
      "a_1 = 10.322137, a_2 = 6.825919, b = 2.308182\n",
      "\tgrad = 2.717666\n",
      "rate = 0.002724\n",
      "Step 495 / 1000, loss = -7914.246850\n",
      "a_1 = 10.327980, a_2 = 6.830087, b = 2.309522\n",
      "\tgrad = 2.685889\n",
      "rate = 0.002718\n",
      "Step 496 / 1000, loss = -7914.346468\n",
      "a_1 = 10.334048, a_2 = 6.834290, b = 2.310868\n",
      "\tgrad = 2.765548\n",
      "rate = 0.002713\n",
      "Step 497 / 1000, loss = -7914.447041\n",
      "a_1 = 10.340201, a_2 = 6.838485, b = 2.312255\n",
      "\tgrad = 2.797408\n",
      "rate = 0.002708\n",
      "Step 498 / 1000, loss = -7914.552162\n",
      "a_1 = 10.346621, a_2 = 6.842961, b = 2.313671\n",
      "\tgrad = 2.942590\n",
      "rate = 0.002703\n",
      "Step 499 / 1000, loss = -7914.646210\n",
      "a_1 = 10.352480, a_2 = 6.846835, b = 2.314965\n",
      "\tgrad = 2.647792\n",
      "rate = 0.002697\n",
      "Step 500 / 1000, loss = -7914.738924\n",
      "a_1 = 10.357989, a_2 = 6.850881, b = 2.316263\n",
      "\tgrad = 2.584101\n",
      "rate = 0.002692\n",
      "Step 501 / 1000, loss = -7914.833360\n",
      "a_1 = 10.363766, a_2 = 6.854880, b = 2.317580\n",
      "\tgrad = 2.660237\n",
      "rate = 0.002687\n",
      "Step 502 / 1000, loss = -7914.934471\n",
      "a_1 = 10.369682, a_2 = 6.859442, b = 2.318983\n",
      "\tgrad = 2.834101\n",
      "rate = 0.002682\n",
      "Step 503 / 1000, loss = -7915.026300\n",
      "a_1 = 10.375454, a_2 = 6.863210, b = 2.320275\n",
      "\tgrad = 2.620003\n",
      "rate = 0.002677\n",
      "Step 504 / 1000, loss = -7915.122621\n",
      "a_1 = 10.381328, a_2 = 6.867404, b = 2.321598\n",
      "\tgrad = 2.746607\n",
      "rate = 0.002672\n",
      "Step 505 / 1000, loss = -7915.220178\n",
      "a_1 = 10.387285, a_2 = 6.871638, b = 2.322955\n",
      "\tgrad = 2.787383\n",
      "rate = 0.002667\n",
      "Step 506 / 1000, loss = -7915.313411\n",
      "a_1 = 10.393068, a_2 = 6.875606, b = 2.324262\n",
      "\tgrad = 2.680455\n",
      "rate = 0.002662\n",
      "Step 507 / 1000, loss = -7915.410464\n",
      "a_1 = 10.399035, a_2 = 6.879844, b = 2.325601\n",
      "\tgrad = 2.800526\n",
      "rate = 0.002657\n",
      "Step 508 / 1000, loss = -7915.500219\n",
      "a_1 = 10.404586, a_2 = 6.883671, b = 2.326887\n",
      "\tgrad = 2.588932\n",
      "rate = 0.002652\n",
      "Step 509 / 1000, loss = -7915.591475\n",
      "a_1 = 10.410088, a_2 = 6.887716, b = 2.328192\n",
      "\tgrad = 2.627074\n",
      "rate = 0.002647\n",
      "Step 510 / 1000, loss = -7915.685533\n",
      "a_1 = 10.415906, a_2 = 6.891787, b = 2.329528\n",
      "\tgrad = 2.735071\n",
      "rate = 0.002642\n",
      "Step 511 / 1000, loss = -7915.776606\n",
      "a_1 = 10.421586, a_2 = 6.895705, b = 2.330823\n",
      "\tgrad = 2.662780\n",
      "rate = 0.002637\n",
      "Step 512 / 1000, loss = -7915.868297\n",
      "a_1 = 10.427341, a_2 = 6.899654, b = 2.332115\n",
      "\tgrad = 2.697529\n",
      "rate = 0.002632\n",
      "Step 513 / 1000, loss = -7915.951745\n",
      "a_1 = 10.432586, a_2 = 6.903201, b = 2.333326\n",
      "\tgrad = 2.454127\n",
      "rate = 0.002627\n",
      "Step 514 / 1000, loss = -7916.045892\n",
      "a_1 = 10.438437, a_2 = 6.907417, b = 2.334613\n",
      "\tgrad = 2.794232\n",
      "rate = 0.002622\n",
      "Step 515 / 1000, loss = -7916.131280\n",
      "a_1 = 10.443619, a_2 = 6.911249, b = 2.335853\n",
      "\tgrad = 2.508121\n",
      "rate = 0.002617\n",
      "Step 516 / 1000, loss = -7916.219213\n",
      "a_1 = 10.449225, a_2 = 6.915012, b = 2.337104\n",
      "\tgrad = 2.629074\n",
      "rate = 0.002612\n",
      "Step 517 / 1000, loss = -7916.309446\n",
      "a_1 = 10.454891, a_2 = 6.918943, b = 2.338405\n",
      "\tgrad = 2.691818\n",
      "rate = 0.002607\n",
      "Step 518 / 1000, loss = -7916.398693\n",
      "a_1 = 10.460344, a_2 = 6.923000, b = 2.339686\n",
      "\tgrad = 2.657671\n",
      "rate = 0.002602\n",
      "Step 519 / 1000, loss = -7916.488875\n",
      "a_1 = 10.465873, a_2 = 6.927102, b = 2.340979\n",
      "\tgrad = 2.696903\n",
      "rate = 0.002597\n",
      "Step 520 / 1000, loss = -7916.576488\n",
      "a_1 = 10.471252, a_2 = 6.931098, b = 2.342236\n",
      "\tgrad = 2.629816\n",
      "rate = 0.002593\n",
      "Step 521 / 1000, loss = -7916.665420\n",
      "a_1 = 10.476927, a_2 = 6.934991, b = 2.343504\n",
      "\tgrad = 2.704262\n",
      "rate = 0.002588\n",
      "Step 522 / 1000, loss = -7916.752622\n",
      "a_1 = 10.482413, a_2 = 6.938889, b = 2.344755\n",
      "\tgrad = 2.649632\n",
      "rate = 0.002583\n",
      "Step 523 / 1000, loss = -7916.847617\n",
      "a_1 = 10.488432, a_2 = 6.943112, b = 2.346119\n",
      "\tgrad = 2.900669\n",
      "rate = 0.002578\n",
      "Step 524 / 1000, loss = -7916.940591\n",
      "a_1 = 10.494077, a_2 = 6.947478, b = 2.347462\n",
      "\tgrad = 2.821765\n",
      "rate = 0.002574\n",
      "Step 525 / 1000, loss = -7917.031361\n",
      "a_1 = 10.500004, a_2 = 6.951348, b = 2.348793\n",
      "\tgrad = 2.803889\n",
      "rate = 0.002569\n",
      "Step 526 / 1000, loss = -7917.120427\n",
      "a_1 = 10.505751, a_2 = 6.955221, b = 2.350103\n",
      "\tgrad = 2.750519\n",
      "rate = 0.002564\n",
      "Step 527 / 1000, loss = -7917.211637\n",
      "a_1 = 10.511723, a_2 = 6.959085, b = 2.351469\n",
      "\tgrad = 2.829923\n",
      "rate = 0.002559\n",
      "Step 528 / 1000, loss = -7917.297300\n",
      "a_1 = 10.517334, a_2 = 6.962759, b = 2.352737\n",
      "\tgrad = 2.671728\n",
      "rate = 0.002555\n",
      "Step 529 / 1000, loss = -7917.386995\n",
      "a_1 = 10.523211, a_2 = 6.966643, b = 2.354052\n",
      "\tgrad = 2.810185\n",
      "rate = 0.002550\n",
      "Step 530 / 1000, loss = -7917.477781\n",
      "a_1 = 10.528983, a_2 = 6.970735, b = 2.355396\n",
      "\tgrad = 2.829439\n",
      "rate = 0.002545\n",
      "Step 531 / 1000, loss = -7917.562909\n",
      "a_1 = 10.534497, a_2 = 6.974502, b = 2.356654\n",
      "\tgrad = 2.674583\n",
      "rate = 0.002541\n",
      "Step 532 / 1000, loss = -7917.649541\n",
      "a_1 = 10.539981, a_2 = 6.978510, b = 2.357912\n",
      "\tgrad = 2.723683\n",
      "rate = 0.002536\n",
      "Step 533 / 1000, loss = -7917.734531\n",
      "a_1 = 10.545424, a_2 = 6.982357, b = 2.359173\n",
      "\tgrad = 2.679306\n",
      "rate = 0.002532\n",
      "Step 534 / 1000, loss = -7917.822618\n",
      "a_1 = 10.551137, a_2 = 6.986403, b = 2.360419\n",
      "\tgrad = 2.813652\n",
      "rate = 0.002527\n",
      "Step 535 / 1000, loss = -7917.911350\n",
      "a_1 = 10.556753, a_2 = 6.990518, b = 2.361735\n",
      "\tgrad = 2.809208\n",
      "rate = 0.002523\n",
      "Step 536 / 1000, loss = -7917.996706\n",
      "a_1 = 10.562369, a_2 = 6.994349, b = 2.362974\n",
      "\tgrad = 2.744223\n",
      "rate = 0.002518\n",
      "Step 537 / 1000, loss = -7918.078508\n",
      "a_1 = 10.567612, a_2 = 6.998092, b = 2.364203\n",
      "\tgrad = 2.609474\n",
      "rate = 0.002513\n",
      "Step 538 / 1000, loss = -7918.163349\n",
      "a_1 = 10.572858, a_2 = 7.002197, b = 2.365463\n",
      "\tgrad = 2.701661\n",
      "rate = 0.002509\n",
      "Step 539 / 1000, loss = -7918.251974\n",
      "a_1 = 10.578727, a_2 = 7.006152, b = 2.366775\n",
      "\tgrad = 2.874067\n",
      "rate = 0.002504\n",
      "Step 540 / 1000, loss = -7918.333831\n",
      "a_1 = 10.584015, a_2 = 7.009931, b = 2.367995\n",
      "\tgrad = 2.645425\n",
      "rate = 0.002500\n",
      "Step 541 / 1000, loss = -7918.420037\n",
      "a_1 = 10.589923, a_2 = 7.013658, b = 2.369258\n",
      "\tgrad = 2.844322\n",
      "rate = 0.002496\n",
      "Step 542 / 1000, loss = -7918.502943\n",
      "a_1 = 10.595401, a_2 = 7.017415, b = 2.370491\n",
      "\tgrad = 2.711999\n",
      "rate = 0.002491\n",
      "Step 543 / 1000, loss = -7918.588773\n",
      "a_1 = 10.601002, a_2 = 7.021337, b = 2.371796\n",
      "\tgrad = 2.799483\n",
      "rate = 0.002487\n",
      "Step 544 / 1000, loss = -7918.668865\n",
      "a_1 = 10.606351, a_2 = 7.024884, b = 2.373025\n",
      "\tgrad = 2.632502\n",
      "rate = 0.002482\n",
      "Step 545 / 1000, loss = -7918.743369\n",
      "a_1 = 10.611033, a_2 = 7.028456, b = 2.374175\n",
      "\tgrad = 2.421649\n",
      "rate = 0.002478\n",
      "Step 546 / 1000, loss = -7918.823587\n",
      "a_1 = 10.616353, a_2 = 7.032091, b = 2.375397\n",
      "\tgrad = 2.651169\n",
      "rate = 0.002473\n",
      "Step 547 / 1000, loss = -7918.898956\n",
      "a_1 = 10.621269, a_2 = 7.035609, b = 2.376537\n",
      "\tgrad = 2.491649\n",
      "rate = 0.002469\n",
      "Step 548 / 1000, loss = -7918.980356\n",
      "a_1 = 10.626442, a_2 = 7.039564, b = 2.377762\n",
      "\tgrad = 2.688118\n",
      "rate = 0.002465\n",
      "Step 549 / 1000, loss = -7919.057243\n",
      "a_1 = 10.631510, a_2 = 7.043154, b = 2.378916\n",
      "\tgrad = 2.567468\n",
      "rate = 0.002460\n",
      "Step 550 / 1000, loss = -7919.137055\n",
      "a_1 = 10.636635, a_2 = 7.046999, b = 2.380127\n",
      "\tgrad = 2.654862\n",
      "rate = 0.002456\n",
      "Step 551 / 1000, loss = -7919.221292\n",
      "a_1 = 10.642286, a_2 = 7.050877, b = 2.381392\n",
      "\tgrad = 2.842236\n",
      "rate = 0.002452\n",
      "Step 552 / 1000, loss = -7919.303558\n",
      "a_1 = 10.647778, a_2 = 7.054679, b = 2.382643\n",
      "\tgrad = 2.776742\n",
      "rate = 0.002448\n",
      "Step 553 / 1000, loss = -7919.386101\n",
      "a_1 = 10.653252, a_2 = 7.058596, b = 2.383870\n",
      "\tgrad = 2.800330\n",
      "rate = 0.002443\n",
      "Step 554 / 1000, loss = -7919.468546\n",
      "a_1 = 10.658788, a_2 = 7.062375, b = 2.385145\n",
      "\tgrad = 2.797572\n",
      "rate = 0.002439\n",
      "Step 555 / 1000, loss = -7919.549013\n",
      "a_1 = 10.664103, a_2 = 7.066169, b = 2.386387\n",
      "\tgrad = 2.729795\n",
      "rate = 0.002435\n",
      "Step 556 / 1000, loss = -7919.631551\n",
      "a_1 = 10.669452, a_2 = 7.070214, b = 2.387636\n",
      "\tgrad = 2.806908\n",
      "rate = 0.002431\n",
      "Step 557 / 1000, loss = -7919.713557\n",
      "a_1 = 10.674922, a_2 = 7.074091, b = 2.388888\n",
      "\tgrad = 2.810821\n",
      "rate = 0.002426\n",
      "Step 558 / 1000, loss = -7919.793195\n",
      "a_1 = 10.680227, a_2 = 7.077888, b = 2.390099\n",
      "\tgrad = 2.739435\n",
      "rate = 0.002422\n",
      "Step 559 / 1000, loss = -7919.872925\n",
      "a_1 = 10.685681, a_2 = 7.081526, b = 2.391340\n",
      "\tgrad = 2.759455\n",
      "rate = 0.002418\n",
      "Step 560 / 1000, loss = -7919.951107\n",
      "a_1 = 10.691018, a_2 = 7.085103, b = 2.392566\n",
      "\tgrad = 2.709661\n",
      "rate = 0.002414\n",
      "Step 561 / 1000, loss = -7920.030588\n",
      "a_1 = 10.696374, a_2 = 7.088923, b = 2.393754\n",
      "\tgrad = 2.774512\n",
      "rate = 0.002410\n",
      "Step 562 / 1000, loss = -7920.105530\n",
      "a_1 = 10.701324, a_2 = 7.092599, b = 2.394894\n",
      "\tgrad = 2.606313\n",
      "rate = 0.002405\n",
      "Step 563 / 1000, loss = -7920.180159\n",
      "a_1 = 10.706281, a_2 = 7.096196, b = 2.396059\n",
      "\tgrad = 2.596534\n",
      "rate = 0.002401\n",
      "Step 564 / 1000, loss = -7920.257640\n",
      "a_1 = 10.711484, a_2 = 7.099885, b = 2.397274\n",
      "\tgrad = 2.708373\n",
      "rate = 0.002397\n",
      "Step 565 / 1000, loss = -7920.333913\n",
      "a_1 = 10.716568, a_2 = 7.103559, b = 2.398475\n",
      "\tgrad = 2.668635\n",
      "rate = 0.002393\n",
      "Step 566 / 1000, loss = -7920.408375\n",
      "a_1 = 10.721572, a_2 = 7.107161, b = 2.399627\n",
      "\tgrad = 2.625370\n",
      "rate = 0.002389\n",
      "Step 567 / 1000, loss = -7920.482647\n",
      "a_1 = 10.726538, a_2 = 7.110778, b = 2.400784\n",
      "\tgrad = 2.621112\n",
      "rate = 0.002385\n",
      "Step 568 / 1000, loss = -7920.558623\n",
      "a_1 = 10.731658, a_2 = 7.114431, b = 2.401981\n",
      "\tgrad = 2.689233\n",
      "rate = 0.002381\n",
      "Step 569 / 1000, loss = -7920.631501\n",
      "a_1 = 10.736543, a_2 = 7.118014, b = 2.403108\n",
      "\tgrad = 2.592361\n",
      "rate = 0.002377\n",
      "Step 570 / 1000, loss = -7920.704496\n",
      "a_1 = 10.741536, a_2 = 7.121507, b = 2.404247\n",
      "\tgrad = 2.612351\n",
      "rate = 0.002373\n",
      "Step 571 / 1000, loss = -7920.780612\n",
      "a_1 = 10.746556, a_2 = 7.125375, b = 2.405412\n",
      "\tgrad = 2.720396\n",
      "rate = 0.002369\n",
      "Step 572 / 1000, loss = -7920.855088\n",
      "a_1 = 10.751581, a_2 = 7.128977, b = 2.406606\n",
      "\tgrad = 2.662577\n",
      "rate = 0.002365\n",
      "Step 573 / 1000, loss = -7920.934682\n",
      "a_1 = 10.757074, a_2 = 7.132779, b = 2.407855\n",
      "\tgrad = 2.878522\n",
      "rate = 0.002361\n",
      "Step 574 / 1000, loss = -7921.009559\n",
      "a_1 = 10.762179, a_2 = 7.136443, b = 2.409022\n",
      "\tgrad = 2.711821\n",
      "rate = 0.002357\n",
      "Step 575 / 1000, loss = -7921.085228\n",
      "a_1 = 10.767452, a_2 = 7.140058, b = 2.410201\n",
      "\tgrad = 2.762851\n",
      "rate = 0.002353\n",
      "Step 576 / 1000, loss = -7921.158069\n",
      "a_1 = 10.772393, a_2 = 7.143594, b = 2.411382\n",
      "\tgrad = 2.635048\n",
      "rate = 0.002349\n",
      "Step 577 / 1000, loss = -7921.230179\n",
      "a_1 = 10.777349, a_2 = 7.147066, b = 2.412543\n",
      "\tgrad = 2.627379\n",
      "rate = 0.002345\n",
      "Step 578 / 1000, loss = -7921.303883\n",
      "a_1 = 10.782545, a_2 = 7.150541, b = 2.413711\n",
      "\tgrad = 2.716342\n",
      "rate = 0.002341\n",
      "Step 579 / 1000, loss = -7921.377376\n",
      "a_1 = 10.787418, a_2 = 7.154308, b = 2.414875\n",
      "\tgrad = 2.681846\n",
      "rate = 0.002337\n",
      "Step 580 / 1000, loss = -7921.449819\n",
      "a_1 = 10.792435, a_2 = 7.157817, b = 2.416035\n",
      "\tgrad = 2.670539\n",
      "rate = 0.002333\n",
      "Step 581 / 1000, loss = -7921.523390\n",
      "a_1 = 10.797571, a_2 = 7.161386, b = 2.417197\n",
      "\tgrad = 2.730706\n",
      "rate = 0.002329\n",
      "Step 582 / 1000, loss = -7921.594797\n",
      "a_1 = 10.802516, a_2 = 7.164905, b = 2.418323\n",
      "\tgrad = 2.654449\n",
      "rate = 0.002326\n",
      "Step 583 / 1000, loss = -7921.666942\n",
      "a_1 = 10.807681, a_2 = 7.168286, b = 2.419479\n",
      "\tgrad = 2.705079\n",
      "rate = 0.002322\n",
      "Step 584 / 1000, loss = -7921.740323\n",
      "a_1 = 10.812899, a_2 = 7.171753, b = 2.420666\n",
      "\tgrad = 2.751154\n",
      "rate = 0.002318\n",
      "Step 585 / 1000, loss = -7921.816900\n",
      "a_1 = 10.818051, a_2 = 7.175689, b = 2.421888\n",
      "\tgrad = 2.850991\n",
      "rate = 0.002314\n",
      "Step 586 / 1000, loss = -7921.884984\n",
      "a_1 = 10.822974, a_2 = 7.178858, b = 2.422990\n",
      "\tgrad = 2.578855\n",
      "rate = 0.002310\n",
      "Step 587 / 1000, loss = -7921.951973\n",
      "a_1 = 10.827576, a_2 = 7.182222, b = 2.424069\n",
      "\tgrad = 2.515163\n",
      "rate = 0.002306\n",
      "Step 588 / 1000, loss = -7922.025044\n",
      "a_1 = 10.832675, a_2 = 7.185858, b = 2.425232\n",
      "\tgrad = 2.766341\n",
      "rate = 0.002303\n",
      "Step 589 / 1000, loss = -7922.097726\n",
      "a_1 = 10.837922, a_2 = 7.189328, b = 2.426388\n",
      "\tgrad = 2.782494\n",
      "rate = 0.002299\n",
      "Step 590 / 1000, loss = -7922.170414\n",
      "a_1 = 10.843228, a_2 = 7.192785, b = 2.427531\n",
      "\tgrad = 2.803625\n",
      "rate = 0.002295\n",
      "Step 591 / 1000, loss = -7922.240810\n",
      "a_1 = 10.848302, a_2 = 7.196158, b = 2.428665\n",
      "\tgrad = 2.704721\n",
      "rate = 0.002291\n",
      "Step 592 / 1000, loss = -7922.310857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 10.853345, a_2 = 7.199523, b = 2.429800\n",
      "\tgrad = 2.696206\n",
      "rate = 0.002288\n",
      "Step 593 / 1000, loss = -7922.378986\n",
      "a_1 = 10.858031, a_2 = 7.203004, b = 2.430908\n",
      "\tgrad = 2.601695\n",
      "rate = 0.002284\n",
      "Step 594 / 1000, loss = -7922.450960\n",
      "a_1 = 10.863018, a_2 = 7.206697, b = 2.432059\n",
      "\tgrad = 2.767805\n",
      "rate = 0.002280\n",
      "Step 595 / 1000, loss = -7922.520170\n",
      "a_1 = 10.867761, a_2 = 7.210254, b = 2.433197\n",
      "\tgrad = 2.652162\n",
      "rate = 0.002276\n",
      "Step 596 / 1000, loss = -7922.590510\n",
      "a_1 = 10.872667, a_2 = 7.213850, b = 2.434329\n",
      "\tgrad = 2.722285\n",
      "rate = 0.002273\n",
      "Step 597 / 1000, loss = -7922.658601\n",
      "a_1 = 10.877521, a_2 = 7.217251, b = 2.435423\n",
      "\tgrad = 2.656281\n",
      "rate = 0.002269\n",
      "Step 598 / 1000, loss = -7922.732624\n",
      "a_1 = 10.882897, a_2 = 7.220912, b = 2.436589\n",
      "\tgrad = 2.917066\n",
      "rate = 0.002265\n",
      "Step 599 / 1000, loss = -7922.798904\n",
      "a_1 = 10.887496, a_2 = 7.224337, b = 2.437670\n",
      "\tgrad = 2.580020\n",
      "rate = 0.002262\n",
      "Step 600 / 1000, loss = -7922.863769\n",
      "a_1 = 10.892041, a_2 = 7.227635, b = 2.438743\n",
      "\tgrad = 2.531595\n",
      "rate = 0.002258\n",
      "Step 601 / 1000, loss = -7922.935188\n",
      "a_1 = 10.896972, a_2 = 7.231363, b = 2.439915\n",
      "\tgrad = 2.790864\n",
      "rate = 0.002254\n",
      "Step 602 / 1000, loss = -7923.001442\n",
      "a_1 = 10.901858, a_2 = 7.234592, b = 2.440978\n",
      "\tgrad = 2.644545\n",
      "rate = 0.002251\n",
      "Step 603 / 1000, loss = -7923.066888\n",
      "a_1 = 10.906460, a_2 = 7.237901, b = 2.442083\n",
      "\tgrad = 2.569723\n",
      "rate = 0.002247\n",
      "Step 604 / 1000, loss = -7923.140034\n",
      "a_1 = 10.911698, a_2 = 7.241614, b = 2.443270\n",
      "\tgrad = 2.910414\n",
      "rate = 0.002244\n",
      "Step 605 / 1000, loss = -7923.206929\n",
      "a_1 = 10.916387, a_2 = 7.245108, b = 2.444361\n",
      "\tgrad = 2.655535\n",
      "rate = 0.002240\n",
      "Step 606 / 1000, loss = -7923.272082\n",
      "a_1 = 10.921033, a_2 = 7.248447, b = 2.445426\n",
      "\tgrad = 2.602049\n",
      "rate = 0.002236\n",
      "Step 607 / 1000, loss = -7923.339812\n",
      "a_1 = 10.925914, a_2 = 7.251850, b = 2.446551\n",
      "\tgrad = 2.712100\n",
      "rate = 0.002233\n",
      "Step 608 / 1000, loss = -7923.404474\n",
      "a_1 = 10.930549, a_2 = 7.255150, b = 2.447617\n",
      "\tgrad = 2.596826\n",
      "rate = 0.002229\n",
      "Step 609 / 1000, loss = -7923.467915\n",
      "a_1 = 10.935196, a_2 = 7.258315, b = 2.448658\n",
      "\tgrad = 2.569096\n",
      "rate = 0.002226\n",
      "Step 610 / 1000, loss = -7923.537357\n",
      "a_1 = 10.940403, a_2 = 7.261714, b = 2.449780\n",
      "\tgrad = 2.843478\n",
      "rate = 0.002222\n",
      "Step 611 / 1000, loss = -7923.600921\n",
      "a_1 = 10.944940, a_2 = 7.264938, b = 2.450870\n",
      "\tgrad = 2.556216\n",
      "rate = 0.002219\n",
      "Step 612 / 1000, loss = -7923.665423\n",
      "a_1 = 10.949733, a_2 = 7.268160, b = 2.451913\n",
      "\tgrad = 2.649062\n",
      "rate = 0.002215\n",
      "Step 613 / 1000, loss = -7923.727277\n",
      "a_1 = 10.954127, a_2 = 7.271345, b = 2.452970\n",
      "\tgrad = 2.499974\n",
      "rate = 0.002212\n",
      "Step 614 / 1000, loss = -7923.795487\n",
      "a_1 = 10.959174, a_2 = 7.274788, b = 2.454079\n",
      "\tgrad = 2.811973\n",
      "rate = 0.002208\n",
      "Step 615 / 1000, loss = -7923.858904\n",
      "a_1 = 10.963633, a_2 = 7.278145, b = 2.455150\n",
      "\tgrad = 2.577409\n",
      "rate = 0.002205\n",
      "Step 616 / 1000, loss = -7923.924305\n",
      "a_1 = 10.968448, a_2 = 7.281449, b = 2.456238\n",
      "\tgrad = 2.698699\n",
      "rate = 0.002201\n",
      "Step 617 / 1000, loss = -7923.992604\n",
      "a_1 = 10.973540, a_2 = 7.284822, b = 2.457392\n",
      "\tgrad = 2.828270\n",
      "rate = 0.002198\n",
      "Step 618 / 1000, loss = -7924.056490\n",
      "a_1 = 10.978358, a_2 = 7.288018, b = 2.458427\n",
      "\tgrad = 2.676576\n",
      "rate = 0.002194\n",
      "Step 619 / 1000, loss = -7924.121821\n",
      "a_1 = 10.983335, a_2 = 7.291171, b = 2.459531\n",
      "\tgrad = 2.736042\n",
      "rate = 0.002191\n",
      "Step 620 / 1000, loss = -7924.185445\n",
      "a_1 = 10.987912, a_2 = 7.294506, b = 2.460605\n",
      "\tgrad = 2.635060\n",
      "rate = 0.002188\n",
      "Step 621 / 1000, loss = -7924.245399\n",
      "a_1 = 10.992155, a_2 = 7.297731, b = 2.461615\n",
      "\tgrad = 2.483282\n",
      "rate = 0.002184\n",
      "Step 622 / 1000, loss = -7924.313061\n",
      "a_1 = 10.997211, a_2 = 7.301144, b = 2.462748\n",
      "\tgrad = 2.845225\n",
      "rate = 0.002181\n",
      "Step 623 / 1000, loss = -7924.378338\n",
      "a_1 = 11.002028, a_2 = 7.304535, b = 2.463826\n",
      "\tgrad = 2.750665\n",
      "rate = 0.002177\n",
      "Step 624 / 1000, loss = -7924.444252\n",
      "a_1 = 11.006910, a_2 = 7.307974, b = 2.464904\n",
      "\tgrad = 2.791612\n",
      "rate = 0.002174\n",
      "Step 625 / 1000, loss = -7924.504332\n",
      "a_1 = 11.011375, a_2 = 7.310977, b = 2.465959\n",
      "\tgrad = 2.525778\n",
      "rate = 0.002171\n",
      "Step 626 / 1000, loss = -7924.569424\n",
      "a_1 = 11.016027, a_2 = 7.314484, b = 2.467062\n",
      "\tgrad = 2.736475\n",
      "rate = 0.002167\n",
      "Step 627 / 1000, loss = -7924.629920\n",
      "a_1 = 11.020531, a_2 = 7.317596, b = 2.468084\n",
      "\tgrad = 2.573728\n",
      "rate = 0.002164\n",
      "Step 628 / 1000, loss = -7924.692132\n",
      "a_1 = 11.025198, a_2 = 7.320788, b = 2.469127\n",
      "\tgrad = 2.661224\n",
      "rate = 0.002160\n",
      "Step 629 / 1000, loss = -7924.752459\n",
      "a_1 = 11.029676, a_2 = 7.323861, b = 2.470182\n",
      "\tgrad = 2.564442\n",
      "rate = 0.002157\n",
      "Step 630 / 1000, loss = -7924.816788\n",
      "a_1 = 11.034504, a_2 = 7.327235, b = 2.471233\n",
      "\tgrad = 2.777931\n",
      "rate = 0.002154\n",
      "Step 631 / 1000, loss = -7924.884215\n",
      "a_1 = 11.039443, a_2 = 7.330828, b = 2.472373\n",
      "\tgrad = 2.889024\n",
      "rate = 0.002151\n",
      "Step 632 / 1000, loss = -7924.942950\n",
      "a_1 = 11.043775, a_2 = 7.333892, b = 2.473393\n",
      "\tgrad = 2.516403\n",
      "rate = 0.002147\n",
      "Step 633 / 1000, loss = -7925.004091\n",
      "a_1 = 11.048327, a_2 = 7.337083, b = 2.474439\n",
      "\tgrad = 2.638114\n",
      "rate = 0.002144\n",
      "Step 634 / 1000, loss = -7925.065982\n",
      "a_1 = 11.053137, a_2 = 7.340154, b = 2.475488\n",
      "\tgrad = 2.710902\n",
      "rate = 0.002141\n",
      "Step 635 / 1000, loss = -7925.123425\n",
      "a_1 = 11.057425, a_2 = 7.343146, b = 2.476480\n",
      "\tgrad = 2.489841\n",
      "rate = 0.002137\n",
      "Step 636 / 1000, loss = -7925.184770\n",
      "a_1 = 11.062057, a_2 = 7.346293, b = 2.477545\n",
      "\tgrad = 2.670861\n",
      "rate = 0.002134\n",
      "Step 637 / 1000, loss = -7925.250032\n",
      "a_1 = 11.066880, a_2 = 7.349781, b = 2.478661\n",
      "\tgrad = 2.841801\n",
      "rate = 0.002131\n",
      "Step 638 / 1000, loss = -7925.310025\n",
      "a_1 = 11.071394, a_2 = 7.352889, b = 2.479706\n",
      "\tgrad = 2.622702\n",
      "rate = 0.002128\n",
      "Step 639 / 1000, loss = -7925.373065\n",
      "a_1 = 11.076150, a_2 = 7.356214, b = 2.480772\n",
      "\tgrad = 2.777342\n",
      "rate = 0.002124\n",
      "Step 640 / 1000, loss = -7925.432325\n",
      "a_1 = 11.080478, a_2 = 7.359436, b = 2.481801\n",
      "\tgrad = 2.589164\n",
      "rate = 0.002121\n",
      "Step 641 / 1000, loss = -7925.496550\n",
      "a_1 = 11.085346, a_2 = 7.362811, b = 2.482896\n",
      "\tgrad = 2.844277\n",
      "rate = 0.002118\n",
      "Step 642 / 1000, loss = -7925.556155\n",
      "a_1 = 11.089808, a_2 = 7.365994, b = 2.483920\n",
      "\tgrad = 2.636318\n",
      "rate = 0.002115\n",
      "Step 643 / 1000, loss = -7925.614372\n",
      "a_1 = 11.094136, a_2 = 7.369123, b = 2.484929\n",
      "\tgrad = 2.574040\n",
      "rate = 0.002112\n",
      "Step 644 / 1000, loss = -7925.674433\n",
      "a_1 = 11.098699, a_2 = 7.372314, b = 2.485947\n",
      "\tgrad = 2.684591\n",
      "rate = 0.002108\n",
      "Step 645 / 1000, loss = -7925.738902\n",
      "a_1 = 11.103569, a_2 = 7.375728, b = 2.487067\n",
      "\tgrad = 2.874726\n",
      "rate = 0.002105\n",
      "Step 646 / 1000, loss = -7925.798631\n",
      "a_1 = 11.108099, a_2 = 7.378881, b = 2.488108\n",
      "\tgrad = 2.671685\n",
      "rate = 0.002102\n",
      "Step 647 / 1000, loss = -7925.854896\n",
      "a_1 = 11.112294, a_2 = 7.381907, b = 2.489099\n",
      "\tgrad = 2.509560\n",
      "rate = 0.002099\n",
      "Step 648 / 1000, loss = -7925.914643\n",
      "a_1 = 11.116747, a_2 = 7.385112, b = 2.490163\n",
      "\tgrad = 2.666292\n",
      "rate = 0.002096\n",
      "Step 649 / 1000, loss = -7925.975502\n",
      "a_1 = 11.121502, a_2 = 7.388246, b = 2.491214\n",
      "\tgrad = 2.767461\n",
      "rate = 0.002093\n",
      "Step 650 / 1000, loss = -7926.038613\n",
      "a_1 = 11.126276, a_2 = 7.391641, b = 2.492311\n",
      "\tgrad = 2.851899\n",
      "rate = 0.002090\n",
      "Step 651 / 1000, loss = -7926.098015\n",
      "a_1 = 11.130742, a_2 = 7.394848, b = 2.493356\n",
      "\tgrad = 2.682801\n",
      "rate = 0.002086\n",
      "Step 652 / 1000, loss = -7926.155621\n",
      "a_1 = 11.135081, a_2 = 7.397976, b = 2.494362\n",
      "\tgrad = 2.612432\n",
      "rate = 0.002083\n",
      "Step 653 / 1000, loss = -7926.216440\n",
      "a_1 = 11.139651, a_2 = 7.401372, b = 2.495386\n",
      "\tgrad = 2.780717\n",
      "rate = 0.002080\n",
      "Step 654 / 1000, loss = -7926.276288\n",
      "a_1 = 11.144317, a_2 = 7.404532, b = 2.496412\n",
      "\tgrad = 2.758024\n",
      "rate = 0.002077\n",
      "Step 655 / 1000, loss = -7926.336051\n",
      "a_1 = 11.148975, a_2 = 7.407652, b = 2.497464\n",
      "\tgrad = 2.750027\n",
      "rate = 0.002074\n",
      "Step 656 / 1000, loss = -7926.392963\n",
      "a_1 = 11.153418, a_2 = 7.410629, b = 2.498464\n",
      "\tgrad = 2.627187\n",
      "rate = 0.002071\n",
      "Step 657 / 1000, loss = -7926.451532\n",
      "a_1 = 11.158029, a_2 = 7.413716, b = 2.499467\n",
      "\tgrad = 2.726720\n",
      "rate = 0.002068\n",
      "Step 658 / 1000, loss = -7926.509678\n",
      "a_1 = 11.162515, a_2 = 7.416835, b = 2.500485\n",
      "\tgrad = 2.691618\n",
      "rate = 0.002065\n",
      "Step 659 / 1000, loss = -7926.568187\n",
      "a_1 = 11.167011, a_2 = 7.420000, b = 2.501509\n",
      "\tgrad = 2.712779\n",
      "rate = 0.002062\n",
      "Step 660 / 1000, loss = -7926.626449\n",
      "a_1 = 11.171532, a_2 = 7.423125, b = 2.502529\n",
      "\tgrad = 2.714776\n",
      "rate = 0.002059\n",
      "Step 661 / 1000, loss = -7926.683698\n",
      "a_1 = 11.175851, a_2 = 7.426275, b = 2.503554\n",
      "\tgrad = 2.647766\n",
      "rate = 0.002056\n",
      "Step 662 / 1000, loss = -7926.738857\n",
      "a_1 = 11.180103, a_2 = 7.429265, b = 2.504527\n",
      "\tgrad = 2.575852\n",
      "rate = 0.002053\n",
      "Step 663 / 1000, loss = -7926.796828\n",
      "a_1 = 11.184655, a_2 = 7.432331, b = 2.505554\n",
      "\tgrad = 2.724237\n",
      "rate = 0.002050\n",
      "Step 664 / 1000, loss = -7926.849428\n",
      "a_1 = 11.188739, a_2 = 7.435140, b = 2.506500\n",
      "\tgrad = 2.465447\n",
      "rate = 0.002047\n",
      "Step 665 / 1000, loss = -7926.904601\n",
      "a_1 = 11.193103, a_2 = 7.438088, b = 2.507456\n",
      "\tgrad = 2.618741\n",
      "rate = 0.002044\n",
      "Step 666 / 1000, loss = -7926.963177\n",
      "a_1 = 11.197599, a_2 = 7.441330, b = 2.508485\n",
      "\tgrad = 2.762633\n",
      "rate = 0.002041\n",
      "Step 667 / 1000, loss = -7927.018693\n",
      "a_1 = 11.201846, a_2 = 7.444417, b = 2.509465\n",
      "\tgrad = 2.620720\n",
      "rate = 0.002038\n",
      "Step 668 / 1000, loss = -7927.078118\n",
      "a_1 = 11.206468, a_2 = 7.447659, b = 2.510515\n",
      "\tgrad = 2.822282\n",
      "rate = 0.002035\n",
      "Step 669 / 1000, loss = -7927.134936\n",
      "a_1 = 11.211098, a_2 = 7.450557, b = 2.511529\n",
      "\tgrad = 2.733918\n",
      "rate = 0.002032\n",
      "Step 670 / 1000, loss = -7927.193350\n",
      "a_1 = 11.215745, a_2 = 7.453680, b = 2.512556\n",
      "\tgrad = 2.805573\n",
      "rate = 0.002029\n",
      "Step 671 / 1000, loss = -7927.252575\n",
      "a_1 = 11.220280, a_2 = 7.457051, b = 2.513581\n",
      "\tgrad = 2.834416\n",
      "rate = 0.002026\n",
      "Step 672 / 1000, loss = -7927.306767\n",
      "a_1 = 11.224670, a_2 = 7.459869, b = 2.514548\n",
      "\tgrad = 2.622341\n",
      "rate = 0.002023\n",
      "Step 673 / 1000, loss = -7927.366317\n",
      "a_1 = 11.229418, a_2 = 7.463042, b = 2.515613\n",
      "\tgrad = 2.875794\n",
      "rate = 0.002020\n",
      "Step 674 / 1000, loss = -7927.422468\n",
      "a_1 = 11.233782, a_2 = 7.466145, b = 2.516619\n",
      "\tgrad = 2.700806\n",
      "rate = 0.002017\n",
      "Step 675 / 1000, loss = -7927.478189\n",
      "a_1 = 11.238232, a_2 = 7.469131, b = 2.517614\n",
      "\tgrad = 2.705581\n",
      "rate = 0.002014\n",
      "Step 676 / 1000, loss = -7927.535182\n",
      "a_1 = 11.242761, a_2 = 7.472193, b = 2.518644\n",
      "\tgrad = 2.765846\n",
      "rate = 0.002011\n",
      "Step 677 / 1000, loss = -7927.590990\n",
      "a_1 = 11.247180, a_2 = 7.475202, b = 2.519661\n",
      "\tgrad = 2.709347\n",
      "rate = 0.002009\n",
      "Step 678 / 1000, loss = -7927.644014\n",
      "a_1 = 11.251295, a_2 = 7.478082, b = 2.520661\n",
      "\tgrad = 2.553315\n",
      "rate = 0.002006\n",
      "Step 679 / 1000, loss = -7927.698910\n",
      "a_1 = 11.255668, a_2 = 7.481067, b = 2.521645\n",
      "\tgrad = 2.688762\n",
      "rate = 0.002003\n",
      "Step 680 / 1000, loss = -7927.752446\n",
      "a_1 = 11.260025, a_2 = 7.483863, b = 2.522625\n",
      "\tgrad = 2.634329\n",
      "rate = 0.002000\n",
      "Step 681 / 1000, loss = -7927.809465\n",
      "a_1 = 11.264526, a_2 = 7.487042, b = 2.523635\n",
      "\tgrad = 2.805215\n",
      "rate = 0.001997\n",
      "Step 682 / 1000, loss = -7927.863314\n",
      "a_1 = 11.268764, a_2 = 7.490045, b = 2.524601\n",
      "\tgrad = 2.649197\n",
      "rate = 0.001994\n",
      "Step 683 / 1000, loss = -7927.919976\n",
      "a_1 = 11.273279, a_2 = 7.493135, b = 2.525632\n",
      "\tgrad = 2.795538\n",
      "rate = 0.001991\n",
      "Step 684 / 1000, loss = -7927.975884\n",
      "a_1 = 11.277515, a_2 = 7.496414, b = 2.526640\n",
      "\tgrad = 2.741092\n",
      "rate = 0.001989\n",
      "Step 685 / 1000, loss = -7928.031176\n",
      "a_1 = 11.281881, a_2 = 7.499533, b = 2.527621\n",
      "\tgrad = 2.746944\n",
      "rate = 0.001986\n",
      "Step 686 / 1000, loss = -7928.085439\n",
      "a_1 = 11.286176, a_2 = 7.502596, b = 2.528583\n",
      "\tgrad = 2.704265\n",
      "rate = 0.001983\n",
      "Step 687 / 1000, loss = -7928.141622\n",
      "a_1 = 11.290500, a_2 = 7.505859, b = 2.529597\n",
      "\tgrad = 2.782733\n",
      "rate = 0.001980\n",
      "Step 688 / 1000, loss = -7928.195348\n",
      "a_1 = 11.294687, a_2 = 7.508960, b = 2.530556\n",
      "\tgrad = 2.679023\n",
      "rate = 0.001977\n",
      "Step 689 / 1000, loss = -7928.248817\n",
      "a_1 = 11.299110, a_2 = 7.511748, b = 2.531547\n",
      "\tgrad = 2.695364\n",
      "rate = 0.001975\n",
      "Step 690 / 1000, loss = -7928.303609\n",
      "a_1 = 11.303487, a_2 = 7.514816, b = 2.532533\n",
      "\tgrad = 2.756254\n",
      "rate = 0.001972\n",
      "Step 691 / 1000, loss = -7928.357279\n",
      "a_1 = 11.307764, a_2 = 7.517794, b = 2.533524\n",
      "\tgrad = 2.694020\n",
      "rate = 0.001969\n",
      "Step 692 / 1000, loss = -7928.407946\n",
      "a_1 = 11.311627, a_2 = 7.520766, b = 2.534464\n",
      "\tgrad = 2.524515\n",
      "rate = 0.001966\n",
      "Step 693 / 1000, loss = -7928.460393\n",
      "a_1 = 11.315847, a_2 = 7.523671, b = 2.535424\n",
      "\tgrad = 2.654436\n",
      "rate = 0.001964\n",
      "Step 694 / 1000, loss = -7928.517015\n",
      "a_1 = 11.320425, a_2 = 7.526824, b = 2.536445\n",
      "\tgrad = 2.882566\n",
      "rate = 0.001961\n",
      "Step 695 / 1000, loss = -7928.572976\n",
      "a_1 = 11.324926, a_2 = 7.529927, b = 2.537479\n",
      "\tgrad = 2.841670\n",
      "rate = 0.001958\n",
      "Step 696 / 1000, loss = -7928.623487\n",
      "a_1 = 11.328972, a_2 = 7.532775, b = 2.538400\n",
      "\tgrad = 2.574140\n",
      "rate = 0.001955\n",
      "Step 697 / 1000, loss = -7928.675748\n",
      "a_1 = 11.332983, a_2 = 7.535868, b = 2.539367\n",
      "\tgrad = 2.640612\n",
      "rate = 0.001953\n",
      "Step 698 / 1000, loss = -7928.724927\n",
      "a_1 = 11.336846, a_2 = 7.538661, b = 2.540299\n",
      "\tgrad = 2.491433\n",
      "rate = 0.001950\n",
      "Step 699 / 1000, loss = -7928.777625\n",
      "a_1 = 11.341058, a_2 = 7.541608, b = 2.541292\n",
      "\tgrad = 2.688551\n",
      "rate = 0.001947\n",
      "Step 700 / 1000, loss = -7928.827116\n",
      "a_1 = 11.344970, a_2 = 7.544437, b = 2.542217\n",
      "\tgrad = 2.528077\n",
      "rate = 0.001944\n",
      "Step 701 / 1000, loss = -7928.880184\n",
      "a_1 = 11.349257, a_2 = 7.547431, b = 2.543190\n",
      "\tgrad = 2.739145\n",
      "rate = 0.001942\n",
      "Step 702 / 1000, loss = -7928.932319\n",
      "a_1 = 11.353338, a_2 = 7.550440, b = 2.544179\n",
      "\tgrad = 2.663968\n",
      "rate = 0.001939\n",
      "Step 703 / 1000, loss = -7928.985457\n",
      "a_1 = 11.357779, a_2 = 7.553300, b = 2.545163\n",
      "\tgrad = 2.775053\n",
      "rate = 0.001936\n",
      "Step 704 / 1000, loss = -7929.037734\n",
      "a_1 = 11.362083, a_2 = 7.556214, b = 2.546114\n",
      "\tgrad = 2.732804\n",
      "rate = 0.001934\n",
      "Step 705 / 1000, loss = -7929.088484\n",
      "a_1 = 11.366168, a_2 = 7.559097, b = 2.547060\n",
      "\tgrad = 2.634773\n",
      "rate = 0.001931\n",
      "Step 706 / 1000, loss = -7929.140127\n",
      "a_1 = 11.370400, a_2 = 7.562003, b = 2.548005\n",
      "\tgrad = 2.706703\n",
      "rate = 0.001928\n",
      "Step 707 / 1000, loss = -7929.191225\n",
      "a_1 = 11.374623, a_2 = 7.564829, b = 2.548952\n",
      "\tgrad = 2.684538\n",
      "rate = 0.001926\n",
      "Step 708 / 1000, loss = -7929.244696\n",
      "a_1 = 11.378994, a_2 = 7.567836, b = 2.549947\n",
      "\tgrad = 2.806804\n",
      "rate = 0.001923\n",
      "Step 709 / 1000, loss = -7929.298290\n",
      "a_1 = 11.383314, a_2 = 7.570973, b = 2.550913\n",
      "\tgrad = 2.825310\n",
      "rate = 0.001920\n",
      "Step 710 / 1000, loss = -7929.351722\n",
      "a_1 = 11.387589, a_2 = 7.574080, b = 2.551908\n",
      "\tgrad = 2.803815\n",
      "rate = 0.001918\n",
      "Step 711 / 1000, loss = -7929.403795\n",
      "a_1 = 11.391784, a_2 = 7.577070, b = 2.552889\n",
      "\tgrad = 2.738146\n",
      "rate = 0.001915\n",
      "Step 712 / 1000, loss = -7929.455462\n",
      "a_1 = 11.395920, a_2 = 7.580083, b = 2.553854\n",
      "\tgrad = 2.722726\n",
      "rate = 0.001913\n",
      "Step 713 / 1000, loss = -7929.503791\n",
      "a_1 = 11.399923, a_2 = 7.582771, b = 2.554765\n",
      "\tgrad = 2.569203\n",
      "rate = 0.001910\n",
      "Step 714 / 1000, loss = -7929.555925\n",
      "a_1 = 11.404187, a_2 = 7.585748, b = 2.555738\n",
      "\tgrad = 2.773903\n",
      "rate = 0.001907\n",
      "Step 715 / 1000, loss = -7929.606439\n",
      "a_1 = 11.408317, a_2 = 7.588654, b = 2.556675\n",
      "\tgrad = 2.696121\n",
      "rate = 0.001905\n",
      "Step 716 / 1000, loss = -7929.657395\n",
      "a_1 = 11.412486, a_2 = 7.591568, b = 2.557632\n",
      "\tgrad = 2.721257\n",
      "rate = 0.001902\n",
      "Step 717 / 1000, loss = -7929.705666\n",
      "a_1 = 11.416470, a_2 = 7.594270, b = 2.558557\n",
      "\tgrad = 2.580436\n",
      "rate = 0.001900\n",
      "Step 718 / 1000, loss = -7929.758304\n",
      "a_1 = 11.420899, a_2 = 7.597217, b = 2.559528\n",
      "\tgrad = 2.850926\n",
      "rate = 0.001897\n",
      "Step 719 / 1000, loss = -7929.808270\n",
      "a_1 = 11.424962, a_2 = 7.600139, b = 2.560459\n",
      "\tgrad = 2.686878\n",
      "rate = 0.001894\n",
      "Step 720 / 1000, loss = -7929.860387\n",
      "a_1 = 11.429357, a_2 = 7.603061, b = 2.561424\n",
      "\tgrad = 2.835619\n",
      "rate = 0.001892\n",
      "Step 721 / 1000, loss = -7929.913248\n",
      "a_1 = 11.433636, a_2 = 7.606195, b = 2.562404\n",
      "\tgrad = 2.854863\n",
      "rate = 0.001889\n",
      "Step 722 / 1000, loss = -7929.962151\n",
      "a_1 = 11.437921, a_2 = 7.608786, b = 2.563319\n",
      "\tgrad = 2.697775\n",
      "rate = 0.001887\n",
      "Step 723 / 1000, loss = -7930.012550\n",
      "a_1 = 11.441987, a_2 = 7.611786, b = 2.564263\n",
      "\tgrad = 2.728264\n",
      "rate = 0.001884\n",
      "Step 724 / 1000, loss = -7930.060132\n",
      "a_1 = 11.445961, a_2 = 7.614522, b = 2.565144\n",
      "\tgrad = 2.606339\n",
      "rate = 0.001882\n",
      "Step 725 / 1000, loss = -7930.110582\n",
      "a_1 = 11.450134, a_2 = 7.617397, b = 2.566115\n",
      "\tgrad = 2.745654\n",
      "rate = 0.001879\n",
      "Step 726 / 1000, loss = -7930.161634\n",
      "a_1 = 11.454434, a_2 = 7.620264, b = 2.567087\n",
      "\tgrad = 2.802310\n",
      "rate = 0.001877\n",
      "Step 727 / 1000, loss = -7930.208763\n",
      "a_1 = 11.458357, a_2 = 7.622986, b = 2.567972\n",
      "\tgrad = 2.591128\n",
      "rate = 0.001874\n",
      "Step 728 / 1000, loss = -7930.256532\n",
      "a_1 = 11.462310, a_2 = 7.625732, b = 2.568891\n",
      "\tgrad = 2.618023\n",
      "rate = 0.001872\n",
      "Step 729 / 1000, loss = -7930.304241\n",
      "a_1 = 11.466244, a_2 = 7.628527, b = 2.569792\n",
      "\tgrad = 2.626468\n",
      "rate = 0.001869\n",
      "Step 730 / 1000, loss = -7930.353910\n",
      "a_1 = 11.470427, a_2 = 7.631397, b = 2.570712\n",
      "\tgrad = 2.762251\n",
      "rate = 0.001867\n",
      "Step 731 / 1000, loss = -7930.402673\n",
      "a_1 = 11.474519, a_2 = 7.634201, b = 2.571635\n",
      "\tgrad = 2.706504\n",
      "rate = 0.001864\n",
      "Step 732 / 1000, loss = -7930.450683\n",
      "a_1 = 11.478446, a_2 = 7.637046, b = 2.572553\n",
      "\tgrad = 2.650831\n",
      "rate = 0.001862\n",
      "Step 733 / 1000, loss = -7930.500336\n",
      "a_1 = 11.482711, a_2 = 7.639838, b = 2.573486\n",
      "\tgrad = 2.787455\n",
      "rate = 0.001859\n",
      "Step 734 / 1000, loss = -7930.549673\n",
      "a_1 = 11.486884, a_2 = 7.642690, b = 2.574409\n",
      "\tgrad = 2.767028\n",
      "rate = 0.001857\n",
      "Step 735 / 1000, loss = -7930.597383\n",
      "a_1 = 11.490906, a_2 = 7.645430, b = 2.575321\n",
      "\tgrad = 2.670070\n",
      "rate = 0.001854\n",
      "Step 736 / 1000, loss = -7930.648204\n",
      "a_1 = 11.495072, a_2 = 7.648479, b = 2.576286\n",
      "\tgrad = 2.836246\n",
      "rate = 0.001852\n",
      "Step 737 / 1000, loss = -7930.694897\n",
      "a_1 = 11.498880, a_2 = 7.651269, b = 2.577192\n",
      "\tgrad = 2.599246\n",
      "rate = 0.001849\n",
      "Step 738 / 1000, loss = -7930.739690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 11.502606, a_2 = 7.653888, b = 2.578060\n",
      "\tgrad = 2.510154\n",
      "rate = 0.001847\n",
      "Step 739 / 1000, loss = -7930.785041\n",
      "a_1 = 11.506276, a_2 = 7.656664, b = 2.578927\n",
      "\tgrad = 2.538407\n",
      "rate = 0.001845\n",
      "Step 740 / 1000, loss = -7930.830859\n",
      "a_1 = 11.510168, a_2 = 7.659292, b = 2.579810\n",
      "\tgrad = 2.594183\n",
      "rate = 0.001842\n",
      "Step 741 / 1000, loss = -7930.881455\n",
      "a_1 = 11.514466, a_2 = 7.662286, b = 2.580740\n",
      "\tgrad = 2.891694\n",
      "rate = 0.001840\n",
      "Step 742 / 1000, loss = -7930.927496\n",
      "a_1 = 11.518311, a_2 = 7.664967, b = 2.581646\n",
      "\tgrad = 2.598530\n",
      "rate = 0.001837\n",
      "Step 743 / 1000, loss = -7930.974157\n",
      "a_1 = 11.522158, a_2 = 7.667763, b = 2.582551\n",
      "\tgrad = 2.638496\n",
      "rate = 0.001835\n",
      "Step 744 / 1000, loss = -7931.019217\n",
      "a_1 = 11.525944, a_2 = 7.670396, b = 2.583429\n",
      "\tgrad = 2.561991\n",
      "rate = 0.001832\n",
      "Step 745 / 1000, loss = -7931.063240\n",
      "a_1 = 11.529704, a_2 = 7.672898, b = 2.584298\n",
      "\tgrad = 2.512802\n",
      "rate = 0.001830\n",
      "Step 746 / 1000, loss = -7931.107973\n",
      "a_1 = 11.533388, a_2 = 7.675566, b = 2.585184\n",
      "\tgrad = 2.535684\n",
      "rate = 0.001828\n",
      "Step 747 / 1000, loss = -7931.151486\n",
      "a_1 = 11.537190, a_2 = 7.678044, b = 2.586006\n",
      "\tgrad = 2.526799\n",
      "rate = 0.001825\n",
      "Step 748 / 1000, loss = -7931.197272\n",
      "a_1 = 11.541189, a_2 = 7.680633, b = 2.586884\n",
      "\tgrad = 2.657271\n",
      "rate = 0.001823\n",
      "Step 749 / 1000, loss = -7931.247485\n",
      "a_1 = 11.545481, a_2 = 7.683561, b = 2.587851\n",
      "\tgrad = 2.902922\n",
      "rate = 0.001821\n",
      "Step 750 / 1000, loss = -7931.293544\n",
      "a_1 = 11.549378, a_2 = 7.686291, b = 2.588738\n",
      "\tgrad = 2.661800\n",
      "rate = 0.001818\n",
      "Step 751 / 1000, loss = -7931.339271\n",
      "a_1 = 11.553137, a_2 = 7.689119, b = 2.589613\n",
      "\tgrad = 2.635505\n",
      "rate = 0.001816\n",
      "Step 752 / 1000, loss = -7931.387276\n",
      "a_1 = 11.557253, a_2 = 7.691957, b = 2.590524\n",
      "\tgrad = 2.801969\n",
      "rate = 0.001813\n",
      "Step 753 / 1000, loss = -7931.434779\n",
      "a_1 = 11.561403, a_2 = 7.694661, b = 2.591446\n",
      "\tgrad = 2.781923\n",
      "rate = 0.001811\n",
      "Step 754 / 1000, loss = -7931.481851\n",
      "a_1 = 11.565397, a_2 = 7.697465, b = 2.592355\n",
      "\tgrad = 2.744193\n",
      "rate = 0.001809\n",
      "Step 755 / 1000, loss = -7931.529260\n",
      "a_1 = 11.569554, a_2 = 7.700217, b = 2.593248\n",
      "\tgrad = 2.804042\n",
      "rate = 0.001806\n",
      "Step 756 / 1000, loss = -7931.576146\n",
      "a_1 = 11.573582, a_2 = 7.702963, b = 2.594163\n",
      "\tgrad = 2.749188\n",
      "rate = 0.001804\n",
      "Step 757 / 1000, loss = -7931.622471\n",
      "a_1 = 11.577495, a_2 = 7.705765, b = 2.595056\n",
      "\tgrad = 2.716443\n",
      "rate = 0.001802\n",
      "Step 758 / 1000, loss = -7931.669203\n",
      "a_1 = 11.581495, a_2 = 7.708542, b = 2.595961\n",
      "\tgrad = 2.752864\n",
      "rate = 0.001799\n",
      "Step 759 / 1000, loss = -7931.716945\n",
      "a_1 = 11.585504, a_2 = 7.711438, b = 2.596898\n",
      "\tgrad = 2.800446\n",
      "rate = 0.001797\n",
      "Step 760 / 1000, loss = -7931.762710\n",
      "a_1 = 11.589416, a_2 = 7.714177, b = 2.597784\n",
      "\tgrad = 2.706412\n",
      "rate = 0.001795\n",
      "Step 761 / 1000, loss = -7931.806645\n",
      "a_1 = 11.593123, a_2 = 7.716869, b = 2.598630\n",
      "\tgrad = 2.598835\n",
      "rate = 0.001793\n",
      "Step 762 / 1000, loss = -7931.850164\n",
      "a_1 = 11.596840, a_2 = 7.719450, b = 2.599495\n",
      "\tgrad = 2.573180\n",
      "rate = 0.001790\n",
      "Step 763 / 1000, loss = -7931.895422\n",
      "a_1 = 11.600585, a_2 = 7.722282, b = 2.600378\n",
      "\tgrad = 2.672105\n",
      "rate = 0.001788\n",
      "Step 764 / 1000, loss = -7931.939616\n",
      "a_1 = 11.604367, a_2 = 7.724960, b = 2.601230\n",
      "\tgrad = 2.638421\n",
      "rate = 0.001786\n",
      "Step 765 / 1000, loss = -7931.985502\n",
      "a_1 = 11.608397, a_2 = 7.727662, b = 2.602109\n",
      "\tgrad = 2.764972\n",
      "rate = 0.001783\n",
      "Step 766 / 1000, loss = -7932.029900\n",
      "a_1 = 11.612273, a_2 = 7.730252, b = 2.602988\n",
      "\tgrad = 2.663449\n",
      "rate = 0.001781\n",
      "Step 767 / 1000, loss = -7932.075287\n",
      "a_1 = 11.616083, a_2 = 7.733098, b = 2.603859\n",
      "\tgrad = 2.717797\n",
      "rate = 0.001779\n",
      "Step 768 / 1000, loss = -7932.119756\n",
      "a_1 = 11.619727, a_2 = 7.735909, b = 2.604748\n",
      "\tgrad = 2.638406\n",
      "rate = 0.001777\n",
      "Step 769 / 1000, loss = -7932.165250\n",
      "a_1 = 11.623666, a_2 = 7.738640, b = 2.605635\n",
      "\tgrad = 2.746810\n",
      "rate = 0.001774\n",
      "Step 770 / 1000, loss = -7932.209891\n",
      "a_1 = 11.627554, a_2 = 7.741285, b = 2.606515\n",
      "\tgrad = 2.699861\n",
      "rate = 0.001772\n",
      "Step 771 / 1000, loss = -7932.253941\n",
      "a_1 = 11.631403, a_2 = 7.743895, b = 2.607383\n",
      "\tgrad = 2.672634\n",
      "rate = 0.001770\n",
      "Step 772 / 1000, loss = -7932.297501\n",
      "a_1 = 11.635214, a_2 = 7.746519, b = 2.608219\n",
      "\tgrad = 2.659840\n",
      "rate = 0.001768\n",
      "Step 773 / 1000, loss = -7932.341587\n",
      "a_1 = 11.638842, a_2 = 7.749308, b = 2.609109\n",
      "\tgrad = 2.640970\n",
      "rate = 0.001765\n",
      "Step 774 / 1000, loss = -7932.386695\n",
      "a_1 = 11.642736, a_2 = 7.752051, b = 2.609994\n",
      "\tgrad = 2.747309\n",
      "rate = 0.001763\n",
      "Step 775 / 1000, loss = -7932.433563\n",
      "a_1 = 11.646991, a_2 = 7.754737, b = 2.610902\n",
      "\tgrad = 2.903397\n",
      "rate = 0.001761\n",
      "Step 776 / 1000, loss = -7932.479793\n",
      "a_1 = 11.650985, a_2 = 7.757542, b = 2.611819\n",
      "\tgrad = 2.823534\n",
      "rate = 0.001759\n",
      "Step 777 / 1000, loss = -7932.522174\n",
      "a_1 = 11.654627, a_2 = 7.760112, b = 2.612672\n",
      "\tgrad = 2.583780\n",
      "rate = 0.001757\n",
      "Step 778 / 1000, loss = -7932.564565\n",
      "a_1 = 11.658292, a_2 = 7.762705, b = 2.613507\n",
      "\tgrad = 2.602767\n",
      "rate = 0.001754\n",
      "Step 779 / 1000, loss = -7932.610398\n",
      "a_1 = 11.662438, a_2 = 7.765327, b = 2.614420\n",
      "\tgrad = 2.847760\n",
      "rate = 0.001752\n",
      "Step 780 / 1000, loss = -7932.653392\n",
      "a_1 = 11.666249, a_2 = 7.767889, b = 2.615264\n",
      "\tgrad = 2.668488\n",
      "rate = 0.001750\n",
      "Step 781 / 1000, loss = -7932.696776\n",
      "a_1 = 11.670078, a_2 = 7.770484, b = 2.616122\n",
      "\tgrad = 2.691604\n",
      "rate = 0.001748\n",
      "Step 782 / 1000, loss = -7932.740757\n",
      "a_1 = 11.673906, a_2 = 7.773197, b = 2.616979\n",
      "\tgrad = 2.731678\n",
      "rate = 0.001746\n",
      "Step 783 / 1000, loss = -7932.785494\n",
      "a_1 = 11.677788, a_2 = 7.775990, b = 2.617842\n",
      "\tgrad = 2.787360\n",
      "rate = 0.001743\n",
      "Step 784 / 1000, loss = -7932.827678\n",
      "a_1 = 11.681401, a_2 = 7.778628, b = 2.618680\n",
      "\tgrad = 2.613870\n",
      "rate = 0.001741\n",
      "Step 785 / 1000, loss = -7932.869294\n",
      "a_1 = 11.685042, a_2 = 7.781179, b = 2.619499\n",
      "\tgrad = 2.599724\n",
      "rate = 0.001739\n",
      "Step 786 / 1000, loss = -7932.909103\n",
      "a_1 = 11.688503, a_2 = 7.783631, b = 2.620291\n",
      "\tgrad = 2.483834\n",
      "rate = 0.001737\n",
      "Step 787 / 1000, loss = -7932.954378\n",
      "a_1 = 11.692516, a_2 = 7.786382, b = 2.621177\n",
      "\tgrad = 2.850740\n",
      "rate = 0.001735\n",
      "Step 788 / 1000, loss = -7932.997240\n",
      "a_1 = 11.696215, a_2 = 7.789024, b = 2.622049\n",
      "\tgrad = 2.671003\n",
      "rate = 0.001733\n",
      "Step 789 / 1000, loss = -7933.040347\n",
      "a_1 = 11.699957, a_2 = 7.791714, b = 2.622900\n",
      "\tgrad = 2.708618\n",
      "rate = 0.001731\n",
      "Step 790 / 1000, loss = -7933.083082\n",
      "a_1 = 11.703674, a_2 = 7.794357, b = 2.623758\n",
      "\tgrad = 2.684838\n",
      "rate = 0.001728\n",
      "Step 791 / 1000, loss = -7933.123402\n",
      "a_1 = 11.707329, a_2 = 7.796672, b = 2.624591\n",
      "\tgrad = 2.552243\n",
      "rate = 0.001726\n",
      "Step 792 / 1000, loss = -7933.167684\n",
      "a_1 = 11.711157, a_2 = 7.799452, b = 2.625476\n",
      "\tgrad = 2.791636\n",
      "rate = 0.001724\n",
      "Step 793 / 1000, loss = -7933.212443\n",
      "a_1 = 11.715024, a_2 = 7.802292, b = 2.626359\n",
      "\tgrad = 2.833007\n",
      "rate = 0.001722\n",
      "Step 794 / 1000, loss = -7933.257308\n",
      "a_1 = 11.719163, a_2 = 7.804900, b = 2.627247\n",
      "\tgrad = 2.890942\n",
      "rate = 0.001720\n",
      "Step 795 / 1000, loss = -7933.301481\n",
      "a_1 = 11.723092, a_2 = 7.807589, b = 2.628131\n",
      "\tgrad = 2.818885\n",
      "rate = 0.001718\n",
      "Step 796 / 1000, loss = -7933.343989\n",
      "a_1 = 11.726678, a_2 = 7.810310, b = 2.629010\n",
      "\tgrad = 2.673317\n",
      "rate = 0.001716\n",
      "Step 797 / 1000, loss = -7933.386887\n",
      "a_1 = 11.730356, a_2 = 7.813036, b = 2.629882\n",
      "\tgrad = 2.719518\n",
      "rate = 0.001714\n",
      "Step 798 / 1000, loss = -7933.427722\n",
      "a_1 = 11.733925, a_2 = 7.815591, b = 2.630704\n",
      "\tgrad = 2.609144\n",
      "rate = 0.001711\n",
      "Step 799 / 1000, loss = -7933.471389\n",
      "a_1 = 11.737833, a_2 = 7.818279, b = 2.631565\n",
      "\tgrad = 2.820034\n",
      "rate = 0.001709\n",
      "Step 800 / 1000, loss = -7933.514049\n",
      "a_1 = 11.741760, a_2 = 7.820794, b = 2.632415\n",
      "\tgrad = 2.776528\n",
      "rate = 0.001707\n",
      "Step 801 / 1000, loss = -7933.555841\n",
      "a_1 = 11.745478, a_2 = 7.823388, b = 2.633246\n",
      "\tgrad = 2.702851\n",
      "rate = 0.001705\n",
      "Step 802 / 1000, loss = -7933.597054\n",
      "a_1 = 11.749188, a_2 = 7.825932, b = 2.634055\n",
      "\tgrad = 2.683394\n",
      "rate = 0.001703\n",
      "Step 803 / 1000, loss = -7933.639965\n",
      "a_1 = 11.753037, a_2 = 7.828540, b = 2.634927\n",
      "\tgrad = 2.781373\n",
      "rate = 0.001701\n",
      "Step 804 / 1000, loss = -7933.679454\n",
      "a_1 = 11.756493, a_2 = 7.831022, b = 2.635733\n",
      "\tgrad = 2.548692\n",
      "rate = 0.001699\n",
      "Step 805 / 1000, loss = -7933.721234\n",
      "a_1 = 11.760217, a_2 = 7.833602, b = 2.636580\n",
      "\tgrad = 2.715932\n",
      "rate = 0.001697\n",
      "Step 806 / 1000, loss = -7933.761597\n",
      "a_1 = 11.763766, a_2 = 7.836115, b = 2.637413\n",
      "\tgrad = 2.612329\n",
      "rate = 0.001695\n",
      "Step 807 / 1000, loss = -7933.803443\n",
      "a_1 = 11.767572, a_2 = 7.838622, b = 2.638272\n",
      "\tgrad = 2.739470\n",
      "rate = 0.001693\n",
      "Step 808 / 1000, loss = -7933.845598\n",
      "a_1 = 11.771371, a_2 = 7.841194, b = 2.639132\n",
      "\tgrad = 2.760609\n",
      "rate = 0.001691\n",
      "Step 809 / 1000, loss = -7933.887644\n",
      "a_1 = 11.775113, a_2 = 7.843816, b = 2.639987\n",
      "\tgrad = 2.752778\n",
      "rate = 0.001689\n",
      "Step 810 / 1000, loss = -7933.927626\n",
      "a_1 = 11.778651, a_2 = 7.846324, b = 2.640805\n",
      "\tgrad = 2.616403\n",
      "rate = 0.001687\n",
      "Step 811 / 1000, loss = -7933.969003\n",
      "a_1 = 11.782467, a_2 = 7.848785, b = 2.641651\n",
      "\tgrad = 2.741697\n",
      "rate = 0.001685\n",
      "Step 812 / 1000, loss = -7934.009995\n",
      "a_1 = 11.786127, a_2 = 7.851367, b = 2.642475\n",
      "\tgrad = 2.706158\n",
      "rate = 0.001683\n",
      "Step 813 / 1000, loss = -7934.049441\n",
      "a_1 = 11.789484, a_2 = 7.853969, b = 2.643289\n",
      "\tgrad = 2.573243\n",
      "rate = 0.001681\n",
      "Step 814 / 1000, loss = -7934.091346\n",
      "a_1 = 11.793371, a_2 = 7.856486, b = 2.644131\n",
      "\tgrad = 2.804221\n",
      "rate = 0.001679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 815 / 1000, loss = -7934.134023\n",
      "a_1 = 11.797049, a_2 = 7.859305, b = 2.644995\n",
      "\tgrad = 2.811193\n",
      "rate = 0.001677\n",
      "Step 816 / 1000, loss = -7934.173862\n",
      "a_1 = 11.800600, a_2 = 7.861780, b = 2.645829\n",
      "\tgrad = 2.632070\n",
      "rate = 0.001675\n",
      "Step 817 / 1000, loss = -7934.216604\n",
      "a_1 = 11.804441, a_2 = 7.864510, b = 2.646673\n",
      "\tgrad = 2.862115\n",
      "rate = 0.001673\n",
      "Step 818 / 1000, loss = -7934.255693\n",
      "a_1 = 11.807949, a_2 = 7.866953, b = 2.647479\n",
      "\tgrad = 2.604011\n",
      "rate = 0.001671\n",
      "Step 819 / 1000, loss = -7934.295518\n",
      "a_1 = 11.811526, a_2 = 7.869454, b = 2.648295\n",
      "\tgrad = 2.660957\n",
      "rate = 0.001669\n",
      "Step 820 / 1000, loss = -7934.335644\n",
      "a_1 = 11.815143, a_2 = 7.871959, b = 2.649121\n",
      "\tgrad = 2.686032\n",
      "rate = 0.001667\n",
      "Step 821 / 1000, loss = -7934.376170\n",
      "a_1 = 11.818798, a_2 = 7.874485, b = 2.649960\n",
      "\tgrad = 2.716377\n",
      "rate = 0.001665\n",
      "Step 822 / 1000, loss = -7934.417430\n",
      "a_1 = 11.822572, a_2 = 7.877031, b = 2.650807\n",
      "\tgrad = 2.784729\n",
      "rate = 0.001663\n",
      "Step 823 / 1000, loss = -7934.455104\n",
      "a_1 = 11.825956, a_2 = 7.879383, b = 2.651597\n",
      "\tgrad = 2.526754\n",
      "rate = 0.001661\n",
      "Step 824 / 1000, loss = -7934.496612\n",
      "a_1 = 11.829705, a_2 = 7.882013, b = 2.652441\n",
      "\tgrad = 2.807358\n",
      "rate = 0.001659\n",
      "Step 825 / 1000, loss = -7934.538157\n",
      "a_1 = 11.833409, a_2 = 7.884706, b = 2.653281\n",
      "\tgrad = 2.810222\n",
      "rate = 0.001657\n",
      "Step 826 / 1000, loss = -7934.577891\n",
      "a_1 = 11.836916, a_2 = 7.887325, b = 2.654082\n",
      "\tgrad = 2.688927\n",
      "rate = 0.001655\n",
      "Step 827 / 1000, loss = -7934.617723\n",
      "a_1 = 11.840568, a_2 = 7.889835, b = 2.654884\n",
      "\tgrad = 2.724005\n",
      "rate = 0.001653\n",
      "Step 828 / 1000, loss = -7934.657973\n",
      "a_1 = 11.844070, a_2 = 7.892500, b = 2.655719\n",
      "\tgrad = 2.713080\n",
      "rate = 0.001651\n",
      "Step 829 / 1000, loss = -7934.697991\n",
      "a_1 = 11.847671, a_2 = 7.895054, b = 2.656545\n",
      "\tgrad = 2.724015\n",
      "rate = 0.001649\n",
      "Step 830 / 1000, loss = -7934.736083\n",
      "a_1 = 11.851131, a_2 = 7.897415, b = 2.657356\n",
      "\tgrad = 2.590328\n",
      "rate = 0.001647\n",
      "Step 831 / 1000, loss = -7934.776613\n",
      "a_1 = 11.854739, a_2 = 7.900046, b = 2.658195\n",
      "\tgrad = 2.761676\n",
      "rate = 0.001645\n",
      "Step 832 / 1000, loss = -7934.814496\n",
      "a_1 = 11.858266, a_2 = 7.902372, b = 2.658977\n",
      "\tgrad = 2.615065\n",
      "rate = 0.001643\n",
      "Step 833 / 1000, loss = -7934.852646\n",
      "a_1 = 11.861695, a_2 = 7.904824, b = 2.659770\n",
      "\tgrad = 2.613089\n",
      "rate = 0.001641\n",
      "Step 834 / 1000, loss = -7934.892207\n",
      "a_1 = 11.865225, a_2 = 7.907387, b = 2.660596\n",
      "\tgrad = 2.708410\n",
      "rate = 0.001639\n",
      "Step 835 / 1000, loss = -7934.930982\n",
      "a_1 = 11.868740, a_2 = 7.909849, b = 2.661408\n",
      "\tgrad = 2.667651\n",
      "rate = 0.001637\n",
      "Step 836 / 1000, loss = -7934.968598\n",
      "a_1 = 11.872132, a_2 = 7.912294, b = 2.662178\n",
      "\tgrad = 2.599632\n",
      "rate = 0.001636\n",
      "Step 837 / 1000, loss = -7935.008521\n",
      "a_1 = 11.875738, a_2 = 7.914830, b = 2.663026\n",
      "\tgrad = 2.748363\n",
      "rate = 0.001634\n",
      "Step 838 / 1000, loss = -7935.046246\n",
      "a_1 = 11.879266, a_2 = 7.917148, b = 2.663814\n",
      "\tgrad = 2.631467\n",
      "rate = 0.001632\n",
      "Step 839 / 1000, loss = -7935.087156\n",
      "a_1 = 11.883011, a_2 = 7.919723, b = 2.664678\n",
      "\tgrad = 2.838802\n",
      "rate = 0.001630\n",
      "Step 840 / 1000, loss = -7935.127530\n",
      "a_1 = 11.886568, a_2 = 7.922413, b = 2.665523\n",
      "\tgrad = 2.788132\n",
      "rate = 0.001628\n",
      "Step 841 / 1000, loss = -7935.167419\n",
      "a_1 = 11.890232, a_2 = 7.924890, b = 2.666383\n",
      "\tgrad = 2.770887\n",
      "rate = 0.001626\n",
      "Step 842 / 1000, loss = -7935.207366\n",
      "a_1 = 11.893884, a_2 = 7.927445, b = 2.667218\n",
      "\tgrad = 2.791652\n",
      "rate = 0.001624\n",
      "Step 843 / 1000, loss = -7935.247926\n",
      "a_1 = 11.897724, a_2 = 7.929981, b = 2.668036\n",
      "\tgrad = 2.881540\n",
      "rate = 0.001622\n",
      "Step 844 / 1000, loss = -7935.284377\n",
      "a_1 = 11.900945, a_2 = 7.932422, b = 2.668799\n",
      "\tgrad = 2.538071\n",
      "rate = 0.001620\n",
      "Step 845 / 1000, loss = -7935.322999\n",
      "a_1 = 11.904503, a_2 = 7.934892, b = 2.669601\n",
      "\tgrad = 2.721856\n",
      "rate = 0.001618\n",
      "Step 846 / 1000, loss = -7935.361496\n",
      "a_1 = 11.908107, a_2 = 7.937326, b = 2.670392\n",
      "\tgrad = 2.734015\n",
      "rate = 0.001617\n",
      "Step 847 / 1000, loss = -7935.401064\n",
      "a_1 = 11.911774, a_2 = 7.939871, b = 2.671203\n",
      "\tgrad = 2.809664\n",
      "rate = 0.001615\n",
      "Step 848 / 1000, loss = -7935.438193\n",
      "a_1 = 11.915172, a_2 = 7.942253, b = 2.671990\n",
      "\tgrad = 2.618444\n",
      "rate = 0.001613\n",
      "Step 849 / 1000, loss = -7935.476819\n",
      "a_1 = 11.918646, a_2 = 7.944821, b = 2.672794\n",
      "\tgrad = 2.727677\n",
      "rate = 0.001611\n",
      "Step 850 / 1000, loss = -7935.512632\n",
      "a_1 = 11.921917, a_2 = 7.947152, b = 2.673543\n",
      "\tgrad = 2.539427\n",
      "rate = 0.001609\n",
      "Step 851 / 1000, loss = -7935.548766\n",
      "a_1 = 11.925237, a_2 = 7.949457, b = 2.674318\n",
      "\tgrad = 2.559964\n",
      "rate = 0.001607\n",
      "Step 852 / 1000, loss = -7935.586188\n",
      "a_1 = 11.928595, a_2 = 7.951956, b = 2.675103\n",
      "\tgrad = 2.652487\n",
      "rate = 0.001606\n",
      "Step 853 / 1000, loss = -7935.623741\n",
      "a_1 = 11.932010, a_2 = 7.954409, b = 2.675900\n",
      "\tgrad = 2.668789\n",
      "rate = 0.001604\n",
      "Step 854 / 1000, loss = -7935.663106\n",
      "a_1 = 11.935659, a_2 = 7.956950, b = 2.676722\n",
      "\tgrad = 2.823031\n",
      "rate = 0.001602\n",
      "Step 855 / 1000, loss = -7935.701295\n",
      "a_1 = 11.939206, a_2 = 7.959403, b = 2.677525\n",
      "\tgrad = 2.741564\n",
      "rate = 0.001600\n",
      "Step 856 / 1000, loss = -7935.737628\n",
      "a_1 = 11.942446, a_2 = 7.961841, b = 2.678302\n",
      "\tgrad = 2.583111\n",
      "rate = 0.001598\n",
      "Step 857 / 1000, loss = -7935.773487\n",
      "a_1 = 11.945733, a_2 = 7.964201, b = 2.679052\n",
      "\tgrad = 2.578302\n",
      "rate = 0.001596\n",
      "Step 858 / 1000, loss = -7935.811301\n",
      "a_1 = 11.949252, a_2 = 7.966636, b = 2.679850\n",
      "\tgrad = 2.729769\n",
      "rate = 0.001595\n",
      "Step 859 / 1000, loss = -7935.850443\n",
      "a_1 = 11.952951, a_2 = 7.969095, b = 2.680683\n",
      "\tgrad = 2.837485\n",
      "rate = 0.001593\n",
      "Step 860 / 1000, loss = -7935.887257\n",
      "a_1 = 11.956263, a_2 = 7.971583, b = 2.681457\n",
      "\tgrad = 2.648966\n",
      "rate = 0.001591\n",
      "Step 861 / 1000, loss = -7935.923525\n",
      "a_1 = 11.959595, a_2 = 7.973950, b = 2.682234\n",
      "\tgrad = 2.617720\n",
      "rate = 0.001589\n",
      "Step 862 / 1000, loss = -7935.961628\n",
      "a_1 = 11.963064, a_2 = 7.976557, b = 2.683006\n",
      "\tgrad = 2.777042\n",
      "rate = 0.001587\n",
      "Step 863 / 1000, loss = -7935.997729\n",
      "a_1 = 11.966460, a_2 = 7.978847, b = 2.683781\n",
      "\tgrad = 2.629164\n",
      "rate = 0.001586\n",
      "Step 864 / 1000, loss = -7936.036317\n",
      "a_1 = 11.970115, a_2 = 7.981303, b = 2.684597\n",
      "\tgrad = 2.827581\n",
      "rate = 0.001584\n",
      "Step 865 / 1000, loss = -7936.072758\n",
      "a_1 = 11.973472, a_2 = 7.983676, b = 2.685386\n",
      "\tgrad = 2.646317\n",
      "rate = 0.001582\n",
      "Step 866 / 1000, loss = -7936.108396\n",
      "a_1 = 11.976756, a_2 = 7.986005, b = 2.686156\n",
      "\tgrad = 2.594501\n",
      "rate = 0.001580\n",
      "Step 867 / 1000, loss = -7936.145631\n",
      "a_1 = 11.980200, a_2 = 7.988441, b = 2.686956\n",
      "\tgrad = 2.719951\n",
      "rate = 0.001578\n",
      "Step 868 / 1000, loss = -7936.183886\n",
      "a_1 = 11.983701, a_2 = 7.991030, b = 2.687754\n",
      "\tgrad = 2.808039\n",
      "rate = 0.001577\n",
      "Step 869 / 1000, loss = -7936.219287\n",
      "a_1 = 11.986924, a_2 = 7.993449, b = 2.688491\n",
      "\tgrad = 2.601447\n",
      "rate = 0.001575\n",
      "Step 870 / 1000, loss = -7936.255928\n",
      "a_1 = 11.990449, a_2 = 7.995782, b = 2.689255\n",
      "\tgrad = 2.730606\n",
      "rate = 0.001573\n",
      "Step 871 / 1000, loss = -7936.292210\n",
      "a_1 = 11.993763, a_2 = 7.998273, b = 2.690005\n",
      "\tgrad = 2.681448\n",
      "rate = 0.001571\n",
      "Step 872 / 1000, loss = -7936.328361\n",
      "a_1 = 11.997109, a_2 = 8.000652, b = 2.690786\n",
      "\tgrad = 2.662786\n",
      "rate = 0.001570\n",
      "Step 873 / 1000, loss = -7936.363887\n",
      "a_1 = 12.000316, a_2 = 8.003041, b = 2.691568\n",
      "\tgrad = 2.599143\n",
      "rate = 0.001568\n",
      "Step 874 / 1000, loss = -7936.400883\n",
      "a_1 = 12.003745, a_2 = 8.005469, b = 2.692375\n",
      "\tgrad = 2.731955\n",
      "rate = 0.001566\n",
      "Step 875 / 1000, loss = -7936.437048\n",
      "a_1 = 12.007159, a_2 = 8.007797, b = 2.693160\n",
      "\tgrad = 2.688818\n",
      "rate = 0.001564\n",
      "Step 876 / 1000, loss = -7936.473817\n",
      "a_1 = 12.010610, a_2 = 8.010224, b = 2.693940\n",
      "\tgrad = 2.745712\n",
      "rate = 0.001562\n",
      "Step 877 / 1000, loss = -7936.509335\n",
      "a_1 = 12.013875, a_2 = 8.012604, b = 2.694709\n",
      "\tgrad = 2.635317\n",
      "rate = 0.001561\n",
      "Step 878 / 1000, loss = -7936.543915\n",
      "a_1 = 12.017046, a_2 = 8.014946, b = 2.695451\n",
      "\tgrad = 2.573355\n",
      "rate = 0.001559\n",
      "Step 879 / 1000, loss = -7936.580437\n",
      "a_1 = 12.020389, a_2 = 8.017402, b = 2.696250\n",
      "\tgrad = 2.712470\n",
      "rate = 0.001557\n",
      "Step 880 / 1000, loss = -7936.614725\n",
      "a_1 = 12.023500, a_2 = 8.019756, b = 2.696991\n",
      "\tgrad = 2.552753\n",
      "rate = 0.001556\n",
      "Step 881 / 1000, loss = -7936.651258\n",
      "a_1 = 12.026925, a_2 = 8.022228, b = 2.697749\n",
      "\tgrad = 2.761904\n",
      "rate = 0.001554\n",
      "Step 882 / 1000, loss = -7936.689267\n",
      "a_1 = 12.030428, a_2 = 8.024856, b = 2.698541\n",
      "\tgrad = 2.867066\n",
      "rate = 0.001552\n",
      "Step 883 / 1000, loss = -7936.724429\n",
      "a_1 = 12.033795, a_2 = 8.027108, b = 2.699308\n",
      "\tgrad = 2.659212\n",
      "rate = 0.001550\n",
      "Step 884 / 1000, loss = -7936.758125\n",
      "a_1 = 12.036998, a_2 = 8.029298, b = 2.700041\n",
      "\tgrad = 2.549764\n",
      "rate = 0.001549\n",
      "Step 885 / 1000, loss = -7936.794139\n",
      "a_1 = 12.040439, a_2 = 8.031649, b = 2.700812\n",
      "\tgrad = 2.739707\n",
      "rate = 0.001547\n",
      "Step 886 / 1000, loss = -7936.828794\n",
      "a_1 = 12.043715, a_2 = 8.033923, b = 2.701568\n",
      "\tgrad = 2.626699\n",
      "rate = 0.001545\n",
      "Step 887 / 1000, loss = -7936.863135\n",
      "a_1 = 12.046941, a_2 = 8.036203, b = 2.702315\n",
      "\tgrad = 2.604642\n",
      "rate = 0.001544\n",
      "Step 888 / 1000, loss = -7936.897637\n",
      "a_1 = 12.050189, a_2 = 8.038519, b = 2.703052\n",
      "\tgrad = 2.631063\n",
      "rate = 0.001542\n",
      "Step 889 / 1000, loss = -7936.933505\n",
      "a_1 = 12.053695, a_2 = 8.040775, b = 2.703838\n",
      "\tgrad = 2.754767\n",
      "rate = 0.001540\n",
      "Step 890 / 1000, loss = -7936.967136\n",
      "a_1 = 12.057065, a_2 = 8.042838, b = 2.704565\n",
      "\tgrad = 2.611463\n",
      "rate = 0.001538\n",
      "Step 891 / 1000, loss = -7937.001147\n",
      "a_1 = 12.060285, a_2 = 8.045064, b = 2.705320\n",
      "\tgrad = 2.593802\n",
      "rate = 0.001537\n",
      "Step 892 / 1000, loss = -7937.035898\n",
      "a_1 = 12.063541, a_2 = 8.047434, b = 2.706060\n",
      "\tgrad = 2.667615\n",
      "rate = 0.001535\n",
      "Step 893 / 1000, loss = -7937.070971\n",
      "a_1 = 12.066797, a_2 = 8.049808, b = 2.706833\n",
      "\tgrad = 2.675600\n",
      "rate = 0.001533\n",
      "Step 894 / 1000, loss = -7937.105626\n",
      "a_1 = 12.070086, a_2 = 8.052091, b = 2.707597\n",
      "\tgrad = 2.661368\n",
      "rate = 0.001532\n",
      "Step 895 / 1000, loss = -7937.140036\n",
      "a_1 = 12.073401, a_2 = 8.054340, b = 2.708345\n",
      "\tgrad = 2.663034\n",
      "rate = 0.001530\n",
      "Step 896 / 1000, loss = -7937.173808\n",
      "a_1 = 12.076587, a_2 = 8.056623, b = 2.709074\n",
      "\tgrad = 2.608603\n",
      "rate = 0.001528\n",
      "Step 897 / 1000, loss = -7937.206625\n",
      "a_1 = 12.079665, a_2 = 8.058841, b = 2.709793\n",
      "\tgrad = 2.529398\n",
      "rate = 0.001527\n",
      "Step 898 / 1000, loss = -7937.242676\n",
      "a_1 = 12.083183, a_2 = 8.061189, b = 2.710568\n",
      "\tgrad = 2.819435\n",
      "rate = 0.001525\n",
      "Step 899 / 1000, loss = -7937.277740\n",
      "a_1 = 12.086594, a_2 = 8.063467, b = 2.711331\n",
      "\tgrad = 2.738974\n",
      "rate = 0.001523\n",
      "Step 900 / 1000, loss = -7937.313373\n",
      "a_1 = 12.089934, a_2 = 8.065897, b = 2.712110\n",
      "\tgrad = 2.761724\n",
      "rate = 0.001522\n",
      "Step 901 / 1000, loss = -7937.348763\n",
      "a_1 = 12.093317, a_2 = 8.068252, b = 2.712886\n",
      "\tgrad = 2.759311\n",
      "rate = 0.001520\n",
      "Step 902 / 1000, loss = -7937.383165\n",
      "a_1 = 12.096569, a_2 = 8.070596, b = 2.713631\n",
      "\tgrad = 2.684892\n",
      "rate = 0.001518\n",
      "Step 903 / 1000, loss = -7937.418705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 12.100063, a_2 = 8.072916, b = 2.714393\n",
      "\tgrad = 2.810721\n",
      "rate = 0.001517\n",
      "Step 904 / 1000, loss = -7937.451643\n",
      "a_1 = 12.103247, a_2 = 8.075102, b = 2.715108\n",
      "\tgrad = 2.592291\n",
      "rate = 0.001515\n",
      "Step 905 / 1000, loss = -7937.486784\n",
      "a_1 = 12.106513, a_2 = 8.077556, b = 2.715872\n",
      "\tgrad = 2.745905\n",
      "rate = 0.001514\n",
      "Step 906 / 1000, loss = -7937.520620\n",
      "a_1 = 12.109706, a_2 = 8.079878, b = 2.716608\n",
      "\tgrad = 2.656676\n",
      "rate = 0.001512\n",
      "Step 907 / 1000, loss = -7937.554697\n",
      "a_1 = 12.112971, a_2 = 8.082169, b = 2.717354\n",
      "\tgrad = 2.686569\n",
      "rate = 0.001510\n",
      "Step 908 / 1000, loss = -7937.588430\n",
      "a_1 = 12.116263, a_2 = 8.084421, b = 2.718075\n",
      "\tgrad = 2.686402\n",
      "rate = 0.001509\n",
      "Step 909 / 1000, loss = -7937.623110\n",
      "a_1 = 12.119574, a_2 = 8.086727, b = 2.718858\n",
      "\tgrad = 2.727426\n",
      "rate = 0.001507\n",
      "Step 910 / 1000, loss = -7937.656099\n",
      "a_1 = 12.122741, a_2 = 8.088915, b = 2.719598\n",
      "\tgrad = 2.604398\n",
      "rate = 0.001505\n",
      "Step 911 / 1000, loss = -7937.689284\n",
      "a_1 = 12.125998, a_2 = 8.091056, b = 2.720344\n",
      "\tgrad = 2.638613\n",
      "rate = 0.001504\n",
      "Step 912 / 1000, loss = -7937.722308\n",
      "a_1 = 12.129178, a_2 = 8.093261, b = 2.721079\n",
      "\tgrad = 2.622258\n",
      "rate = 0.001502\n",
      "Step 913 / 1000, loss = -7937.755926\n",
      "a_1 = 12.132354, a_2 = 8.095558, b = 2.721830\n",
      "\tgrad = 2.659691\n",
      "rate = 0.001501\n",
      "Step 914 / 1000, loss = -7937.790135\n",
      "a_1 = 12.135780, a_2 = 8.097730, b = 2.722592\n",
      "\tgrad = 2.753961\n",
      "rate = 0.001499\n",
      "Step 915 / 1000, loss = -7937.823759\n",
      "a_1 = 12.139138, a_2 = 8.099900, b = 2.723330\n",
      "\tgrad = 2.714798\n",
      "rate = 0.001497\n",
      "Step 916 / 1000, loss = -7937.857586\n",
      "a_1 = 12.142392, a_2 = 8.102192, b = 2.724076\n",
      "\tgrad = 2.707622\n",
      "rate = 0.001496\n",
      "Step 917 / 1000, loss = -7937.889921\n",
      "a_1 = 12.145566, a_2 = 8.104308, b = 2.724801\n",
      "\tgrad = 2.598756\n",
      "rate = 0.001494\n",
      "Step 918 / 1000, loss = -7937.922137\n",
      "a_1 = 12.148701, a_2 = 8.106436, b = 2.725528\n",
      "\tgrad = 2.584874\n",
      "rate = 0.001493\n",
      "Step 919 / 1000, loss = -7937.955935\n",
      "a_1 = 12.152095, a_2 = 8.108629, b = 2.726264\n",
      "\tgrad = 2.754688\n",
      "rate = 0.001491\n",
      "Step 920 / 1000, loss = -7937.989278\n",
      "a_1 = 12.155298, a_2 = 8.110911, b = 2.727000\n",
      "\tgrad = 2.686367\n",
      "rate = 0.001489\n",
      "Step 921 / 1000, loss = -7938.022661\n",
      "a_1 = 12.158557, a_2 = 8.113152, b = 2.727737\n",
      "\tgrad = 2.704634\n",
      "rate = 0.001488\n",
      "Step 922 / 1000, loss = -7938.054595\n",
      "a_1 = 12.161560, a_2 = 8.115362, b = 2.728463\n",
      "\tgrad = 2.555763\n",
      "rate = 0.001486\n",
      "Step 923 / 1000, loss = -7938.088906\n",
      "a_1 = 12.164912, a_2 = 8.117655, b = 2.729229\n",
      "\tgrad = 2.784059\n",
      "rate = 0.001485\n",
      "Step 924 / 1000, loss = -7938.122316\n",
      "a_1 = 12.168254, a_2 = 8.119829, b = 2.729972\n",
      "\tgrad = 2.734208\n",
      "rate = 0.001483\n",
      "Step 925 / 1000, loss = -7938.154470\n",
      "a_1 = 12.171369, a_2 = 8.122007, b = 2.730692\n",
      "\tgrad = 2.611291\n",
      "rate = 0.001481\n",
      "Step 926 / 1000, loss = -7938.187719\n",
      "a_1 = 12.174570, a_2 = 8.124291, b = 2.731432\n",
      "\tgrad = 2.703742\n",
      "rate = 0.001480\n",
      "Step 927 / 1000, loss = -7938.218606\n",
      "a_1 = 12.177730, a_2 = 8.126224, b = 2.732132\n",
      "\tgrad = 2.550333\n",
      "rate = 0.001478\n",
      "Step 928 / 1000, loss = -7938.252718\n",
      "a_1 = 12.181093, a_2 = 8.128497, b = 2.732895\n",
      "\tgrad = 2.796565\n",
      "rate = 0.001477\n",
      "Step 929 / 1000, loss = -7938.285028\n",
      "a_1 = 12.184346, a_2 = 8.130596, b = 2.733616\n",
      "\tgrad = 2.669496\n",
      "rate = 0.001475\n",
      "Step 930 / 1000, loss = -7938.317157\n",
      "a_1 = 12.187486, a_2 = 8.132788, b = 2.734327\n",
      "\tgrad = 2.642586\n",
      "rate = 0.001474\n",
      "Step 931 / 1000, loss = -7938.350608\n",
      "a_1 = 12.190824, a_2 = 8.134952, b = 2.735097\n",
      "\tgrad = 2.752473\n",
      "rate = 0.001472\n",
      "Step 932 / 1000, loss = -7938.384674\n",
      "a_1 = 12.194083, a_2 = 8.137340, b = 2.735854\n",
      "\tgrad = 2.795594\n",
      "rate = 0.001471\n",
      "Step 933 / 1000, loss = -7938.417843\n",
      "a_1 = 12.197358, a_2 = 8.139581, b = 2.736590\n",
      "\tgrad = 2.747317\n",
      "rate = 0.001469\n",
      "Step 934 / 1000, loss = -7938.450652\n",
      "a_1 = 12.200489, a_2 = 8.141884, b = 2.737327\n",
      "\tgrad = 2.695411\n",
      "rate = 0.001468\n",
      "Step 935 / 1000, loss = -7938.481718\n",
      "a_1 = 12.203534, a_2 = 8.144024, b = 2.738010\n",
      "\tgrad = 2.581160\n",
      "rate = 0.001466\n",
      "Step 936 / 1000, loss = -7938.513350\n",
      "a_1 = 12.206490, a_2 = 8.146312, b = 2.738719\n",
      "\tgrad = 2.598160\n",
      "rate = 0.001464\n",
      "Step 937 / 1000, loss = -7938.546676\n",
      "a_1 = 12.209670, a_2 = 8.148692, b = 2.739453\n",
      "\tgrad = 2.761226\n",
      "rate = 0.001463\n",
      "Step 938 / 1000, loss = -7938.580861\n",
      "a_1 = 12.213148, a_2 = 8.150930, b = 2.740213\n",
      "\tgrad = 2.877293\n",
      "rate = 0.001461\n",
      "Step 939 / 1000, loss = -7938.613046\n",
      "a_1 = 12.216306, a_2 = 8.153103, b = 2.740950\n",
      "\tgrad = 2.674193\n",
      "rate = 0.001460\n",
      "Step 940 / 1000, loss = -7938.643908\n",
      "a_1 = 12.219236, a_2 = 8.155291, b = 2.741652\n",
      "\tgrad = 2.553415\n",
      "rate = 0.001458\n",
      "Step 941 / 1000, loss = -7938.674462\n",
      "a_1 = 12.222214, a_2 = 8.157402, b = 2.742341\n",
      "\tgrad = 2.549990\n",
      "rate = 0.001457\n",
      "Step 942 / 1000, loss = -7938.706621\n",
      "a_1 = 12.225463, a_2 = 8.159520, b = 2.743068\n",
      "\tgrad = 2.711416\n",
      "rate = 0.001455\n",
      "Step 943 / 1000, loss = -7938.739617\n",
      "a_1 = 12.228592, a_2 = 8.161940, b = 2.743787\n",
      "\tgrad = 2.764904\n",
      "rate = 0.001454\n",
      "Step 944 / 1000, loss = -7938.773750\n",
      "a_1 = 12.231953, a_2 = 8.164307, b = 2.744543\n",
      "\tgrad = 2.878379\n",
      "rate = 0.001452\n",
      "Step 945 / 1000, loss = -7938.808711\n",
      "a_1 = 12.235470, a_2 = 8.166647, b = 2.745330\n",
      "\tgrad = 2.961999\n",
      "rate = 0.001451\n",
      "Step 946 / 1000, loss = -7938.841280\n",
      "a_1 = 12.238683, a_2 = 8.168894, b = 2.746060\n",
      "\tgrad = 2.751610\n",
      "rate = 0.001449\n",
      "Step 947 / 1000, loss = -7938.873218\n",
      "a_1 = 12.241827, a_2 = 8.171095, b = 2.746782\n",
      "\tgrad = 2.697697\n",
      "rate = 0.001448\n",
      "Step 948 / 1000, loss = -7938.905086\n",
      "a_1 = 12.244941, a_2 = 8.173290, b = 2.747517\n",
      "\tgrad = 2.682661\n",
      "rate = 0.001446\n",
      "Step 949 / 1000, loss = -7938.935481\n",
      "a_1 = 12.247949, a_2 = 8.175405, b = 2.748192\n",
      "\tgrad = 2.587191\n",
      "rate = 0.001445\n",
      "Step 950 / 1000, loss = -7938.966932\n",
      "a_1 = 12.251038, a_2 = 8.177614, b = 2.748892\n",
      "\tgrad = 2.675781\n",
      "rate = 0.001443\n",
      "Step 951 / 1000, loss = -7938.998926\n",
      "a_1 = 12.254178, a_2 = 8.179830, b = 2.749623\n",
      "\tgrad = 2.713744\n",
      "rate = 0.001442\n",
      "Step 952 / 1000, loss = -7939.030935\n",
      "a_1 = 12.257237, a_2 = 8.182127, b = 2.750354\n",
      "\tgrad = 2.703767\n",
      "rate = 0.001440\n",
      "Step 953 / 1000, loss = -7939.062861\n",
      "a_1 = 12.260442, a_2 = 8.184297, b = 2.751077\n",
      "\tgrad = 2.736470\n",
      "rate = 0.001439\n",
      "Step 954 / 1000, loss = -7939.093180\n",
      "a_1 = 12.263478, a_2 = 8.186359, b = 2.751768\n",
      "\tgrad = 2.597855\n",
      "rate = 0.001437\n",
      "Step 955 / 1000, loss = -7939.125204\n",
      "a_1 = 12.266765, a_2 = 8.188512, b = 2.752476\n",
      "\tgrad = 2.780635\n",
      "rate = 0.001436\n",
      "Step 956 / 1000, loss = -7939.154815\n",
      "a_1 = 12.269783, a_2 = 8.190470, b = 2.753159\n",
      "\tgrad = 2.552906\n",
      "rate = 0.001434\n",
      "Step 957 / 1000, loss = -7939.184861\n",
      "a_1 = 12.272687, a_2 = 8.192625, b = 2.753841\n",
      "\tgrad = 2.568387\n",
      "rate = 0.001433\n",
      "Step 958 / 1000, loss = -7939.214714\n",
      "a_1 = 12.275606, a_2 = 8.194705, b = 2.754537\n",
      "\tgrad = 2.550353\n",
      "rate = 0.001431\n",
      "Step 959 / 1000, loss = -7939.246152\n",
      "a_1 = 12.278746, a_2 = 8.196875, b = 2.755252\n",
      "\tgrad = 2.715186\n",
      "rate = 0.001430\n",
      "Step 960 / 1000, loss = -7939.276748\n",
      "a_1 = 12.281922, a_2 = 8.198867, b = 2.755954\n",
      "\tgrad = 2.670357\n",
      "rate = 0.001429\n",
      "Step 961 / 1000, loss = -7939.305979\n",
      "a_1 = 12.284745, a_2 = 8.200968, b = 2.756625\n",
      "\tgrad = 2.510120\n",
      "rate = 0.001427\n",
      "Step 962 / 1000, loss = -7939.335612\n",
      "a_1 = 12.287719, a_2 = 8.203000, b = 2.757305\n",
      "\tgrad = 2.570743\n",
      "rate = 0.001426\n",
      "Step 963 / 1000, loss = -7939.369013\n",
      "a_1 = 12.291113, a_2 = 8.205262, b = 2.758069\n",
      "\tgrad = 2.914039\n",
      "rate = 0.001424\n",
      "Step 964 / 1000, loss = -7939.400258\n",
      "a_1 = 12.294273, a_2 = 8.207402, b = 2.758780\n",
      "\tgrad = 2.728743\n",
      "rate = 0.001423\n",
      "Step 965 / 1000, loss = -7939.431032\n",
      "a_1 = 12.297424, a_2 = 8.209485, b = 2.759478\n",
      "\tgrad = 2.702369\n",
      "rate = 0.001421\n",
      "Step 966 / 1000, loss = -7939.461119\n",
      "a_1 = 12.300413, a_2 = 8.211609, b = 2.760159\n",
      "\tgrad = 2.627076\n",
      "rate = 0.001420\n",
      "Step 967 / 1000, loss = -7939.493427\n",
      "a_1 = 12.303882, a_2 = 8.213675, b = 2.760884\n",
      "\tgrad = 2.891803\n",
      "rate = 0.001418\n",
      "Step 968 / 1000, loss = -7939.524821\n",
      "a_1 = 12.306904, a_2 = 8.216007, b = 2.761586\n",
      "\tgrad = 2.739120\n",
      "rate = 0.001417\n",
      "Step 969 / 1000, loss = -7939.557579\n",
      "a_1 = 12.310220, a_2 = 8.218269, b = 2.762333\n",
      "\tgrad = 2.883829\n",
      "rate = 0.001416\n",
      "Step 970 / 1000, loss = -7939.589313\n",
      "a_1 = 12.313331, a_2 = 8.220529, b = 2.763070\n",
      "\tgrad = 2.768967\n",
      "rate = 0.001414\n",
      "Step 971 / 1000, loss = -7939.618869\n",
      "a_1 = 12.316159, a_2 = 8.222732, b = 2.763741\n",
      "\tgrad = 2.581466\n",
      "rate = 0.001413\n",
      "Step 972 / 1000, loss = -7939.650295\n",
      "a_1 = 12.319188, a_2 = 8.225043, b = 2.764462\n",
      "\tgrad = 2.747698\n",
      "rate = 0.001411\n",
      "Step 973 / 1000, loss = -7939.681239\n",
      "a_1 = 12.322324, a_2 = 8.227153, b = 2.765188\n",
      "\tgrad = 2.729702\n",
      "rate = 0.001410\n",
      "Step 974 / 1000, loss = -7939.712823\n",
      "a_1 = 12.325368, a_2 = 8.229526, b = 2.765892\n",
      "\tgrad = 2.785437\n",
      "rate = 0.001408\n",
      "Step 975 / 1000, loss = -7939.743534\n",
      "a_1 = 12.328456, a_2 = 8.231681, b = 2.766597\n",
      "\tgrad = 2.722819\n",
      "rate = 0.001407\n",
      "Step 976 / 1000, loss = -7939.774533\n",
      "a_1 = 12.331440, a_2 = 8.234021, b = 2.767289\n",
      "\tgrad = 2.742314\n",
      "rate = 0.001406\n",
      "Step 977 / 1000, loss = -7939.805156\n",
      "a_1 = 12.334471, a_2 = 8.236179, b = 2.768013\n",
      "\tgrad = 2.699547\n",
      "rate = 0.001404\n",
      "Step 978 / 1000, loss = -7939.834365\n",
      "a_1 = 12.337425, a_2 = 8.238178, b = 2.768708\n",
      "\tgrad = 2.590374\n",
      "rate = 0.001403\n",
      "Step 979 / 1000, loss = -7939.865540\n",
      "a_1 = 12.340649, a_2 = 8.240296, b = 2.769427\n",
      "\tgrad = 2.799901\n",
      "rate = 0.001401\n",
      "Step 980 / 1000, loss = -7939.897241\n",
      "a_1 = 12.343777, a_2 = 8.242637, b = 2.770134\n",
      "\tgrad = 2.836341\n",
      "rate = 0.001400\n",
      "Step 981 / 1000, loss = -7939.928376\n",
      "a_1 = 12.346899, a_2 = 8.244848, b = 2.770853\n",
      "\tgrad = 2.782781\n",
      "rate = 0.001399\n",
      "Step 982 / 1000, loss = -7939.957624\n",
      "a_1 = 12.349913, a_2 = 8.246831, b = 2.771540\n",
      "\tgrad = 2.628889\n",
      "rate = 0.001397\n",
      "Step 983 / 1000, loss = -7939.987719\n",
      "a_1 = 12.352850, a_2 = 8.249029, b = 2.772245\n",
      "\tgrad = 2.676107\n",
      "rate = 0.001396\n",
      "Step 984 / 1000, loss = -7940.015900\n",
      "a_1 = 12.355723, a_2 = 8.250989, b = 2.772900\n",
      "\tgrad = 2.538130\n",
      "rate = 0.001394\n",
      "Step 985 / 1000, loss = -7940.047318\n",
      "a_1 = 12.358870, a_2 = 8.253261, b = 2.773615\n",
      "\tgrad = 2.833238\n",
      "rate = 0.001393\n",
      "Step 986 / 1000, loss = -7940.079159\n",
      "a_1 = 12.362170, a_2 = 8.255419, b = 2.774364\n",
      "\tgrad = 2.884200\n",
      "rate = 0.001392\n",
      "Step 987 / 1000, loss = -7940.107671\n",
      "a_1 = 12.364997, a_2 = 8.257470, b = 2.775035\n",
      "\tgrad = 2.557844\n",
      "rate = 0.001390\n",
      "Step 988 / 1000, loss = -7940.136376\n",
      "a_1 = 12.367923, a_2 = 8.259473, b = 2.775707\n",
      "\tgrad = 2.598750\n",
      "rate = 0.001389\n",
      "Step 989 / 1000, loss = -7940.167521\n",
      "a_1 = 12.371083, a_2 = 8.261713, b = 2.776412\n",
      "\tgrad = 2.837347\n",
      "rate = 0.001388\n",
      "Step 990 / 1000, loss = -7940.196954\n",
      "a_1 = 12.374119, a_2 = 8.263742, b = 2.777102\n",
      "\tgrad = 2.680713\n",
      "rate = 0.001386\n",
      "Step 991 / 1000, loss = -7940.226264\n",
      "a_1 = 12.377057, a_2 = 8.265834, b = 2.777793\n",
      "\tgrad = 2.652481\n",
      "rate = 0.001385\n",
      "Step 992 / 1000, loss = -7940.255310\n",
      "a_1 = 12.380001, a_2 = 8.267914, b = 2.778463\n",
      "\tgrad = 2.649908\n",
      "rate = 0.001383\n",
      "Step 993 / 1000, loss = -7940.287579\n",
      "a_1 = 12.383226, a_2 = 8.270238, b = 2.779223\n",
      "\tgrad = 2.928030\n",
      "rate = 0.001382\n",
      "Step 994 / 1000, loss = -7940.316309\n",
      "a_1 = 12.386198, a_2 = 8.272231, b = 2.779894\n",
      "\tgrad = 2.637084\n",
      "rate = 0.001381\n",
      "Step 995 / 1000, loss = -7940.345341\n",
      "a_1 = 12.389095, a_2 = 8.274379, b = 2.780555\n",
      "\tgrad = 2.658486\n",
      "rate = 0.001379\n",
      "Step 996 / 1000, loss = -7940.375624\n",
      "a_1 = 12.392158, a_2 = 8.276565, b = 2.781255\n",
      "\tgrad = 2.777997\n",
      "rate = 0.001378\n",
      "Step 997 / 1000, loss = -7940.405315\n",
      "a_1 = 12.395212, a_2 = 8.278653, b = 2.781949\n",
      "\tgrad = 2.733996\n",
      "rate = 0.001377\n",
      "Step 998 / 1000, loss = -7940.435131\n",
      "a_1 = 12.398260, a_2 = 8.280750, b = 2.782655\n",
      "\tgrad = 2.738551\n",
      "rate = 0.001375\n",
      "Step 999 / 1000, loss = -7940.463215\n",
      "a_1 = 12.401046, a_2 = 8.282826, b = 2.783311\n",
      "\tgrad = 2.573490\n",
      "rate = 0.001374\n",
      "Step 1000 / 1000, loss = -7940.492792\n",
      "a_1 = 12.404094, a_2 = 8.284927, b = 2.783994\n",
      "\tgrad = 2.742870\n",
      "rate = 0.001373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "print (generic function with 45 methods)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf = readtable(\"data.csv\")\n",
    "x,y = convertdata_to_array(dtf)\n",
    "nb_steps = 1000\n",
    "\n",
    "params = NNparams(init_params(x))\n",
    "param_history_a1 = Float64[]\n",
    "param_history_a2 = Float64[]\n",
    "param_history_a3 = Float64[]\n",
    "loss_history = Float64[]\n",
    "output_history = Float64[]\n",
    "grad_history = Float64[]\n",
    "learning_rate_history = Float64[]\n",
    "\n",
    "for s = 1:nb_steps  \n",
    "    x_training,y_training = select_trainingdata(x,y,1000)\n",
    "    grad = ∇(x_training, y_training, params)\n",
    "    learning_rate = update_learning_rate(.07,s)\n",
    "    params = updateNNparams(grad,params,learning_rate)\n",
    "    result = output(params, x_training[s,:])\n",
    "    loss_at_this_step = loss(params,y,x)\n",
    "    @printf(\"Step %d / %d, loss = %f\\n\", s, nb_steps, loss_at_this_step)\n",
    "    @printf(\"a_1 = %f, a_2 = %f, b = %f\\n\", params.a[1],params.a[2],\n",
    "        params.a[3])\n",
    "    @printf(\"\\tgrad = %f\\n\", norm(grad))\n",
    "    @printf(\"rate = %f\\n\",learning_rate)\n",
    "\n",
    "    #push!(param_history,params)\n",
    "    push!(param_history_a1, params.a[1])\n",
    "    push!(param_history_a2, params.a[2])\n",
    "    push!(param_history_a3, params.a[3])\n",
    "    \n",
    "    push!(loss_history, loss_at_this_step)\n",
    "    \n",
    "    #if s == 10\n",
    "        #for i = 1:s\n",
    "        #printNNparam(param_history[i])\n",
    "        #end\n",
    "    #end\n",
    "    #for i = 1:length(x_training[:,1])\n",
    "       push!(output_history,result)\n",
    "    #end\n",
    "end\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" />"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [i for i= 1:nb_steps] ; y = loss_history\n",
    "plot(x,y)\n",
    "title!(\"Steps vs Loss History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" />"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = param_history_a1;\n",
    "y = param_history_a2\n",
    "plot(x,y)\n",
    "title!(\"A1 vs A2 params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAlgAAAGQCAYAAAByNR6YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3XtU1HXi//HXIDAGOSCaCCIgt7Qwr6ycstRK89hFLN0Tq24eUyuzdrO8tNvWr62tTLtt7kp1TEvbwlJza/2qWaLt1iZWZqWlGDiooIkKXhHk/fvD46wjoGJvZgCfj3Pm5MznMu8Pb6hnn8/w0WGMMQIAAIA1Af4eAAAAQFNDYAGwatSoUXI4HCooKPD3UADAbwgsADUqKCiQw+HQwIEDa10nJydHDodDd999t9X3HDVqlJX9AYC/EFgArHr66ae1adMmtWvXzt9DAQC/CfT3AAA0LVFRUYqKivL3MADArziDBcCq2j6DtXDhQvXp00dt2rRR8+bNFR0dreuvv14LFy6UJM2dO1cdOnSQJL3xxhtyOByeR05Ojmc/hw4d0mOPPaaOHTuqefPmioiI0I033qj//Oc/NY5nz549GjdunNq0aaOQkBClpaVp8eLFmjt3rhwOh+bOnetZ99RLlJs2bdKQIUPUqlUrr+NZvHixMjMzlZSUpJCQEIWFhenqq6/2HMepTt/fTTfdpPDwcLVs2VKZmZnas2ePJOnzzz/XddddJ5fLpZYtW2rMmDE6dOjQec4AgIaAM1gA6t2sWbM0fvx4RUVFeaKluLhYa9eu1eLFi3Xbbbepa9eu+t3vfqeXXnpJXbp0UUZGhmf7+Ph4SdLRo0d17bXXau3aterevbt+//vfa9euXcrOztby5cv19ttva9iwYZ7tDh48qD59+mjjxo268sordc0112j79u26/fbbdcMNN9Q63ry8PKWnp6tz584aNWqUSkpKFBwcLEl6+OGHFRwcrN69eysqKko///yz/vnPf2ro0KH661//qvvuu6/a/vLz83XllVeqZ8+eGjNmjNatW6d33nlHhYWFeuaZZzRgwAD1799f48aNU05OjmbPnq2qqiq9/vrrlmYAgM8ZAKhBfn6+kWQSExPNY489VuPjjjvuMJLMXXfd5dnu5Gv5+fme17p3726Cg4PNrl27qr3Pnj17qr3nHXfcUeOYHn/8cSPJDB8+3FRVVXle/+qrr0xwcLAJDw83ZWVlntcfeeQRI8mMGzfOaz8rV640kowkM2fOnGrvL8k8+uijNY5h69at1V47cOCA6dy5swkLCzOHDh2qcX8vvvii5/WqqiozaNAgI8mEh4eb999/37Ps2LFj5oorrjCBgYGmuLi4xjEAaPgILAA1OjUOzvY4l8AKDQ01e/fuPaf3rC2wEhISTFBQkCksLKy2bOzYsUaSefPNNz2vxcfHm+Dg4BpDZcCAAbUGVtu2bU15efkZx3q65557zkgyOTk51faXmJjoFYTGGPPmm28aSaZfv37V9vXnP//ZSDKffPJJncYAoOHgM1gAzuiGG26QOfE/Y9Ueq1atOqd93H777Tp06JBSU1M1adIkLV26VGVlZXUaR1lZmX766SclJSUpJiam2vJ+/fpJktavX+9Zv6CgQElJSYqMjKy2/lVXXVXre3Xp0sVzSfB0u3fv1sSJE9WpUyeFhIR4Pif24IMPSpJ27txZbZsrrrhCDofD67WTvwjQtWvXauufXFbTvgA0DnwGC0C9e+ihh9SqVSvNmjVLzz33nGbMmKHAwEDdeOONeuGFFzwfbj+Tk0FWUyxJ/4uSk+ud/GebNm1qXL+2/Zxp2d69e5WWlia3262rrrpK119/vcLDw9WsWTOtX79eS5YsUXl5ebXtXC5XtdcCAwPPuqyioqLWMQJo2AgsAPXO4XBo9OjRGj16tEpKSvTpp5/q7bff1oIFC7RlyxZt2LBBzZo1O+M+TobIrl27alxeXFzstd7Jf+7evbvG9Wvbz8nx1mT27Nlyu9164okn9Mgjj3gte+aZZ7RkyZIzHAGACwmXCAH4VKtWrZSRkaHs7Gxde+212rhxo/Ly8iTJE1nHjx+vtp3L5VJCQoLy8vK0Y8eOastP3srh5CU3l8ul+Ph45eXl1RhZn332WZ3HvnXrVknS4MGDqy379NNP67w/AE0XgQWg3uXk5MgY4/VaRUWF9u7dK0lq3ry5JKlly5ZyOBwqLCyscT933HGHKioq9PDDD3vtb8OGDZo7d67CwsK8bu8wfPhwHTt2TI899li18SxfvrzOxxEXFydJ+ve//+31+j/+8Q8tXbq0zvsD0HRxiRBAvcvIyJDL5VJ6erri4uJUUVGhjz76SBs3btTQoUM94XLxxRcrLS1Na9as0ciRI5WcnKyAgACNHDlScXFxmjx5sv71r39p3rx52rRpk6677jrt3r1b2dnZqqys1GuvvaYWLVp43nfKlClauHChsrKy9N133+nqq6/W9u3btWDBAt1888364IMPFBBw7v+fOXLkSE2bNk333XefVq1apbi4OH3zzTf6+OOPdeutt2rRokXWv3YAGicCC0C9e/rpp7Vs2TKtXbtWH3zwgUJDQ5WYmKhZs2bpzjvv9Fp33rx5euCBB/Thhx+qtLRUxhj17t1bcXFxat68uT755BNNmzZN2dnZeuGFFxQSEqI+ffroD3/4g3r37u21rxYtWmjNmjV6+OGHtWTJEq1bt06XX3653n77bf3000/64IMPavyQeW1iYmK0evVqTZ48WStXrlRlZaW6d++uFStWqLCwkMAC4OEwp5+3B4ALwIgRI/TWW29p48aN6tSpk7+HA6CJ4TNYAJq0oqKiaq+tXr1a77zzji699FLiCkC94BIhgCZt0KBBuuiii9S1a1eFhoZq48aNWrZsmZo1a6aXX37Z38MD0ERxiRBAk/biiy/qrbfe0tatW3XgwAGFh4frqquu0sMPP6xevXr5e3gAmigCCwAAwDI+gwUAAGAZgQUAAGCZTwPLGKOysrJqd3QGAABoSnwaWAcOHFBYWJgOHDjgy7etd6Wlpf4eAnyAeW76mOMLA/Pc9BUVFcnhcNTpcVFIqNxut7UxcJsGC2r6i2nR9DDPTR9zfGFgnps+z/3vRmZJsd3OvkHxJh2dPUp79uxRbGyslTEQWAAAoGmK7SbFnUNg1QM+5A4AAGAZgQUAAGBZg7pEePDgQe3cuVNVVVX+Hkqd7N+/X+Hh4Z7nAQEBio6O1sUXX+zHUQEAAH9pMIH13//+VxMnTtSxY8f8PZQ6q6qqUkCA98nA4OBgPf/880pPT/fTqAAAgL80iMA6ePCgJk6cqJ49e2rs2LEKCgry95DqpLKyUoGB//tSVlRU6LXXXtPEiRO1YsUKzmQBAHCBaRCBtXPnTh07dkxjx45V586d/T2cOjs9sCRp7Nix+uyzz7Rz506lpKT4aWQAAMAfGsSH3E9+5qqxnbk6k5PH0tg+TwYAAH65BhFYjUlBQYH69u2rsLAwde3a1d/DAQAADVCDuER40p+2XKLtP1b65L1SW0qvXVP3w3e5XHryySdVWlqqP/7xj/UwMgAA0Ng1qMDacihY3xzw1V8E7Tjj0hkzZmjz5s169dVXJZ24FUNSUpI2b96s3r17KycnxwdjBAAAjRGXCGsxZswYvf/++9q/f78kac6cORo8eLAiIiL8PDIAANDQEVi1CA8P19ChQ/X666/LGKNZs2ZpwoQJ/h4WAABoBBrUJcKG5v7779ctt9yiTp066ZJLLlG3bv75CyMBAEDj0qACKzn0mC666CKfvFdqy7Ov07FjRyUkJGjcuHF69tln639QAACgSWhQgfVE8s/q2LGVv4fhZezYsZowYYKGDh0qSTp8+LBSUlJUXl6u0tJSxcTEaPjw4Zo2bZqfRwoAABqKBhVYDdGqVas0fvx4z41DQ0JCtH37dq91Kit9c2sJAADQOBBYtdi5c6euvfZaRUREaPny5f4eDgAAaEQIrFpER0frhx9+8PcwAABAI8RtGgAAACxrEIEVEHBiGMePH/fzSOw5eSwnjw0AAFw4qv3Xf+nSperevbu6du2q1NRUvfHGG5Kk3bt3a+DAgUpOTlZqaqrWrFnj2ebw4cPKzMxUUlKSUlJS9N5779VpEOHh4ZJU7cPjjdnJY2nZ8hzuBwEAAJoUr89gGWM0YsQI5eTk6IorrlBBQYE6duyoW2+9VVOnTlV6erqWLVum3NxcDRkyRPn5+QoKCtKMGTPkdDqVl5en/Px89erVS/369VOrVud2y4XWrVure/fu+tvf/qbIyEg1b968Xg62vlRWViow8H9fyqNHj2rmzJnq0aPHOX8NAABA01HtQ+4Oh8Pz9++VlZWpVatWcjqdWrBggfLy8iRJaWlpio6O1urVq3X99dcrOztbs2fPliR16NBBffv21eLFizVmzJhzGkRAQIAee+wxZWZmnvM2DUlVVVW1S4EhISHKysriEiEAABcgr8ByOBzKzs7WrbfeqtDQUO3bt0+LFi3SgQMHVFFRobZt23rWjY+Pl9vtliS53W7FxcXVuKwmZWVlXs+dTqfatWunlStXyu12N7r7Su3fv99zmVOSAgMDFRsbq+DgYD+OCgAA+ItXYFVWVurJJ5/UokWLdM011yg3N1e33HKL1q9fb/VN27dv7/V88uTJmjJliiQpIiLC6nv5QlBQULXPWh08eNBPo0F92bdvn7+HgHrGHF8YmOemr7S09Ly327t373lte3q/eAXW+vXrtXPnTl1zzTWSTlwKjImJ0YYNGxQYGKji4mLPWayCggLFxsZKkmJjY7Vt2zZFRUV5lg0YMKDWQRQWFsrlcnmeO51OOZ3O8zqghqIxhiHqjnlu+pjjCwPz3LSFhYWd93a2vje8PiDUvn17FRUVadOmTZKkvLw8bd26VZdeeqmGDRumrKwsSVJubq527NihPn36SJLXsvz8fOXk5CgjI6PWN3W5XF6Pxh5XAAAAp/I6gxUZGalXX31Vv/71rxUQEKCqqirNnDlTsbGxmjZtmkaOHKnk5GQFBwdr/vz5nr+fb9KkSRo9erQSExPVrFkzzZw5U61bt/bLAQEAAPhbtd8izMzMVGZmZrUVIyMjtWLFihp3EhoaquzsbPujAwAAaIS4hwAAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBlBBYAAIBl1QKrvLxcEyZMUHJysjp37qwRI0ZIknbv3q2BAwcqOTlZqampWrNmjWebw4cPKzMzU0lJSUpJSdF7773nuyMAAABoYAJPf2Hq1KlyOBzavHmzHA6HiouLPa+np6dr2bJlys3N1ZAhQ5Sfn6+goCDNmDFDTqdTeXl5ys/PV69evdSvXz+1atXK5wcEAADgb15nsA4dOqTZs2frL3/5ixwOhySpbdu2kqQFCxbo7rvvliSlpaUpOjpaq1evliRlZ2d7lnXo0EF9+/bV4sWLfXYQAAAADYlXYG3dulURERF66qmn1LNnT1199dX6+OOPVVJSooqKCk9sSVJ8fLzcbrckye12Ky4ursZlNSkrK/N6lJeX2z4uAAAAv/G6RFhZWalt27bpsssu0zPPPKOvv/5a/fv31/fff2/1Tdu3b+/1fPLkyZoyZYrV9/Clffv2+XsI8AHmueljji8MzHPTV1paet7b7d2797y2jYiI8HruFVixsbEKCAjQ8OHDJUndunVThw4d9O233yowMFDFxcWes1gFBQWKjY31bLdt2zZFRUV5lg0YMKDWQRQWFsrlcnmeO51OOZ3O8zqghuL0LyyaJua56WOOLwzMc9MWFhZ23tvZ+t7wukTYunVrXXfddVq+fLkkKT8/X/n5+erUqZOGDRumrKwsSVJubq527NihPn36SJLXsvz8fOXk5CgjI6PWN3W5XF6Pxh5XAAAAp6r2W4RZWVm68847NWXKFAUEBOiVV15Ru3btNG3aNI0cOVLJyckKDg7W/PnzFRQUJEmaNGmSRo8ercTERDVr1kwzZ85U69atfX4wAAAADUG1wEpISNCqVauqrRgZGakVK1bUuJPQ0FBlZ2fbHx0AAEAjxJ3cAQAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALKsxsObMmSOHw6H3339fkrR7924NHDhQycnJSk1N1Zo1azzrHj58WJmZmUpKSlJKSoree+8934wcAACggQo8/YWCggK99tprSk9P97w2depUpaena9myZcrNzdWQIUOUn5+voKAgzZgxQ06nU3l5ecrPz1evXr3Ur18/tWrVyqcHAgAA0FB4ncGqqqrSmDFj9PLLL8vpdHpeX7Bgge6++25JUlpamqKjo7V69WpJUnZ2tmdZhw4d1LdvXy1evNhX4wcAAGhwvM5gPf/887rqqqvUo0cPz2slJSWqqKhQ27ZtPa/Fx8fL7XZLktxut+Li4mpcVpuysjKv506n0yvoAAAAGjNPYH333XdauHCh1+er6kv79u29nk+ePFlTpkyp9/etL/v27fP3EOADzHPTxxxfGJjnpq+0tPS8t9u7d+95bRsREeH13BNYn376qQoKCpScnCxJKi4u1rhx4/T4448rMDBQxcXFnrNYBQUFio2NlSTFxsZq27ZtioqK8iwbMGDAGQdRWFgol8vled4UzmCd/oVF08Q8N33M8YWBeW7awsLCzns7W98bns9g3XPPPSoqKlJBQYEKCgqUnp6uV199Vffcc4+GDRumrKwsSVJubq527NihPn36SJLXsvz8fOXk5CgjI+OMb+pyubwejT2uAAAATlXttwhrMm3aNI0cOVLJyckKDg7W/PnzFRQUJEmaNGmSRo8ercTERDVr1kwzZ85U69at63XQAAAADVmtgZWTk+P5c2RkpFasWFHjeqGhocrOzrY+MAAAgMaKO7kDAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABYRmABAABY5hVYR48eVUZGhlJSUtSlSxf1799feXl5kqTdu3dr4MCBSk5OVmpqqtasWePZ7vDhw8rMzFRSUpJSUlL03nvv+fYoAAAAGpBqZ7DGjRunH3/8Ud98840GDx6sMWPGSJKmTp2q9PR0bdmyRXPmzNFvfvMbVVRUSJJmzJghp9OpvLw8LV++XOPHj1dJSYlvjwQAAKCB8Aqs5s2ba9CgQXI4HJKk9PR0FRQUSJIWLFigu+++W5KUlpam6OhorV69WpKUnZ3tWdahQwf17dtXixcv9tUxAAAANCiBZ1r40ksvafDgwSopKVFFRYXatm3rWRYfHy+32y1JcrvdiouLq3FZTcrKyryeO51OOZ3O8zoAAACAhqbWwHrqqaeUl5enjz/+WEeOHLH6pu3bt/d6PnnyZE2ZMsXqe/jSvn37/D0E+ADz3PQxxxcG5rnpKy0tPe/t9u7de17bRkREeD2vMbBmzJihRYsWaeXKlQoJCVFISIgCAwNVXFzsOYtVUFCg2NhYSVJsbKy2bdumqKgoz7IBAwbUOojCwkK5XC7P86ZwBuv0LyyaJua56WOOLwzMc9MWFhZ23tvZ+t6o9iH3559/Xm+//bY++ugjhYeHe14fNmyYsrKyJEm5ubnasWOH+vTpU21Zfn6+cnJylJGRUeubulwur0djjysAAIBTeZ3B2r59ux588EElJCSoX79+kk6cXfriiy80bdo0jRw5UsnJyQoODtb8+fMVFBQkSZo0aZJGjx6txMRENWvWTDNnzlTr1q19fzQAAAANgFdgxcTEyBhT44qRkZFasWJFjctCQ0OVnZ1tf3QAAACNEHdyBwAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsIzAAgAAsCzQ3wMAAAA4m6KiIhUVFZ3Tups2barn0ZwdgQUAABq0oqIiRUdH+3sYdUJgAQCABs1z5mpklhTb7ewbfPd/0pL/V69jOhsCCwAANA6x3aS4cwisoh/qfyxnwYfcAQAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwAAAALCOwfqHy8nJNmzZN5eXl/h4K6hHz3PQxxxcG5hm+Yi2wtmzZoiuvvFIpKSlKS0vT999/b2vXDVp5ebmeffZZflibOOa56WOOLwzMM3zFWmDdddddGjdunDZv3qwpU6Zo1KhRtnYNAADQqFgJrN27d2vdunUaMWKEJOm2225TYWGh8vLybOweAACgUQm0sZPCwkJFRUUpMPDE7hwOh2JjY+V2u5WUlORZzxgjSdqxY4fKyso8rzudTjmdznN6r/Xr1+ubb74557E1b95cR48ePef167rNkSNHJElZWVm66KKL6mVMDW39hjim+l7/QpznC+37whdzfD7bNPb1G9qYGuLPsi/eo7GvX1hYeOIP7q+k8oNn36B4U93W37VZknTw4EGvPqmrFi1ayOFwnHhiLFi3bp1JSUnxei0tLc18/PHHXq8VFhYaSTx48ODBgwcPHk3uUVpa6mkeK2ew2rdvr6KiIlVWViowMFDGGLndbsXGxnqtFx0dra1btyooKOh/hae6ncECAABoiFq0aOH5s5XAatOmjbp376758+dr1KhRWrhwoWJiYrwuD0pSQECAEhISbLwlAABAg+UwJz8Y9Qv9+OOPGjVqlEpKSuRyuTRnzhx17tzZxq4BAAAaFWuBBQAAgBO4k3stzvXGqdOnT1dqaqouu+wyDRkyRPv37/cs27dvn4YPH66UlBRdfvnlmjp1qq+Gj3P0S+f522+/VdeuXT2P+Ph4RURE+PIQcA5s/Dy/8cYb6ty5s7p27apu3bpp6dKlvho+zoGNOZ43b566dOmi1NRUXXfddXK73b4aPs7B/fffr/j4eDkcDq1fv77W9T788EN17NhRycnJuvXWW71+K/CLL75Qly5dlJKSomuvvVY7duyovwHb+C3Cpqhfv35mzpw5xhhj3n33XdOzZ89q66xYscJ06tTJlJWVGWOMeeKJJ8z48eM9yzMyMsz06dM9z4uKiup30KgzG/N8qnvvvddMmDCh3saL8/NL57mkpMS0aNHC8zP86aefmksuucQ3g8c5+aX0ldsZAAAEWElEQVRzvGnTJhMZGWl27txpjDFm3rx5ZtCgQb4ZPM7J6tWrTWFhoYmLizNff/11jescOHDAtGnTxmzatMkYc+LfyQ899JAxxpjjx4+bxMRE88knnxhjjJk+fboZOnRovY2XwKrBrl27TIsWLUxFRYUxxpiqqioTGRlptmzZ4rXe9OnTzdixYz3Pv/zyS9OiRQtjjDFbtmwxMTEx5vjx474bOOrExjyf6siRIyY8PLzWH3z4h415/vnnn83FF19sNm/ebIwx5oMPPjDdunXz0RHgbGzM8bvvvmv69+/vWVZSUmIcDofZs2ePD44AdXGmwFqwYIG54YYbPM+///57065dO2OMMWvXrjWXXnqpZ1lZWZlxOp3myJEj9TJOLhHW4Ew3Tj1Vjx49tHLlShUXF8sYo7feeksHDhzQ3r17tXHjRsXExOiee+5Rjx49NGDAAH399df+OBzUwsY8n2rRokVKSEhQ165dfXYMODsb89y6dWtlZWWpe/fuiouL0+jRozV37lw/HA1qYmOOu3Tpoq+++kqbN5+44eT8+fNljNG2bdt8fjw4f263W3FxcZ7n8fHxnttInb6sRYsWcrlc2rlzZ72MhcD6Bfr166eHHnpIN910k9LT03XJJZdIkgIDA1VZWam1a9fq9ttv15dffqkHHnhAN910kyoqKvw8atTVmeb5VLNnz9add97pjyHCgjPNc2lpqV566SWtXbtW27Zt0+zZszVkyBAdO3bMz6NGXZxpjpOTk5WVlaXf/va36tmzp0pKShQeHl7t5xw4Z/VyXqyRO9fTzaf7/PPPTUxMjDHGmNzcXNO+fXuv5a1btz7rPuA7Nub5pJ9++smEhISYffv21dt4cX5szPPpl4+MOfHzfPKSIfzL5s/ySUVFRcbpdJpDhw5ZHy9+GZuXCIODg7lE6Eun3jhVUq03TpWkoqIiSdLhw4f16KOPavLkyZJOnIp2uVzasGGDJGnt2rUyxqh9+/Y+OgqcjY15Pun111/XkCFDFB4eXv8DR53YmOeEhAStX79excXFkqTPP/9clZWV/Dw3ELZ+lk8uO378uKZMmaJ7771XISEhPjgC2DJw4EB99dVX+uGHHyRJf//733X77bdLOvHf5YqKCq1atUqS9Morr+jmm29W8+bN62cw9ZJtTcAPP/xg0tPTTXJysunRo4fZsGGDMcaYP/3pT2bWrFme9VJTU81ll11mkpKSzOOPP26qqqo8y9atW2d+9atfmc6dO5uePXuanJwcnx8HzszGPB8/ftzExMR4fjMFDY+NeX7xxRdNp06dzBVXXGG6d+9uVqxY4fPjQO1szPHAgQNNp06dTEJCgrnvvvvM0aNHfX4cqN24ceNMu3btTLNmzUybNm1MYmKiMab6HC9ZssRceumlJjEx0QwePNjs37/fs+yzzz4znTt3NsnJyaZPnz7G7XbX23i50SgAAIBlXCIEAACwjMACAACwjMACAACw7P8Dbt+XyYtL4B0AAAAASUVORK5CYII=\" />"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Histogram of Final Output\n",
    "histogram(output_history, bins= 50)\n",
    "title!(\"Histogram\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Array{Float64,1}:\n",
       " 0.996958\n",
       " 0.992427\n",
       " 0.999961\n",
       " 0.999105\n",
       " 0.9993  \n",
       " 0.99997 \n",
       " 0.999974\n",
       " 0.999349\n",
       " 0.957532\n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " ⋮       \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     \n",
       " 1.0     "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: y_training not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: y_training not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "sum(y_training.==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
