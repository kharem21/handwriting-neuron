{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNparams([0.289862, 0.90701, 0.63549])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type NNparams\n",
    "    a::Array{Float64}\n",
    "end \n",
    "toyparams = NNparams([rand(),rand(),rand()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6224593312018546"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function σ(z::Float64)\n",
    "    return 1.0 / (1.0 + exp(-z))\n",
    "end\n",
    "σ(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: ∇ not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: ∇ not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "function updateNNparams(gradient::Array{Float64,1}, \n",
    "                        params::NNparams, learning_rate::Float64)\n",
    "   params.a = params.a - gradient*learning_rate\n",
    "    return params\n",
    "end\n",
    "#test\n",
    "toyparams = NNparams([rand(),rand(),rand()])\n",
    "grad = ∇(x,y,toyparams)\n",
    "updateNNparams(grad,toyparams,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printNNparam (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function printNNparam(param::NNparams)\n",
    "    @printf(\"PrintNN ==> %f %f %f\\n\", param.a[1], param.a[2], param.a[3])\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function output(params::NNparams, x::Array{Float64,1})\n",
    "    #nb_data = size(x[1,:])\n",
    "    #for i = 1:nb_data\n",
    "    #x = x[i, :]\n",
    "    return σ(dot(params.a,x))\n",
    "    #end\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(params::NNparams, yi::Array{Float64,1}, \n",
    "                x::Array{Float64,2})\n",
    "    nb_data = size(x)[1]\n",
    "     y_pred = zeros(length(yi))\n",
    "    @assert(size(x)[1]== length(yi))\n",
    "   for i = 1:nb_data\n",
    "        y_pred[i]= output(params,x[i,:])\n",
    "    end\n",
    "    return sum(yi.*log.(1e-7+y_pred) .+ (1-yi).*log.(1e-7+1-y_pred))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇ (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradient \n",
    "function ∇(x::Array{Float64,2},y::Array{Float64,1}, params::NNparams)\n",
    "    grad = [0.0 for i=1:size(x)[2]]\n",
    "    nb_data = size(x)[1]\n",
    "    for i = 1:nb_data\n",
    "        xi = x[i, :]\n",
    "        yi = y[i]\n",
    "        y_pred = output(params, xi)\n",
    "        grad = grad .+ xi.*(yi - y_pred)\n",
    "    end\n",
    "    grad = grad/ nb_data\n",
    "    return grad::Array{Float64,1}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convertdata_to_array (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function convertdata_to_array(dtf::DataFrame)\n",
    "    nb_data = size(dtf)[1]\n",
    "        x = zeros(Float64, nb_data, 3)\n",
    "        \n",
    "        x[:,1] = dtf[:x1]\n",
    "        x[:,2] = dtf[:x2]\n",
    "        x[:,3] = ones(Float64,size(x)[1])\n",
    "        \n",
    "        y = convert(Array, dtf[:y]) * 1.0\n",
    "        #x = convert(Array, df[:x1], df[:x2], ones(Float64, size(x)[1]))\n",
    "        return x,y\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.135437\n",
       " 0.52602 \n",
       " 0.548247\n",
       " 0.4612  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_params(x::Array{Float64,2})\n",
    "    return [rand() for i = 1:size(x[1, :])[1]]\n",
    "    end \n",
    "test = init_params(rand(4,4))\n",
    "x= rand(5,5)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "select_trainingdata (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function select_trainingdata(x::Array{Float64,2}, y::Array{Float64,1}, batch_size::Int)\n",
    "    nb_data = length(y)\n",
    "    \n",
    "    ids = [i for i = 1:nb_data]\n",
    "    sampled_ids = sample(ids, batch_size)\n",
    "    \n",
    "    x_training = x[sampled_ids, :]\n",
    "    y_training = y[sampled_ids]\n",
    "    \n",
    "    return x_training, y_training\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: dtf not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: dtf not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "x,y = convertdata_to_array(dtf)\n",
    "testparams = init_params(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_learning_rate (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_learning_rate(init_learning_rate::Float64, nb_steps::Int)\n",
    "    return init_learning_rate* ((1.0)/ (1.0 + (.05*nb_steps)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 / 1000, loss = -1157.449084\n",
      "a_1 = 0.126641, a_2 = 0.362720, b = 0.500172\n",
      "\tgrad = 1.885241\n",
      "rate = 0.066667\n",
      "Step 2 / 1000, loss = -1534.416328\n",
      "a_1 = 0.248630, a_2 = 0.454906, b = 0.528224\n",
      "\tgrad = 2.442868\n",
      "rate = 0.063636\n",
      "Step 3 / 1000, loss = -1920.869562\n",
      "a_1 = 0.367813, a_2 = 0.542419, b = 0.556414\n",
      "\tgrad = 2.472914\n",
      "rate = 0.060870\n",
      "Step 4 / 1000, loss = -2313.124115\n",
      "a_1 = 0.488878, a_2 = 0.625526, b = 0.583925\n",
      "\tgrad = 2.561138\n",
      "rate = 0.058333\n",
      "Step 5 / 1000, loss = -2715.790442\n",
      "a_1 = 0.609962, a_2 = 0.712754, b = 0.611962\n",
      "\tgrad = 2.711489\n",
      "rate = 0.056000\n",
      "Step 6 / 1000, loss = -3089.410990\n",
      "a_1 = 0.720049, a_2 = 0.795809, b = 0.638094\n",
      "\tgrad = 2.606625\n",
      "rate = 0.053846\n",
      "Step 7 / 1000, loss = -3473.074328\n",
      "a_1 = 0.837752, a_2 = 0.874751, b = 0.664206\n",
      "\tgrad = 2.779263\n",
      "rate = 0.051852\n",
      "Step 8 / 1000, loss = -3809.802286\n",
      "a_1 = 0.938789, a_2 = 0.948584, b = 0.687957\n",
      "\tgrad = 2.547448\n",
      "rate = 0.050000\n",
      "Step 9 / 1000, loss = -4141.516989\n",
      "a_1 = 1.041298, a_2 = 1.020601, b = 0.711468\n",
      "\tgrad = 2.640345\n",
      "rate = 0.048276\n",
      "Step 10 / 1000, loss = -4456.405488\n",
      "a_1 = 1.144136, a_2 = 1.086801, b = 0.734795\n",
      "\tgrad = 2.668038\n",
      "rate = 0.046667\n",
      "Step 11 / 1000, loss = -4749.346228\n",
      "a_1 = 1.240810, a_2 = 1.155512, b = 0.758024\n",
      "\tgrad = 2.676150\n",
      "rate = 0.045161\n",
      "Step 12 / 1000, loss = -5013.949487\n",
      "a_1 = 1.334636, a_2 = 1.220228, b = 0.778910\n",
      "\tgrad = 2.648630\n",
      "rate = 0.043750\n",
      "Step 13 / 1000, loss = -5250.470218\n",
      "a_1 = 1.423763, a_2 = 1.283751, b = 0.799904\n",
      "\tgrad = 2.626877\n",
      "rate = 0.042424\n",
      "Step 14 / 1000, loss = -5462.714030\n",
      "a_1 = 1.513058, a_2 = 1.343002, b = 0.819580\n",
      "\tgrad = 2.646084\n",
      "rate = 0.041176\n",
      "Step 15 / 1000, loss = -5649.495053\n",
      "a_1 = 1.597739, a_2 = 1.402092, b = 0.839184\n",
      "\tgrad = 2.627583\n",
      "rate = 0.040000\n",
      "Step 16 / 1000, loss = -5817.378833\n",
      "a_1 = 1.681638, a_2 = 1.460435, b = 0.858708\n",
      "\tgrad = 2.675291\n",
      "rate = 0.038889\n",
      "Step 17 / 1000, loss = -5967.600878\n",
      "a_1 = 1.762914, a_2 = 1.519776, b = 0.877586\n",
      "\tgrad = 2.706005\n",
      "rate = 0.037838\n",
      "Step 18 / 1000, loss = -6091.068142\n",
      "a_1 = 1.836002, a_2 = 1.572960, b = 0.894635\n",
      "\tgrad = 2.496699\n",
      "rate = 0.036842\n",
      "Step 19 / 1000, loss = -6203.348633\n",
      "a_1 = 1.909168, a_2 = 1.623953, b = 0.912097\n",
      "\tgrad = 2.531548\n",
      "rate = 0.035897\n",
      "Step 20 / 1000, loss = -6306.769861\n",
      "a_1 = 1.981164, a_2 = 1.676079, b = 0.928990\n",
      "\tgrad = 2.585024\n",
      "rate = 0.035000\n",
      "Step 21 / 1000, loss = -6396.940142\n",
      "a_1 = 2.051397, a_2 = 1.722221, b = 0.944603\n",
      "\tgrad = 2.503127\n",
      "rate = 0.034146\n",
      "Step 22 / 1000, loss = -6483.434337\n",
      "a_1 = 2.124471, a_2 = 1.768958, b = 0.960847\n",
      "\tgrad = 2.647492\n",
      "rate = 0.033333\n",
      "Step 23 / 1000, loss = -6566.794032\n",
      "a_1 = 2.198130, a_2 = 1.819616, b = 0.977460\n",
      "\tgrad = 2.792793\n",
      "rate = 0.032558\n",
      "Step 24 / 1000, loss = -6644.420502\n",
      "a_1 = 2.270619, a_2 = 1.871449, b = 0.994009\n",
      "\tgrad = 2.848603\n",
      "rate = 0.031818\n",
      "Step 25 / 1000, loss = -6708.818734\n",
      "a_1 = 2.336860, a_2 = 1.915095, b = 1.008858\n",
      "\tgrad = 2.594084\n",
      "rate = 0.031111\n",
      "Step 26 / 1000, loss = -6769.957184\n",
      "a_1 = 2.403103, a_2 = 1.959758, b = 1.023845\n",
      "\tgrad = 2.670845\n",
      "rate = 0.030435\n",
      "Step 27 / 1000, loss = -6826.446100\n",
      "a_1 = 2.466481, a_2 = 2.005462, b = 1.038102\n",
      "\tgrad = 2.666535\n",
      "rate = 0.029787\n",
      "Step 28 / 1000, loss = -6880.061879\n",
      "a_1 = 2.529569, a_2 = 2.052001, b = 1.053044\n",
      "\tgrad = 2.736276\n",
      "rate = 0.029167\n",
      "Step 29 / 1000, loss = -6929.117655\n",
      "a_1 = 2.594289, a_2 = 2.093842, b = 1.067004\n",
      "\tgrad = 2.741229\n",
      "rate = 0.028571\n",
      "Step 30 / 1000, loss = -6975.821814\n",
      "a_1 = 2.659069, a_2 = 2.136635, b = 1.081065\n",
      "\tgrad = 2.817920\n",
      "rate = 0.028000\n",
      "Step 31 / 1000, loss = -7018.544397\n",
      "a_1 = 2.720604, a_2 = 2.179173, b = 1.095026\n",
      "\tgrad = 2.772152\n",
      "rate = 0.027451\n",
      "Step 32 / 1000, loss = -7057.284069\n",
      "a_1 = 2.778628, a_2 = 2.220601, b = 1.108962\n",
      "\tgrad = 2.698222\n",
      "rate = 0.026923\n",
      "Step 33 / 1000, loss = -7093.922496\n",
      "a_1 = 2.839887, a_2 = 2.258990, b = 1.122390\n",
      "\tgrad = 2.783661\n",
      "rate = 0.026415\n",
      "Step 34 / 1000, loss = -7126.210760\n",
      "a_1 = 2.894253, a_2 = 2.296979, b = 1.135111\n",
      "\tgrad = 2.604823\n",
      "rate = 0.025926\n",
      "Step 35 / 1000, loss = -7155.302981\n",
      "a_1 = 2.946266, a_2 = 2.332548, b = 1.146911\n",
      "\tgrad = 2.518507\n",
      "rate = 0.025455\n",
      "Step 36 / 1000, loss = -7185.293399\n",
      "a_1 = 3.001526, a_2 = 2.372168, b = 1.159678\n",
      "\tgrad = 2.767350\n",
      "rate = 0.025000\n",
      "Step 37 / 1000, loss = -7213.903389\n",
      "a_1 = 3.057662, a_2 = 2.411435, b = 1.172612\n",
      "\tgrad = 2.838476\n",
      "rate = 0.024561\n",
      "Step 38 / 1000, loss = -7239.701221\n",
      "a_1 = 3.111865, a_2 = 2.448068, b = 1.184605\n",
      "\tgrad = 2.755475\n",
      "rate = 0.024138\n",
      "Step 39 / 1000, loss = -7264.500385\n",
      "a_1 = 3.164285, a_2 = 2.487188, b = 1.196886\n",
      "\tgrad = 2.804656\n",
      "rate = 0.023729\n",
      "Step 40 / 1000, loss = -7286.718247\n",
      "a_1 = 3.215116, a_2 = 2.522567, b = 1.208685\n",
      "\tgrad = 2.701919\n",
      "rate = 0.023333\n",
      "Step 41 / 1000, loss = -7306.792501\n",
      "a_1 = 3.261763, a_2 = 2.557403, b = 1.219743\n",
      "\tgrad = 2.582041\n",
      "rate = 0.022951\n",
      "Step 42 / 1000, loss = -7325.317808\n",
      "a_1 = 3.308864, a_2 = 2.589037, b = 1.230641\n",
      "\tgrad = 2.558632\n",
      "rate = 0.022581\n",
      "Step 43 / 1000, loss = -7343.802503\n",
      "a_1 = 3.358161, a_2 = 2.622184, b = 1.241416\n",
      "\tgrad = 2.716831\n",
      "rate = 0.022222\n",
      "Step 44 / 1000, loss = -7360.419970\n",
      "a_1 = 3.404287, a_2 = 2.653172, b = 1.251975\n",
      "\tgrad = 2.585719\n",
      "rate = 0.021875\n",
      "Step 45 / 1000, loss = -7377.554162\n",
      "a_1 = 3.451544, a_2 = 2.688840, b = 1.262808\n",
      "\tgrad = 2.794547\n",
      "rate = 0.021538\n",
      "Step 46 / 1000, loss = -7393.336143\n",
      "a_1 = 3.499048, a_2 = 2.721250, b = 1.273347\n",
      "\tgrad = 2.756181\n",
      "rate = 0.021212\n",
      "Step 47 / 1000, loss = -7408.209203\n",
      "a_1 = 3.543441, a_2 = 2.754790, b = 1.283977\n",
      "\tgrad = 2.710883\n",
      "rate = 0.020896\n",
      "Step 48 / 1000, loss = -7421.278803\n",
      "a_1 = 3.586754, a_2 = 2.783059, b = 1.293506\n",
      "\tgrad = 2.554440\n",
      "rate = 0.020588\n",
      "Step 49 / 1000, loss = -7433.964504\n",
      "a_1 = 3.629860, a_2 = 2.811792, b = 1.303156\n",
      "\tgrad = 2.597198\n",
      "rate = 0.020290\n",
      "Step 50 / 1000, loss = -7445.702393\n",
      "a_1 = 3.669900, a_2 = 2.840210, b = 1.312569\n",
      "\tgrad = 2.499656\n",
      "rate = 0.020000\n",
      "Step 51 / 1000, loss = -7457.924794\n",
      "a_1 = 3.713557, a_2 = 2.870443, b = 1.322482\n",
      "\tgrad = 2.739597\n",
      "rate = 0.019718\n",
      "Step 52 / 1000, loss = -7469.975522\n",
      "a_1 = 3.757680, a_2 = 2.901626, b = 1.332589\n",
      "\tgrad = 2.826882\n",
      "rate = 0.019444\n",
      "Step 53 / 1000, loss = -7480.262634\n",
      "a_1 = 3.797556, a_2 = 2.927970, b = 1.341885\n",
      "\tgrad = 2.538732\n",
      "rate = 0.019178\n",
      "Step 54 / 1000, loss = -7491.343629\n",
      "a_1 = 3.841240, a_2 = 2.958100, b = 1.351608\n",
      "\tgrad = 2.851674\n",
      "rate = 0.018919\n",
      "Step 55 / 1000, loss = -7501.631616\n",
      "a_1 = 3.883306, a_2 = 2.986729, b = 1.360898\n",
      "\tgrad = 2.770987\n",
      "rate = 0.018667\n",
      "Step 56 / 1000, loss = -7511.808381\n",
      "a_1 = 3.926001, a_2 = 3.016069, b = 1.370310\n",
      "\tgrad = 2.858284\n",
      "rate = 0.018421\n",
      "Step 57 / 1000, loss = -7520.806941\n",
      "a_1 = 3.964768, a_2 = 3.042419, b = 1.379433\n",
      "\tgrad = 2.626428\n",
      "rate = 0.018182\n",
      "Step 58 / 1000, loss = -7530.194378\n",
      "a_1 = 4.006813, a_2 = 3.070533, b = 1.388726\n",
      "\tgrad = 2.865147\n",
      "rate = 0.017949\n",
      "Step 59 / 1000, loss = -7538.981874\n",
      "a_1 = 4.046021, a_2 = 3.098661, b = 1.397656\n",
      "\tgrad = 2.769127\n",
      "rate = 0.017722\n",
      "Step 60 / 1000, loss = -7547.473889\n",
      "a_1 = 4.086122, a_2 = 3.125506, b = 1.406474\n",
      "\tgrad = 2.803254\n",
      "rate = 0.017500\n",
      "Step 61 / 1000, loss = -7555.692578\n",
      "a_1 = 4.124405, a_2 = 3.153410, b = 1.415392\n",
      "\tgrad = 2.788989\n",
      "rate = 0.017284\n",
      "Step 62 / 1000, loss = -7563.350460\n",
      "a_1 = 4.160845, a_2 = 3.180189, b = 1.423874\n",
      "\tgrad = 2.694881\n",
      "rate = 0.017073\n",
      "Step 63 / 1000, loss = -7571.084819\n",
      "a_1 = 4.199091, a_2 = 3.207399, b = 1.432678\n",
      "\tgrad = 2.831244\n",
      "rate = 0.016867\n",
      "Step 64 / 1000, loss = -7578.239892\n",
      "a_1 = 4.235609, a_2 = 3.233014, b = 1.440891\n",
      "\tgrad = 2.721356\n",
      "rate = 0.016667\n",
      "Step 65 / 1000, loss = -7584.975960\n",
      "a_1 = 4.270875, a_2 = 3.257478, b = 1.448960\n",
      "\tgrad = 2.651560\n",
      "rate = 0.016471\n",
      "Step 66 / 1000, loss = -7592.033647\n",
      "a_1 = 4.308287, a_2 = 3.284344, b = 1.457211\n",
      "\tgrad = 2.874365\n",
      "rate = 0.016279\n",
      "Step 67 / 1000, loss = -7598.274213\n",
      "a_1 = 4.340319, a_2 = 3.309916, b = 1.465159\n",
      "\tgrad = 2.594569\n",
      "rate = 0.016092\n",
      "Step 68 / 1000, loss = -7604.375605\n",
      "a_1 = 4.373860, a_2 = 3.334207, b = 1.472889\n",
      "\tgrad = 2.648011\n",
      "rate = 0.015909\n",
      "Step 69 / 1000, loss = -7610.061173\n",
      "a_1 = 4.405872, a_2 = 3.357098, b = 1.480406\n",
      "\tgrad = 2.547064\n",
      "rate = 0.015730\n",
      "Step 70 / 1000, loss = -7615.879505\n",
      "a_1 = 4.439589, a_2 = 3.380949, b = 1.487995\n",
      "\tgrad = 2.699474\n",
      "rate = 0.015556\n",
      "Step 71 / 1000, loss = -7621.629503\n",
      "a_1 = 4.474465, a_2 = 3.404332, b = 1.495546\n",
      "\tgrad = 2.773071\n",
      "rate = 0.015385\n",
      "Step 72 / 1000, loss = -7627.040152\n",
      "a_1 = 4.506909, a_2 = 3.427557, b = 1.503062\n",
      "\tgrad = 2.668095\n",
      "rate = 0.015217\n",
      "Step 73 / 1000, loss = -7632.332001\n",
      "a_1 = 4.539844, a_2 = 3.450239, b = 1.510542\n",
      "\tgrad = 2.702565\n",
      "rate = 0.015054\n",
      "Step 74 / 1000, loss = -7637.215093\n",
      "a_1 = 4.570340, a_2 = 3.471921, b = 1.517719\n",
      "\tgrad = 2.558171\n",
      "rate = 0.014894\n",
      "Step 75 / 1000, loss = -7641.685975\n",
      "a_1 = 4.599095, a_2 = 3.491799, b = 1.524465\n",
      "\tgrad = 2.415845\n",
      "rate = 0.014737\n",
      "Step 76 / 1000, loss = -7646.543153\n",
      "a_1 = 4.630939, a_2 = 3.513804, b = 1.531888\n",
      "\tgrad = 2.702575\n",
      "rate = 0.014583\n",
      "Step 77 / 1000, loss = -7651.270111\n",
      "a_1 = 4.662466, a_2 = 3.535794, b = 1.539118\n",
      "\tgrad = 2.709911\n",
      "rate = 0.014433\n",
      "Step 78 / 1000, loss = -7655.955894\n",
      "a_1 = 4.694162, a_2 = 3.558254, b = 1.546302\n",
      "\tgrad = 2.765425\n",
      "rate = 0.014286\n",
      "Step 79 / 1000, loss = -7660.222106\n",
      "a_1 = 4.723200, a_2 = 3.579304, b = 1.553103\n",
      "\tgrad = 2.581350\n",
      "rate = 0.014141\n",
      "Step 80 / 1000, loss = -7664.451413\n",
      "a_1 = 4.753897, a_2 = 3.599175, b = 1.560088\n",
      "\tgrad = 2.659169\n",
      "rate = 0.014000\n",
      "Step 81 / 1000, loss = -7668.826474\n",
      "a_1 = 4.784026, a_2 = 3.622330, b = 1.567198\n",
      "\tgrad = 2.788913\n",
      "rate = 0.013861\n",
      "Step 82 / 1000, loss = -7672.725361\n",
      "a_1 = 4.812172, a_2 = 3.642561, b = 1.573689\n",
      "\tgrad = 2.569301\n",
      "rate = 0.013725\n",
      "Step 83 / 1000, loss = -7676.707572\n",
      "a_1 = 4.841154, a_2 = 3.663908, b = 1.580333\n",
      "\tgrad = 2.692948\n",
      "rate = 0.013592\n",
      "Step 84 / 1000, loss = -7680.647853\n",
      "a_1 = 4.870696, a_2 = 3.684881, b = 1.587264\n",
      "\tgrad = 2.740214\n",
      "rate = 0.013462\n",
      "Step 85 / 1000, loss = -7684.357070\n",
      "a_1 = 4.898771, a_2 = 3.705218, b = 1.593837\n",
      "\tgrad = 2.646307\n",
      "rate = 0.013333\n",
      "Step 86 / 1000, loss = -7687.981172\n",
      "a_1 = 4.926082, a_2 = 3.725952, b = 1.600372\n",
      "\tgrad = 2.642976\n",
      "rate = 0.013208\n",
      "Step 87 / 1000, loss = -7691.452057\n",
      "a_1 = 4.954034, a_2 = 3.744907, b = 1.606705\n",
      "\tgrad = 2.626147\n",
      "rate = 0.013084\n",
      "Step 88 / 1000, loss = -7694.859310\n",
      "a_1 = 4.981459, a_2 = 3.764294, b = 1.612952\n",
      "\tgrad = 2.635344\n",
      "rate = 0.012963\n",
      "Step 89 / 1000, loss = -7698.439926\n",
      "a_1 = 5.011196, a_2 = 3.784655, b = 1.619565\n",
      "\tgrad = 2.852804\n",
      "rate = 0.012844\n",
      "Step 90 / 1000, loss = -7701.644519\n",
      "a_1 = 5.038114, a_2 = 3.803316, b = 1.625560\n",
      "\tgrad = 2.616246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate = 0.012727\n",
      "Step 91 / 1000, loss = -7704.723951\n",
      "a_1 = 5.065204, a_2 = 3.820584, b = 1.631612\n",
      "\tgrad = 2.591913\n",
      "rate = 0.012613\n",
      "Step 92 / 1000, loss = -7707.753064\n",
      "a_1 = 5.091351, a_2 = 3.838630, b = 1.637687\n",
      "\tgrad = 2.587650\n",
      "rate = 0.012500\n",
      "Step 93 / 1000, loss = -7710.837844\n",
      "a_1 = 5.118762, a_2 = 3.857022, b = 1.643869\n",
      "\tgrad = 2.710651\n",
      "rate = 0.012389\n",
      "Step 94 / 1000, loss = -7713.838884\n",
      "a_1 = 5.145992, a_2 = 3.874996, b = 1.650032\n",
      "\tgrad = 2.703784\n",
      "rate = 0.012281\n",
      "Step 95 / 1000, loss = -7716.704709\n",
      "a_1 = 5.171221, a_2 = 3.893663, b = 1.655813\n",
      "\tgrad = 2.621363\n",
      "rate = 0.012174\n",
      "Step 96 / 1000, loss = -7719.526356\n",
      "a_1 = 5.196767, a_2 = 3.911856, b = 1.661749\n",
      "\tgrad = 2.644690\n",
      "rate = 0.012069\n",
      "Step 97 / 1000, loss = -7722.437415\n",
      "a_1 = 5.223810, a_2 = 3.930681, b = 1.667910\n",
      "\tgrad = 2.801432\n",
      "rate = 0.011966\n",
      "Step 98 / 1000, loss = -7725.080331\n",
      "a_1 = 5.248283, a_2 = 3.948564, b = 1.673439\n",
      "\tgrad = 2.596848\n",
      "rate = 0.011864\n",
      "Step 99 / 1000, loss = -7727.635286\n",
      "a_1 = 5.273139, a_2 = 3.965054, b = 1.679109\n",
      "\tgrad = 2.580866\n",
      "rate = 0.011765\n",
      "Step 100 / 1000, loss = -7730.125459\n",
      "a_1 = 5.296480, a_2 = 3.982598, b = 1.684580\n",
      "\tgrad = 2.546351\n",
      "rate = 0.011667\n",
      "Step 101 / 1000, loss = -7732.491414\n",
      "a_1 = 5.320444, a_2 = 3.997953, b = 1.689994\n",
      "\tgrad = 2.503936\n",
      "rate = 0.011570\n",
      "Step 102 / 1000, loss = -7735.115914\n",
      "a_1 = 5.344865, a_2 = 4.017653, b = 1.696018\n",
      "\tgrad = 2.784223\n",
      "rate = 0.011475\n",
      "Step 103 / 1000, loss = -7737.550760\n",
      "a_1 = 5.369784, a_2 = 4.034294, b = 1.701754\n",
      "\tgrad = 2.680437\n",
      "rate = 0.011382\n",
      "Step 104 / 1000, loss = -7739.994054\n",
      "a_1 = 5.394477, a_2 = 4.051954, b = 1.707467\n",
      "\tgrad = 2.735996\n",
      "rate = 0.011290\n",
      "Step 105 / 1000, loss = -7742.363660\n",
      "a_1 = 5.418147, a_2 = 4.070042, b = 1.712921\n",
      "\tgrad = 2.704041\n",
      "rate = 0.011200\n",
      "Step 106 / 1000, loss = -7744.756759\n",
      "a_1 = 5.443349, a_2 = 4.087481, b = 1.718676\n",
      "\tgrad = 2.806492\n",
      "rate = 0.011111\n",
      "Step 107 / 1000, loss = -7746.990993\n",
      "a_1 = 5.466166, a_2 = 4.105006, b = 1.724076\n",
      "\tgrad = 2.655513\n",
      "rate = 0.011024\n",
      "Step 108 / 1000, loss = -7749.307062\n",
      "a_1 = 5.490874, a_2 = 4.122763, b = 1.729697\n",
      "\tgrad = 2.828915\n",
      "rate = 0.010938\n",
      "Step 109 / 1000, loss = -7751.452096\n",
      "a_1 = 5.514259, a_2 = 4.139145, b = 1.735069\n",
      "\tgrad = 2.677085\n",
      "rate = 0.010853\n",
      "Step 110 / 1000, loss = -7753.562072\n",
      "a_1 = 5.537968, a_2 = 4.155099, b = 1.740389\n",
      "\tgrad = 2.699149\n",
      "rate = 0.010769\n",
      "Step 111 / 1000, loss = -7755.531995\n",
      "a_1 = 5.559820, a_2 = 4.170608, b = 1.745529\n",
      "\tgrad = 2.553012\n",
      "rate = 0.010687\n",
      "Step 112 / 1000, loss = -7757.406587\n",
      "a_1 = 5.582062, a_2 = 4.184401, b = 1.750450\n",
      "\tgrad = 2.510840\n",
      "rate = 0.010606\n",
      "Step 113 / 1000, loss = -7759.394945\n",
      "a_1 = 5.605031, a_2 = 4.200087, b = 1.755722\n",
      "\tgrad = 2.689437\n",
      "rate = 0.010526\n",
      "Step 114 / 1000, loss = -7761.215202\n",
      "a_1 = 5.625195, a_2 = 4.215584, b = 1.760726\n",
      "\tgrad = 2.480801\n",
      "rate = 0.010448\n",
      "Step 115 / 1000, loss = -7763.159007\n",
      "a_1 = 5.648334, a_2 = 4.231222, b = 1.765922\n",
      "\tgrad = 2.739184\n",
      "rate = 0.010370\n",
      "Step 116 / 1000, loss = -7764.911284\n",
      "a_1 = 5.669399, a_2 = 4.245402, b = 1.770780\n",
      "\tgrad = 2.511583\n",
      "rate = 0.010294\n",
      "Step 117 / 1000, loss = -7766.678484\n",
      "a_1 = 5.691062, a_2 = 4.259739, b = 1.775684\n",
      "\tgrad = 2.587010\n",
      "rate = 0.010219\n",
      "Step 118 / 1000, loss = -7768.544106\n",
      "a_1 = 5.713757, a_2 = 4.275675, b = 1.780736\n",
      "\tgrad = 2.778486\n",
      "rate = 0.010145\n",
      "Step 119 / 1000, loss = -7770.281719\n",
      "a_1 = 5.734821, a_2 = 4.290982, b = 1.785530\n",
      "\tgrad = 2.628636\n",
      "rate = 0.010072\n",
      "Step 120 / 1000, loss = -7771.985762\n",
      "a_1 = 5.756032, a_2 = 4.305744, b = 1.790389\n",
      "\tgrad = 2.629560\n",
      "rate = 0.010000\n",
      "Step 121 / 1000, loss = -7773.817938\n",
      "a_1 = 5.778975, a_2 = 4.322104, b = 1.795512\n",
      "\tgrad = 2.884445\n",
      "rate = 0.009929\n",
      "Step 122 / 1000, loss = -7775.434210\n",
      "a_1 = 5.799461, a_2 = 4.336642, b = 1.800136\n",
      "\tgrad = 2.590710\n",
      "rate = 0.009859\n",
      "Step 123 / 1000, loss = -7777.120877\n",
      "a_1 = 5.821624, a_2 = 4.351335, b = 1.805118\n",
      "\tgrad = 2.763347\n",
      "rate = 0.009790\n",
      "Step 124 / 1000, loss = -7778.647285\n",
      "a_1 = 5.840750, a_2 = 4.365943, b = 1.809668\n",
      "\tgrad = 2.519336\n",
      "rate = 0.009722\n",
      "Step 125 / 1000, loss = -7780.300675\n",
      "a_1 = 5.862575, a_2 = 4.381083, b = 1.814630\n",
      "\tgrad = 2.798666\n",
      "rate = 0.009655\n",
      "Step 126 / 1000, loss = -7781.953314\n",
      "a_1 = 5.884501, a_2 = 4.396519, b = 1.819664\n",
      "\tgrad = 2.845174\n",
      "rate = 0.009589\n",
      "Step 127 / 1000, loss = -7783.532705\n",
      "a_1 = 5.905162, a_2 = 4.411999, b = 1.824511\n",
      "\tgrad = 2.758138\n",
      "rate = 0.009524\n",
      "Step 128 / 1000, loss = -7785.073716\n",
      "a_1 = 5.925835, a_2 = 4.427048, b = 1.829231\n",
      "\tgrad = 2.748784\n",
      "rate = 0.009459\n",
      "Step 129 / 1000, loss = -7786.589375\n",
      "a_1 = 5.946928, a_2 = 4.441424, b = 1.833966\n",
      "\tgrad = 2.763086\n",
      "rate = 0.009396\n",
      "Step 130 / 1000, loss = -7788.024592\n",
      "a_1 = 5.967408, a_2 = 4.454791, b = 1.838586\n",
      "\tgrad = 2.666675\n",
      "rate = 0.009333\n",
      "Step 131 / 1000, loss = -7789.412046\n",
      "a_1 = 5.986998, a_2 = 4.468286, b = 1.843082\n",
      "\tgrad = 2.611118\n",
      "rate = 0.009272\n",
      "Step 132 / 1000, loss = -7790.870802\n",
      "a_1 = 6.007908, a_2 = 4.482640, b = 1.847752\n",
      "\tgrad = 2.799953\n",
      "rate = 0.009211\n",
      "Step 133 / 1000, loss = -7792.277417\n",
      "a_1 = 6.028747, a_2 = 4.496179, b = 1.852281\n",
      "\tgrad = 2.760610\n",
      "rate = 0.009150\n",
      "Step 134 / 1000, loss = -7793.578912\n",
      "a_1 = 6.047874, a_2 = 4.509024, b = 1.856671\n",
      "\tgrad = 2.580012\n",
      "rate = 0.009091\n",
      "Step 135 / 1000, loss = -7794.927253\n",
      "a_1 = 6.068066, a_2 = 4.522396, b = 1.861159\n",
      "\tgrad = 2.726993\n",
      "rate = 0.009032\n",
      "Step 136 / 1000, loss = -7796.220030\n",
      "a_1 = 6.086947, a_2 = 4.535921, b = 1.865619\n",
      "\tgrad = 2.635190\n",
      "rate = 0.008974\n",
      "Step 137 / 1000, loss = -7797.608634\n",
      "a_1 = 6.107767, a_2 = 4.550531, b = 1.870211\n",
      "\tgrad = 2.898471\n",
      "rate = 0.008917\n",
      "Step 138 / 1000, loss = -7798.871484\n",
      "a_1 = 6.126878, a_2 = 4.563920, b = 1.874482\n",
      "\tgrad = 2.677183\n",
      "rate = 0.008861\n",
      "Step 139 / 1000, loss = -7800.094288\n",
      "a_1 = 6.145876, a_2 = 4.576552, b = 1.878778\n",
      "\tgrad = 2.636540\n",
      "rate = 0.008805\n",
      "Step 140 / 1000, loss = -7801.284948\n",
      "a_1 = 6.163845, a_2 = 4.589661, b = 1.883039\n",
      "\tgrad = 2.588316\n",
      "rate = 0.008750\n",
      "Step 141 / 1000, loss = -7802.488957\n",
      "a_1 = 6.183079, a_2 = 4.602167, b = 1.887344\n",
      "\tgrad = 2.684360\n",
      "rate = 0.008696\n",
      "Step 142 / 1000, loss = -7803.766202\n",
      "a_1 = 6.203247, a_2 = 4.616099, b = 1.891889\n",
      "\tgrad = 2.884769\n",
      "rate = 0.008642\n",
      "Step 143 / 1000, loss = -7804.941595\n",
      "a_1 = 6.221883, a_2 = 4.629160, b = 1.896115\n",
      "\tgrad = 2.694824\n",
      "rate = 0.008589\n",
      "Step 144 / 1000, loss = -7806.118905\n",
      "a_1 = 6.240725, a_2 = 4.642407, b = 1.900357\n",
      "\tgrad = 2.743491\n",
      "rate = 0.008537\n",
      "Step 145 / 1000, loss = -7807.208645\n",
      "a_1 = 6.258416, a_2 = 4.654594, b = 1.904404\n",
      "\tgrad = 2.576496\n",
      "rate = 0.008485\n",
      "Step 146 / 1000, loss = -7808.299787\n",
      "a_1 = 6.275735, a_2 = 4.667501, b = 1.908485\n",
      "\tgrad = 2.606351\n",
      "rate = 0.008434\n",
      "Step 147 / 1000, loss = -7809.403809\n",
      "a_1 = 6.294540, a_2 = 4.679462, b = 1.912685\n",
      "\tgrad = 2.705234\n",
      "rate = 0.008383\n",
      "Step 148 / 1000, loss = -7810.470170\n",
      "a_1 = 6.311983, a_2 = 4.692055, b = 1.916776\n",
      "\tgrad = 2.627930\n",
      "rate = 0.008333\n",
      "Step 149 / 1000, loss = -7811.510313\n",
      "a_1 = 6.329305, a_2 = 4.704264, b = 1.920818\n",
      "\tgrad = 2.604365\n",
      "rate = 0.008284\n",
      "Step 150 / 1000, loss = -7812.561558\n",
      "a_1 = 6.346911, a_2 = 4.716865, b = 1.924862\n",
      "\tgrad = 2.674460\n",
      "rate = 0.008235\n",
      "Step 151 / 1000, loss = -7813.630206\n",
      "a_1 = 6.365087, a_2 = 4.729656, b = 1.929021\n",
      "\tgrad = 2.761802\n",
      "rate = 0.008187\n",
      "Step 152 / 1000, loss = -7814.674089\n",
      "a_1 = 6.382800, a_2 = 4.742334, b = 1.933245\n",
      "\tgrad = 2.725963\n",
      "rate = 0.008140\n",
      "Step 153 / 1000, loss = -7815.721295\n",
      "a_1 = 6.401026, a_2 = 4.755029, b = 1.937372\n",
      "\tgrad = 2.791791\n",
      "rate = 0.008092\n",
      "Step 154 / 1000, loss = -7816.793590\n",
      "a_1 = 6.419398, a_2 = 4.768796, b = 1.941507\n",
      "\tgrad = 2.899192\n",
      "rate = 0.008046\n",
      "Step 155 / 1000, loss = -7817.798412\n",
      "a_1 = 6.437228, a_2 = 4.781264, b = 1.945475\n",
      "\tgrad = 2.764419\n",
      "rate = 0.008000\n",
      "Step 156 / 1000, loss = -7818.768689\n",
      "a_1 = 6.454223, a_2 = 4.793652, b = 1.949468\n",
      "\tgrad = 2.691132\n",
      "rate = 0.007955\n",
      "Step 157 / 1000, loss = -7819.727713\n",
      "a_1 = 6.471160, a_2 = 4.806152, b = 1.953328\n",
      "\tgrad = 2.705759\n",
      "rate = 0.007910\n",
      "Step 158 / 1000, loss = -7820.640610\n",
      "a_1 = 6.487932, a_2 = 4.817540, b = 1.957088\n",
      "\tgrad = 2.621528\n",
      "rate = 0.007865\n",
      "Step 159 / 1000, loss = -7821.585283\n",
      "a_1 = 6.505547, a_2 = 4.829310, b = 1.961006\n",
      "\tgrad = 2.754577\n",
      "rate = 0.007821\n",
      "Step 160 / 1000, loss = -7822.514152\n",
      "a_1 = 6.522657, a_2 = 4.841263, b = 1.964972\n",
      "\tgrad = 2.731539\n",
      "rate = 0.007778\n",
      "Step 161 / 1000, loss = -7823.434988\n",
      "a_1 = 6.539826, a_2 = 4.853190, b = 1.968901\n",
      "\tgrad = 2.750021\n",
      "rate = 0.007735\n",
      "Step 162 / 1000, loss = -7824.340757\n",
      "a_1 = 6.557038, a_2 = 4.864851, b = 1.972778\n",
      "\tgrad = 2.749346\n",
      "rate = 0.007692\n",
      "Step 163 / 1000, loss = -7825.172720\n",
      "a_1 = 6.572960, a_2 = 4.875563, b = 1.976450\n",
      "\tgrad = 2.553988\n",
      "rate = 0.007650\n",
      "Step 164 / 1000, loss = -7826.073408\n",
      "a_1 = 6.590172, a_2 = 4.887528, b = 1.980376\n",
      "\tgrad = 2.802894\n",
      "rate = 0.007609\n",
      "Step 165 / 1000, loss = -7826.922396\n",
      "a_1 = 6.606053, a_2 = 4.899387, b = 1.984122\n",
      "\tgrad = 2.665377\n",
      "rate = 0.007568\n",
      "Step 166 / 1000, loss = -7827.771281\n",
      "a_1 = 6.622545, a_2 = 4.910800, b = 1.987915\n",
      "\tgrad = 2.711821\n",
      "rate = 0.007527\n",
      "Step 167 / 1000, loss = -7828.633352\n",
      "a_1 = 6.639495, a_2 = 4.922513, b = 1.991718\n",
      "\tgrad = 2.798487\n",
      "rate = 0.007487\n",
      "Step 168 / 1000, loss = -7829.480704\n",
      "a_1 = 6.656218, a_2 = 4.934152, b = 1.995523\n",
      "\tgrad = 2.783423\n",
      "rate = 0.007447\n",
      "Step 169 / 1000, loss = -7830.277394\n",
      "a_1 = 6.671620, a_2 = 4.945561, b = 1.999204\n",
      "\tgrad = 2.634907\n",
      "rate = 0.007407\n",
      "Step 170 / 1000, loss = -7831.059622\n",
      "a_1 = 6.687234, a_2 = 4.956452, b = 2.002844\n",
      "\tgrad = 2.630366\n",
      "rate = 0.007368\n",
      "Step 171 / 1000, loss = -7831.826380\n",
      "a_1 = 6.702733, a_2 = 4.967246, b = 2.006340\n",
      "\tgrad = 2.620501\n",
      "rate = 0.007330\n",
      "Step 172 / 1000, loss = -7832.608301\n",
      "a_1 = 6.718357, a_2 = 4.978570, b = 2.010000\n",
      "\tgrad = 2.693575\n",
      "rate = 0.007292\n",
      "Step 173 / 1000, loss = -7833.376767\n",
      "a_1 = 6.733824, a_2 = 4.989814, b = 2.013605\n",
      "\tgrad = 2.682501\n",
      "rate = 0.007254\n",
      "Step 174 / 1000, loss = -7834.115537\n",
      "a_1 = 6.748895, a_2 = 5.000487, b = 2.017192\n",
      "\tgrad = 2.606938\n",
      "rate = 0.007216\n",
      "Step 175 / 1000, loss = -7834.869078\n",
      "a_1 = 6.764353, a_2 = 5.011603, b = 2.020782\n",
      "\tgrad = 2.698704\n",
      "rate = 0.007179\n",
      "Step 176 / 1000, loss = -7835.569930\n",
      "a_1 = 6.779341, a_2 = 5.021444, b = 2.024174\n",
      "\tgrad = 2.554682\n",
      "rate = 0.007143\n",
      "Step 177 / 1000, loss = -7836.339008\n",
      "a_1 = 6.795731, a_2 = 5.032642, b = 2.027820\n",
      "\tgrad = 2.839943\n",
      "rate = 0.007107\n",
      "Step 178 / 1000, loss = -7837.071481\n",
      "a_1 = 6.811198, a_2 = 5.043725, b = 2.031270\n",
      "\tgrad = 2.734996\n",
      "rate = 0.007071\n",
      "Step 179 / 1000, loss = -7837.798043\n",
      "a_1 = 6.826671, a_2 = 5.054685, b = 2.034794\n",
      "\tgrad = 2.741386\n",
      "rate = 0.007035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 180 / 1000, loss = -7838.498163\n",
      "a_1 = 6.842036, a_2 = 5.065010, b = 2.038175\n",
      "\tgrad = 2.688165\n",
      "rate = 0.007000\n",
      "Step 181 / 1000, loss = -7839.179257\n",
      "a_1 = 6.856292, a_2 = 5.075826, b = 2.041595\n",
      "\tgrad = 2.615767\n",
      "rate = 0.006965\n",
      "Step 182 / 1000, loss = -7839.842506\n",
      "a_1 = 6.870949, a_2 = 5.085822, b = 2.044866\n",
      "\tgrad = 2.602978\n",
      "rate = 0.006931\n",
      "Step 183 / 1000, loss = -7840.506212\n",
      "a_1 = 6.885760, a_2 = 5.095806, b = 2.048196\n",
      "\tgrad = 2.634508\n",
      "rate = 0.006897\n",
      "Step 184 / 1000, loss = -7841.158775\n",
      "a_1 = 6.900427, a_2 = 5.105661, b = 2.051511\n",
      "\tgrad = 2.619780\n",
      "rate = 0.006863\n",
      "Step 185 / 1000, loss = -7841.837027\n",
      "a_1 = 6.915445, a_2 = 5.116377, b = 2.054939\n",
      "\tgrad = 2.747745\n",
      "rate = 0.006829\n",
      "Step 186 / 1000, loss = -7842.475771\n",
      "a_1 = 6.929704, a_2 = 5.126410, b = 2.058276\n",
      "\tgrad = 2.612015\n",
      "rate = 0.006796\n",
      "Step 187 / 1000, loss = -7843.140230\n",
      "a_1 = 6.945332, a_2 = 5.136322, b = 2.061671\n",
      "\tgrad = 2.781966\n",
      "rate = 0.006763\n",
      "Step 188 / 1000, loss = -7843.762832\n",
      "a_1 = 6.959246, a_2 = 5.146480, b = 2.064922\n",
      "\tgrad = 2.604668\n",
      "rate = 0.006731\n",
      "Step 189 / 1000, loss = -7844.399360\n",
      "a_1 = 6.973934, a_2 = 5.156539, b = 2.068278\n",
      "\tgrad = 2.704385\n",
      "rate = 0.006699\n",
      "Step 190 / 1000, loss = -7845.029593\n",
      "a_1 = 6.988211, a_2 = 5.167013, b = 2.071571\n",
      "\tgrad = 2.701612\n",
      "rate = 0.006667\n",
      "Step 191 / 1000, loss = -7845.650582\n",
      "a_1 = 7.002288, a_2 = 5.177340, b = 2.074955\n",
      "\tgrad = 2.680313\n",
      "rate = 0.006635\n",
      "Step 192 / 1000, loss = -7846.256843\n",
      "a_1 = 7.016452, a_2 = 5.187144, b = 2.078283\n",
      "\tgrad = 2.656647\n",
      "rate = 0.006604\n",
      "Step 193 / 1000, loss = -7846.852252\n",
      "a_1 = 7.030633, a_2 = 5.196746, b = 2.081497\n",
      "\tgrad = 2.651073\n",
      "rate = 0.006573\n",
      "Step 194 / 1000, loss = -7847.427921\n",
      "a_1 = 7.044193, a_2 = 5.206355, b = 2.084611\n",
      "\tgrad = 2.584591\n",
      "rate = 0.006542\n",
      "Step 195 / 1000, loss = -7847.986112\n",
      "a_1 = 7.056880, a_2 = 5.216161, b = 2.087749\n",
      "\tgrad = 2.509387\n",
      "rate = 0.006512\n",
      "Step 196 / 1000, loss = -7848.606890\n",
      "a_1 = 7.071842, a_2 = 5.226546, b = 2.091113\n",
      "\tgrad = 2.857417\n",
      "rate = 0.006481\n",
      "Step 197 / 1000, loss = -7849.173961\n",
      "a_1 = 7.085201, a_2 = 5.236417, b = 2.094274\n",
      "\tgrad = 2.620870\n",
      "rate = 0.006452\n",
      "Step 198 / 1000, loss = -7849.736572\n",
      "a_1 = 7.099290, a_2 = 5.245501, b = 2.097427\n",
      "\tgrad = 2.656055\n",
      "rate = 0.006422\n",
      "Step 199 / 1000, loss = -7850.302363\n",
      "a_1 = 7.113137, a_2 = 5.255155, b = 2.100591\n",
      "\tgrad = 2.686435\n",
      "rate = 0.006393\n",
      "Step 200 / 1000, loss = -7850.890254\n",
      "a_1 = 7.128050, a_2 = 5.264823, b = 2.103888\n",
      "\tgrad = 2.840518\n",
      "rate = 0.006364\n",
      "Step 201 / 1000, loss = -7851.420657\n",
      "a_1 = 7.141145, a_2 = 5.274038, b = 2.106897\n",
      "\tgrad = 2.571947\n",
      "rate = 0.006335\n",
      "Step 202 / 1000, loss = -7851.982867\n",
      "a_1 = 7.155140, a_2 = 5.283787, b = 2.110144\n",
      "\tgrad = 2.753202\n",
      "rate = 0.006306\n",
      "Step 203 / 1000, loss = -7852.536654\n",
      "a_1 = 7.168467, a_2 = 5.294200, b = 2.113220\n",
      "\tgrad = 2.738082\n",
      "rate = 0.006278\n",
      "Step 204 / 1000, loss = -7853.097776\n",
      "a_1 = 7.182690, a_2 = 5.304119, b = 2.116395\n",
      "\tgrad = 2.820545\n",
      "rate = 0.006250\n",
      "Step 205 / 1000, loss = -7853.626577\n",
      "a_1 = 7.196015, a_2 = 5.313659, b = 2.119431\n",
      "\tgrad = 2.678618\n",
      "rate = 0.006222\n",
      "Step 206 / 1000, loss = -7854.133838\n",
      "a_1 = 7.208653, a_2 = 5.322944, b = 2.122473\n",
      "\tgrad = 2.578691\n",
      "rate = 0.006195\n",
      "Step 207 / 1000, loss = -7854.650174\n",
      "a_1 = 7.221756, a_2 = 5.332407, b = 2.125495\n",
      "\tgrad = 2.666113\n",
      "rate = 0.006167\n",
      "Step 208 / 1000, loss = -7855.159327\n",
      "a_1 = 7.234891, a_2 = 5.341543, b = 2.128577\n",
      "\tgrad = 2.653620\n",
      "rate = 0.006140\n",
      "Step 209 / 1000, loss = -7855.728602\n",
      "a_1 = 7.250066, a_2 = 5.351691, b = 2.131842\n",
      "\tgrad = 3.033380\n",
      "rate = 0.006114\n",
      "Step 210 / 1000, loss = -7856.213896\n",
      "a_1 = 7.262678, a_2 = 5.360589, b = 2.134806\n",
      "\tgrad = 2.582122\n",
      "rate = 0.006087\n",
      "Step 211 / 1000, loss = -7856.721343\n",
      "a_1 = 7.276257, a_2 = 5.369795, b = 2.137800\n",
      "\tgrad = 2.751650\n",
      "rate = 0.006061\n",
      "Step 212 / 1000, loss = -7857.213005\n",
      "a_1 = 7.289156, a_2 = 5.379009, b = 2.140793\n",
      "\tgrad = 2.673263\n",
      "rate = 0.006034\n",
      "Step 213 / 1000, loss = -7857.703146\n",
      "a_1 = 7.302109, a_2 = 5.388361, b = 2.143695\n",
      "\tgrad = 2.702438\n",
      "rate = 0.006009\n",
      "Step 214 / 1000, loss = -7858.199116\n",
      "a_1 = 7.315530, a_2 = 5.397528, b = 2.146734\n",
      "\tgrad = 2.763710\n",
      "rate = 0.005983\n",
      "Step 215 / 1000, loss = -7858.660466\n",
      "a_1 = 7.327927, a_2 = 5.406190, b = 2.149635\n",
      "\tgrad = 2.584696\n",
      "rate = 0.005957\n",
      "Step 216 / 1000, loss = -7859.141804\n",
      "a_1 = 7.340937, a_2 = 5.415371, b = 2.152607\n",
      "\tgrad = 2.730605\n",
      "rate = 0.005932\n",
      "Step 217 / 1000, loss = -7859.611110\n",
      "a_1 = 7.353775, a_2 = 5.424265, b = 2.155542\n",
      "\tgrad = 2.690244\n",
      "rate = 0.005907\n",
      "Step 218 / 1000, loss = -7860.070107\n",
      "a_1 = 7.366172, a_2 = 5.433219, b = 2.158448\n",
      "\tgrad = 2.646294\n",
      "rate = 0.005882\n",
      "Step 219 / 1000, loss = -7860.529106\n",
      "a_1 = 7.378890, a_2 = 5.442042, b = 2.161318\n",
      "\tgrad = 2.687439\n",
      "rate = 0.005858\n",
      "Step 220 / 1000, loss = -7860.960720\n",
      "a_1 = 7.390360, a_2 = 5.450799, b = 2.164136\n",
      "\tgrad = 2.520454\n",
      "rate = 0.005833\n",
      "Step 221 / 1000, loss = -7861.415345\n",
      "a_1 = 7.402973, a_2 = 5.459792, b = 2.166982\n",
      "\tgrad = 2.711193\n",
      "rate = 0.005809\n",
      "Step 222 / 1000, loss = -7861.866396\n",
      "a_1 = 7.415435, a_2 = 5.468743, b = 2.169927\n",
      "\tgrad = 2.700766\n",
      "rate = 0.005785\n",
      "Step 223 / 1000, loss = -7862.292387\n",
      "a_1 = 7.427078, a_2 = 5.477544, b = 2.172640\n",
      "\tgrad = 2.576679\n",
      "rate = 0.005761\n",
      "Step 224 / 1000, loss = -7862.731870\n",
      "a_1 = 7.439527, a_2 = 5.486221, b = 2.175515\n",
      "\tgrad = 2.691728\n",
      "rate = 0.005738\n",
      "Step 225 / 1000, loss = -7863.132785\n",
      "a_1 = 7.450863, a_2 = 5.494283, b = 2.178132\n",
      "\tgrad = 2.477014\n",
      "rate = 0.005714\n",
      "Step 226 / 1000, loss = -7863.565353\n",
      "a_1 = 7.463268, a_2 = 5.502939, b = 2.180954\n",
      "\tgrad = 2.703807\n",
      "rate = 0.005691\n",
      "Step 227 / 1000, loss = -7863.962739\n",
      "a_1 = 7.474771, a_2 = 5.510754, b = 2.183658\n",
      "\tgrad = 2.499496\n",
      "rate = 0.005668\n",
      "Step 228 / 1000, loss = -7864.367728\n",
      "a_1 = 7.486692, a_2 = 5.518772, b = 2.186317\n",
      "\tgrad = 2.588110\n",
      "rate = 0.005645\n",
      "Step 229 / 1000, loss = -7864.776674\n",
      "a_1 = 7.498597, a_2 = 5.526964, b = 2.189117\n",
      "\tgrad = 2.618099\n",
      "rate = 0.005622\n",
      "Step 230 / 1000, loss = -7865.194461\n",
      "a_1 = 7.510851, a_2 = 5.535422, b = 2.191939\n",
      "\tgrad = 2.706130\n",
      "rate = 0.005600\n",
      "Step 231 / 1000, loss = -7865.607506\n",
      "a_1 = 7.522898, a_2 = 5.544040, b = 2.194683\n",
      "\tgrad = 2.700810\n",
      "rate = 0.005578\n",
      "Step 232 / 1000, loss = -7866.003753\n",
      "a_1 = 7.534570, a_2 = 5.552215, b = 2.197389\n",
      "\tgrad = 2.610873\n",
      "rate = 0.005556\n",
      "Step 233 / 1000, loss = -7866.405897\n",
      "a_1 = 7.546878, a_2 = 5.560188, b = 2.200128\n",
      "\tgrad = 2.696026\n",
      "rate = 0.005534\n",
      "Step 234 / 1000, loss = -7866.803659\n",
      "a_1 = 7.558740, a_2 = 5.568423, b = 2.202895\n",
      "\tgrad = 2.667450\n",
      "rate = 0.005512\n",
      "Step 235 / 1000, loss = -7867.182257\n",
      "a_1 = 7.570092, a_2 = 5.576385, b = 2.205475\n",
      "\tgrad = 2.568893\n",
      "rate = 0.005490\n",
      "Step 236 / 1000, loss = -7867.577767\n",
      "a_1 = 7.582098, a_2 = 5.584631, b = 2.208203\n",
      "\tgrad = 2.709688\n",
      "rate = 0.005469\n",
      "Step 237 / 1000, loss = -7867.967069\n",
      "a_1 = 7.594280, a_2 = 5.592533, b = 2.210873\n",
      "\tgrad = 2.710280\n",
      "rate = 0.005447\n",
      "Step 238 / 1000, loss = -7868.345941\n",
      "a_1 = 7.605599, a_2 = 5.600755, b = 2.213548\n",
      "\tgrad = 2.624771\n",
      "rate = 0.005426\n",
      "Step 239 / 1000, loss = -7868.735445\n",
      "a_1 = 7.617404, a_2 = 5.609203, b = 2.216267\n",
      "\tgrad = 2.732180\n",
      "rate = 0.005405\n",
      "Step 240 / 1000, loss = -7869.105643\n",
      "a_1 = 7.628780, a_2 = 5.617167, b = 2.218867\n",
      "\tgrad = 2.623937\n",
      "rate = 0.005385\n",
      "Step 241 / 1000, loss = -7869.497365\n",
      "a_1 = 7.640936, a_2 = 5.625577, b = 2.221635\n",
      "\tgrad = 2.803533\n",
      "rate = 0.005364\n",
      "Step 242 / 1000, loss = -7869.868557\n",
      "a_1 = 7.652283, a_2 = 5.633714, b = 2.224339\n",
      "\tgrad = 2.661634\n",
      "rate = 0.005344\n",
      "Step 243 / 1000, loss = -7870.233088\n",
      "a_1 = 7.663373, a_2 = 5.642045, b = 2.226862\n",
      "\tgrad = 2.648441\n",
      "rate = 0.005323\n",
      "Step 244 / 1000, loss = -7870.593059\n",
      "a_1 = 7.675039, a_2 = 5.649628, b = 2.229397\n",
      "\tgrad = 2.666876\n",
      "rate = 0.005303\n",
      "Step 245 / 1000, loss = -7870.955406\n",
      "a_1 = 7.686570, a_2 = 5.657528, b = 2.231980\n",
      "\tgrad = 2.690583\n",
      "rate = 0.005283\n",
      "Step 246 / 1000, loss = -7871.301474\n",
      "a_1 = 7.697423, a_2 = 5.665260, b = 2.234496\n",
      "\tgrad = 2.576678\n",
      "rate = 0.005263\n",
      "Step 247 / 1000, loss = -7871.657966\n",
      "a_1 = 7.708663, a_2 = 5.673237, b = 2.237112\n",
      "\tgrad = 2.675443\n",
      "rate = 0.005243\n",
      "Step 248 / 1000, loss = -7872.006870\n",
      "a_1 = 7.719621, a_2 = 5.681230, b = 2.239640\n",
      "\tgrad = 2.641218\n",
      "rate = 0.005224\n",
      "Step 249 / 1000, loss = -7872.350940\n",
      "a_1 = 7.730306, a_2 = 5.689278, b = 2.242170\n",
      "\tgrad = 2.615818\n",
      "rate = 0.005204\n",
      "Step 250 / 1000, loss = -7872.706792\n",
      "a_1 = 7.741927, a_2 = 5.697190, b = 2.244762\n",
      "\tgrad = 2.757102\n",
      "rate = 0.005185\n",
      "Step 251 / 1000, loss = -7873.052432\n",
      "a_1 = 7.752810, a_2 = 5.705304, b = 2.247325\n",
      "\tgrad = 2.674113\n",
      "rate = 0.005166\n",
      "Step 252 / 1000, loss = -7873.386695\n",
      "a_1 = 7.763732, a_2 = 5.712827, b = 2.249831\n",
      "\tgrad = 2.622211\n",
      "rate = 0.005147\n",
      "Step 253 / 1000, loss = -7873.731118\n",
      "a_1 = 7.775202, a_2 = 5.720532, b = 2.252370\n",
      "\tgrad = 2.739608\n",
      "rate = 0.005128\n",
      "Step 254 / 1000, loss = -7874.058255\n",
      "a_1 = 7.786134, a_2 = 5.727824, b = 2.254843\n",
      "\tgrad = 2.616873\n",
      "rate = 0.005109\n",
      "Step 255 / 1000, loss = -7874.392072\n",
      "a_1 = 7.797247, a_2 = 5.735439, b = 2.257337\n",
      "\tgrad = 2.691288\n",
      "rate = 0.005091\n",
      "Step 256 / 1000, loss = -7874.749728\n",
      "a_1 = 7.809352, a_2 = 5.743481, b = 2.260036\n",
      "\tgrad = 2.913896\n",
      "rate = 0.005072\n",
      "Step 257 / 1000, loss = -7875.069986\n",
      "a_1 = 7.820375, a_2 = 5.750637, b = 2.262426\n",
      "\tgrad = 2.642959\n",
      "rate = 0.005054\n",
      "Step 258 / 1000, loss = -7875.386582\n",
      "a_1 = 7.830969, a_2 = 5.758061, b = 2.264808\n",
      "\tgrad = 2.612092\n",
      "rate = 0.005036\n",
      "Step 259 / 1000, loss = -7875.686859\n",
      "a_1 = 7.841291, a_2 = 5.764828, b = 2.267136\n",
      "\tgrad = 2.502943\n",
      "rate = 0.005018\n",
      "Step 260 / 1000, loss = -7875.989041\n",
      "a_1 = 7.851345, a_2 = 5.771954, b = 2.269536\n",
      "\tgrad = 2.511014\n",
      "rate = 0.005000\n",
      "Step 261 / 1000, loss = -7876.288701\n",
      "a_1 = 7.861197, a_2 = 5.779300, b = 2.271853\n",
      "\tgrad = 2.510155\n",
      "rate = 0.004982\n",
      "Step 262 / 1000, loss = -7876.622257\n",
      "a_1 = 7.872707, a_2 = 5.787032, b = 2.274449\n",
      "\tgrad = 2.841413\n",
      "rate = 0.004965\n",
      "Step 263 / 1000, loss = -7876.930869\n",
      "a_1 = 7.883125, a_2 = 5.794441, b = 2.276888\n",
      "\tgrad = 2.630782\n",
      "rate = 0.004947\n",
      "Step 264 / 1000, loss = -7877.266876\n",
      "a_1 = 7.894946, a_2 = 5.802310, b = 2.279432\n",
      "\tgrad = 2.926469\n",
      "rate = 0.004930\n",
      "Step 265 / 1000, loss = -7877.579233\n",
      "a_1 = 7.905955, a_2 = 5.809582, b = 2.281878\n",
      "\tgrad = 2.731748\n",
      "rate = 0.004912\n",
      "Step 266 / 1000, loss = -7877.859292\n",
      "a_1 = 7.915329, a_2 = 5.816613, b = 2.284095\n",
      "\tgrad = 2.436210\n",
      "rate = 0.004895\n",
      "Step 267 / 1000, loss = -7878.165734\n",
      "a_1 = 7.926243, a_2 = 5.823700, b = 2.286569\n",
      "\tgrad = 2.715632\n",
      "rate = 0.004878\n",
      "Step 268 / 1000, loss = -7878.448154\n",
      "a_1 = 7.936137, a_2 = 5.830532, b = 2.288800\n",
      "\tgrad = 2.515615\n",
      "rate = 0.004861\n",
      "Step 269 / 1000, loss = -7878.732524\n",
      "a_1 = 7.946096, a_2 = 5.837350, b = 2.291144\n",
      "\tgrad = 2.537925\n",
      "rate = 0.004844\n",
      "Step 270 / 1000, loss = -7879.029976\n",
      "a_1 = 7.956222, a_2 = 5.844847, b = 2.293587\n",
      "\tgrad = 2.658583\n",
      "rate = 0.004828\n",
      "Step 271 / 1000, loss = -7879.324685\n",
      "a_1 = 7.966397, a_2 = 5.852332, b = 2.295930\n",
      "\tgrad = 2.670215\n",
      "rate = 0.004811\n",
      "Step 272 / 1000, loss = -7879.627502\n",
      "a_1 = 7.977038, a_2 = 5.859844, b = 2.298399\n",
      "\tgrad = 2.765028\n",
      "rate = 0.004795\n",
      "Step 273 / 1000, loss = -7879.929581\n",
      "a_1 = 7.987943, a_2 = 5.867186, b = 2.300836\n",
      "\tgrad = 2.798367\n",
      "rate = 0.004778\n",
      "Step 274 / 1000, loss = -7880.226020\n",
      "a_1 = 7.998790, a_2 = 5.874368, b = 2.303207\n",
      "\tgrad = 2.776764\n",
      "rate = 0.004762\n",
      "Step 275 / 1000, loss = -7880.525376\n",
      "a_1 = 8.009563, a_2 = 5.881863, b = 2.305608\n",
      "\tgrad = 2.811372\n",
      "rate = 0.004746\n",
      "Step 276 / 1000, loss = -7880.807694\n",
      "a_1 = 8.019886, a_2 = 5.888754, b = 2.307945\n",
      "\tgrad = 2.670338\n",
      "rate = 0.004730\n",
      "Step 277 / 1000, loss = -7881.092225\n",
      "a_1 = 8.029607, a_2 = 5.896487, b = 2.310250\n",
      "\tgrad = 2.680050\n",
      "rate = 0.004714\n",
      "Step 278 / 1000, loss = -7881.378473\n",
      "a_1 = 8.039785, a_2 = 5.903867, b = 2.312641\n",
      "\tgrad = 2.724042\n",
      "rate = 0.004698\n",
      "Step 279 / 1000, loss = -7881.665385\n",
      "a_1 = 8.050060, a_2 = 5.911353, b = 2.314982\n",
      "\tgrad = 2.760806\n",
      "rate = 0.004682\n",
      "Step 280 / 1000, loss = -7881.937978\n",
      "a_1 = 8.059887, a_2 = 5.918410, b = 2.317255\n",
      "\tgrad = 2.637696\n",
      "rate = 0.004667\n",
      "Step 281 / 1000, loss = -7882.209978\n",
      "a_1 = 8.069495, a_2 = 5.925662, b = 2.319552\n",
      "\tgrad = 2.635054\n",
      "rate = 0.004651\n",
      "Step 282 / 1000, loss = -7882.480190\n",
      "a_1 = 8.079403, a_2 = 5.932636, b = 2.321810\n",
      "\tgrad = 2.658440\n",
      "rate = 0.004636\n",
      "Step 283 / 1000, loss = -7882.757309\n",
      "a_1 = 8.089791, a_2 = 5.939609, b = 2.324152\n",
      "\tgrad = 2.754914\n",
      "rate = 0.004620\n",
      "Step 284 / 1000, loss = -7883.038406\n",
      "a_1 = 8.100424, a_2 = 5.946629, b = 2.326556\n",
      "\tgrad = 2.815586\n",
      "rate = 0.004605\n",
      "Step 285 / 1000, loss = -7883.292392\n",
      "a_1 = 8.109858, a_2 = 5.953202, b = 2.328727\n",
      "\tgrad = 2.549176\n",
      "rate = 0.004590\n",
      "Step 286 / 1000, loss = -7883.548686\n",
      "a_1 = 8.119527, a_2 = 5.959746, b = 2.330928\n",
      "\tgrad = 2.596724\n",
      "rate = 0.004575\n",
      "Step 287 / 1000, loss = -7883.814188\n",
      "a_1 = 8.129737, a_2 = 5.966464, b = 2.333172\n",
      "\tgrad = 2.724910\n",
      "rate = 0.004560\n",
      "Step 288 / 1000, loss = -7884.093672\n",
      "a_1 = 8.139971, a_2 = 5.974133, b = 2.335503\n",
      "\tgrad = 2.859961\n",
      "rate = 0.004545\n",
      "Step 289 / 1000, loss = -7884.358076\n",
      "a_1 = 8.150066, a_2 = 5.981062, b = 2.337719\n",
      "\tgrad = 2.746206\n",
      "rate = 0.004531\n",
      "Step 290 / 1000, loss = -7884.605474\n",
      "a_1 = 8.159636, a_2 = 5.987361, b = 2.339882\n",
      "\tgrad = 2.581802\n",
      "rate = 0.004516\n",
      "Step 291 / 1000, loss = -7884.869172\n",
      "a_1 = 8.169854, a_2 = 5.994200, b = 2.342137\n",
      "\tgrad = 2.776865\n",
      "rate = 0.004502\n",
      "Step 292 / 1000, loss = -7885.137846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 8.180276, a_2 = 6.001165, b = 2.344480\n",
      "\tgrad = 2.841886\n",
      "rate = 0.004487\n",
      "Step 293 / 1000, loss = -7885.400670\n",
      "a_1 = 8.190152, a_2 = 6.008321, b = 2.346787\n",
      "\tgrad = 2.775089\n",
      "rate = 0.004473\n",
      "Step 294 / 1000, loss = -7885.644630\n",
      "a_1 = 8.199571, a_2 = 6.014795, b = 2.348928\n",
      "\tgrad = 2.607974\n",
      "rate = 0.004459\n",
      "Step 295 / 1000, loss = -7885.896540\n",
      "a_1 = 8.209179, a_2 = 6.021653, b = 2.351136\n",
      "\tgrad = 2.702287\n",
      "rate = 0.004444\n",
      "Step 296 / 1000, loss = -7886.152311\n",
      "a_1 = 8.218720, a_2 = 6.028923, b = 2.353352\n",
      "\tgrad = 2.753188\n",
      "rate = 0.004430\n",
      "Step 297 / 1000, loss = -7886.406445\n",
      "a_1 = 8.228591, a_2 = 6.035665, b = 2.355679\n",
      "\tgrad = 2.757380\n",
      "rate = 0.004416\n",
      "Step 298 / 1000, loss = -7886.641817\n",
      "a_1 = 8.237778, a_2 = 6.042026, b = 2.357766\n",
      "\tgrad = 2.582064\n",
      "rate = 0.004403\n",
      "Step 299 / 1000, loss = -7886.885583\n",
      "a_1 = 8.247151, a_2 = 6.048796, b = 2.359934\n",
      "\tgrad = 2.680475\n",
      "rate = 0.004389\n",
      "Step 300 / 1000, loss = -7887.128680\n",
      "a_1 = 8.256402, a_2 = 6.055629, b = 2.362143\n",
      "\tgrad = 2.676825\n",
      "rate = 0.004375\n",
      "Step 301 / 1000, loss = -7887.387780\n",
      "a_1 = 8.266300, a_2 = 6.063038, b = 2.364433\n",
      "\tgrad = 2.883172\n",
      "rate = 0.004361\n",
      "Step 302 / 1000, loss = -7887.621630\n",
      "a_1 = 8.275231, a_2 = 6.069683, b = 2.366572\n",
      "\tgrad = 2.606968\n",
      "rate = 0.004348\n",
      "Step 303 / 1000, loss = -7887.857486\n",
      "a_1 = 8.284457, a_2 = 6.076299, b = 2.368687\n",
      "\tgrad = 2.664624\n",
      "rate = 0.004334\n",
      "Step 304 / 1000, loss = -7888.095960\n",
      "a_1 = 8.294131, a_2 = 6.082704, b = 2.370843\n",
      "\tgrad = 2.730840\n",
      "rate = 0.004321\n",
      "Step 305 / 1000, loss = -7888.326864\n",
      "a_1 = 8.303303, a_2 = 6.089038, b = 2.373001\n",
      "\tgrad = 2.635732\n",
      "rate = 0.004308\n",
      "Step 306 / 1000, loss = -7888.567053\n",
      "a_1 = 8.312845, a_2 = 6.095748, b = 2.375204\n",
      "\tgrad = 2.764270\n",
      "rate = 0.004294\n",
      "Step 307 / 1000, loss = -7888.811309\n",
      "a_1 = 8.322663, a_2 = 6.102586, b = 2.377405\n",
      "\tgrad = 2.841533\n",
      "rate = 0.004281\n",
      "Step 308 / 1000, loss = -7889.041000\n",
      "a_1 = 8.331826, a_2 = 6.109101, b = 2.379500\n",
      "\tgrad = 2.679353\n",
      "rate = 0.004268\n",
      "Step 309 / 1000, loss = -7889.258700\n",
      "a_1 = 8.340656, a_2 = 6.115222, b = 2.381466\n",
      "\tgrad = 2.566865\n",
      "rate = 0.004255\n",
      "Step 310 / 1000, loss = -7889.505419\n",
      "a_1 = 8.350906, a_2 = 6.121953, b = 2.383723\n",
      "\tgrad = 2.938904\n",
      "rate = 0.004242\n",
      "Step 311 / 1000, loss = -7889.730667\n",
      "a_1 = 8.360308, a_2 = 6.128127, b = 2.385774\n",
      "\tgrad = 2.703339\n",
      "rate = 0.004230\n",
      "Step 312 / 1000, loss = -7889.943355\n",
      "a_1 = 8.369026, a_2 = 6.134016, b = 2.387807\n",
      "\tgrad = 2.540831\n",
      "rate = 0.004217\n",
      "Step 313 / 1000, loss = -7890.173940\n",
      "a_1 = 8.378550, a_2 = 6.140468, b = 2.389955\n",
      "\tgrad = 2.783722\n",
      "rate = 0.004204\n",
      "Step 314 / 1000, loss = -7890.394588\n",
      "a_1 = 8.387156, a_2 = 6.147141, b = 2.392030\n",
      "\tgrad = 2.644623\n",
      "rate = 0.004192\n",
      "Step 315 / 1000, loss = -7890.609192\n",
      "a_1 = 8.396078, a_2 = 6.153068, b = 2.394116\n",
      "\tgrad = 2.611355\n",
      "rate = 0.004179\n",
      "Step 316 / 1000, loss = -7890.839606\n",
      "a_1 = 8.405429, a_2 = 6.159872, b = 2.396240\n",
      "\tgrad = 2.821681\n",
      "rate = 0.004167\n",
      "Step 317 / 1000, loss = -7891.045511\n",
      "a_1 = 8.413968, a_2 = 6.165695, b = 2.398230\n",
      "\tgrad = 2.533664\n",
      "rate = 0.004154\n",
      "Step 318 / 1000, loss = -7891.257781\n",
      "a_1 = 8.422554, a_2 = 6.172012, b = 2.400239\n",
      "\tgrad = 2.618807\n",
      "rate = 0.004142\n",
      "Step 319 / 1000, loss = -7891.469165\n",
      "a_1 = 8.431223, a_2 = 6.178183, b = 2.402279\n",
      "\tgrad = 2.623682\n",
      "rate = 0.004130\n",
      "Step 320 / 1000, loss = -7891.684461\n",
      "a_1 = 8.440038, a_2 = 6.184587, b = 2.404322\n",
      "\tgrad = 2.691997\n",
      "rate = 0.004118\n",
      "Step 321 / 1000, loss = -7891.899722\n",
      "a_1 = 8.449246, a_2 = 6.190664, b = 2.406370\n",
      "\tgrad = 2.733265\n",
      "rate = 0.004106\n",
      "Step 322 / 1000, loss = -7892.106130\n",
      "a_1 = 8.457966, a_2 = 6.196647, b = 2.408331\n",
      "\tgrad = 2.627449\n",
      "rate = 0.004094\n",
      "Step 323 / 1000, loss = -7892.315743\n",
      "a_1 = 8.466400, a_2 = 6.203078, b = 2.410380\n",
      "\tgrad = 2.646519\n",
      "rate = 0.004082\n",
      "Step 324 / 1000, loss = -7892.523137\n",
      "a_1 = 8.475184, a_2 = 6.209186, b = 2.412337\n",
      "\tgrad = 2.672491\n",
      "rate = 0.004070\n",
      "Step 325 / 1000, loss = -7892.720153\n",
      "a_1 = 8.483503, a_2 = 6.214900, b = 2.414301\n",
      "\tgrad = 2.533799\n",
      "rate = 0.004058\n",
      "Step 326 / 1000, loss = -7892.923870\n",
      "a_1 = 8.492044, a_2 = 6.220997, b = 2.416276\n",
      "\tgrad = 2.638894\n",
      "rate = 0.004046\n",
      "Step 327 / 1000, loss = -7893.119331\n",
      "a_1 = 8.500275, a_2 = 6.226844, b = 2.418180\n",
      "\tgrad = 2.546437\n",
      "rate = 0.004035\n",
      "Step 328 / 1000, loss = -7893.313191\n",
      "a_1 = 8.508703, a_2 = 6.232509, b = 2.420023\n",
      "\tgrad = 2.565490\n",
      "rate = 0.004023\n",
      "Step 329 / 1000, loss = -7893.520118\n",
      "a_1 = 8.517487, a_2 = 6.238760, b = 2.422016\n",
      "\tgrad = 2.733316\n",
      "rate = 0.004011\n",
      "Step 330 / 1000, loss = -7893.712887\n",
      "a_1 = 8.525588, a_2 = 6.244586, b = 2.423952\n",
      "\tgrad = 2.541107\n",
      "rate = 0.004000\n",
      "Step 331 / 1000, loss = -7893.923465\n",
      "a_1 = 8.534828, a_2 = 6.250777, b = 2.425975\n",
      "\tgrad = 2.834162\n",
      "rate = 0.003989\n",
      "Step 332 / 1000, loss = -7894.116628\n",
      "a_1 = 8.542832, a_2 = 6.256876, b = 2.427872\n",
      "\tgrad = 2.574786\n",
      "rate = 0.003977\n",
      "Step 333 / 1000, loss = -7894.322045\n",
      "a_1 = 8.551877, a_2 = 6.262919, b = 2.429886\n",
      "\tgrad = 2.789351\n",
      "rate = 0.003966\n",
      "Step 334 / 1000, loss = -7894.526452\n",
      "a_1 = 8.560838, a_2 = 6.269054, b = 2.431868\n",
      "\tgrad = 2.791341\n",
      "rate = 0.003955\n",
      "Step 335 / 1000, loss = -7894.715455\n",
      "a_1 = 8.569015, a_2 = 6.274863, b = 2.433705\n",
      "\tgrad = 2.585770\n",
      "rate = 0.003944\n",
      "Step 336 / 1000, loss = -7894.903339\n",
      "a_1 = 8.577017, a_2 = 6.280753, b = 2.435562\n",
      "\tgrad = 2.570386\n",
      "rate = 0.003933\n",
      "Step 337 / 1000, loss = -7895.095157\n",
      "a_1 = 8.585455, a_2 = 6.286460, b = 2.437522\n",
      "\tgrad = 2.645331\n",
      "rate = 0.003922\n",
      "Step 338 / 1000, loss = -7895.288941\n",
      "a_1 = 8.593842, a_2 = 6.292462, b = 2.439462\n",
      "\tgrad = 2.683407\n",
      "rate = 0.003911\n",
      "Step 339 / 1000, loss = -7895.477068\n",
      "a_1 = 8.602515, a_2 = 6.297871, b = 2.441322\n",
      "\tgrad = 2.664215\n",
      "rate = 0.003900\n",
      "Step 340 / 1000, loss = -7895.677799\n",
      "a_1 = 8.611360, a_2 = 6.304039, b = 2.443329\n",
      "\tgrad = 2.820294\n",
      "rate = 0.003889\n",
      "Step 341 / 1000, loss = -7895.860036\n",
      "a_1 = 8.619586, a_2 = 6.309467, b = 2.445171\n",
      "\tgrad = 2.585284\n",
      "rate = 0.003878\n",
      "Step 342 / 1000, loss = -7896.063326\n",
      "a_1 = 8.628532, a_2 = 6.315751, b = 2.447247\n",
      "\tgrad = 2.877356\n",
      "rate = 0.003867\n",
      "Step 343 / 1000, loss = -7896.244337\n",
      "a_1 = 8.636559, a_2 = 6.321346, b = 2.449087\n",
      "\tgrad = 2.581519\n",
      "rate = 0.003857\n",
      "Step 344 / 1000, loss = -7896.431904\n",
      "a_1 = 8.645012, a_2 = 6.327106, b = 2.450964\n",
      "\tgrad = 2.703776\n",
      "rate = 0.003846\n",
      "Step 345 / 1000, loss = -7896.614421\n",
      "a_1 = 8.652997, a_2 = 6.332989, b = 2.452782\n",
      "\tgrad = 2.628991\n",
      "rate = 0.003836\n",
      "Step 346 / 1000, loss = -7896.798475\n",
      "a_1 = 8.661038, a_2 = 6.338894, b = 2.454668\n",
      "\tgrad = 2.654340\n",
      "rate = 0.003825\n",
      "Step 347 / 1000, loss = -7896.986398\n",
      "a_1 = 8.668989, a_2 = 6.345249, b = 2.456568\n",
      "\tgrad = 2.714308\n",
      "rate = 0.003815\n",
      "Step 348 / 1000, loss = -7897.171719\n",
      "a_1 = 8.677429, a_2 = 6.351038, b = 2.458416\n",
      "\tgrad = 2.733651\n",
      "rate = 0.003804\n",
      "Step 349 / 1000, loss = -7897.362452\n",
      "a_1 = 8.686302, a_2 = 6.356781, b = 2.460374\n",
      "\tgrad = 2.833284\n",
      "rate = 0.003794\n",
      "Step 350 / 1000, loss = -7897.545625\n",
      "a_1 = 8.694568, a_2 = 6.362573, b = 2.462258\n",
      "\tgrad = 2.713518\n",
      "rate = 0.003784\n",
      "Step 351 / 1000, loss = -7897.736632\n",
      "a_1 = 8.703226, a_2 = 6.368655, b = 2.464202\n",
      "\tgrad = 2.850823\n",
      "rate = 0.003774\n",
      "Step 352 / 1000, loss = -7897.920161\n",
      "a_1 = 8.711238, a_2 = 6.374802, b = 2.466087\n",
      "\tgrad = 2.729834\n",
      "rate = 0.003763\n",
      "Step 353 / 1000, loss = -7898.108081\n",
      "a_1 = 8.719847, a_2 = 6.380724, b = 2.468043\n",
      "\tgrad = 2.832216\n",
      "rate = 0.003753\n",
      "Step 354 / 1000, loss = -7898.285817\n",
      "a_1 = 8.728014, a_2 = 6.386298, b = 2.469922\n",
      "\tgrad = 2.688667\n",
      "rate = 0.003743\n",
      "Step 355 / 1000, loss = -7898.467582\n",
      "a_1 = 8.736292, a_2 = 6.392143, b = 2.471822\n",
      "\tgrad = 2.761650\n",
      "rate = 0.003733\n",
      "Step 356 / 1000, loss = -7898.642719\n",
      "a_1 = 8.744341, a_2 = 6.397793, b = 2.473624\n",
      "\tgrad = 2.685088\n",
      "rate = 0.003723\n",
      "Step 357 / 1000, loss = -7898.818030\n",
      "a_1 = 8.752270, a_2 = 6.403538, b = 2.475473\n",
      "\tgrad = 2.683272\n",
      "rate = 0.003714\n",
      "Step 358 / 1000, loss = -7898.986073\n",
      "a_1 = 8.760076, a_2 = 6.408852, b = 2.477270\n",
      "\tgrad = 2.595470\n",
      "rate = 0.003704\n",
      "Step 359 / 1000, loss = -7899.170497\n",
      "a_1 = 8.768377, a_2 = 6.415063, b = 2.479187\n",
      "\tgrad = 2.854089\n",
      "rate = 0.003694\n",
      "Step 360 / 1000, loss = -7899.340991\n",
      "a_1 = 8.776013, a_2 = 6.420753, b = 2.481040\n",
      "\tgrad = 2.633478\n",
      "rate = 0.003684\n",
      "Step 361 / 1000, loss = -7899.509492\n",
      "a_1 = 8.783892, a_2 = 6.426175, b = 2.482826\n",
      "\tgrad = 2.647838\n",
      "rate = 0.003675\n",
      "Step 362 / 1000, loss = -7899.673475\n",
      "a_1 = 8.791622, a_2 = 6.431442, b = 2.484556\n",
      "\tgrad = 2.595571\n",
      "rate = 0.003665\n",
      "Step 363 / 1000, loss = -7899.843355\n",
      "a_1 = 8.799707, a_2 = 6.436861, b = 2.486350\n",
      "\tgrad = 2.707448\n",
      "rate = 0.003655\n",
      "Step 364 / 1000, loss = -7900.013159\n",
      "a_1 = 8.807514, a_2 = 6.442557, b = 2.488155\n",
      "\tgrad = 2.696567\n",
      "rate = 0.003646\n",
      "Step 365 / 1000, loss = -7900.178486\n",
      "a_1 = 8.815250, a_2 = 6.447906, b = 2.489980\n",
      "\tgrad = 2.634792\n",
      "rate = 0.003636\n",
      "Step 366 / 1000, loss = -7900.345048\n",
      "a_1 = 8.822913, a_2 = 6.453520, b = 2.491779\n",
      "\tgrad = 2.665571\n",
      "rate = 0.003627\n",
      "Step 367 / 1000, loss = -7900.506117\n",
      "a_1 = 8.830326, a_2 = 6.459039, b = 2.493483\n",
      "\tgrad = 2.597713\n",
      "rate = 0.003618\n",
      "Step 368 / 1000, loss = -7900.670515\n",
      "a_1 = 8.838285, a_2 = 6.464321, b = 2.495233\n",
      "\tgrad = 2.691440\n",
      "rate = 0.003608\n",
      "Step 369 / 1000, loss = -7900.838327\n",
      "a_1 = 8.846328, a_2 = 6.469825, b = 2.497022\n",
      "\tgrad = 2.753177\n",
      "rate = 0.003599\n",
      "Step 370 / 1000, loss = -7901.004966\n",
      "a_1 = 8.854185, a_2 = 6.475383, b = 2.498842\n",
      "\tgrad = 2.728410\n",
      "rate = 0.003590\n",
      "Step 371 / 1000, loss = -7901.160739\n",
      "a_1 = 8.861690, a_2 = 6.480502, b = 2.500518\n",
      "\tgrad = 2.580042\n",
      "rate = 0.003581\n",
      "Step 372 / 1000, loss = -7901.313071\n",
      "a_1 = 8.869051, a_2 = 6.485412, b = 2.502225\n",
      "\tgrad = 2.523310\n",
      "rate = 0.003571\n",
      "Step 373 / 1000, loss = -7901.479365\n",
      "a_1 = 8.877223, a_2 = 6.490783, b = 2.504024\n",
      "\tgrad = 2.791193\n",
      "rate = 0.003562\n",
      "Step 374 / 1000, loss = -7901.637599\n",
      "a_1 = 8.884858, a_2 = 6.496068, b = 2.505733\n",
      "\tgrad = 2.657102\n",
      "rate = 0.003553\n",
      "Step 375 / 1000, loss = -7901.794570\n",
      "a_1 = 8.892174, a_2 = 6.501469, b = 2.507505\n",
      "\tgrad = 2.613841\n",
      "rate = 0.003544\n",
      "Step 376 / 1000, loss = -7901.956884\n",
      "a_1 = 8.899849, a_2 = 6.507095, b = 2.509269\n",
      "\tgrad = 2.737594\n",
      "rate = 0.003535\n",
      "Step 377 / 1000, loss = -7902.110297\n",
      "a_1 = 8.907207, a_2 = 6.512285, b = 2.510976\n",
      "\tgrad = 2.599101\n",
      "rate = 0.003526\n",
      "Step 378 / 1000, loss = -7902.267677\n",
      "a_1 = 8.914811, a_2 = 6.517627, b = 2.512706\n",
      "\tgrad = 2.687021\n",
      "rate = 0.003518\n",
      "Step 379 / 1000, loss = -7902.427329\n",
      "a_1 = 8.922642, a_2 = 6.523000, b = 2.514443\n",
      "\tgrad = 2.751681\n",
      "rate = 0.003509\n",
      "Step 380 / 1000, loss = -7902.576057\n",
      "a_1 = 8.929906, a_2 = 6.528032, b = 2.516085\n",
      "\tgrad = 2.567925\n",
      "rate = 0.003500\n",
      "Step 381 / 1000, loss = -7902.730245\n",
      "a_1 = 8.937438, a_2 = 6.533244, b = 2.517809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad = 2.669775\n",
      "rate = 0.003491\n",
      "Step 382 / 1000, loss = -7902.893246\n",
      "a_1 = 8.945591, a_2 = 6.538605, b = 2.519638\n",
      "\tgrad = 2.850474\n",
      "rate = 0.003483\n",
      "Step 383 / 1000, loss = -7903.038968\n",
      "a_1 = 8.952744, a_2 = 6.543495, b = 2.521312\n",
      "\tgrad = 2.540288\n",
      "rate = 0.003474\n",
      "Step 384 / 1000, loss = -7903.190449\n",
      "a_1 = 8.960368, a_2 = 6.548518, b = 2.523000\n",
      "\tgrad = 2.679312\n",
      "rate = 0.003465\n",
      "Step 385 / 1000, loss = -7903.343063\n",
      "a_1 = 8.968025, a_2 = 6.553585, b = 2.524732\n",
      "\tgrad = 2.703032\n",
      "rate = 0.003457\n",
      "Step 386 / 1000, loss = -7903.497362\n",
      "a_1 = 8.975524, a_2 = 6.558979, b = 2.526480\n",
      "\tgrad = 2.726342\n",
      "rate = 0.003448\n",
      "Step 387 / 1000, loss = -7903.660160\n",
      "a_1 = 8.983709, a_2 = 6.564539, b = 2.528268\n",
      "\tgrad = 2.923222\n",
      "rate = 0.003440\n",
      "Step 388 / 1000, loss = -7903.812801\n",
      "a_1 = 8.991380, a_2 = 6.569786, b = 2.529950\n",
      "\tgrad = 2.752364\n",
      "rate = 0.003431\n",
      "Step 389 / 1000, loss = -7903.960689\n",
      "a_1 = 8.998748, a_2 = 6.574947, b = 2.531589\n",
      "\tgrad = 2.671319\n",
      "rate = 0.003423\n",
      "Step 390 / 1000, loss = -7904.112538\n",
      "a_1 = 9.006719, a_2 = 6.579818, b = 2.533321\n",
      "\tgrad = 2.782359\n",
      "rate = 0.003415\n",
      "Step 391 / 1000, loss = -7904.254831\n",
      "a_1 = 9.013831, a_2 = 6.584772, b = 2.534932\n",
      "\tgrad = 2.588279\n",
      "rate = 0.003406\n",
      "Step 392 / 1000, loss = -7904.410223\n",
      "a_1 = 9.021512, a_2 = 6.590295, b = 2.536695\n",
      "\tgrad = 2.831865\n",
      "rate = 0.003398\n",
      "Step 393 / 1000, loss = -7904.548580\n",
      "a_1 = 9.028433, a_2 = 6.595134, b = 2.538285\n",
      "\tgrad = 2.534887\n",
      "rate = 0.003390\n",
      "Step 394 / 1000, loss = -7904.690332\n",
      "a_1 = 9.035445, a_2 = 6.600102, b = 2.539972\n",
      "\tgrad = 2.589899\n",
      "rate = 0.003382\n",
      "Step 395 / 1000, loss = -7904.836432\n",
      "a_1 = 9.042738, a_2 = 6.605241, b = 2.541683\n",
      "\tgrad = 2.692608\n",
      "rate = 0.003373\n",
      "Step 396 / 1000, loss = -7904.995588\n",
      "a_1 = 9.050803, a_2 = 6.610819, b = 2.543510\n",
      "\tgrad = 2.964103\n",
      "rate = 0.003365\n",
      "Step 397 / 1000, loss = -7905.135364\n",
      "a_1 = 9.058006, a_2 = 6.615626, b = 2.545122\n",
      "\tgrad = 2.623770\n",
      "rate = 0.003357\n",
      "Step 398 / 1000, loss = -7905.286354\n",
      "a_1 = 9.065766, a_2 = 6.620851, b = 2.546877\n",
      "\tgrad = 2.841849\n",
      "rate = 0.003349\n",
      "Step 399 / 1000, loss = -7905.426154\n",
      "a_1 = 9.072717, a_2 = 6.625930, b = 2.548510\n",
      "\tgrad = 2.622534\n",
      "rate = 0.003341\n",
      "Step 400 / 1000, loss = -7905.565882\n",
      "a_1 = 9.079993, a_2 = 6.630707, b = 2.550154\n",
      "\tgrad = 2.657371\n",
      "rate = 0.003333\n",
      "Step 401 / 1000, loss = -7905.703925\n",
      "a_1 = 9.086812, a_2 = 6.635873, b = 2.551740\n",
      "\tgrad = 2.616115\n",
      "rate = 0.003325\n",
      "Step 402 / 1000, loss = -7905.850718\n",
      "a_1 = 9.094038, a_2 = 6.641403, b = 2.553439\n",
      "\tgrad = 2.790394\n",
      "rate = 0.003318\n",
      "Step 403 / 1000, loss = -7905.983268\n",
      "a_1 = 9.100542, a_2 = 6.646439, b = 2.554978\n",
      "\tgrad = 2.528558\n",
      "rate = 0.003310\n",
      "Step 404 / 1000, loss = -7906.123789\n",
      "a_1 = 9.107785, a_2 = 6.651430, b = 2.556638\n",
      "\tgrad = 2.710817\n",
      "rate = 0.003302\n",
      "Step 405 / 1000, loss = -7906.258627\n",
      "a_1 = 9.114540, a_2 = 6.656445, b = 2.558226\n",
      "\tgrad = 2.599122\n",
      "rate = 0.003294\n",
      "Step 406 / 1000, loss = -7906.396853\n",
      "a_1 = 9.121464, a_2 = 6.661556, b = 2.559892\n",
      "\tgrad = 2.667234\n",
      "rate = 0.003286\n",
      "Step 407 / 1000, loss = -7906.535463\n",
      "a_1 = 9.128765, a_2 = 6.666389, b = 2.561551\n",
      "\tgrad = 2.718003\n",
      "rate = 0.003279\n",
      "Step 408 / 1000, loss = -7906.672643\n",
      "a_1 = 9.135822, a_2 = 6.671430, b = 2.563154\n",
      "\tgrad = 2.696168\n",
      "rate = 0.003271\n",
      "Step 409 / 1000, loss = -7906.803757\n",
      "a_1 = 9.142425, a_2 = 6.676346, b = 2.564727\n",
      "\tgrad = 2.568243\n",
      "rate = 0.003263\n",
      "Step 410 / 1000, loss = -7906.928060\n",
      "a_1 = 9.148723, a_2 = 6.680928, b = 2.566261\n",
      "\tgrad = 2.438056\n",
      "rate = 0.003256\n",
      "Step 411 / 1000, loss = -7907.071774\n",
      "a_1 = 9.156064, a_2 = 6.686355, b = 2.567940\n",
      "\tgrad = 2.857672\n",
      "rate = 0.003248\n",
      "Step 412 / 1000, loss = -7907.206680\n",
      "a_1 = 9.163092, a_2 = 6.691245, b = 2.569580\n",
      "\tgrad = 2.690153\n",
      "rate = 0.003241\n",
      "Step 413 / 1000, loss = -7907.350000\n",
      "a_1 = 9.170401, a_2 = 6.696721, b = 2.571264\n",
      "\tgrad = 2.872328\n",
      "rate = 0.003233\n",
      "Step 414 / 1000, loss = -7907.478972\n",
      "a_1 = 9.177081, a_2 = 6.701458, b = 2.572854\n",
      "\tgrad = 2.585990\n",
      "rate = 0.003226\n",
      "Step 415 / 1000, loss = -7907.608253\n",
      "a_1 = 9.183913, a_2 = 6.706186, b = 2.574399\n",
      "\tgrad = 2.625732\n",
      "rate = 0.003218\n",
      "Step 416 / 1000, loss = -7907.744183\n",
      "a_1 = 9.191271, a_2 = 6.711077, b = 2.575989\n",
      "\tgrad = 2.795859\n",
      "rate = 0.003211\n",
      "Step 417 / 1000, loss = -7907.877347\n",
      "a_1 = 9.198106, a_2 = 6.716128, b = 2.577626\n",
      "\tgrad = 2.701444\n",
      "rate = 0.003204\n",
      "Step 418 / 1000, loss = -7908.007006\n",
      "a_1 = 9.204884, a_2 = 6.720998, b = 2.579195\n",
      "\tgrad = 2.656911\n",
      "rate = 0.003196\n",
      "Step 419 / 1000, loss = -7908.136006\n",
      "a_1 = 9.211363, a_2 = 6.726115, b = 2.580764\n",
      "\tgrad = 2.635154\n",
      "rate = 0.003189\n",
      "Step 420 / 1000, loss = -7908.263523\n",
      "a_1 = 9.218061, a_2 = 6.730948, b = 2.582298\n",
      "\tgrad = 2.640303\n",
      "rate = 0.003182\n",
      "Step 421 / 1000, loss = -7908.402171\n",
      "a_1 = 9.225300, a_2 = 6.736296, b = 2.583955\n",
      "\tgrad = 2.882642\n",
      "rate = 0.003175\n",
      "Step 422 / 1000, loss = -7908.531369\n",
      "a_1 = 9.232168, a_2 = 6.741094, b = 2.585558\n",
      "\tgrad = 2.693167\n",
      "rate = 0.003167\n",
      "Step 423 / 1000, loss = -7908.658989\n",
      "a_1 = 9.238889, a_2 = 6.745987, b = 2.587103\n",
      "\tgrad = 2.675722\n",
      "rate = 0.003160\n",
      "Step 424 / 1000, loss = -7908.787051\n",
      "a_1 = 9.245472, a_2 = 6.751025, b = 2.588689\n",
      "\tgrad = 2.676427\n",
      "rate = 0.003153\n",
      "Step 425 / 1000, loss = -7908.920345\n",
      "a_1 = 9.252702, a_2 = 6.755964, b = 2.590322\n",
      "\tgrad = 2.831181\n",
      "rate = 0.003146\n",
      "Step 426 / 1000, loss = -7909.037940\n",
      "a_1 = 9.259127, a_2 = 6.760308, b = 2.591759\n",
      "\tgrad = 2.512858\n",
      "rate = 0.003139\n",
      "Step 427 / 1000, loss = -7909.154637\n",
      "a_1 = 9.265366, a_2 = 6.764726, b = 2.593216\n",
      "\tgrad = 2.484921\n",
      "rate = 0.003132\n",
      "Step 428 / 1000, loss = -7909.276221\n",
      "a_1 = 9.271923, a_2 = 6.769284, b = 2.594744\n",
      "\tgrad = 2.601642\n",
      "rate = 0.003125\n",
      "Step 429 / 1000, loss = -7909.407739\n",
      "a_1 = 9.279041, a_2 = 6.774294, b = 2.596353\n",
      "\tgrad = 2.838875\n",
      "rate = 0.003118\n",
      "Step 430 / 1000, loss = -7909.541074\n",
      "a_1 = 9.286466, a_2 = 6.779237, b = 2.597964\n",
      "\tgrad = 2.913479\n",
      "rate = 0.003111\n",
      "Step 431 / 1000, loss = -7909.656924\n",
      "a_1 = 9.292641, a_2 = 6.783748, b = 2.599411\n",
      "\tgrad = 2.507271\n",
      "rate = 0.003104\n",
      "Step 432 / 1000, loss = -7909.779841\n",
      "a_1 = 9.299241, a_2 = 6.788565, b = 2.600916\n",
      "\tgrad = 2.682373\n",
      "rate = 0.003097\n",
      "Step 433 / 1000, loss = -7909.900719\n",
      "a_1 = 9.306025, a_2 = 6.792988, b = 2.602430\n",
      "\tgrad = 2.665944\n",
      "rate = 0.003091\n",
      "Step 434 / 1000, loss = -7910.023779\n",
      "a_1 = 9.312845, a_2 = 6.797629, b = 2.603957\n",
      "\tgrad = 2.720440\n",
      "rate = 0.003084\n",
      "Step 435 / 1000, loss = -7910.147426\n",
      "a_1 = 9.319437, a_2 = 6.802518, b = 2.605523\n",
      "\tgrad = 2.715593\n",
      "rate = 0.003077\n",
      "Step 436 / 1000, loss = -7910.267120\n",
      "a_1 = 9.326085, a_2 = 6.807035, b = 2.607030\n",
      "\tgrad = 2.663525\n",
      "rate = 0.003070\n",
      "Step 437 / 1000, loss = -7910.387094\n",
      "a_1 = 9.332709, a_2 = 6.811630, b = 2.608541\n",
      "\tgrad = 2.677272\n",
      "rate = 0.003063\n",
      "Step 438 / 1000, loss = -7910.515663\n",
      "a_1 = 9.339750, a_2 = 6.816679, b = 2.610136\n",
      "\tgrad = 2.882029\n",
      "rate = 0.003057\n",
      "Step 439 / 1000, loss = -7910.640922\n",
      "a_1 = 9.346906, a_2 = 6.821380, b = 2.611667\n",
      "\tgrad = 2.851850\n",
      "rate = 0.003050\n",
      "Step 440 / 1000, loss = -7910.756286\n",
      "a_1 = 9.353206, a_2 = 6.825877, b = 2.613162\n",
      "\tgrad = 2.590178\n",
      "rate = 0.003043\n",
      "Step 441 / 1000, loss = -7910.868014\n",
      "a_1 = 9.359376, a_2 = 6.830122, b = 2.614650\n",
      "\tgrad = 2.514077\n",
      "rate = 0.003037\n",
      "Step 442 / 1000, loss = -7910.992731\n",
      "a_1 = 9.366282, a_2 = 6.835025, b = 2.616220\n",
      "\tgrad = 2.842538\n",
      "rate = 0.003030\n",
      "Step 443 / 1000, loss = -7911.112219\n",
      "a_1 = 9.373061, a_2 = 6.839554, b = 2.617747\n",
      "\tgrad = 2.743051\n",
      "rate = 0.003024\n",
      "Step 444 / 1000, loss = -7911.232401\n",
      "a_1 = 9.379763, a_2 = 6.844276, b = 2.619267\n",
      "\tgrad = 2.763627\n",
      "rate = 0.003017\n",
      "Step 445 / 1000, loss = -7911.355403\n",
      "a_1 = 9.386883, a_2 = 6.848966, b = 2.620776\n",
      "\tgrad = 2.875930\n",
      "rate = 0.003011\n",
      "Step 446 / 1000, loss = -7911.475274\n",
      "a_1 = 9.393847, a_2 = 6.853416, b = 2.622320\n",
      "\tgrad = 2.798332\n",
      "rate = 0.003004\n",
      "Step 447 / 1000, loss = -7911.595707\n",
      "a_1 = 9.400655, a_2 = 6.858142, b = 2.623846\n",
      "\tgrad = 2.811056\n",
      "rate = 0.002998\n",
      "Step 448 / 1000, loss = -7911.712288\n",
      "a_1 = 9.406854, a_2 = 6.863130, b = 2.625320\n",
      "\tgrad = 2.705069\n",
      "rate = 0.002991\n",
      "Step 449 / 1000, loss = -7911.828834\n",
      "a_1 = 9.413318, a_2 = 6.867863, b = 2.626807\n",
      "\tgrad = 2.729724\n",
      "rate = 0.002985\n",
      "Step 450 / 1000, loss = -7911.947425\n",
      "a_1 = 9.420090, a_2 = 6.872512, b = 2.628323\n",
      "\tgrad = 2.804211\n",
      "rate = 0.002979\n",
      "Step 451 / 1000, loss = -7912.064261\n",
      "a_1 = 9.426533, a_2 = 6.877336, b = 2.629821\n",
      "\tgrad = 2.754268\n",
      "rate = 0.002972\n",
      "Step 452 / 1000, loss = -7912.176873\n",
      "a_1 = 9.432919, a_2 = 6.881768, b = 2.631307\n",
      "\tgrad = 2.668223\n",
      "rate = 0.002966\n",
      "Step 453 / 1000, loss = -7912.291440\n",
      "a_1 = 9.439676, a_2 = 6.886080, b = 2.632802\n",
      "\tgrad = 2.754590\n",
      "rate = 0.002960\n",
      "Step 454 / 1000, loss = -7912.403066\n",
      "a_1 = 9.446149, a_2 = 6.890419, b = 2.634255\n",
      "\tgrad = 2.684025\n",
      "rate = 0.002954\n",
      "Step 455 / 1000, loss = -7912.515991\n",
      "a_1 = 9.452630, a_2 = 6.894865, b = 2.635747\n",
      "\tgrad = 2.714087\n",
      "rate = 0.002947\n",
      "Step 456 / 1000, loss = -7912.626924\n",
      "a_1 = 9.458840, a_2 = 6.899416, b = 2.637208\n",
      "\tgrad = 2.664566\n",
      "rate = 0.002941\n",
      "Step 457 / 1000, loss = -7912.740722\n",
      "a_1 = 9.465450, a_2 = 6.903913, b = 2.638687\n",
      "\tgrad = 2.770001\n",
      "rate = 0.002935\n",
      "Step 458 / 1000, loss = -7912.849892\n",
      "a_1 = 9.471577, a_2 = 6.908403, b = 2.640140\n",
      "\tgrad = 2.640581\n",
      "rate = 0.002929\n",
      "Step 459 / 1000, loss = -7912.961919\n",
      "a_1 = 9.478074, a_2 = 6.912863, b = 2.641613\n",
      "\tgrad = 2.742878\n",
      "rate = 0.002923\n",
      "Step 460 / 1000, loss = -7913.081662\n",
      "a_1 = 9.485005, a_2 = 6.917767, b = 2.643133\n",
      "\tgrad = 2.957262\n",
      "rate = 0.002917\n",
      "Step 461 / 1000, loss = -7913.188615\n",
      "a_1 = 9.491191, a_2 = 6.922088, b = 2.644541\n",
      "\tgrad = 2.637432\n",
      "rate = 0.002911\n",
      "Step 462 / 1000, loss = -7913.296673\n",
      "a_1 = 9.497601, a_2 = 6.926322, b = 2.645965\n",
      "\tgrad = 2.689910\n",
      "rate = 0.002905\n",
      "Step 463 / 1000, loss = -7913.402371\n",
      "a_1 = 9.503661, a_2 = 6.930645, b = 2.647385\n",
      "\tgrad = 2.614479\n",
      "rate = 0.002899\n",
      "Step 464 / 1000, loss = -7913.506118\n",
      "a_1 = 9.509786, a_2 = 6.934748, b = 2.648773\n",
      "\tgrad = 2.593427\n",
      "rate = 0.002893\n",
      "Step 465 / 1000, loss = -7913.612584\n",
      "a_1 = 9.515901, a_2 = 6.939147, b = 2.650199\n",
      "\tgrad = 2.656088\n",
      "rate = 0.002887\n",
      "Step 466 / 1000, loss = -7913.719640\n",
      "a_1 = 9.521913, a_2 = 6.943688, b = 2.651657\n",
      "\tgrad = 2.664009\n",
      "rate = 0.002881\n",
      "Step 467 / 1000, loss = -7913.830486\n",
      "a_1 = 9.528424, a_2 = 6.948241, b = 2.653106\n",
      "\tgrad = 2.809227\n",
      "rate = 0.002875\n",
      "Step 468 / 1000, loss = -7913.934782\n",
      "a_1 = 9.534701, a_2 = 6.952338, b = 2.654506\n",
      "\tgrad = 2.657876\n",
      "rate = 0.002869\n",
      "Step 469 / 1000, loss = -7914.040392\n",
      "a_1 = 9.541069, a_2 = 6.956460, b = 2.655946\n",
      "\tgrad = 2.696830\n",
      "rate = 0.002863\n",
      "Step 470 / 1000, loss = -7914.148216\n",
      "a_1 = 9.547364, a_2 = 6.960943, b = 2.657389\n",
      "\tgrad = 2.751622\n",
      "rate = 0.002857\n",
      "Step 471 / 1000, loss = -7914.258743\n",
      "a_1 = 9.553945, a_2 = 6.965527, b = 2.658817\n",
      "\tgrad = 2.857148\n",
      "rate = 0.002851\n",
      "Step 472 / 1000, loss = -7914.365211\n",
      "a_1 = 9.560210, a_2 = 6.969981, b = 2.660229\n",
      "\tgrad = 2.746305\n",
      "rate = 0.002846\n",
      "Step 473 / 1000, loss = -7914.462470\n",
      "a_1 = 9.565934, a_2 = 6.973955, b = 2.661583\n",
      "\tgrad = 2.500082\n",
      "rate = 0.002840\n",
      "Step 474 / 1000, loss = -7914.571718\n",
      "a_1 = 9.572103, a_2 = 6.978756, b = 2.663074\n",
      "\tgrad = 2.807689\n",
      "rate = 0.002834\n",
      "Step 475 / 1000, loss = -7914.671410\n",
      "a_1 = 9.578020, a_2 = 6.982911, b = 2.664414\n",
      "\tgrad = 2.600022\n",
      "rate = 0.002828\n",
      "Step 476 / 1000, loss = -7914.770893\n",
      "a_1 = 9.583909, a_2 = 6.987079, b = 2.665761\n",
      "\tgrad = 2.600494\n",
      "rate = 0.002823\n",
      "Step 477 / 1000, loss = -7914.873244\n",
      "a_1 = 9.590006, a_2 = 6.991358, b = 2.667144\n",
      "\tgrad = 2.689433\n",
      "rate = 0.002817\n",
      "Step 478 / 1000, loss = -7914.975649\n",
      "a_1 = 9.596230, a_2 = 6.995479, b = 2.668564\n",
      "\tgrad = 2.702697\n",
      "rate = 0.002811\n",
      "Step 479 / 1000, loss = -7915.076848\n",
      "a_1 = 9.602302, a_2 = 6.999627, b = 2.669980\n",
      "\tgrad = 2.669237\n",
      "rate = 0.002806\n",
      "Step 480 / 1000, loss = -7915.174574\n",
      "a_1 = 9.608226, a_2 = 7.003603, b = 2.671344\n",
      "\tgrad = 2.594283\n",
      "rate = 0.002800\n",
      "Step 481 / 1000, loss = -7915.274488\n",
      "a_1 = 9.614147, a_2 = 7.007853, b = 2.672722\n",
      "\tgrad = 2.654413\n",
      "rate = 0.002794\n",
      "Step 482 / 1000, loss = -7915.380014\n",
      "a_1 = 9.620577, a_2 = 7.012212, b = 2.674166\n",
      "\tgrad = 2.833101\n",
      "rate = 0.002789\n",
      "Step 483 / 1000, loss = -7915.481904\n",
      "a_1 = 9.626612, a_2 = 7.016601, b = 2.675569\n",
      "\tgrad = 2.728029\n",
      "rate = 0.002783\n",
      "Step 484 / 1000, loss = -7915.585371\n",
      "a_1 = 9.632655, a_2 = 7.021161, b = 2.676997\n",
      "\tgrad = 2.773335\n",
      "rate = 0.002778\n",
      "Step 485 / 1000, loss = -7915.686666\n",
      "a_1 = 9.638781, a_2 = 7.025458, b = 2.678386\n",
      "\tgrad = 2.745330\n",
      "rate = 0.002772\n",
      "Step 486 / 1000, loss = -7915.785697\n",
      "a_1 = 9.644863, a_2 = 7.029551, b = 2.679766\n",
      "\tgrad = 2.696128\n",
      "rate = 0.002767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 487 / 1000, loss = -7915.881526\n",
      "a_1 = 9.650753, a_2 = 7.033547, b = 2.681092\n",
      "\tgrad = 2.621918\n",
      "rate = 0.002761\n",
      "Step 488 / 1000, loss = -7915.979442\n",
      "a_1 = 9.656789, a_2 = 7.037559, b = 2.682489\n",
      "\tgrad = 2.678343\n",
      "rate = 0.002756\n",
      "Step 489 / 1000, loss = -7916.075043\n",
      "a_1 = 9.662696, a_2 = 7.041518, b = 2.683834\n",
      "\tgrad = 2.631307\n",
      "rate = 0.002750\n",
      "Step 490 / 1000, loss = -7916.169959\n",
      "a_1 = 9.668517, a_2 = 7.045574, b = 2.685135\n",
      "\tgrad = 2.627437\n",
      "rate = 0.002745\n",
      "Step 491 / 1000, loss = -7916.266775\n",
      "a_1 = 9.674454, a_2 = 7.049662, b = 2.686502\n",
      "\tgrad = 2.678057\n",
      "rate = 0.002740\n",
      "Step 492 / 1000, loss = -7916.359332\n",
      "a_1 = 9.680121, a_2 = 7.053586, b = 2.687817\n",
      "\tgrad = 2.566222\n",
      "rate = 0.002734\n",
      "Step 493 / 1000, loss = -7916.458117\n",
      "a_1 = 9.686251, a_2 = 7.057745, b = 2.689204\n",
      "\tgrad = 2.761768\n",
      "rate = 0.002729\n",
      "Step 494 / 1000, loss = -7916.556559\n",
      "a_1 = 9.692389, a_2 = 7.061935, b = 2.690557\n",
      "\tgrad = 2.773200\n",
      "rate = 0.002724\n",
      "Step 495 / 1000, loss = -7916.655963\n",
      "a_1 = 9.698581, a_2 = 7.066180, b = 2.691933\n",
      "\tgrad = 2.807489\n",
      "rate = 0.002718\n",
      "Step 496 / 1000, loss = -7916.750691\n",
      "a_1 = 9.704474, a_2 = 7.070192, b = 2.693279\n",
      "\tgrad = 2.674063\n",
      "rate = 0.002713\n",
      "Step 497 / 1000, loss = -7916.848083\n",
      "a_1 = 9.710517, a_2 = 7.074398, b = 2.694638\n",
      "\tgrad = 2.764975\n",
      "rate = 0.002708\n",
      "Step 498 / 1000, loss = -7916.939962\n",
      "a_1 = 9.716282, a_2 = 7.078274, b = 2.695949\n",
      "\tgrad = 2.615546\n",
      "rate = 0.002703\n",
      "Step 499 / 1000, loss = -7917.031116\n",
      "a_1 = 9.721781, a_2 = 7.082285, b = 2.697289\n",
      "\tgrad = 2.571756\n",
      "rate = 0.002697\n",
      "Step 500 / 1000, loss = -7917.128162\n",
      "a_1 = 9.727802, a_2 = 7.086495, b = 2.698670\n",
      "\tgrad = 2.776745\n",
      "rate = 0.002692\n",
      "Step 501 / 1000, loss = -7917.220420\n",
      "a_1 = 9.733625, a_2 = 7.090362, b = 2.700017\n",
      "\tgrad = 2.649103\n",
      "rate = 0.002687\n",
      "Step 502 / 1000, loss = -7917.312091\n",
      "a_1 = 9.739331, a_2 = 7.094365, b = 2.701320\n",
      "\tgrad = 2.643800\n",
      "rate = 0.002682\n",
      "Step 503 / 1000, loss = -7917.410168\n",
      "a_1 = 9.745386, a_2 = 7.098724, b = 2.702712\n",
      "\tgrad = 2.835238\n",
      "rate = 0.002677\n",
      "Step 504 / 1000, loss = -7917.506943\n",
      "a_1 = 9.751338, a_2 = 7.103047, b = 2.704099\n",
      "\tgrad = 2.801827\n",
      "rate = 0.002672\n",
      "Step 505 / 1000, loss = -7917.597073\n",
      "a_1 = 9.756916, a_2 = 7.107027, b = 2.705408\n",
      "\tgrad = 2.616333\n",
      "rate = 0.002667\n",
      "Step 506 / 1000, loss = -7917.685937\n",
      "a_1 = 9.762415, a_2 = 7.110945, b = 2.706715\n",
      "\tgrad = 2.583620\n",
      "rate = 0.002662\n",
      "Step 507 / 1000, loss = -7917.776063\n",
      "a_1 = 9.768105, a_2 = 7.114882, b = 2.708009\n",
      "\tgrad = 2.649882\n",
      "rate = 0.002657\n",
      "Step 508 / 1000, loss = -7917.866149\n",
      "a_1 = 9.773641, a_2 = 7.119000, b = 2.709295\n",
      "\tgrad = 2.647066\n",
      "rate = 0.002652\n",
      "Step 509 / 1000, loss = -7917.961468\n",
      "a_1 = 9.779688, a_2 = 7.123203, b = 2.710650\n",
      "\tgrad = 2.829275\n",
      "rate = 0.002647\n",
      "Step 510 / 1000, loss = -7918.051084\n",
      "a_1 = 9.785384, a_2 = 7.127123, b = 2.711947\n",
      "\tgrad = 2.663337\n",
      "rate = 0.002642\n",
      "Step 511 / 1000, loss = -7918.143306\n",
      "a_1 = 9.791303, a_2 = 7.131114, b = 2.713286\n",
      "\tgrad = 2.754707\n",
      "rate = 0.002637\n",
      "Step 512 / 1000, loss = -7918.234581\n",
      "a_1 = 9.796984, a_2 = 7.135215, b = 2.714636\n",
      "\tgrad = 2.711605\n",
      "rate = 0.002632\n",
      "Step 513 / 1000, loss = -7918.323112\n",
      "a_1 = 9.802551, a_2 = 7.139184, b = 2.715931\n",
      "\tgrad = 2.649086\n",
      "rate = 0.002627\n",
      "Step 514 / 1000, loss = -7918.412802\n",
      "a_1 = 9.807880, a_2 = 7.143547, b = 2.717234\n",
      "\tgrad = 2.673745\n",
      "rate = 0.002622\n",
      "Step 515 / 1000, loss = -7918.506015\n",
      "a_1 = 9.813823, a_2 = 7.147659, b = 2.718613\n",
      "\tgrad = 2.811582\n",
      "rate = 0.002617\n",
      "Step 516 / 1000, loss = -7918.594688\n",
      "a_1 = 9.819603, a_2 = 7.151491, b = 2.719911\n",
      "\tgrad = 2.701151\n",
      "rate = 0.002612\n",
      "Step 517 / 1000, loss = -7918.682191\n",
      "a_1 = 9.825173, a_2 = 7.155440, b = 2.721183\n",
      "\tgrad = 2.664116\n",
      "rate = 0.002607\n",
      "Step 518 / 1000, loss = -7918.771448\n",
      "a_1 = 9.830940, a_2 = 7.159441, b = 2.722461\n",
      "\tgrad = 2.741393\n",
      "rate = 0.002602\n",
      "Step 519 / 1000, loss = -7918.852459\n",
      "a_1 = 9.836013, a_2 = 7.163176, b = 2.723661\n",
      "\tgrad = 2.469028\n",
      "rate = 0.002597\n",
      "Step 520 / 1000, loss = -7918.935808\n",
      "a_1 = 9.841131, a_2 = 7.167133, b = 2.724898\n",
      "\tgrad = 2.540532\n",
      "rate = 0.002593\n",
      "Step 521 / 1000, loss = -7919.023341\n",
      "a_1 = 9.846638, a_2 = 7.171196, b = 2.726186\n",
      "\tgrad = 2.690945\n",
      "rate = 0.002588\n",
      "Step 522 / 1000, loss = -7919.110598\n",
      "a_1 = 9.852265, a_2 = 7.175178, b = 2.727444\n",
      "\tgrad = 2.712816\n",
      "rate = 0.002583\n",
      "Step 523 / 1000, loss = -7919.199066\n",
      "a_1 = 9.857837, a_2 = 7.179282, b = 2.728767\n",
      "\tgrad = 2.732646\n",
      "rate = 0.002578\n",
      "Step 524 / 1000, loss = -7919.282896\n",
      "a_1 = 9.863289, a_2 = 7.183037, b = 2.730010\n",
      "\tgrad = 2.617514\n",
      "rate = 0.002574\n",
      "Step 525 / 1000, loss = -7919.370041\n",
      "a_1 = 9.868777, a_2 = 7.187129, b = 2.731307\n",
      "\tgrad = 2.712369\n",
      "rate = 0.002569\n",
      "Step 526 / 1000, loss = -7919.460192\n",
      "a_1 = 9.874676, a_2 = 7.191190, b = 2.732635\n",
      "\tgrad = 2.840388\n",
      "rate = 0.002564\n",
      "Step 527 / 1000, loss = -7919.544540\n",
      "a_1 = 9.880107, a_2 = 7.195060, b = 2.733897\n",
      "\tgrad = 2.651994\n",
      "rate = 0.002559\n",
      "Step 528 / 1000, loss = -7919.628364\n",
      "a_1 = 9.885480, a_2 = 7.198949, b = 2.735152\n",
      "\tgrad = 2.642173\n",
      "rate = 0.002555\n",
      "Step 529 / 1000, loss = -7919.714585\n",
      "a_1 = 9.891060, a_2 = 7.202901, b = 2.736450\n",
      "\tgrad = 2.729250\n",
      "rate = 0.002550\n",
      "Step 530 / 1000, loss = -7919.795990\n",
      "a_1 = 9.896341, a_2 = 7.206617, b = 2.737687\n",
      "\tgrad = 2.582892\n",
      "rate = 0.002545\n",
      "Step 531 / 1000, loss = -7919.879691\n",
      "a_1 = 9.901886, a_2 = 7.210381, b = 2.738937\n",
      "\tgrad = 2.683404\n",
      "rate = 0.002541\n",
      "Step 532 / 1000, loss = -7919.957592\n",
      "a_1 = 9.906975, a_2 = 7.213926, b = 2.740126\n",
      "\tgrad = 2.489767\n",
      "rate = 0.002536\n",
      "Step 533 / 1000, loss = -7920.040533\n",
      "a_1 = 9.912513, a_2 = 7.217623, b = 2.741379\n",
      "\tgrad = 2.676319\n",
      "rate = 0.002532\n",
      "Step 534 / 1000, loss = -7920.118155\n",
      "a_1 = 9.917803, a_2 = 7.220939, b = 2.742582\n",
      "\tgrad = 2.515951\n",
      "rate = 0.002527\n",
      "Step 535 / 1000, loss = -7920.206021\n",
      "a_1 = 9.923695, a_2 = 7.224911, b = 2.743886\n",
      "\tgrad = 2.864070\n",
      "rate = 0.002523\n",
      "Step 536 / 1000, loss = -7920.285992\n",
      "a_1 = 9.928849, a_2 = 7.228703, b = 2.745100\n",
      "\tgrad = 2.586377\n",
      "rate = 0.002518\n",
      "Step 537 / 1000, loss = -7920.365287\n",
      "a_1 = 9.933990, a_2 = 7.232443, b = 2.746306\n",
      "\tgrad = 2.574685\n",
      "rate = 0.002513\n",
      "Step 538 / 1000, loss = -7920.447883\n",
      "a_1 = 9.939362, a_2 = 7.236350, b = 2.747558\n",
      "\tgrad = 2.693906\n",
      "rate = 0.002509\n",
      "Step 539 / 1000, loss = -7920.530001\n",
      "a_1 = 9.944771, a_2 = 7.240207, b = 2.748791\n",
      "\tgrad = 2.697857\n",
      "rate = 0.002504\n",
      "Step 540 / 1000, loss = -7920.610606\n",
      "a_1 = 9.950094, a_2 = 7.243932, b = 2.750036\n",
      "\tgrad = 2.646269\n",
      "rate = 0.002500\n",
      "Step 541 / 1000, loss = -7920.697105\n",
      "a_1 = 9.955801, a_2 = 7.248043, b = 2.751323\n",
      "\tgrad = 2.865268\n",
      "rate = 0.002496\n",
      "Step 542 / 1000, loss = -7920.777233\n",
      "a_1 = 9.961305, a_2 = 7.251613, b = 2.752539\n",
      "\tgrad = 2.678256\n",
      "rate = 0.002491\n",
      "Step 543 / 1000, loss = -7920.855930\n",
      "a_1 = 9.966354, a_2 = 7.255471, b = 2.753742\n",
      "\tgrad = 2.600961\n",
      "rate = 0.002487\n",
      "Step 544 / 1000, loss = -7920.931683\n",
      "a_1 = 9.971313, a_2 = 7.259053, b = 2.754929\n",
      "\tgrad = 2.510129\n",
      "rate = 0.002482\n",
      "Step 545 / 1000, loss = -7921.011711\n",
      "a_1 = 9.976658, a_2 = 7.262797, b = 2.756156\n",
      "\tgrad = 2.679908\n",
      "rate = 0.002478\n",
      "Step 546 / 1000, loss = -7921.089420\n",
      "a_1 = 9.981999, a_2 = 7.266298, b = 2.757348\n",
      "\tgrad = 2.626504\n",
      "rate = 0.002473\n",
      "Step 547 / 1000, loss = -7921.168762\n",
      "a_1 = 9.987117, a_2 = 7.270240, b = 2.758555\n",
      "\tgrad = 2.661616\n",
      "rate = 0.002469\n",
      "Step 548 / 1000, loss = -7921.247053\n",
      "a_1 = 9.992440, a_2 = 7.273878, b = 2.759746\n",
      "\tgrad = 2.660128\n",
      "rate = 0.002465\n",
      "Step 549 / 1000, loss = -7921.325824\n",
      "a_1 = 9.997573, a_2 = 7.277712, b = 2.760978\n",
      "\tgrad = 2.651763\n",
      "rate = 0.002460\n",
      "Step 550 / 1000, loss = -7921.402527\n",
      "a_1 = 10.002733, a_2 = 7.281324, b = 2.762167\n",
      "\tgrad = 2.609397\n",
      "rate = 0.002456\n",
      "Step 551 / 1000, loss = -7921.481609\n",
      "a_1 = 10.008076, a_2 = 7.285050, b = 2.763388\n",
      "\tgrad = 2.703019\n",
      "rate = 0.002452\n",
      "Step 552 / 1000, loss = -7921.561307\n",
      "a_1 = 10.013407, a_2 = 7.288861, b = 2.764627\n",
      "\tgrad = 2.724877\n",
      "rate = 0.002448\n",
      "Step 553 / 1000, loss = -7921.643203\n",
      "a_1 = 10.019075, a_2 = 7.292674, b = 2.765863\n",
      "\tgrad = 2.841435\n",
      "rate = 0.002443\n",
      "Step 554 / 1000, loss = -7921.722008\n",
      "a_1 = 10.024332, a_2 = 7.296533, b = 2.767065\n",
      "\tgrad = 2.718810\n",
      "rate = 0.002439\n",
      "Step 555 / 1000, loss = -7921.796021\n",
      "a_1 = 10.029185, a_2 = 7.300113, b = 2.768273\n",
      "\tgrad = 2.525885\n",
      "rate = 0.002435\n",
      "Step 556 / 1000, loss = -7921.877098\n",
      "a_1 = 10.034706, a_2 = 7.303997, b = 2.769515\n",
      "\tgrad = 2.824075\n",
      "rate = 0.002431\n",
      "Step 557 / 1000, loss = -7921.950870\n",
      "a_1 = 10.039824, a_2 = 7.307387, b = 2.770682\n",
      "\tgrad = 2.575205\n",
      "rate = 0.002426\n",
      "Step 558 / 1000, loss = -7922.031482\n",
      "a_1 = 10.045493, a_2 = 7.311150, b = 2.771893\n",
      "\tgrad = 2.853390\n",
      "rate = 0.002422\n",
      "Step 559 / 1000, loss = -7922.106282\n",
      "a_1 = 10.050504, a_2 = 7.314816, b = 2.773066\n",
      "\tgrad = 2.613045\n",
      "rate = 0.002418\n",
      "Step 560 / 1000, loss = -7922.185178\n",
      "a_1 = 10.055842, a_2 = 7.318675, b = 2.774287\n",
      "\tgrad = 2.775622\n",
      "rate = 0.002414\n",
      "Step 561 / 1000, loss = -7922.264809\n",
      "a_1 = 10.061179, a_2 = 7.322584, b = 2.775550\n",
      "\tgrad = 2.794871\n",
      "rate = 0.002410\n",
      "Step 562 / 1000, loss = -7922.337953\n",
      "a_1 = 10.066099, a_2 = 7.326138, b = 2.776728\n",
      "\tgrad = 2.570212\n",
      "rate = 0.002405\n",
      "Step 563 / 1000, loss = -7922.412702\n",
      "a_1 = 10.071086, a_2 = 7.329856, b = 2.777917\n",
      "\tgrad = 2.637078\n",
      "rate = 0.002401\n",
      "Step 564 / 1000, loss = -7922.483141\n",
      "a_1 = 10.075949, a_2 = 7.333230, b = 2.779027\n",
      "\tgrad = 2.512152\n",
      "rate = 0.002397\n",
      "Step 565 / 1000, loss = -7922.559054\n",
      "a_1 = 10.081050, a_2 = 7.337047, b = 2.780209\n",
      "\tgrad = 2.707639\n",
      "rate = 0.002393\n",
      "Step 566 / 1000, loss = -7922.627208\n",
      "a_1 = 10.085710, a_2 = 7.340361, b = 2.781296\n",
      "\tgrad = 2.436364\n",
      "rate = 0.002389\n",
      "Step 567 / 1000, loss = -7922.701355\n",
      "a_1 = 10.090943, a_2 = 7.343845, b = 2.782465\n",
      "\tgrad = 2.681226\n",
      "rate = 0.002385\n",
      "Step 568 / 1000, loss = -7922.775110\n",
      "a_1 = 10.096129, a_2 = 7.347348, b = 2.783627\n",
      "\tgrad = 2.673140\n",
      "rate = 0.002381\n",
      "Step 569 / 1000, loss = -7922.845053\n",
      "a_1 = 10.101000, a_2 = 7.350679, b = 2.784756\n",
      "\tgrad = 2.527926\n",
      "rate = 0.002377\n",
      "Step 570 / 1000, loss = -7922.916807\n",
      "a_1 = 10.105929, a_2 = 7.354185, b = 2.785911\n",
      "\tgrad = 2.594942\n",
      "rate = 0.002373\n",
      "Step 571 / 1000, loss = -7922.989934\n",
      "a_1 = 10.111129, a_2 = 7.357659, b = 2.787056\n",
      "\tgrad = 2.684044\n",
      "rate = 0.002369\n",
      "Step 572 / 1000, loss = -7923.063827\n",
      "a_1 = 10.116520, a_2 = 7.361002, b = 2.788238\n",
      "\tgrad = 2.728475\n",
      "rate = 0.002365\n",
      "Step 573 / 1000, loss = -7923.133636\n",
      "a_1 = 10.121546, a_2 = 7.364220, b = 2.789366\n",
      "\tgrad = 2.572678\n",
      "rate = 0.002361\n",
      "Step 574 / 1000, loss = -7923.203926\n",
      "a_1 = 10.126389, a_2 = 7.367643, b = 2.790528\n",
      "\tgrad = 2.563824\n",
      "rate = 0.002357\n",
      "Step 575 / 1000, loss = -7923.275069\n",
      "a_1 = 10.131343, a_2 = 7.371152, b = 2.791660\n",
      "\tgrad = 2.624579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate = 0.002353\n",
      "Step 576 / 1000, loss = -7923.341877\n",
      "a_1 = 10.136218, a_2 = 7.374202, b = 2.792743\n",
      "\tgrad = 2.491227\n",
      "rate = 0.002349\n",
      "Step 577 / 1000, loss = -7923.415786\n",
      "a_1 = 10.141382, a_2 = 7.377853, b = 2.793923\n",
      "\tgrad = 2.743525\n",
      "rate = 0.002345\n",
      "Step 578 / 1000, loss = -7923.488693\n",
      "a_1 = 10.146414, a_2 = 7.381537, b = 2.795084\n",
      "\tgrad = 2.709395\n",
      "rate = 0.002341\n",
      "Step 579 / 1000, loss = -7923.566042\n",
      "a_1 = 10.151847, a_2 = 7.385385, b = 2.796306\n",
      "\tgrad = 2.896491\n",
      "rate = 0.002337\n",
      "Step 580 / 1000, loss = -7923.638103\n",
      "a_1 = 10.156816, a_2 = 7.389041, b = 2.797466\n",
      "\tgrad = 2.689808\n",
      "rate = 0.002333\n",
      "Step 581 / 1000, loss = -7923.708553\n",
      "a_1 = 10.161765, a_2 = 7.392537, b = 2.798600\n",
      "\tgrad = 2.646497\n",
      "rate = 0.002329\n",
      "Step 582 / 1000, loss = -7923.784608\n",
      "a_1 = 10.166931, a_2 = 7.396519, b = 2.799817\n",
      "\tgrad = 2.852894\n",
      "rate = 0.002326\n",
      "Step 583 / 1000, loss = -7923.854895\n",
      "a_1 = 10.171775, a_2 = 7.400158, b = 2.800933\n",
      "\tgrad = 2.653687\n",
      "rate = 0.002322\n",
      "Step 584 / 1000, loss = -7923.925519\n",
      "a_1 = 10.176546, a_2 = 7.403891, b = 2.802074\n",
      "\tgrad = 2.659390\n",
      "rate = 0.002318\n",
      "Step 585 / 1000, loss = -7923.994410\n",
      "a_1 = 10.181383, a_2 = 7.407312, b = 2.803214\n",
      "\tgrad = 2.607195\n",
      "rate = 0.002314\n",
      "Step 586 / 1000, loss = -7924.061821\n",
      "a_1 = 10.186148, a_2 = 7.410647, b = 2.804328\n",
      "\tgrad = 2.563279\n",
      "rate = 0.002310\n",
      "Step 587 / 1000, loss = -7924.130089\n",
      "a_1 = 10.191012, a_2 = 7.414004, b = 2.805454\n",
      "\tgrad = 2.608479\n",
      "rate = 0.002306\n",
      "Step 588 / 1000, loss = -7924.196942\n",
      "a_1 = 10.195783, a_2 = 7.417253, b = 2.806580\n",
      "\tgrad = 2.553962\n",
      "rate = 0.002303\n",
      "Step 589 / 1000, loss = -7924.266805\n",
      "a_1 = 10.200790, a_2 = 7.420696, b = 2.807727\n",
      "\tgrad = 2.690161\n",
      "rate = 0.002299\n",
      "Step 590 / 1000, loss = -7924.342505\n",
      "a_1 = 10.206367, a_2 = 7.424335, b = 2.808948\n",
      "\tgrad = 2.949783\n",
      "rate = 0.002295\n",
      "Step 591 / 1000, loss = -7924.409244\n",
      "a_1 = 10.211139, a_2 = 7.427674, b = 2.810038\n",
      "\tgrad = 2.585954\n",
      "rate = 0.002291\n",
      "Step 592 / 1000, loss = -7924.479817\n",
      "a_1 = 10.216303, a_2 = 7.431133, b = 2.811175\n",
      "\tgrad = 2.762281\n",
      "rate = 0.002288\n",
      "Step 593 / 1000, loss = -7924.547355\n",
      "a_1 = 10.221137, a_2 = 7.434515, b = 2.812290\n",
      "\tgrad = 2.628895\n",
      "rate = 0.002284\n",
      "Step 594 / 1000, loss = -7924.615145\n",
      "a_1 = 10.225874, a_2 = 7.438027, b = 2.813414\n",
      "\tgrad = 2.632813\n",
      "rate = 0.002280\n",
      "Step 595 / 1000, loss = -7924.686694\n",
      "a_1 = 10.230934, a_2 = 7.441673, b = 2.814609\n",
      "\tgrad = 2.789501\n",
      "rate = 0.002276\n",
      "Step 596 / 1000, loss = -7924.753525\n",
      "a_1 = 10.235759, a_2 = 7.445042, b = 2.815700\n",
      "\tgrad = 2.633548\n",
      "rate = 0.002273\n",
      "Step 597 / 1000, loss = -7924.823810\n",
      "a_1 = 10.240799, a_2 = 7.448646, b = 2.816841\n",
      "\tgrad = 2.776431\n",
      "rate = 0.002269\n",
      "Step 598 / 1000, loss = -7924.895926\n",
      "a_1 = 10.246079, a_2 = 7.452289, b = 2.817992\n",
      "\tgrad = 2.876978\n",
      "rate = 0.002265\n",
      "Step 599 / 1000, loss = -7924.963809\n",
      "a_1 = 10.250908, a_2 = 7.455796, b = 2.819116\n",
      "\tgrad = 2.685129\n",
      "rate = 0.002262\n",
      "Step 600 / 1000, loss = -7925.030268\n",
      "a_1 = 10.255677, a_2 = 7.459208, b = 2.820213\n",
      "\tgrad = 2.641881\n",
      "rate = 0.002258\n",
      "Step 601 / 1000, loss = -7925.098766\n",
      "a_1 = 10.260528, a_2 = 7.462797, b = 2.821347\n",
      "\tgrad = 2.723526\n",
      "rate = 0.002254\n",
      "Step 602 / 1000, loss = -7925.166233\n",
      "a_1 = 10.265283, a_2 = 7.466344, b = 2.822477\n",
      "\tgrad = 2.682959\n",
      "rate = 0.002251\n",
      "Step 603 / 1000, loss = -7925.234045\n",
      "a_1 = 10.270158, a_2 = 7.469856, b = 2.823599\n",
      "\tgrad = 2.719729\n",
      "rate = 0.002247\n",
      "Step 604 / 1000, loss = -7925.303083\n",
      "a_1 = 10.275149, a_2 = 7.473366, b = 2.824767\n",
      "\tgrad = 2.769282\n",
      "rate = 0.002244\n",
      "Step 605 / 1000, loss = -7925.368064\n",
      "a_1 = 10.279910, a_2 = 7.476630, b = 2.825863\n",
      "\tgrad = 2.623044\n",
      "rate = 0.002240\n",
      "Step 606 / 1000, loss = -7925.435765\n",
      "a_1 = 10.284814, a_2 = 7.480068, b = 2.827021\n",
      "\tgrad = 2.727481\n",
      "rate = 0.002236\n",
      "Step 607 / 1000, loss = -7925.502048\n",
      "a_1 = 10.289805, a_2 = 7.483357, b = 2.828104\n",
      "\tgrad = 2.720397\n",
      "rate = 0.002233\n",
      "Step 608 / 1000, loss = -7925.568658\n",
      "a_1 = 10.294670, a_2 = 7.486774, b = 2.829219\n",
      "\tgrad = 2.713444\n",
      "rate = 0.002229\n",
      "Step 609 / 1000, loss = -7925.639237\n",
      "a_1 = 10.299907, a_2 = 7.490336, b = 2.830396\n",
      "\tgrad = 2.894231\n",
      "rate = 0.002226\n",
      "Step 610 / 1000, loss = -7925.703186\n",
      "a_1 = 10.304538, a_2 = 7.493656, b = 2.831481\n",
      "\tgrad = 2.610268\n",
      "rate = 0.002222\n",
      "Step 611 / 1000, loss = -7925.771080\n",
      "a_1 = 10.309545, a_2 = 7.497076, b = 2.832648\n",
      "\tgrad = 2.782969\n",
      "rate = 0.002219\n",
      "Step 612 / 1000, loss = -7925.836889\n",
      "a_1 = 10.314435, a_2 = 7.500388, b = 2.833769\n",
      "\tgrad = 2.713631\n",
      "rate = 0.002215\n",
      "Step 613 / 1000, loss = -7925.903539\n",
      "a_1 = 10.319312, a_2 = 7.503822, b = 2.834908\n",
      "\tgrad = 2.745935\n",
      "rate = 0.002212\n",
      "Step 614 / 1000, loss = -7925.969632\n",
      "a_1 = 10.324272, a_2 = 7.507202, b = 2.835994\n",
      "\tgrad = 2.761984\n",
      "rate = 0.002208\n",
      "Step 615 / 1000, loss = -7926.034001\n",
      "a_1 = 10.329033, a_2 = 7.510498, b = 2.837092\n",
      "\tgrad = 2.673668\n",
      "rate = 0.002205\n",
      "Step 616 / 1000, loss = -7926.100154\n",
      "a_1 = 10.334017, a_2 = 7.513830, b = 2.838210\n",
      "\tgrad = 2.770359\n",
      "rate = 0.002201\n",
      "Step 617 / 1000, loss = -7926.164242\n",
      "a_1 = 10.338914, a_2 = 7.517048, b = 2.839270\n",
      "\tgrad = 2.709471\n",
      "rate = 0.002198\n",
      "Step 618 / 1000, loss = -7926.229901\n",
      "a_1 = 10.343762, a_2 = 7.520454, b = 2.840393\n",
      "\tgrad = 2.747847\n",
      "rate = 0.002194\n",
      "Step 619 / 1000, loss = -7926.296356\n",
      "a_1 = 10.348804, a_2 = 7.523806, b = 2.841517\n",
      "\tgrad = 2.810645\n",
      "rate = 0.002191\n",
      "Step 620 / 1000, loss = -7926.362023\n",
      "a_1 = 10.353610, a_2 = 7.527333, b = 2.842613\n",
      "\tgrad = 2.770953\n",
      "rate = 0.002188\n",
      "Step 621 / 1000, loss = -7926.425169\n",
      "a_1 = 10.358330, a_2 = 7.530585, b = 2.843696\n",
      "\tgrad = 2.670653\n",
      "rate = 0.002184\n",
      "Step 622 / 1000, loss = -7926.491474\n",
      "a_1 = 10.363383, a_2 = 7.533920, b = 2.844832\n",
      "\tgrad = 2.824774\n",
      "rate = 0.002181\n",
      "Step 623 / 1000, loss = -7926.556339\n",
      "a_1 = 10.368422, a_2 = 7.537132, b = 2.845928\n",
      "\tgrad = 2.790277\n",
      "rate = 0.002177\n",
      "Step 624 / 1000, loss = -7926.618322\n",
      "a_1 = 10.372962, a_2 = 7.540433, b = 2.847001\n",
      "\tgrad = 2.629113\n",
      "rate = 0.002174\n",
      "Step 625 / 1000, loss = -7926.680732\n",
      "a_1 = 10.377632, a_2 = 7.543705, b = 2.848065\n",
      "\tgrad = 2.672539\n",
      "rate = 0.002171\n",
      "Step 626 / 1000, loss = -7926.743897\n",
      "a_1 = 10.382392, a_2 = 7.546959, b = 2.849162\n",
      "\tgrad = 2.708106\n",
      "rate = 0.002167\n",
      "Step 627 / 1000, loss = -7926.806404\n",
      "a_1 = 10.387108, a_2 = 7.550213, b = 2.850233\n",
      "\tgrad = 2.693534\n",
      "rate = 0.002164\n",
      "Step 628 / 1000, loss = -7926.867606\n",
      "a_1 = 10.391547, a_2 = 7.553539, b = 2.851306\n",
      "\tgrad = 2.615044\n",
      "rate = 0.002160\n",
      "Step 629 / 1000, loss = -7926.931716\n",
      "a_1 = 10.396397, a_2 = 7.556921, b = 2.852387\n",
      "\tgrad = 2.786714\n",
      "rate = 0.002157\n",
      "Step 630 / 1000, loss = -7926.989968\n",
      "a_1 = 10.400840, a_2 = 7.559888, b = 2.853412\n",
      "\tgrad = 2.525803\n",
      "rate = 0.002154\n",
      "Step 631 / 1000, loss = -7927.048607\n",
      "a_1 = 10.405175, a_2 = 7.563022, b = 2.854445\n",
      "\tgrad = 2.533029\n",
      "rate = 0.002151\n",
      "Step 632 / 1000, loss = -7927.114724\n",
      "a_1 = 10.410033, a_2 = 7.566679, b = 2.855565\n",
      "\tgrad = 2.879591\n",
      "rate = 0.002147\n",
      "Step 633 / 1000, loss = -7927.176076\n",
      "a_1 = 10.414702, a_2 = 7.569853, b = 2.856644\n",
      "\tgrad = 2.680993\n",
      "rate = 0.002144\n",
      "Step 634 / 1000, loss = -7927.235178\n",
      "a_1 = 10.419315, a_2 = 7.572806, b = 2.857684\n",
      "\tgrad = 2.604311\n",
      "rate = 0.002141\n",
      "Step 635 / 1000, loss = -7927.296802\n",
      "a_1 = 10.423925, a_2 = 7.576149, b = 2.858740\n",
      "\tgrad = 2.709548\n",
      "rate = 0.002137\n",
      "Step 636 / 1000, loss = -7927.360012\n",
      "a_1 = 10.428622, a_2 = 7.579602, b = 2.859833\n",
      "\tgrad = 2.779545\n",
      "rate = 0.002134\n",
      "Step 637 / 1000, loss = -7927.419111\n",
      "a_1 = 10.433094, a_2 = 7.582746, b = 2.860864\n",
      "\tgrad = 2.610400\n",
      "rate = 0.002131\n",
      "Step 638 / 1000, loss = -7927.480285\n",
      "a_1 = 10.437913, a_2 = 7.585848, b = 2.861919\n",
      "\tgrad = 2.738747\n",
      "rate = 0.002128\n",
      "Step 639 / 1000, loss = -7927.542302\n",
      "a_1 = 10.442759, a_2 = 7.589029, b = 2.862997\n",
      "\tgrad = 2.775575\n",
      "rate = 0.002124\n",
      "Step 640 / 1000, loss = -7927.606636\n",
      "a_1 = 10.447825, a_2 = 7.592352, b = 2.864089\n",
      "\tgrad = 2.902240\n",
      "rate = 0.002121\n",
      "Step 641 / 1000, loss = -7927.671596\n",
      "a_1 = 10.452861, a_2 = 7.595790, b = 2.865197\n",
      "\tgrad = 2.925978\n",
      "rate = 0.002118\n",
      "Step 642 / 1000, loss = -7927.730665\n",
      "a_1 = 10.457558, a_2 = 7.598785, b = 2.866218\n",
      "\tgrad = 2.678052\n",
      "rate = 0.002115\n",
      "Step 643 / 1000, loss = -7927.789042\n",
      "a_1 = 10.462016, a_2 = 7.601934, b = 2.867230\n",
      "\tgrad = 2.628622\n",
      "rate = 0.002112\n",
      "Step 644 / 1000, loss = -7927.850780\n",
      "a_1 = 10.466693, a_2 = 7.605338, b = 2.868286\n",
      "\tgrad = 2.789061\n",
      "rate = 0.002108\n",
      "Step 645 / 1000, loss = -7927.916538\n",
      "a_1 = 10.471952, a_2 = 7.608702, b = 2.869412\n",
      "\tgrad = 3.013333\n",
      "rate = 0.002105\n",
      "Step 646 / 1000, loss = -7927.974399\n",
      "a_1 = 10.476343, a_2 = 7.611845, b = 2.870436\n",
      "\tgrad = 2.614354\n",
      "rate = 0.002102\n",
      "Step 647 / 1000, loss = -7928.031499\n",
      "a_1 = 10.480749, a_2 = 7.614894, b = 2.871441\n",
      "\tgrad = 2.597414\n",
      "rate = 0.002099\n",
      "Step 648 / 1000, loss = -7928.092883\n",
      "a_1 = 10.485512, a_2 = 7.618200, b = 2.872500\n",
      "\tgrad = 2.812378\n",
      "rate = 0.002096\n",
      "Step 649 / 1000, loss = -7928.149453\n",
      "a_1 = 10.489979, a_2 = 7.621147, b = 2.873494\n",
      "\tgrad = 2.600801\n",
      "rate = 0.002093\n",
      "Step 650 / 1000, loss = -7928.207558\n",
      "a_1 = 10.494517, a_2 = 7.624208, b = 2.874528\n",
      "\tgrad = 2.666016\n",
      "rate = 0.002090\n",
      "Step 651 / 1000, loss = -7928.266654\n",
      "a_1 = 10.499110, a_2 = 7.627400, b = 2.875557\n",
      "\tgrad = 2.725539\n",
      "rate = 0.002086\n",
      "Step 652 / 1000, loss = -7928.321620\n",
      "a_1 = 10.503488, a_2 = 7.630238, b = 2.876532\n",
      "\tgrad = 2.548103\n",
      "rate = 0.002083\n",
      "Step 653 / 1000, loss = -7928.380748\n",
      "a_1 = 10.507972, a_2 = 7.633503, b = 2.877593\n",
      "\tgrad = 2.714459\n",
      "rate = 0.002080\n",
      "Step 654 / 1000, loss = -7928.439748\n",
      "a_1 = 10.512613, a_2 = 7.636678, b = 2.878614\n",
      "\tgrad = 2.751338\n",
      "rate = 0.002077\n",
      "Step 655 / 1000, loss = -7928.496494\n",
      "a_1 = 10.516897, a_2 = 7.639838, b = 2.879639\n",
      "\tgrad = 2.614063\n",
      "rate = 0.002074\n",
      "Step 656 / 1000, loss = -7928.554220\n",
      "a_1 = 10.521406, a_2 = 7.642902, b = 2.880689\n",
      "\tgrad = 2.680390\n",
      "rate = 0.002071\n",
      "Step 657 / 1000, loss = -7928.609061\n",
      "a_1 = 10.525610, a_2 = 7.645858, b = 2.881709\n",
      "\tgrad = 2.533740\n",
      "rate = 0.002068\n",
      "Step 658 / 1000, loss = -7928.666094\n",
      "a_1 = 10.529914, a_2 = 7.649099, b = 2.882722\n",
      "\tgrad = 2.654945\n",
      "rate = 0.002065\n",
      "Step 659 / 1000, loss = -7928.718362\n",
      "a_1 = 10.533940, a_2 = 7.651985, b = 2.883659\n",
      "\tgrad = 2.444982\n",
      "rate = 0.002062\n",
      "Step 660 / 1000, loss = -7928.776562\n",
      "a_1 = 10.538293, a_2 = 7.655369, b = 2.884684\n",
      "\tgrad = 2.724086\n",
      "rate = 0.002059\n",
      "Step 661 / 1000, loss = -7928.833956\n",
      "a_1 = 10.542721, a_2 = 7.658541, b = 2.885718\n",
      "\tgrad = 2.696679\n",
      "rate = 0.002056\n",
      "Step 662 / 1000, loss = -7928.889877\n",
      "a_1 = 10.547235, a_2 = 7.661480, b = 2.886707\n",
      "\tgrad = 2.667918\n",
      "rate = 0.002053\n",
      "Step 663 / 1000, loss = -7928.947425\n",
      "a_1 = 10.551639, a_2 = 7.664724, b = 2.887740\n",
      "\tgrad = 2.715684\n",
      "rate = 0.002050\n",
      "Step 664 / 1000, loss = -7929.005694\n",
      "a_1 = 10.556007, a_2 = 7.668109, b = 2.888786\n",
      "\tgrad = 2.748010\n",
      "rate = 0.002047\n",
      "Step 665 / 1000, loss = -7929.063475\n",
      "a_1 = 10.560526, a_2 = 7.671299, b = 2.889820\n",
      "\tgrad = 2.753303\n",
      "rate = 0.002044\n",
      "Step 666 / 1000, loss = -7929.121518\n",
      "a_1 = 10.565111, a_2 = 7.674474, b = 2.890857\n",
      "\tgrad = 2.779489\n",
      "rate = 0.002041\n",
      "Step 667 / 1000, loss = -7929.177424\n",
      "a_1 = 10.569579, a_2 = 7.677461, b = 2.891872\n",
      "\tgrad = 2.683695\n",
      "rate = 0.002038\n",
      "Step 668 / 1000, loss = -7929.231941\n",
      "a_1 = 10.573724, a_2 = 7.680572, b = 2.892871\n",
      "\tgrad = 2.594166\n",
      "rate = 0.002035\n",
      "Step 669 / 1000, loss = -7929.286594\n",
      "a_1 = 10.578032, a_2 = 7.683529, b = 2.893885\n",
      "\tgrad = 2.619228\n",
      "rate = 0.002032\n",
      "Step 670 / 1000, loss = -7929.341084\n",
      "a_1 = 10.582352, a_2 = 7.686490, b = 2.894881\n",
      "\tgrad = 2.627588\n",
      "rate = 0.002029\n",
      "Step 671 / 1000, loss = -7929.395377\n",
      "a_1 = 10.586703, a_2 = 7.689364, b = 2.895894\n",
      "\tgrad = 2.622246\n",
      "rate = 0.002026\n",
      "Step 672 / 1000, loss = -7929.453574\n",
      "a_1 = 10.591285, a_2 = 7.692572, b = 2.896962\n",
      "\tgrad = 2.814391\n",
      "rate = 0.002023\n",
      "Step 673 / 1000, loss = -7929.511340\n",
      "a_1 = 10.595874, a_2 = 7.695807, b = 2.897981\n",
      "\tgrad = 2.824815\n",
      "rate = 0.002020\n",
      "Step 674 / 1000, loss = -7929.566017\n",
      "a_1 = 10.600213, a_2 = 7.698853, b = 2.898961\n",
      "\tgrad = 2.672357\n",
      "rate = 0.002017\n",
      "Step 675 / 1000, loss = -7929.620008\n",
      "a_1 = 10.604484, a_2 = 7.701854, b = 2.899944\n",
      "\tgrad = 2.637030\n",
      "rate = 0.002014\n",
      "Step 676 / 1000, loss = -7929.672261\n",
      "a_1 = 10.608659, a_2 = 7.704763, b = 2.900877\n",
      "\tgrad = 2.571733\n",
      "rate = 0.002011\n",
      "Step 677 / 1000, loss = -7929.725845\n",
      "a_1 = 10.612820, a_2 = 7.707820, b = 2.901862\n",
      "\tgrad = 2.617061\n",
      "rate = 0.002009\n",
      "Step 678 / 1000, loss = -7929.777814\n",
      "a_1 = 10.616851, a_2 = 7.710819, b = 2.902806\n",
      "\tgrad = 2.548573\n",
      "rate = 0.002006\n",
      "Step 679 / 1000, loss = -7929.835423\n",
      "a_1 = 10.621455, a_2 = 7.714012, b = 2.903858\n",
      "\tgrad = 2.846257\n",
      "rate = 0.002003\n",
      "Step 680 / 1000, loss = -7929.891217\n",
      "a_1 = 10.625841, a_2 = 7.717176, b = 2.904882\n",
      "\tgrad = 2.752088\n",
      "rate = 0.002000\n",
      "Step 681 / 1000, loss = -7929.943934\n",
      "a_1 = 10.630159, a_2 = 7.720006, b = 2.905848\n",
      "\tgrad = 2.630111\n",
      "rate = 0.001997\n",
      "Step 682 / 1000, loss = -7929.996678\n",
      "a_1 = 10.634442, a_2 = 7.722899, b = 2.906808\n",
      "\tgrad = 2.635942\n",
      "rate = 0.001994\n",
      "Step 683 / 1000, loss = -7930.052797\n",
      "a_1 = 10.638933, a_2 = 7.726012, b = 2.907849\n",
      "\tgrad = 2.793133\n",
      "rate = 0.001991\n",
      "Step 684 / 1000, loss = -7930.106514\n",
      "a_1 = 10.643226, a_2 = 7.729008, b = 2.908845\n",
      "\tgrad = 2.679911\n",
      "rate = 0.001989\n",
      "Step 685 / 1000, loss = -7930.161330\n",
      "a_1 = 10.647607, a_2 = 7.732114, b = 2.909842\n",
      "\tgrad = 2.750498\n",
      "rate = 0.001986\n",
      "Step 686 / 1000, loss = -7930.215967\n",
      "a_1 = 10.652091, a_2 = 7.735132, b = 2.910822\n",
      "\tgrad = 2.770123\n",
      "rate = 0.001983\n",
      "Step 687 / 1000, loss = -7930.270182\n",
      "a_1 = 10.656317, a_2 = 7.738291, b = 2.911828\n",
      "\tgrad = 2.712154\n",
      "rate = 0.001980\n",
      "Step 688 / 1000, loss = -7930.322791\n",
      "a_1 = 10.660497, a_2 = 7.741228, b = 2.912834\n",
      "\tgrad = 2.633400\n",
      "rate = 0.001977\n",
      "Step 689 / 1000, loss = -7930.377656\n",
      "a_1 = 10.664972, a_2 = 7.744278, b = 2.913837\n",
      "\tgrad = 2.789392\n",
      "rate = 0.001975\n",
      "Step 690 / 1000, loss = -7930.431906\n",
      "a_1 = 10.669298, a_2 = 7.747378, b = 2.914841\n",
      "\tgrad = 2.746772\n",
      "rate = 0.001972\n",
      "Step 691 / 1000, loss = -7930.486112\n",
      "a_1 = 10.673661, a_2 = 7.750467, b = 2.915834\n",
      "\tgrad = 2.761048\n",
      "rate = 0.001969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 692 / 1000, loss = -7930.546121\n",
      "a_1 = 10.678305, a_2 = 7.754114, b = 2.916915\n",
      "\tgrad = 3.052701\n",
      "rate = 0.001966\n",
      "Step 693 / 1000, loss = -7930.597369\n",
      "a_1 = 10.682354, a_2 = 7.757115, b = 2.917859\n",
      "\tgrad = 2.611721\n",
      "rate = 0.001964\n",
      "Step 694 / 1000, loss = -7930.649790\n",
      "a_1 = 10.686408, a_2 = 7.760253, b = 2.918840\n",
      "\tgrad = 2.661827\n",
      "rate = 0.001961\n",
      "Step 695 / 1000, loss = -7930.699630\n",
      "a_1 = 10.690334, a_2 = 7.763138, b = 2.919791\n",
      "\tgrad = 2.535017\n",
      "rate = 0.001958\n",
      "Step 696 / 1000, loss = -7930.749467\n",
      "a_1 = 10.694273, a_2 = 7.766076, b = 2.920712\n",
      "\tgrad = 2.557208\n",
      "rate = 0.001955\n",
      "Step 697 / 1000, loss = -7930.802182\n",
      "a_1 = 10.698483, a_2 = 7.769147, b = 2.921689\n",
      "\tgrad = 2.715275\n",
      "rate = 0.001953\n",
      "Step 698 / 1000, loss = -7930.854796\n",
      "a_1 = 10.702766, a_2 = 7.772096, b = 2.922687\n",
      "\tgrad = 2.715680\n",
      "rate = 0.001950\n",
      "Step 699 / 1000, loss = -7930.903692\n",
      "a_1 = 10.706615, a_2 = 7.774980, b = 2.923612\n",
      "\tgrad = 2.515081\n",
      "rate = 0.001947\n",
      "Step 700 / 1000, loss = -7930.954142\n",
      "a_1 = 10.710692, a_2 = 7.777908, b = 2.924541\n",
      "\tgrad = 2.625457\n",
      "rate = 0.001944\n",
      "Step 701 / 1000, loss = -7931.005929\n",
      "a_1 = 10.715053, a_2 = 7.780757, b = 2.925493\n",
      "\tgrad = 2.726864\n",
      "rate = 0.001942\n",
      "Step 702 / 1000, loss = -7931.059611\n",
      "a_1 = 10.719242, a_2 = 7.783985, b = 2.926509\n",
      "\tgrad = 2.777398\n",
      "rate = 0.001939\n",
      "Step 703 / 1000, loss = -7931.111061\n",
      "a_1 = 10.723467, a_2 = 7.786882, b = 2.927483\n",
      "\tgrad = 2.693262\n",
      "rate = 0.001936\n",
      "Step 704 / 1000, loss = -7931.162780\n",
      "a_1 = 10.727754, a_2 = 7.789782, b = 2.928454\n",
      "\tgrad = 2.723109\n",
      "rate = 0.001934\n",
      "Step 705 / 1000, loss = -7931.216727\n",
      "a_1 = 10.732177, a_2 = 7.792877, b = 2.929460\n",
      "\tgrad = 2.843585\n",
      "rate = 0.001931\n",
      "Step 706 / 1000, loss = -7931.268599\n",
      "a_1 = 10.736510, a_2 = 7.795775, b = 2.930432\n",
      "\tgrad = 2.749838\n",
      "rate = 0.001928\n",
      "Step 707 / 1000, loss = -7931.322032\n",
      "a_1 = 10.740915, a_2 = 7.798808, b = 2.931443\n",
      "\tgrad = 2.826313\n",
      "rate = 0.001926\n",
      "Step 708 / 1000, loss = -7931.368232\n",
      "a_1 = 10.744564, a_2 = 7.801551, b = 2.932339\n",
      "\tgrad = 2.419207\n",
      "rate = 0.001923\n",
      "Step 709 / 1000, loss = -7931.417600\n",
      "a_1 = 10.748679, a_2 = 7.804339, b = 2.933266\n",
      "\tgrad = 2.632739\n",
      "rate = 0.001920\n",
      "Step 710 / 1000, loss = -7931.466162\n",
      "a_1 = 10.752727, a_2 = 7.807091, b = 2.934177\n",
      "\tgrad = 2.596464\n",
      "rate = 0.001918\n",
      "Step 711 / 1000, loss = -7931.518429\n",
      "a_1 = 10.756943, a_2 = 7.810227, b = 2.935144\n",
      "\tgrad = 2.789479\n",
      "rate = 0.001915\n",
      "Step 712 / 1000, loss = -7931.570024\n",
      "a_1 = 10.761173, a_2 = 7.813236, b = 2.936114\n",
      "\tgrad = 2.761157\n",
      "rate = 0.001913\n",
      "Step 713 / 1000, loss = -7931.621922\n",
      "a_1 = 10.765365, a_2 = 7.816317, b = 2.937098\n",
      "\tgrad = 2.772123\n",
      "rate = 0.001910\n",
      "Step 714 / 1000, loss = -7931.673970\n",
      "a_1 = 10.769669, a_2 = 7.819308, b = 2.938089\n",
      "\tgrad = 2.796880\n",
      "rate = 0.001907\n",
      "Step 715 / 1000, loss = -7931.724572\n",
      "a_1 = 10.773854, a_2 = 7.822271, b = 2.939030\n",
      "\tgrad = 2.736830\n",
      "rate = 0.001905\n",
      "Step 716 / 1000, loss = -7931.772909\n",
      "a_1 = 10.777880, a_2 = 7.825065, b = 2.939938\n",
      "\tgrad = 2.620162\n",
      "rate = 0.001902\n",
      "Step 717 / 1000, loss = -7931.821156\n",
      "a_1 = 10.781975, a_2 = 7.827776, b = 2.940850\n",
      "\tgrad = 2.629253\n",
      "rate = 0.001900\n",
      "Step 718 / 1000, loss = -7931.869514\n",
      "a_1 = 10.785930, a_2 = 7.830624, b = 2.941775\n",
      "\tgrad = 2.614940\n",
      "rate = 0.001897\n",
      "Step 719 / 1000, loss = -7931.916766\n",
      "a_1 = 10.789782, a_2 = 7.833424, b = 2.942681\n",
      "\tgrad = 2.559039\n",
      "rate = 0.001894\n",
      "Step 720 / 1000, loss = -7931.962372\n",
      "a_1 = 10.793538, a_2 = 7.836064, b = 2.943572\n",
      "\tgrad = 2.472014\n",
      "rate = 0.001892\n",
      "Step 721 / 1000, loss = -7932.012724\n",
      "a_1 = 10.797814, a_2 = 7.838938, b = 2.944517\n",
      "\tgrad = 2.772356\n",
      "rate = 0.001889\n",
      "Step 722 / 1000, loss = -7932.063293\n",
      "a_1 = 10.802008, a_2 = 7.841912, b = 2.945475\n",
      "\tgrad = 2.771924\n",
      "rate = 0.001887\n",
      "Step 723 / 1000, loss = -7932.113241\n",
      "a_1 = 10.806291, a_2 = 7.844745, b = 2.946410\n",
      "\tgrad = 2.770222\n",
      "rate = 0.001884\n",
      "Step 724 / 1000, loss = -7932.161578\n",
      "a_1 = 10.810332, a_2 = 7.847567, b = 2.947330\n",
      "\tgrad = 2.664172\n",
      "rate = 0.001882\n",
      "Step 725 / 1000, loss = -7932.207979\n",
      "a_1 = 10.814100, a_2 = 7.850375, b = 2.948221\n",
      "\tgrad = 2.545643\n",
      "rate = 0.001879\n",
      "Step 726 / 1000, loss = -7932.254566\n",
      "a_1 = 10.818084, a_2 = 7.853018, b = 2.949110\n",
      "\tgrad = 2.590941\n",
      "rate = 0.001877\n",
      "Step 727 / 1000, loss = -7932.301404\n",
      "a_1 = 10.821983, a_2 = 7.855742, b = 2.950027\n",
      "\tgrad = 2.584650\n",
      "rate = 0.001874\n",
      "Step 728 / 1000, loss = -7932.348674\n",
      "a_1 = 10.825855, a_2 = 7.858583, b = 2.950940\n",
      "\tgrad = 2.611881\n",
      "rate = 0.001872\n",
      "Step 729 / 1000, loss = -7932.395405\n",
      "a_1 = 10.829696, a_2 = 7.861409, b = 2.951831\n",
      "\tgrad = 2.595459\n",
      "rate = 0.001869\n",
      "Step 730 / 1000, loss = -7932.440879\n",
      "a_1 = 10.833356, a_2 = 7.864187, b = 2.952727\n",
      "\tgrad = 2.507728\n",
      "rate = 0.001867\n",
      "Step 731 / 1000, loss = -7932.491659\n",
      "a_1 = 10.837704, a_2 = 7.867108, b = 2.953695\n",
      "\tgrad = 2.857442\n",
      "rate = 0.001864\n",
      "Step 732 / 1000, loss = -7932.537581\n",
      "a_1 = 10.841551, a_2 = 7.869811, b = 2.954585\n",
      "\tgrad = 2.570211\n",
      "rate = 0.001862\n",
      "Step 733 / 1000, loss = -7932.585736\n",
      "a_1 = 10.845490, a_2 = 7.872717, b = 2.955533\n",
      "\tgrad = 2.681553\n",
      "rate = 0.001859\n",
      "Step 734 / 1000, loss = -7932.633743\n",
      "a_1 = 10.849582, a_2 = 7.875491, b = 2.956463\n",
      "\tgrad = 2.709167\n",
      "rate = 0.001857\n",
      "Step 735 / 1000, loss = -7932.679943\n",
      "a_1 = 10.853323, a_2 = 7.878344, b = 2.957366\n",
      "\tgrad = 2.583580\n",
      "rate = 0.001854\n",
      "Step 736 / 1000, loss = -7932.726114\n",
      "a_1 = 10.857245, a_2 = 7.881029, b = 2.958266\n",
      "\tgrad = 2.612568\n",
      "rate = 0.001852\n",
      "Step 737 / 1000, loss = -7932.771710\n",
      "a_1 = 10.861092, a_2 = 7.883742, b = 2.959141\n",
      "\tgrad = 2.588865\n",
      "rate = 0.001849\n",
      "Step 738 / 1000, loss = -7932.821246\n",
      "a_1 = 10.865327, a_2 = 7.886667, b = 2.960079\n",
      "\tgrad = 2.832694\n",
      "rate = 0.001847\n",
      "Step 739 / 1000, loss = -7932.867953\n",
      "a_1 = 10.869282, a_2 = 7.889429, b = 2.960985\n",
      "\tgrad = 2.661116\n",
      "rate = 0.001845\n",
      "Step 740 / 1000, loss = -7932.915085\n",
      "a_1 = 10.873210, a_2 = 7.892272, b = 2.961906\n",
      "\tgrad = 2.679192\n",
      "rate = 0.001842\n",
      "Step 741 / 1000, loss = -7932.960329\n",
      "a_1 = 10.877063, a_2 = 7.894920, b = 2.962795\n",
      "\tgrad = 2.586594\n",
      "rate = 0.001840\n",
      "Step 742 / 1000, loss = -7933.006920\n",
      "a_1 = 10.881092, a_2 = 7.897594, b = 2.963710\n",
      "\tgrad = 2.678996\n",
      "rate = 0.001837\n",
      "Step 743 / 1000, loss = -7933.056277\n",
      "a_1 = 10.885235, a_2 = 7.900595, b = 2.964660\n",
      "\tgrad = 2.835580\n",
      "rate = 0.001835\n",
      "Step 744 / 1000, loss = -7933.105828\n",
      "a_1 = 10.889597, a_2 = 7.903401, b = 2.965624\n",
      "\tgrad = 2.878727\n",
      "rate = 0.001832\n",
      "Step 745 / 1000, loss = -7933.150669\n",
      "a_1 = 10.893388, a_2 = 7.906084, b = 2.966504\n",
      "\tgrad = 2.582804\n",
      "rate = 0.001830\n",
      "Step 746 / 1000, loss = -7933.195837\n",
      "a_1 = 10.897268, a_2 = 7.908740, b = 2.967387\n",
      "\tgrad = 2.618159\n",
      "rate = 0.001828\n",
      "Step 747 / 1000, loss = -7933.241527\n",
      "a_1 = 10.901112, a_2 = 7.911501, b = 2.968287\n",
      "\tgrad = 2.639253\n",
      "rate = 0.001825\n",
      "Step 748 / 1000, loss = -7933.287070\n",
      "a_1 = 10.905020, a_2 = 7.914194, b = 2.969180\n",
      "\tgrad = 2.649143\n",
      "rate = 0.001823\n",
      "Step 749 / 1000, loss = -7933.332742\n",
      "a_1 = 10.908977, a_2 = 7.916873, b = 2.970072\n",
      "\tgrad = 2.669932\n",
      "rate = 0.001821\n",
      "Step 750 / 1000, loss = -7933.379407\n",
      "a_1 = 10.912940, a_2 = 7.919696, b = 2.970983\n",
      "\tgrad = 2.722693\n",
      "rate = 0.001818\n",
      "Step 751 / 1000, loss = -7933.425306\n",
      "a_1 = 10.916850, a_2 = 7.922459, b = 2.971884\n",
      "\tgrad = 2.683135\n",
      "rate = 0.001816\n",
      "Step 752 / 1000, loss = -7933.470561\n",
      "a_1 = 10.920793, a_2 = 7.925120, b = 2.972765\n",
      "\tgrad = 2.667527\n",
      "rate = 0.001813\n",
      "Step 753 / 1000, loss = -7933.513291\n",
      "a_1 = 10.924564, a_2 = 7.927558, b = 2.973614\n",
      "\tgrad = 2.523519\n",
      "rate = 0.001811\n",
      "Step 754 / 1000, loss = -7933.559118\n",
      "a_1 = 10.928523, a_2 = 7.930258, b = 2.974528\n",
      "\tgrad = 2.697070\n",
      "rate = 0.001809\n",
      "Step 755 / 1000, loss = -7933.606670\n",
      "a_1 = 10.932656, a_2 = 7.933061, b = 2.975467\n",
      "\tgrad = 2.812787\n",
      "rate = 0.001806\n",
      "Step 756 / 1000, loss = -7933.652928\n",
      "a_1 = 10.936607, a_2 = 7.935893, b = 2.976366\n",
      "\tgrad = 2.740070\n",
      "rate = 0.001804\n",
      "Step 757 / 1000, loss = -7933.697960\n",
      "a_1 = 10.940538, a_2 = 7.938517, b = 2.977270\n",
      "\tgrad = 2.670510\n",
      "rate = 0.001802\n",
      "Step 758 / 1000, loss = -7933.744775\n",
      "a_1 = 10.944593, a_2 = 7.941327, b = 2.978188\n",
      "\tgrad = 2.788813\n",
      "rate = 0.001799\n",
      "Step 759 / 1000, loss = -7933.788066\n",
      "a_1 = 10.948374, a_2 = 7.943868, b = 2.979054\n",
      "\tgrad = 2.580238\n",
      "rate = 0.001797\n",
      "Step 760 / 1000, loss = -7933.833836\n",
      "a_1 = 10.952399, a_2 = 7.946537, b = 2.979969\n",
      "\tgrad = 2.738477\n",
      "rate = 0.001795\n",
      "Step 761 / 1000, loss = -7933.876669\n",
      "a_1 = 10.956107, a_2 = 7.949171, b = 2.980789\n",
      "\tgrad = 2.578444\n",
      "rate = 0.001793\n",
      "Step 762 / 1000, loss = -7933.921341\n",
      "a_1 = 10.959968, a_2 = 7.951821, b = 2.981700\n",
      "\tgrad = 2.664562\n",
      "rate = 0.001790\n",
      "Step 763 / 1000, loss = -7933.964450\n",
      "a_1 = 10.963703, a_2 = 7.954382, b = 2.982576\n",
      "\tgrad = 2.579851\n",
      "rate = 0.001788\n",
      "Step 764 / 1000, loss = -7934.007985\n",
      "a_1 = 10.967544, a_2 = 7.956969, b = 2.983430\n",
      "\tgrad = 2.637340\n",
      "rate = 0.001786\n",
      "Step 765 / 1000, loss = -7934.051601\n",
      "a_1 = 10.971389, a_2 = 7.959539, b = 2.984302\n",
      "\tgrad = 2.638786\n",
      "rate = 0.001783\n",
      "Step 766 / 1000, loss = -7934.093947\n",
      "a_1 = 10.975101, a_2 = 7.962045, b = 2.985157\n",
      "\tgrad = 2.559686\n",
      "rate = 0.001781\n",
      "Step 767 / 1000, loss = -7934.138949\n",
      "a_1 = 10.978982, a_2 = 7.964782, b = 2.986062\n",
      "\tgrad = 2.718068\n",
      "rate = 0.001779\n",
      "Step 768 / 1000, loss = -7934.179339\n",
      "a_1 = 10.982422, a_2 = 7.967265, b = 2.986886\n",
      "\tgrad = 2.432357\n",
      "rate = 0.001777\n",
      "Step 769 / 1000, loss = -7934.222062\n",
      "a_1 = 10.986073, a_2 = 7.969932, b = 2.987735\n",
      "\tgrad = 2.592696\n",
      "rate = 0.001774\n",
      "Step 770 / 1000, loss = -7934.262127\n",
      "a_1 = 10.989523, a_2 = 7.972379, b = 2.988548\n",
      "\tgrad = 2.430469\n",
      "rate = 0.001772\n",
      "Step 771 / 1000, loss = -7934.305375\n",
      "a_1 = 10.993264, a_2 = 7.975046, b = 2.989408\n",
      "\tgrad = 2.640845\n",
      "rate = 0.001770\n",
      "Step 772 / 1000, loss = -7934.351757\n",
      "a_1 = 10.997311, a_2 = 7.977915, b = 2.990313\n",
      "\tgrad = 2.852529\n",
      "rate = 0.001768\n",
      "Step 773 / 1000, loss = -7934.393306\n",
      "a_1 = 11.001234, a_2 = 7.980177, b = 2.991138\n",
      "\tgrad = 2.607319\n",
      "rate = 0.001765\n",
      "Step 774 / 1000, loss = -7934.435885\n",
      "a_1 = 11.004895, a_2 = 7.982857, b = 2.991979\n",
      "\tgrad = 2.616683\n",
      "rate = 0.001763\n",
      "Step 775 / 1000, loss = -7934.480121\n",
      "a_1 = 11.008788, a_2 = 7.985533, b = 2.992866\n",
      "\tgrad = 2.730010\n",
      "rate = 0.001761\n",
      "Step 776 / 1000, loss = -7934.521760\n",
      "a_1 = 11.012285, a_2 = 7.988142, b = 2.993742\n",
      "\tgrad = 2.529996\n",
      "rate = 0.001759\n",
      "Step 777 / 1000, loss = -7934.564262\n",
      "a_1 = 11.015965, a_2 = 7.990791, b = 2.994592\n",
      "\tgrad = 2.626244\n",
      "rate = 0.001757\n",
      "Step 778 / 1000, loss = -7934.608981\n",
      "a_1 = 11.019916, a_2 = 7.993522, b = 2.995480\n",
      "\tgrad = 2.784446\n",
      "rate = 0.001754\n",
      "Step 779 / 1000, loss = -7934.648385\n",
      "a_1 = 11.023344, a_2 = 7.995962, b = 2.996276\n",
      "\tgrad = 2.443451\n",
      "rate = 0.001752\n",
      "Step 780 / 1000, loss = -7934.689905\n",
      "a_1 = 11.026991, a_2 = 7.998476, b = 2.997128\n",
      "\tgrad = 2.577728\n",
      "rate = 0.001750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 781 / 1000, loss = -7934.734555\n",
      "a_1 = 11.030921, a_2 = 8.001209, b = 2.998030\n",
      "\tgrad = 2.786815\n",
      "rate = 0.001748\n",
      "Step 782 / 1000, loss = -7934.776179\n",
      "a_1 = 11.034601, a_2 = 8.003694, b = 2.998897\n",
      "\tgrad = 2.591955\n",
      "rate = 0.001746\n",
      "Step 783 / 1000, loss = -7934.820056\n",
      "a_1 = 11.038472, a_2 = 8.006427, b = 2.999762\n",
      "\tgrad = 2.762902\n",
      "rate = 0.001743\n",
      "Step 784 / 1000, loss = -7934.860243\n",
      "a_1 = 11.042033, a_2 = 8.008863, b = 3.000584\n",
      "\tgrad = 2.522219\n",
      "rate = 0.001741\n",
      "Step 785 / 1000, loss = -7934.905810\n",
      "a_1 = 11.046167, a_2 = 8.011549, b = 3.001511\n",
      "\tgrad = 2.884455\n",
      "rate = 0.001739\n",
      "Step 786 / 1000, loss = -7934.947836\n",
      "a_1 = 11.049878, a_2 = 8.014133, b = 3.002365\n",
      "\tgrad = 2.649239\n",
      "rate = 0.001737\n",
      "Step 787 / 1000, loss = -7934.989414\n",
      "a_1 = 11.053479, a_2 = 8.016771, b = 3.003207\n",
      "\tgrad = 2.618531\n",
      "rate = 0.001735\n",
      "Step 788 / 1000, loss = -7935.032886\n",
      "a_1 = 11.057396, a_2 = 8.019382, b = 3.004090\n",
      "\tgrad = 2.764524\n",
      "rate = 0.001733\n",
      "Step 789 / 1000, loss = -7935.071762\n",
      "a_1 = 11.060802, a_2 = 8.021798, b = 3.004890\n",
      "\tgrad = 2.456943\n",
      "rate = 0.001731\n",
      "Step 790 / 1000, loss = -7935.112004\n",
      "a_1 = 11.064373, a_2 = 8.024292, b = 3.005702\n",
      "\tgrad = 2.563460\n",
      "rate = 0.001728\n",
      "Step 791 / 1000, loss = -7935.154036\n",
      "a_1 = 11.068140, a_2 = 8.026886, b = 3.006541\n",
      "\tgrad = 2.693859\n",
      "rate = 0.001726\n",
      "Step 792 / 1000, loss = -7935.195579\n",
      "a_1 = 11.071770, a_2 = 8.029526, b = 3.007381\n",
      "\tgrad = 2.648372\n",
      "rate = 0.001724\n",
      "Step 793 / 1000, loss = -7935.239257\n",
      "a_1 = 11.075756, a_2 = 8.032148, b = 3.008263\n",
      "\tgrad = 2.817522\n",
      "rate = 0.001722\n",
      "Step 794 / 1000, loss = -7935.281365\n",
      "a_1 = 11.079431, a_2 = 8.034842, b = 3.009114\n",
      "\tgrad = 2.694948\n",
      "rate = 0.001720\n",
      "Step 795 / 1000, loss = -7935.323270\n",
      "a_1 = 11.083270, a_2 = 8.037354, b = 3.009961\n",
      "\tgrad = 2.716193\n",
      "rate = 0.001718\n",
      "Step 796 / 1000, loss = -7935.364920\n",
      "a_1 = 11.086985, a_2 = 8.039978, b = 3.010791\n",
      "\tgrad = 2.694638\n",
      "rate = 0.001716\n",
      "Step 797 / 1000, loss = -7935.404874\n",
      "a_1 = 11.090454, a_2 = 8.042528, b = 3.011621\n",
      "\tgrad = 2.558398\n",
      "rate = 0.001714\n",
      "Step 798 / 1000, loss = -7935.449397\n",
      "a_1 = 11.094433, a_2 = 8.045323, b = 3.012516\n",
      "\tgrad = 2.889507\n",
      "rate = 0.001711\n",
      "Step 799 / 1000, loss = -7935.491892\n",
      "a_1 = 11.098243, a_2 = 8.048019, b = 3.013355\n",
      "\tgrad = 2.773628\n",
      "rate = 0.001709\n",
      "Step 800 / 1000, loss = -7935.532973\n",
      "a_1 = 11.101944, a_2 = 8.050532, b = 3.014207\n",
      "\tgrad = 2.667614\n",
      "rate = 0.001707\n",
      "Step 801 / 1000, loss = -7935.574191\n",
      "a_1 = 11.105671, a_2 = 8.053059, b = 3.015056\n",
      "\tgrad = 2.687068\n",
      "rate = 0.001705\n",
      "Step 802 / 1000, loss = -7935.617002\n",
      "a_1 = 11.109409, a_2 = 8.055828, b = 3.015933\n",
      "\tgrad = 2.779554\n",
      "rate = 0.001703\n",
      "Step 803 / 1000, loss = -7935.658604\n",
      "a_1 = 11.113223, a_2 = 8.058362, b = 3.016780\n",
      "\tgrad = 2.737210\n",
      "rate = 0.001701\n",
      "Step 804 / 1000, loss = -7935.698028\n",
      "a_1 = 11.116582, a_2 = 8.060955, b = 3.017613\n",
      "\tgrad = 2.545411\n",
      "rate = 0.001699\n",
      "Step 805 / 1000, loss = -7935.740522\n",
      "a_1 = 11.120352, a_2 = 8.063643, b = 3.018495\n",
      "\tgrad = 2.777604\n",
      "rate = 0.001697\n",
      "Step 806 / 1000, loss = -7935.781930\n",
      "a_1 = 11.124093, a_2 = 8.066205, b = 3.019355\n",
      "\tgrad = 2.723043\n",
      "rate = 0.001695\n",
      "Step 807 / 1000, loss = -7935.824176\n",
      "a_1 = 11.127849, a_2 = 8.068929, b = 3.020210\n",
      "\tgrad = 2.786516\n",
      "rate = 0.001693\n",
      "Step 808 / 1000, loss = -7935.866104\n",
      "a_1 = 11.131711, a_2 = 8.071492, b = 3.021067\n",
      "\tgrad = 2.787757\n",
      "rate = 0.001691\n",
      "Step 809 / 1000, loss = -7935.907671\n",
      "a_1 = 11.135382, a_2 = 8.074181, b = 3.021921\n",
      "\tgrad = 2.742092\n",
      "rate = 0.001689\n",
      "Step 810 / 1000, loss = -7935.946822\n",
      "a_1 = 11.138907, a_2 = 8.076657, b = 3.022726\n",
      "\tgrad = 2.597939\n",
      "rate = 0.001687\n",
      "Step 811 / 1000, loss = -7935.989582\n",
      "a_1 = 11.142783, a_2 = 8.079358, b = 3.023597\n",
      "\tgrad = 2.851378\n",
      "rate = 0.001685\n",
      "Step 812 / 1000, loss = -7936.030098\n",
      "a_1 = 11.146357, a_2 = 8.081970, b = 3.024447\n",
      "\tgrad = 2.678838\n",
      "rate = 0.001683\n",
      "Step 813 / 1000, loss = -7936.071498\n",
      "a_1 = 11.150101, a_2 = 8.084597, b = 3.025295\n",
      "\tgrad = 2.767509\n",
      "rate = 0.001681\n",
      "Step 814 / 1000, loss = -7936.111559\n",
      "a_1 = 11.153750, a_2 = 8.087097, b = 3.026128\n",
      "\tgrad = 2.681252\n",
      "rate = 0.001679\n",
      "Step 815 / 1000, loss = -7936.152625\n",
      "a_1 = 11.157563, a_2 = 8.089600, b = 3.026980\n",
      "\tgrad = 2.767647\n",
      "rate = 0.001677\n",
      "Step 816 / 1000, loss = -7936.191894\n",
      "a_1 = 11.161140, a_2 = 8.092098, b = 3.027779\n",
      "\tgrad = 2.648469\n",
      "rate = 0.001675\n",
      "Step 817 / 1000, loss = -7936.234983\n",
      "a_1 = 11.165161, a_2 = 8.094734, b = 3.028665\n",
      "\tgrad = 2.922776\n",
      "rate = 0.001673\n",
      "Step 818 / 1000, loss = -7936.276556\n",
      "a_1 = 11.169018, a_2 = 8.097335, b = 3.029505\n",
      "\tgrad = 2.829708\n",
      "rate = 0.001671\n",
      "Step 819 / 1000, loss = -7936.318420\n",
      "a_1 = 11.172850, a_2 = 8.099958, b = 3.030378\n",
      "\tgrad = 2.831934\n",
      "rate = 0.001669\n",
      "Step 820 / 1000, loss = -7936.355793\n",
      "a_1 = 11.176249, a_2 = 8.102322, b = 3.031160\n",
      "\tgrad = 2.528085\n",
      "rate = 0.001667\n",
      "Step 821 / 1000, loss = -7936.393715\n",
      "a_1 = 11.179805, a_2 = 8.104636, b = 3.031947\n",
      "\tgrad = 2.591709\n",
      "rate = 0.001665\n",
      "Step 822 / 1000, loss = -7936.433104\n",
      "a_1 = 11.183382, a_2 = 8.107159, b = 3.032764\n",
      "\tgrad = 2.678124\n",
      "rate = 0.001663\n",
      "Step 823 / 1000, loss = -7936.472023\n",
      "a_1 = 11.186957, a_2 = 8.109605, b = 3.033577\n",
      "\tgrad = 2.654145\n",
      "rate = 0.001661\n",
      "Step 824 / 1000, loss = -7936.512429\n",
      "a_1 = 11.190688, a_2 = 8.112180, b = 3.034398\n",
      "\tgrad = 2.777269\n",
      "rate = 0.001659\n",
      "Step 825 / 1000, loss = -7936.553744\n",
      "a_1 = 11.194417, a_2 = 8.114831, b = 3.035273\n",
      "\tgrad = 2.811819\n",
      "rate = 0.001657\n",
      "Step 826 / 1000, loss = -7936.593959\n",
      "a_1 = 11.198138, a_2 = 8.117344, b = 3.036119\n",
      "\tgrad = 2.760537\n",
      "rate = 0.001655\n",
      "Step 827 / 1000, loss = -7936.631927\n",
      "a_1 = 11.201594, a_2 = 8.119809, b = 3.036901\n",
      "\tgrad = 2.611553\n",
      "rate = 0.001653\n",
      "Step 828 / 1000, loss = -7936.671552\n",
      "a_1 = 11.205215, a_2 = 8.122391, b = 3.037708\n",
      "\tgrad = 2.737970\n",
      "rate = 0.001651\n",
      "Step 829 / 1000, loss = -7936.712680\n",
      "a_1 = 11.208990, a_2 = 8.125083, b = 3.038536\n",
      "\tgrad = 2.855963\n",
      "rate = 0.001649\n",
      "Step 830 / 1000, loss = -7936.750500\n",
      "a_1 = 11.212612, a_2 = 8.127397, b = 3.039308\n",
      "\tgrad = 2.651496\n",
      "rate = 0.001647\n",
      "Step 831 / 1000, loss = -7936.789981\n",
      "a_1 = 11.216219, a_2 = 8.129934, b = 3.040141\n",
      "\tgrad = 2.727879\n",
      "rate = 0.001645\n",
      "Step 832 / 1000, loss = -7936.829721\n",
      "a_1 = 11.219879, a_2 = 8.132498, b = 3.040962\n",
      "\tgrad = 2.765322\n",
      "rate = 0.001643\n",
      "Step 833 / 1000, loss = -7936.868753\n",
      "a_1 = 11.223578, a_2 = 8.134890, b = 3.041786\n",
      "\tgrad = 2.730232\n",
      "rate = 0.001641\n",
      "Step 834 / 1000, loss = -7936.907451\n",
      "a_1 = 11.227105, a_2 = 8.137438, b = 3.042584\n",
      "\tgrad = 2.698598\n",
      "rate = 0.001639\n",
      "Step 835 / 1000, loss = -7936.946156\n",
      "a_1 = 11.230733, a_2 = 8.139863, b = 3.043400\n",
      "\tgrad = 2.711137\n",
      "rate = 0.001637\n",
      "Step 836 / 1000, loss = -7936.985718\n",
      "a_1 = 11.234352, a_2 = 8.142439, b = 3.044231\n",
      "\tgrad = 2.763098\n",
      "rate = 0.001636\n",
      "Step 837 / 1000, loss = -7937.022885\n",
      "a_1 = 11.237834, a_2 = 8.144782, b = 3.045013\n",
      "\tgrad = 2.613379\n",
      "rate = 0.001634\n",
      "Step 838 / 1000, loss = -7937.059283\n",
      "a_1 = 11.241094, a_2 = 8.147224, b = 3.045780\n",
      "\tgrad = 2.540272\n",
      "rate = 0.001632\n",
      "Step 839 / 1000, loss = -7937.099265\n",
      "a_1 = 11.244772, a_2 = 8.149843, b = 3.046611\n",
      "\tgrad = 2.816893\n",
      "rate = 0.001630\n",
      "Step 840 / 1000, loss = -7937.137399\n",
      "a_1 = 11.248333, a_2 = 8.152313, b = 3.047396\n",
      "\tgrad = 2.705230\n",
      "rate = 0.001628\n",
      "Step 841 / 1000, loss = -7937.177673\n",
      "a_1 = 11.252045, a_2 = 8.154953, b = 3.048235\n",
      "\tgrad = 2.848574\n",
      "rate = 0.001626\n",
      "Step 842 / 1000, loss = -7937.215553\n",
      "a_1 = 11.255625, a_2 = 8.157345, b = 3.049031\n",
      "\tgrad = 2.695701\n",
      "rate = 0.001624\n",
      "Step 843 / 1000, loss = -7937.253267\n",
      "a_1 = 11.259001, a_2 = 8.159893, b = 3.049832\n",
      "\tgrad = 2.653980\n",
      "rate = 0.001622\n",
      "Step 844 / 1000, loss = -7937.290473\n",
      "a_1 = 11.262468, a_2 = 8.162344, b = 3.050592\n",
      "\tgrad = 2.661950\n",
      "rate = 0.001620\n",
      "Step 845 / 1000, loss = -7937.329144\n",
      "a_1 = 11.265992, a_2 = 8.164945, b = 3.051397\n",
      "\tgrad = 2.751118\n",
      "rate = 0.001618\n",
      "Step 846 / 1000, loss = -7937.364142\n",
      "a_1 = 11.269318, a_2 = 8.167142, b = 3.052140\n",
      "\tgrad = 2.508249\n",
      "rate = 0.001617\n",
      "Step 847 / 1000, loss = -7937.401868\n",
      "a_1 = 11.272837, a_2 = 8.169570, b = 3.052946\n",
      "\tgrad = 2.694547\n",
      "rate = 0.001615\n",
      "Step 848 / 1000, loss = -7937.438103\n",
      "a_1 = 11.276100, a_2 = 8.172007, b = 3.053727\n",
      "\tgrad = 2.570875\n",
      "rate = 0.001613\n",
      "Step 849 / 1000, loss = -7937.475310\n",
      "a_1 = 11.279568, a_2 = 8.174397, b = 3.054530\n",
      "\tgrad = 2.661703\n",
      "rate = 0.001611\n",
      "Step 850 / 1000, loss = -7937.512082\n",
      "a_1 = 11.283033, a_2 = 8.176771, b = 3.055304\n",
      "\tgrad = 2.654027\n",
      "rate = 0.001609\n",
      "Step 851 / 1000, loss = -7937.547261\n",
      "a_1 = 11.286317, a_2 = 8.179024, b = 3.056071\n",
      "\tgrad = 2.523268\n",
      "rate = 0.001607\n",
      "Step 852 / 1000, loss = -7937.585746\n",
      "a_1 = 11.289876, a_2 = 8.181579, b = 3.056884\n",
      "\tgrad = 2.775502\n",
      "rate = 0.001606\n",
      "Step 853 / 1000, loss = -7937.623422\n",
      "a_1 = 11.293454, a_2 = 8.183956, b = 3.057700\n",
      "\tgrad = 2.726147\n",
      "rate = 0.001604\n",
      "Step 854 / 1000, loss = -7937.661750\n",
      "a_1 = 11.296915, a_2 = 8.186544, b = 3.058533\n",
      "\tgrad = 2.748077\n",
      "rate = 0.001602\n",
      "Step 855 / 1000, loss = -7937.695639\n",
      "a_1 = 11.300023, a_2 = 8.188781, b = 3.059275\n",
      "\tgrad = 2.437850\n",
      "rate = 0.001600\n",
      "Step 856 / 1000, loss = -7937.732348\n",
      "a_1 = 11.303470, a_2 = 8.191159, b = 3.060066\n",
      "\tgrad = 2.666606\n",
      "rate = 0.001598\n",
      "Step 857 / 1000, loss = -7937.771079\n",
      "a_1 = 11.307172, a_2 = 8.193657, b = 3.060879\n",
      "\tgrad = 2.843111\n",
      "rate = 0.001596\n",
      "Step 858 / 1000, loss = -7937.807960\n",
      "a_1 = 11.310648, a_2 = 8.196037, b = 3.061678\n",
      "\tgrad = 2.689260\n",
      "rate = 0.001595\n",
      "Step 859 / 1000, loss = -7937.843401\n",
      "a_1 = 11.314079, a_2 = 8.198250, b = 3.062442\n",
      "\tgrad = 2.607757\n",
      "rate = 0.001593\n",
      "Step 860 / 1000, loss = -7937.882372\n",
      "a_1 = 11.317626, a_2 = 8.200905, b = 3.063282\n",
      "\tgrad = 2.834825\n",
      "rate = 0.001591\n",
      "Step 861 / 1000, loss = -7937.917745\n",
      "a_1 = 11.320908, a_2 = 8.203258, b = 3.064047\n",
      "\tgrad = 2.586144\n",
      "rate = 0.001589\n",
      "Step 862 / 1000, loss = -7937.955473\n",
      "a_1 = 11.324441, a_2 = 8.205741, b = 3.064862\n",
      "\tgrad = 2.768519\n",
      "rate = 0.001587\n",
      "Step 863 / 1000, loss = -7937.991957\n",
      "a_1 = 11.327872, a_2 = 8.208158, b = 3.065639\n",
      "\tgrad = 2.692035\n",
      "rate = 0.001586\n",
      "Step 864 / 1000, loss = -7938.029361\n",
      "a_1 = 11.331280, a_2 = 8.210739, b = 3.066439\n",
      "\tgrad = 2.746362\n",
      "rate = 0.001584\n",
      "Step 865 / 1000, loss = -7938.064512\n",
      "a_1 = 11.334663, a_2 = 8.212999, b = 3.067190\n",
      "\tgrad = 2.615513\n",
      "rate = 0.001582\n",
      "Step 866 / 1000, loss = -7938.100568\n",
      "a_1 = 11.338148, a_2 = 8.215308, b = 3.067962\n",
      "\tgrad = 2.690257\n",
      "rate = 0.001580\n",
      "Step 867 / 1000, loss = -7938.135128\n",
      "a_1 = 11.341387, a_2 = 8.217586, b = 3.068719\n",
      "\tgrad = 2.554256\n",
      "rate = 0.001578\n",
      "Step 868 / 1000, loss = -7938.173266\n",
      "a_1 = 11.345106, a_2 = 8.220012, b = 3.069533\n",
      "\tgrad = 2.863582\n",
      "rate = 0.001577\n",
      "Step 869 / 1000, loss = -7938.211546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 11.348792, a_2 = 8.222520, b = 3.070339\n",
      "\tgrad = 2.876625\n",
      "rate = 0.001575\n",
      "Step 870 / 1000, loss = -7938.248252\n",
      "a_1 = 11.352310, a_2 = 8.224950, b = 3.071110\n",
      "\tgrad = 2.762246\n",
      "rate = 0.001573\n",
      "Step 871 / 1000, loss = -7938.282837\n",
      "a_1 = 11.355626, a_2 = 8.227195, b = 3.071861\n",
      "\tgrad = 2.592654\n",
      "rate = 0.001571\n",
      "Step 872 / 1000, loss = -7938.317659\n",
      "a_1 = 11.359020, a_2 = 8.229397, b = 3.072622\n",
      "\tgrad = 2.623192\n",
      "rate = 0.001570\n",
      "Step 873 / 1000, loss = -7938.353918\n",
      "a_1 = 11.362419, a_2 = 8.231823, b = 3.073415\n",
      "\tgrad = 2.711281\n",
      "rate = 0.001568\n",
      "Step 874 / 1000, loss = -7938.389466\n",
      "a_1 = 11.365952, a_2 = 8.234009, b = 3.074197\n",
      "\tgrad = 2.699286\n",
      "rate = 0.001566\n",
      "Step 875 / 1000, loss = -7938.425158\n",
      "a_1 = 11.369504, a_2 = 8.236212, b = 3.074977\n",
      "\tgrad = 2.718391\n",
      "rate = 0.001564\n",
      "Step 876 / 1000, loss = -7938.464659\n",
      "a_1 = 11.373305, a_2 = 8.238812, b = 3.075826\n",
      "\tgrad = 2.996924\n",
      "rate = 0.001562\n",
      "Step 877 / 1000, loss = -7938.500002\n",
      "a_1 = 11.376647, a_2 = 8.241163, b = 3.076603\n",
      "\tgrad = 2.665133\n",
      "rate = 0.001561\n",
      "Step 878 / 1000, loss = -7938.535504\n",
      "a_1 = 11.380114, a_2 = 8.243435, b = 3.077379\n",
      "\tgrad = 2.704882\n",
      "rate = 0.001559\n",
      "Step 879 / 1000, loss = -7938.570882\n",
      "a_1 = 11.383562, a_2 = 8.245764, b = 3.078127\n",
      "\tgrad = 2.714329\n",
      "rate = 0.001557\n",
      "Step 880 / 1000, loss = -7938.607515\n",
      "a_1 = 11.387047, a_2 = 8.248210, b = 3.078926\n",
      "\tgrad = 2.785187\n",
      "rate = 0.001556\n",
      "Step 881 / 1000, loss = -7938.643598\n",
      "a_1 = 11.390582, a_2 = 8.250537, b = 3.079710\n",
      "\tgrad = 2.769864\n",
      "rate = 0.001554\n",
      "Step 882 / 1000, loss = -7938.677243\n",
      "a_1 = 11.393801, a_2 = 8.252746, b = 3.080459\n",
      "\tgrad = 2.561335\n",
      "rate = 0.001552\n",
      "Step 883 / 1000, loss = -7938.710546\n",
      "a_1 = 11.397015, a_2 = 8.254904, b = 3.081205\n",
      "\tgrad = 2.542913\n",
      "rate = 0.001550\n",
      "Step 884 / 1000, loss = -7938.744815\n",
      "a_1 = 11.400160, a_2 = 8.257275, b = 3.081976\n",
      "\tgrad = 2.591762\n",
      "rate = 0.001549\n",
      "Step 885 / 1000, loss = -7938.781117\n",
      "a_1 = 11.403721, a_2 = 8.259623, b = 3.082770\n",
      "\tgrad = 2.804138\n",
      "rate = 0.001547\n",
      "Step 886 / 1000, loss = -7938.815863\n",
      "a_1 = 11.406937, a_2 = 8.262056, b = 3.083530\n",
      "\tgrad = 2.655833\n",
      "rate = 0.001545\n",
      "Step 887 / 1000, loss = -7938.850820\n",
      "a_1 = 11.410336, a_2 = 8.264349, b = 3.084297\n",
      "\tgrad = 2.702593\n",
      "rate = 0.001544\n",
      "Step 888 / 1000, loss = -7938.886852\n",
      "a_1 = 11.413855, a_2 = 8.266680, b = 3.085101\n",
      "\tgrad = 2.786310\n",
      "rate = 0.001542\n",
      "Step 889 / 1000, loss = -7938.921662\n",
      "a_1 = 11.417242, a_2 = 8.268972, b = 3.085864\n",
      "\tgrad = 2.701512\n",
      "rate = 0.001540\n",
      "Step 890 / 1000, loss = -7938.956535\n",
      "a_1 = 11.420598, a_2 = 8.271329, b = 3.086620\n",
      "\tgrad = 2.710753\n",
      "rate = 0.001538\n",
      "Step 891 / 1000, loss = -7938.990837\n",
      "a_1 = 11.423793, a_2 = 8.273715, b = 3.087382\n",
      "\tgrad = 2.641659\n",
      "rate = 0.001537\n",
      "Step 892 / 1000, loss = -7939.026331\n",
      "a_1 = 11.427231, a_2 = 8.276104, b = 3.088151\n",
      "\tgrad = 2.772796\n",
      "rate = 0.001535\n",
      "Step 893 / 1000, loss = -7939.061450\n",
      "a_1 = 11.430520, a_2 = 8.278543, b = 3.088930\n",
      "\tgrad = 2.718302\n",
      "rate = 0.001533\n",
      "Step 894 / 1000, loss = -7939.095966\n",
      "a_1 = 11.433946, a_2 = 8.280750, b = 3.089702\n",
      "\tgrad = 2.707727\n",
      "rate = 0.001532\n",
      "Step 895 / 1000, loss = -7939.130893\n",
      "a_1 = 11.437227, a_2 = 8.283166, b = 3.090482\n",
      "\tgrad = 2.711438\n",
      "rate = 0.001530\n",
      "Step 896 / 1000, loss = -7939.165654\n",
      "a_1 = 11.440584, a_2 = 8.285483, b = 3.091262\n",
      "\tgrad = 2.717265\n",
      "rate = 0.001528\n",
      "Step 897 / 1000, loss = -7939.200418\n",
      "a_1 = 11.443937, a_2 = 8.287833, b = 3.092030\n",
      "\tgrad = 2.728963\n",
      "rate = 0.001527\n",
      "Step 898 / 1000, loss = -7939.234984\n",
      "a_1 = 11.447300, a_2 = 8.290148, b = 3.092794\n",
      "\tgrad = 2.722978\n",
      "rate = 0.001525\n",
      "Step 899 / 1000, loss = -7939.267571\n",
      "a_1 = 11.450466, a_2 = 8.292304, b = 3.093531\n",
      "\tgrad = 2.560638\n",
      "rate = 0.001523\n",
      "Step 900 / 1000, loss = -7939.300453\n",
      "a_1 = 11.453667, a_2 = 8.294527, b = 3.094251\n",
      "\tgrad = 2.604480\n",
      "rate = 0.001522\n",
      "Step 901 / 1000, loss = -7939.333704\n",
      "a_1 = 11.456847, a_2 = 8.296785, b = 3.095003\n",
      "\tgrad = 2.612831\n",
      "rate = 0.001520\n",
      "Step 902 / 1000, loss = -7939.369638\n",
      "a_1 = 11.460305, a_2 = 8.299242, b = 3.095801\n",
      "\tgrad = 2.842601\n",
      "rate = 0.001518\n",
      "Step 903 / 1000, loss = -7939.403453\n",
      "a_1 = 11.463644, a_2 = 8.301489, b = 3.096545\n",
      "\tgrad = 2.699036\n",
      "rate = 0.001517\n",
      "Step 904 / 1000, loss = -7939.437382\n",
      "a_1 = 11.466944, a_2 = 8.303792, b = 3.097295\n",
      "\tgrad = 2.701572\n",
      "rate = 0.001515\n",
      "Step 905 / 1000, loss = -7939.470664\n",
      "a_1 = 11.470118, a_2 = 8.306096, b = 3.098041\n",
      "\tgrad = 2.637249\n",
      "rate = 0.001514\n",
      "Step 906 / 1000, loss = -7939.502489\n",
      "a_1 = 11.473166, a_2 = 8.308271, b = 3.098764\n",
      "\tgrad = 2.522856\n",
      "rate = 0.001512\n",
      "Step 907 / 1000, loss = -7939.534449\n",
      "a_1 = 11.476145, a_2 = 8.310528, b = 3.099495\n",
      "\tgrad = 2.521389\n",
      "rate = 0.001510\n",
      "Step 908 / 1000, loss = -7939.569396\n",
      "a_1 = 11.479460, a_2 = 8.313019, b = 3.100258\n",
      "\tgrad = 2.794740\n",
      "rate = 0.001509\n",
      "Step 909 / 1000, loss = -7939.603210\n",
      "a_1 = 11.482769, a_2 = 8.315308, b = 3.101012\n",
      "\tgrad = 2.716454\n",
      "rate = 0.001507\n",
      "Step 910 / 1000, loss = -7939.639016\n",
      "a_1 = 11.486426, a_2 = 8.317602, b = 3.101805\n",
      "\tgrad = 2.915633\n",
      "rate = 0.001505\n",
      "Step 911 / 1000, loss = -7939.673790\n",
      "a_1 = 11.489892, a_2 = 8.319933, b = 3.102568\n",
      "\tgrad = 2.823406\n",
      "rate = 0.001504\n",
      "Step 912 / 1000, loss = -7939.706760\n",
      "a_1 = 11.493175, a_2 = 8.322112, b = 3.103310\n",
      "\tgrad = 2.669462\n",
      "rate = 0.001502\n",
      "Step 913 / 1000, loss = -7939.742193\n",
      "a_1 = 11.496520, a_2 = 8.324643, b = 3.104102\n",
      "\tgrad = 2.844965\n",
      "rate = 0.001501\n",
      "Step 914 / 1000, loss = -7939.776802\n",
      "a_1 = 11.499868, a_2 = 8.327100, b = 3.104849\n",
      "\tgrad = 2.815043\n",
      "rate = 0.001499\n",
      "Step 915 / 1000, loss = -7939.811838\n",
      "a_1 = 11.503362, a_2 = 8.329454, b = 3.105624\n",
      "\tgrad = 2.860745\n",
      "rate = 0.001497\n",
      "Step 916 / 1000, loss = -7939.844969\n",
      "a_1 = 11.506587, a_2 = 8.331760, b = 3.106357\n",
      "\tgrad = 2.695931\n",
      "rate = 0.001496\n",
      "Step 917 / 1000, loss = -7939.876191\n",
      "a_1 = 11.509621, a_2 = 8.333899, b = 3.107070\n",
      "\tgrad = 2.529795\n",
      "rate = 0.001494\n",
      "Step 918 / 1000, loss = -7939.910505\n",
      "a_1 = 11.512892, a_2 = 8.336339, b = 3.107841\n",
      "\tgrad = 2.782280\n",
      "rate = 0.001493\n",
      "Step 919 / 1000, loss = -7939.944792\n",
      "a_1 = 11.516279, a_2 = 8.338712, b = 3.108591\n",
      "\tgrad = 2.819086\n",
      "rate = 0.001491\n",
      "Step 920 / 1000, loss = -7939.978610\n",
      "a_1 = 11.519575, a_2 = 8.341042, b = 3.109360\n",
      "\tgrad = 2.759010\n",
      "rate = 0.001489\n",
      "Step 921 / 1000, loss = -7940.009808\n",
      "a_1 = 11.522589, a_2 = 8.343203, b = 3.110078\n",
      "\tgrad = 2.538638\n",
      "rate = 0.001488\n",
      "Step 922 / 1000, loss = -7940.040804\n",
      "a_1 = 11.525565, a_2 = 8.345363, b = 3.110796\n",
      "\tgrad = 2.521094\n",
      "rate = 0.001486\n",
      "Step 923 / 1000, loss = -7940.074138\n",
      "a_1 = 11.528798, a_2 = 8.347696, b = 3.111550\n",
      "\tgrad = 2.733218\n",
      "rate = 0.001485\n",
      "Step 924 / 1000, loss = -7940.105172\n",
      "a_1 = 11.531795, a_2 = 8.349842, b = 3.112274\n",
      "\tgrad = 2.532644\n",
      "rate = 0.001483\n",
      "Step 925 / 1000, loss = -7940.138822\n",
      "a_1 = 11.535086, a_2 = 8.352211, b = 3.113021\n",
      "\tgrad = 2.783382\n",
      "rate = 0.001481\n",
      "Step 926 / 1000, loss = -7940.171083\n",
      "a_1 = 11.538223, a_2 = 8.354504, b = 3.113737\n",
      "\tgrad = 2.669614\n",
      "rate = 0.001480\n",
      "Step 927 / 1000, loss = -7940.203385\n",
      "a_1 = 11.541443, a_2 = 8.356703, b = 3.114467\n",
      "\tgrad = 2.683598\n",
      "rate = 0.001478\n",
      "Step 928 / 1000, loss = -7940.234207\n",
      "a_1 = 11.544425, a_2 = 8.358858, b = 3.115181\n",
      "\tgrad = 2.537852\n",
      "rate = 0.001477\n",
      "Step 929 / 1000, loss = -7940.264739\n",
      "a_1 = 11.547470, a_2 = 8.360908, b = 3.115889\n",
      "\tgrad = 2.534293\n",
      "rate = 0.001475\n",
      "Step 930 / 1000, loss = -7940.297060\n",
      "a_1 = 11.550662, a_2 = 8.363151, b = 3.116620\n",
      "\tgrad = 2.693226\n",
      "rate = 0.001474\n",
      "Step 931 / 1000, loss = -7940.329388\n",
      "a_1 = 11.553794, a_2 = 8.365465, b = 3.117347\n",
      "\tgrad = 2.690531\n",
      "rate = 0.001472\n",
      "Step 932 / 1000, loss = -7940.359624\n",
      "a_1 = 11.556830, a_2 = 8.367500, b = 3.118043\n",
      "\tgrad = 2.530463\n",
      "rate = 0.001471\n",
      "Step 933 / 1000, loss = -7940.390481\n",
      "a_1 = 11.559834, a_2 = 8.369675, b = 3.118751\n",
      "\tgrad = 2.570181\n",
      "rate = 0.001469\n",
      "Step 934 / 1000, loss = -7940.421942\n",
      "a_1 = 11.562876, a_2 = 8.371908, b = 3.119477\n",
      "\tgrad = 2.618429\n",
      "rate = 0.001468\n",
      "Step 935 / 1000, loss = -7940.452523\n",
      "a_1 = 11.565794, a_2 = 8.374136, b = 3.120175\n",
      "\tgrad = 2.549353\n",
      "rate = 0.001466\n",
      "Step 936 / 1000, loss = -7940.483938\n",
      "a_1 = 11.568835, a_2 = 8.376349, b = 3.120911\n",
      "\tgrad = 2.616971\n",
      "rate = 0.001464\n",
      "Step 937 / 1000, loss = -7940.514984\n",
      "a_1 = 11.571952, a_2 = 8.378498, b = 3.121608\n",
      "\tgrad = 2.631705\n",
      "rate = 0.001463\n",
      "Step 938 / 1000, loss = -7940.545397\n",
      "a_1 = 11.575066, a_2 = 8.380563, b = 3.122284\n",
      "\tgrad = 2.598066\n",
      "rate = 0.001461\n",
      "Step 939 / 1000, loss = -7940.576870\n",
      "a_1 = 11.578195, a_2 = 8.382750, b = 3.123006\n",
      "\tgrad = 2.661265\n",
      "rate = 0.001460\n",
      "Step 940 / 1000, loss = -7940.608289\n",
      "a_1 = 11.581382, a_2 = 8.384889, b = 3.123720\n",
      "\tgrad = 2.677161\n",
      "rate = 0.001458\n",
      "Step 941 / 1000, loss = -7940.639019\n",
      "a_1 = 11.584405, a_2 = 8.387053, b = 3.124430\n",
      "\tgrad = 2.597976\n",
      "rate = 0.001457\n",
      "Step 942 / 1000, loss = -7940.672894\n",
      "a_1 = 11.587743, a_2 = 8.389496, b = 3.125183\n",
      "\tgrad = 2.888947\n",
      "rate = 0.001455\n",
      "Step 943 / 1000, loss = -7940.704855\n",
      "a_1 = 11.590967, a_2 = 8.391715, b = 3.125905\n",
      "\tgrad = 2.737639\n",
      "rate = 0.001454\n",
      "Step 944 / 1000, loss = -7940.736903\n",
      "a_1 = 11.594151, a_2 = 8.394003, b = 3.126622\n",
      "\tgrad = 2.744589\n",
      "rate = 0.001452\n",
      "Step 945 / 1000, loss = -7940.768873\n",
      "a_1 = 11.597452, a_2 = 8.396167, b = 3.127340\n",
      "\tgrad = 2.765435\n",
      "rate = 0.001451\n",
      "Step 946 / 1000, loss = -7940.799706\n",
      "a_1 = 11.600602, a_2 = 8.398253, b = 3.128052\n",
      "\tgrad = 2.652484\n",
      "rate = 0.001449\n",
      "Step 947 / 1000, loss = -7940.828978\n",
      "a_1 = 11.603550, a_2 = 8.400281, b = 3.128725\n",
      "\tgrad = 2.515308\n",
      "rate = 0.001448\n",
      "Step 948 / 1000, loss = -7940.859214\n",
      "a_1 = 11.606539, a_2 = 8.402428, b = 3.129423\n",
      "\tgrad = 2.589785\n",
      "rate = 0.001446\n",
      "Step 949 / 1000, loss = -7940.891919\n",
      "a_1 = 11.609783, a_2 = 8.404765, b = 3.130169\n",
      "\tgrad = 2.814914\n",
      "rate = 0.001445\n",
      "Step 950 / 1000, loss = -7940.923463\n",
      "a_1 = 11.612913, a_2 = 8.407018, b = 3.130891\n",
      "\tgrad = 2.718112\n",
      "rate = 0.001443\n",
      "Step 951 / 1000, loss = -7940.955359\n",
      "a_1 = 11.616136, a_2 = 8.409243, b = 3.131622\n",
      "\tgrad = 2.763310\n",
      "rate = 0.001442\n",
      "Step 952 / 1000, loss = -7940.984894\n",
      "a_1 = 11.619078, a_2 = 8.411344, b = 3.132300\n",
      "\tgrad = 2.554141\n",
      "rate = 0.001440\n",
      "Step 953 / 1000, loss = -7941.014446\n",
      "a_1 = 11.622038, a_2 = 8.413438, b = 3.132978\n",
      "\tgrad = 2.563675\n",
      "rate = 0.001439\n",
      "Step 954 / 1000, loss = -7941.045204\n",
      "a_1 = 11.625085, a_2 = 8.415627, b = 3.133696\n",
      "\tgrad = 2.657564\n",
      "rate = 0.001437\n",
      "Step 955 / 1000, loss = -7941.076347\n",
      "a_1 = 11.628255, a_2 = 8.417782, b = 3.134417\n",
      "\tgrad = 2.716261\n",
      "rate = 0.001436\n",
      "Step 956 / 1000, loss = -7941.105684\n",
      "a_1 = 11.631134, a_2 = 8.419898, b = 3.135106\n",
      "\tgrad = 2.536678\n",
      "rate = 0.001434\n",
      "Step 957 / 1000, loss = -7941.135448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1 = 11.634033, a_2 = 8.422115, b = 3.135782\n",
      "\tgrad = 2.590112\n",
      "rate = 0.001433\n",
      "Step 958 / 1000, loss = -7941.165903\n",
      "a_1 = 11.637162, a_2 = 8.424213, b = 3.136485\n",
      "\tgrad = 2.676931\n",
      "rate = 0.001431\n",
      "Step 959 / 1000, loss = -7941.196984\n",
      "a_1 = 11.640286, a_2 = 8.426434, b = 3.137197\n",
      "\tgrad = 2.726456\n",
      "rate = 0.001430\n",
      "Step 960 / 1000, loss = -7941.227240\n",
      "a_1 = 11.643303, a_2 = 8.428622, b = 3.137891\n",
      "\tgrad = 2.653390\n",
      "rate = 0.001429\n",
      "Step 961 / 1000, loss = -7941.256956\n",
      "a_1 = 11.646245, a_2 = 8.430764, b = 3.138588\n",
      "\tgrad = 2.596833\n",
      "rate = 0.001427\n",
      "Step 962 / 1000, loss = -7941.285596\n",
      "a_1 = 11.649174, a_2 = 8.432728, b = 3.139268\n",
      "\tgrad = 2.518954\n",
      "rate = 0.001426\n",
      "Step 963 / 1000, loss = -7941.317017\n",
      "a_1 = 11.652390, a_2 = 8.434896, b = 3.140008\n",
      "\tgrad = 2.772425\n",
      "rate = 0.001424\n",
      "Step 964 / 1000, loss = -7941.346704\n",
      "a_1 = 11.655476, a_2 = 8.436914, b = 3.140703\n",
      "\tgrad = 2.637504\n",
      "rate = 0.001423\n",
      "Step 965 / 1000, loss = -7941.376332\n",
      "a_1 = 11.658500, a_2 = 8.439022, b = 3.141378\n",
      "\tgrad = 2.636701\n",
      "rate = 0.001421\n",
      "Step 966 / 1000, loss = -7941.407915\n",
      "a_1 = 11.661810, a_2 = 8.441187, b = 3.142101\n",
      "\tgrad = 2.831326\n",
      "rate = 0.001420\n",
      "Step 967 / 1000, loss = -7941.437735\n",
      "a_1 = 11.664835, a_2 = 8.443301, b = 3.142797\n",
      "\tgrad = 2.647639\n",
      "rate = 0.001418\n",
      "Step 968 / 1000, loss = -7941.468683\n",
      "a_1 = 11.667988, a_2 = 8.445467, b = 3.143530\n",
      "\tgrad = 2.748534\n",
      "rate = 0.001417\n",
      "Step 969 / 1000, loss = -7941.499277\n",
      "a_1 = 11.671109, a_2 = 8.447636, b = 3.144240\n",
      "\tgrad = 2.731745\n",
      "rate = 0.001416\n",
      "Step 970 / 1000, loss = -7941.530031\n",
      "a_1 = 11.674245, a_2 = 8.449838, b = 3.144947\n",
      "\tgrad = 2.755322\n",
      "rate = 0.001414\n",
      "Step 971 / 1000, loss = -7941.561064\n",
      "a_1 = 11.677466, a_2 = 8.452009, b = 3.145662\n",
      "\tgrad = 2.795544\n",
      "rate = 0.001413\n",
      "Step 972 / 1000, loss = -7941.589575\n",
      "a_1 = 11.680346, a_2 = 8.454074, b = 3.146323\n",
      "\tgrad = 2.554524\n",
      "rate = 0.001411\n",
      "Step 973 / 1000, loss = -7941.620192\n",
      "a_1 = 11.683466, a_2 = 8.456265, b = 3.147035\n",
      "\tgrad = 2.751068\n",
      "rate = 0.001410\n",
      "Step 974 / 1000, loss = -7941.650118\n",
      "a_1 = 11.686482, a_2 = 8.458441, b = 3.147732\n",
      "\tgrad = 2.686176\n",
      "rate = 0.001408\n",
      "Step 975 / 1000, loss = -7941.679539\n",
      "a_1 = 11.689488, a_2 = 8.460534, b = 3.148423\n",
      "\tgrad = 2.649481\n",
      "rate = 0.001407\n",
      "Step 976 / 1000, loss = -7941.706839\n",
      "a_1 = 11.692252, a_2 = 8.462476, b = 3.149078\n",
      "\tgrad = 2.448022\n",
      "rate = 0.001406\n",
      "Step 977 / 1000, loss = -7941.734474\n",
      "a_1 = 11.695075, a_2 = 8.464434, b = 3.149735\n",
      "\tgrad = 2.490987\n",
      "rate = 0.001404\n",
      "Step 978 / 1000, loss = -7941.762321\n",
      "a_1 = 11.697903, a_2 = 8.466453, b = 3.150384\n",
      "\tgrad = 2.519577\n",
      "rate = 0.001403\n",
      "Step 979 / 1000, loss = -7941.792196\n",
      "a_1 = 11.701009, a_2 = 8.468564, b = 3.151077\n",
      "\tgrad = 2.725237\n",
      "rate = 0.001401\n",
      "Step 980 / 1000, loss = -7941.822381\n",
      "a_1 = 11.704164, a_2 = 8.470640, b = 3.151799\n",
      "\tgrad = 2.746280\n",
      "rate = 0.001400\n",
      "Step 981 / 1000, loss = -7941.851926\n",
      "a_1 = 11.707199, a_2 = 8.472756, b = 3.152491\n",
      "\tgrad = 2.691227\n",
      "rate = 0.001399\n",
      "Step 982 / 1000, loss = -7941.880026\n",
      "a_1 = 11.710053, a_2 = 8.474807, b = 3.153148\n",
      "\tgrad = 2.558881\n",
      "rate = 0.001397\n",
      "Step 983 / 1000, loss = -7941.909636\n",
      "a_1 = 11.713026, a_2 = 8.477018, b = 3.153833\n",
      "\tgrad = 2.699697\n",
      "rate = 0.001396\n",
      "Step 984 / 1000, loss = -7941.938685\n",
      "a_1 = 11.716010, a_2 = 8.479101, b = 3.154519\n",
      "\tgrad = 2.655569\n",
      "rate = 0.001394\n",
      "Step 985 / 1000, loss = -7941.967232\n",
      "a_1 = 11.718904, a_2 = 8.481182, b = 3.155196\n",
      "\tgrad = 2.604567\n",
      "rate = 0.001393\n",
      "Step 986 / 1000, loss = -7941.996750\n",
      "a_1 = 11.721897, a_2 = 8.483369, b = 3.155881\n",
      "\tgrad = 2.708830\n",
      "rate = 0.001392\n",
      "Step 987 / 1000, loss = -7942.025849\n",
      "a_1 = 11.724939, a_2 = 8.485408, b = 3.156573\n",
      "\tgrad = 2.680893\n",
      "rate = 0.001390\n",
      "Step 988 / 1000, loss = -7942.056097\n",
      "a_1 = 11.728095, a_2 = 8.487573, b = 3.157276\n",
      "\tgrad = 2.801285\n",
      "rate = 0.001389\n",
      "Step 989 / 1000, loss = -7942.084473\n",
      "a_1 = 11.731064, a_2 = 8.489555, b = 3.157957\n",
      "\tgrad = 2.619345\n",
      "rate = 0.001388\n",
      "Step 990 / 1000, loss = -7942.113647\n",
      "a_1 = 11.734134, a_2 = 8.491585, b = 3.158656\n",
      "\tgrad = 2.702323\n",
      "rate = 0.001386\n",
      "Step 991 / 1000, loss = -7942.143741\n",
      "a_1 = 11.737125, a_2 = 8.493855, b = 3.159373\n",
      "\tgrad = 2.760733\n",
      "rate = 0.001385\n",
      "Step 992 / 1000, loss = -7942.172152\n",
      "a_1 = 11.740155, a_2 = 8.495830, b = 3.160040\n",
      "\tgrad = 2.658426\n",
      "rate = 0.001383\n",
      "Step 993 / 1000, loss = -7942.200408\n",
      "a_1 = 11.743096, a_2 = 8.497865, b = 3.160704\n",
      "\tgrad = 2.632502\n",
      "rate = 0.001382\n",
      "Step 994 / 1000, loss = -7942.229767\n",
      "a_1 = 11.746024, a_2 = 8.500109, b = 3.161391\n",
      "\tgrad = 2.717668\n",
      "rate = 0.001381\n",
      "Step 995 / 1000, loss = -7942.258076\n",
      "a_1 = 11.748959, a_2 = 8.502143, b = 3.162068\n",
      "\tgrad = 2.634863\n",
      "rate = 0.001379\n",
      "Step 996 / 1000, loss = -7942.286571\n",
      "a_1 = 11.751942, a_2 = 8.504205, b = 3.162731\n",
      "\tgrad = 2.675638\n",
      "rate = 0.001378\n",
      "Step 997 / 1000, loss = -7942.317160\n",
      "a_1 = 11.755086, a_2 = 8.506473, b = 3.163446\n",
      "\tgrad = 2.863304\n",
      "rate = 0.001377\n",
      "Step 998 / 1000, loss = -7942.344817\n",
      "a_1 = 11.757991, a_2 = 8.508448, b = 3.164102\n",
      "\tgrad = 2.598753\n",
      "rate = 0.001375\n",
      "Step 999 / 1000, loss = -7942.374493\n",
      "a_1 = 11.761019, a_2 = 8.510643, b = 3.164812\n",
      "\tgrad = 2.770631\n",
      "rate = 0.001374\n",
      "Step 1000 / 1000, loss = -7942.403514\n",
      "a_1 = 11.763977, a_2 = 8.512834, b = 3.165489\n",
      "\tgrad = 2.726479\n",
      "rate = 0.001373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "print (generic function with 46 methods)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf = readtable(\"data.csv\")\n",
    "x,y = convertdata_to_array(dtf)\n",
    "nb_steps = 1000\n",
    "\n",
    "params = NNparams(init_params(x))\n",
    "param_history_a1 = Float64[]\n",
    "param_history_a2 = Float64[]\n",
    "param_history_a3 = Float64[]\n",
    "loss_history = Float64[]\n",
    "output_history = Float64[]\n",
    "grad_history = Float64[]\n",
    "learning_rate_history = Float64[]\n",
    "y_pred_a = Float64[] \n",
    "y_training_a =[]\n",
    "\n",
    "for s = 1:nb_steps  \n",
    "    x_training,y_training = select_trainingdata(x,y,1000)\n",
    "    grad = ∇(x_training, y_training, params)\n",
    "    learning_rate = update_learning_rate(.07,s)\n",
    "    params = updateNNparams(grad,params,learning_rate)\n",
    "    result = output(params, x_training[s,:])\n",
    "    loss_at_this_step = loss(params,y,x)\n",
    "    @printf(\"Step %d / %d, loss = %f\\n\", s, nb_steps, loss_at_this_step)\n",
    "    @printf(\"a_1 = %f, a_2 = %f, b = %f\\n\", params.a[1],params.a[2],\n",
    "        params.a[3])\n",
    "    @printf(\"\\tgrad = %f\\n\", norm(grad))\n",
    "    @printf(\"rate = %f\\n\",learning_rate)\n",
    "    y_pred = output(params, x_training[s,:])\n",
    "    #push!(param_history,params)\n",
    "    push!(param_history_a1, params.a[1])\n",
    "    push!(param_history_a2, params.a[2])\n",
    "    push!(param_history_a3, params.a[3])\n",
    "    push!(y_pred_a,y_pred)\n",
    "    push!(loss_history, loss_at_this_step)\n",
    "    push!(output_history,result)\n",
    "    push!(y_training_a,y_training)\n",
    "   \n",
    "end\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" />"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [i for i= 1:nb_steps] ; y = loss_history\n",
    "plot(x,y)\n",
    "title!(\"Steps vs Loss History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" />"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = param_history_a1;\n",
    "y = param_history_a2\n",
    "plot(x,y)\n",
    "title!(\"A1 vs A2 params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" />"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Histogram of Final Output\n",
    "histogram(y_pred_a, bins= 50)\n",
    "title!(\"Histogram\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_training_a.==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Any,1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(y_training_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
